[{"title":"attentionä¸­å¼ é‡å¹¶è¡Œä¸GQA","url":"/2025/08/17/distribute/attention/","content":"\n\n\nä¾‹å­é…ç½®ï¼ˆè´¯ç©¿å…¨æ–‡ï¼‰ï¼š hidden_size=4096, num_attention_heads=32, tensor_parallel_size=4, num_query_groups=8ï¼ˆGQAï¼‰, kv_channels=hidden/heads=128ã€‚ è¾“å…¥å½¢çŠ¶ç”¨ [B, S, H] è®°ï¼ˆæ‰¹ã€åºåˆ—ã€éšè—ï¼‰ã€‚\n\n\n1. åè¯ä¸æ´¾ç”Ÿå˜é‡ï¼ˆå…ˆæŠŠé‡ç®—æ¸…æ¥šï¼‰\n\nå•å¤´ç»´åº¦ï¼ˆä¹Ÿæ˜¯ç¼©æ”¾ç”¨çš„ \\(d_k\\)ï¼‰ï¼škv_channels = 4096 / 32 = 128\nQ æŠ•å½±æ€»ç»´ï¼šquery_projection_size = kv_channels * num_attention_heads = 128*32 = 4096\nK/V æŠ•å½±æ€»ç»´ï¼ˆGQAï¼‰ï¼škv_projection_size = kv_channels * num_query_groups = 128*8 = 1024\næ¯å¡ Q å¤´æ•°ï¼šnum_attention_heads_per_partition = 32 / TP = 8\næ¯å¡ KV ç»„æ•°ï¼šnum_query_groups_per_partition = 8 / TP = 2\næ¯å¡æŠ•å½±ç»´ï¼ˆåˆ—å¹¶è¡Œåæœ¬åœ°è¾“å‡ºç»´ï¼‰ï¼šhidden_size_per_partition = 4096 / TP = 1024\n\n\nGQA çš„å«ä¹‰ï¼šå½“ num_key_value_heads (=num_query_groups) å°äº num_attention_heads æ—¶ï¼Œä¸ºè¾ƒå°‘çš„ KV å¤´/ç»„ äº§å‡º K/Vï¼Œè®©å¤šä¸ª Q å¤´å…±äº«å®ƒä»¬ï¼›=heads é€€åŒ–ä¸º MHAï¼Œ=1 æ˜¯ MQAã€‚è¿™ä¸€ç‚¹åœ¨ HF æ¨¡å‹æ–‡æ¡£ä¸­æ˜¯æ˜ç¡®çš„å®šä¹‰ã€‚(Hugging Face)\n\n\n2. ç«¯åˆ°ç«¯è®¡ç®—ä¸å½¢çŠ¶æµï¼ˆä»¥å•å±‚è‡ªæ³¨æ„åŠ›ä¸ºä¾‹ï¼‰\nMegatron ç»å…¸åšæ³•ï¼šQ/K/V çš„çº¿æ€§å±‚ç”¨åˆ—å¹¶è¡Œï¼ˆColumn-Parallelï¼‰ï¼ŒæŒ‰è¾“å‡ºåˆ—åˆ‡ç»™å„å¡ï¼›è¾“å‡ºæŠ•å½±ç”¨è¡Œå¹¶è¡Œï¼ˆRow-Parallelï¼‰ï¼ŒæŒ‰è¾“å…¥è¡Œåˆ‡ç»™å„å¡ï¼Œå‰å‘åªåœ¨è¾“å‡ºæŠ•å½±åšä¸€æ¬¡ all-reduceã€‚è¿™æ˜¯ Megatron-LM è®ºæ–‡ä¸ Megatron-Core æ–‡æ¡£æ¨èçš„å¼ é‡å¹¶è¡Œåˆ‡æ³•ã€‚(arXiv, NVIDIA Docs)\n2.1 çº¿æ€§æŠ•å½±ï¼ˆåˆ—å¹¶è¡Œï¼‰\n\nQ æŠ•å½±ï¼ˆå…¨å±€æƒé‡ [4096,4096] â†’ æ¯å¡ [4096,1024]ï¼‰ï¼š æœ¬å¡è¾“å‡º Q_local: [B,S,1024] â†’ reshape ä¸º [B, 8, S, 128]ï¼ˆæœ¬å¡ 8 ä¸ª Q å¤´ï¼‰ã€‚\nK æŠ•å½±ï¼ˆå…¨å±€æƒé‡ [4096,1024] â†’ æ¯å¡ [4096,256]ï¼‰ï¼š K_local: [B,S,256] â†’ reshape ä¸º [B, 2, S, 128]ï¼ˆæœ¬å¡ 2 ä¸ª KV ç»„ï¼‰ã€‚\nV æŠ•å½± åŒ Kã€‚\n\n\nä¸ºä»€ä¹ˆå¿…é¡» reshape å‡º head ç»´ï¼Ÿ å¤šå¤´æ³¨æ„åŠ›çš„è¯­ä¹‰æ˜¯â€œå¤´å†…ç‹¬ç«‹â€çš„ç‚¹ç§¯æ³¨æ„åŠ›ï¼Œå†…æ ¸ï¼ˆSDPA/FlashAttentionï¼‰ä¸å¹¿æ’­ï¼ˆmaskã€RoPEã€repeat_kvï¼‰éƒ½è¦æ±‚æ˜¾å¼çš„ head ç»´ [B,H,S,D] æˆ–å±•å¹³ä¸º [BÂ·H,S,D]ã€‚ä¸æ‹†å¤´ä¼šæŠŠä¸åŒ head çš„å­ç©ºé—´æ··åœ¨ä¸€èµ·ï¼Œä¹Ÿæ— æ³•è‡ªç„¶æ‰§è¡Œ GQA çš„ repeat_kvã€‚(PyTorch)\n\n2.2 GQA çš„ K/V å¯¹é½ï¼ˆrepeat/expandï¼‰\næœ¬å¡åªæœ‰ 2 ä¸ª KV ç»„ï¼Œä½†è¦æœåŠ¡ 8 ä¸ª Q å¤´ â‡’ åœ¨å¤´ç»´åšé€»è¾‘é‡å¤/å¹¿æ’­ï¼š [B, 2, S, 128] â†’ [B, 8, S, 128]ï¼ˆæ¯ä¸ª KV ç»„æœåŠ¡ 4 ä¸ª Q å¤´ï¼‰ã€‚ä¸»æµå®ç°ç›´æ¥åœ¨ head ç»´åš repeat_kvã€‚(Hugging Face)\n2.3 Scaled Dot-Product Attentionï¼ˆæ¯å¡åªç®—è‡ªå·±çš„ 8 ä¸ªå¤´ï¼‰\n\nscores = (Q @ K^T) / sqrt(128) â†’ softmax(scores) @ V\nå¾—åˆ°ä¸Šä¸‹æ–‡ ctx_local: [B, 8, S, 128] â†’ æ‹¼æ¥ä¸º [B,S,1024]\nè¿™ä¸€æ­¥å¯ä»¥ç”± PyTorch SDPA æˆ–é—ªå­˜æ³¨æ„åŠ›å†…æ ¸é«˜æ•ˆå®Œæˆã€‚(PyTorch)\n\n2.4 è¾“å‡ºæŠ•å½±ï¼ˆè¡Œå¹¶è¡Œ + 1 æ¬¡ all-reduceï¼‰\n\næ¯å¡æŠŠ [B,S,1024] ä¹˜ä»¥æœ¬å¡çš„è¾“å‡ºæƒé‡åˆ†ç‰‡ï¼Œå¾—åˆ° Y_local: [B,S,4096] çš„éƒ¨åˆ†å’Œï¼›\nè·¨å¡åš all-reduce(sum) å¾—åˆ°æœ€ç»ˆ Y: [B,S,4096]ã€‚ Megatron è®ºæ–‡æŒ‡å‡ºï¼šè‡ªæ³¨æ„åŠ›æœ¬ä½“ä¸éœ€é€šä¿¡ï¼Œåªåœ¨è¾“å‡ºæŠ•å½±å¤„åšä¸€æ¬¡è§„çº¦å³å¯ã€‚(arXiv)\n\n\n3. åˆ—å¹¶è¡Œ / è¡Œå¹¶è¡Œçš„æ•°å­¦ç­‰ä»·ï¼ˆä¸ºä½•â€œåˆ‡äº†å†æ‹¼/æ±‚å’Œâ€ä»ç­‰ä»·å•å¡ï¼‰\næŠŠ [B,S,Â·] å±•å¹³ä¸ºçŸ©é˜µ \\(X\\in\\mathbb{R}^{N\\times(HD)}\\)ï¼ˆ\\(N=B\\cdot S\\)ï¼‰ï¼Œè¾“å‡ºéšè—è®°ä¸º \\(H\\)ã€‚\n3.1 åˆ—å¹¶è¡Œï¼ˆColumn-Parallel Linearï¼‰â‰¡ æ‹¼æ¥\nè®¾ Q çš„å…¨é‡æƒé‡ \\(W_Q\\in\\mathbb{R}^{(HD)\\times(HD)}\\)ï¼Œæ²¿åˆ—åˆ‡æˆ \\(p\\) å—ï¼š\n\\[\nW_Q=\\big[W_Q^{(0)}\\;\\;W_Q^{(1)}\\;\\;\\cdots\\;\\;W_Q^{(p-1)}\\big],\n\\quad W_Q^{(i)}\\in\\mathbb{R}^{(HD)\\times(H/p\\cdot D)}.\n\\]\nåˆ™\n\\[\nQ=XW_Q=\\big[XW_Q^{(0)}\\;\\;XW_Q^{(1)}\\;\\;\\cdots\\;\\;XW_Q^{(p-1)}\\big]\n      =\\operatorname{Concat}(Q^{(0)},\\dots,Q^{(p-1)}).\n\\]\næ¯å¡ç‹¬ç«‹è®¡ç®—è‡ªå·±çš„ \\(Q^{(i)}\\)ï¼Œæ— é¡»é€šä¿¡ã€‚K/V åŒç†ã€‚è¿™å°±æ˜¯ Column-Parallel çš„ç²¾ç¡®å®šä¹‰ã€‚(arXiv, NVIDIA Docs)\n3.2 æ¯å¤´ç‹¬ç«‹ â‡’ æŒ‰å¤´åˆ‡ç»™å„å¡ä»ç„¶æ­£ç¡®\nå•å¤´/å•ç»„æ³¨æ„åŠ›ï¼š\n\\[\nY_h=\\operatorname{softmax}\\!\\Big(\\tfrac{Q_hK_{g(h)}^\\top}{\\sqrt{D}}\\Big)V_{g(h)}.\n\\]\nGQA ä¸‹ \\(g(h)\\) æŠŠå¤šä¸ª Q å¤´æ˜ å°„åˆ°åŒä¸€ KV ç»„ï¼›ç”±äºå¤´é—´äº’ä¸ç›¸å¹²ï¼ŒæŠŠ 32 ä¸ªå¤´å¹³å‡åˆ†æˆ 4 ä»½åˆ° 4 å¼ å¡ï¼Œå„å¡åªä¾èµ–è‡ªå·±çš„ KV ç»„ï¼Œå°±ä¸å•å¡ä¸€è‡´ã€‚repeat_kv æ­£æ˜¯æ²¿ head ç»´æŠŠ KV å¯¹é½åˆ° Q å¤´æ•°ã€‚(Hugging Face)\n3.3 è¡Œå¹¶è¡Œï¼ˆRow-Parallel Linearï¼‰â‰¡ æ±‚å’Œï¼ˆall-reduceï¼‰\næŠŠæ³¨æ„åŠ›è¾“å‡ºçš„æ‹¼æ¥å¼ é‡ \\(C\\in\\mathbb{R}^{N\\times(HD)}\\) æŒ‰åˆ—ï¼ˆç‰¹å¾ï¼‰åˆ‡å—ï¼š\n\\[\nC=\\big[C^{(0)}\\;\\;C^{(1)}\\;\\;\\cdots\\;\\;C^{(p-1)}\\big],\\quad\nC^{(i)}\\in\\mathbb{R}^{N\\times(H/p\\cdot D)}.\n\\]\nè¾“å‡ºæƒé‡ \\(W_O\\in\\mathbb{R}^{(HD)\\times H}\\) æŒ‰è¡Œåˆ‡å—ï¼š\n\\[\nW_O=\\begin{bmatrix}\nW_O^{(0)}\\\\ W_O^{(1)}\\\\ \\vdots\\\\ W_O^{(p-1)}\n\\end{bmatrix},\n\\quad W_O^{(i)}\\in\\mathbb{R}^{(H/p\\cdot D)\\times H}.\n\\]\nå—ä¹˜æ³•æ’ç­‰å¼ï¼š\n\\[\nC\\,W_O=\\sum_{i=0}^{p-1} C^{(i)}W_O^{(i)}.\n\\]\nå› æ­¤å„å¡è®¡ç®— \\(Y^{(i)}=C^{(i)}W_O^{(i)}\\)ï¼Œå† all-reduce(sum)ï¼Œå°±å¾—åˆ°ä¸å•å¡å®Œå…¨ç›¸åŒçš„ \\(Y\\)ã€‚è¿™æ­£æ˜¯ Row-Parallel çš„æœ¬è´¨ã€‚(arXiv)\n\n4. ä¸ºä»€ä¹ˆ GQA ä¼šè®© kv_projection_size å˜å°ã€KV cache å˜çœï¼Ÿ\n\nK/V çº¿æ€§å±‚åªä¸º num_query_groups äº§å‡ºé€šé“ï¼šä» 4096ï¼ˆ=32Ã—128ï¼‰é™ä¸º 1024ï¼ˆ=8Ã—128ï¼‰ï¼ŒK/V æŠ•å½±çš„ å‚æ•°é‡ä¸ FLOPs çº¦ä¸ºåŸæ¥çš„ 1/4ï¼›\næ¨ç†é˜¶æ®µçš„ KV cache ä»¥ã€ŒKV å¤´ Ã— åºåˆ— Ã— å¤´ç»´ã€è®¡é‡ï¼ŒKV å¤´ä» 32 å˜ 8ï¼Œç¼“å­˜ä¸ç›¸å…³å¸¦å®½å‡ç›¸åº”ä¸‹é™ã€‚HF æ–‡æ¡£æ˜ç¡®ä»¥ num_key_value_heads æè¿°è¯¥è¡Œä¸ºã€‚(Hugging Face)\n\n\n5. å½¢çŠ¶é€ŸæŸ¥ï¼ˆä»¥æœ¬ä¾‹ä¸ºå‡†ï¼‰\n\n\n\nå¼ é‡/æ­¥éª¤\nå…¨å±€ï¼ˆä¸åˆ†ç‰‡ï¼‰\næ¯å¡ï¼ˆTP=4ï¼‰\nè¯´æ˜\n\n\n\n\nQ çº¿æ€§è¾“å‡ºç»´\n4096\n1024\nColumn-Parallelï¼Œæ— é€šä¿¡\n\n\nK çº¿æ€§è¾“å‡ºç»´\n1024\n256\nGQAï¼šåªå‡º 8 ä¸ª KV ç»„\n\n\nV çº¿æ€§è¾“å‡ºç»´\n1024\n256\nåŒä¸Š\n\n\nQ å¤´æ•°\n32\n8\næœ¬å¡åªç®—è‡ªå·± 8 ä¸ªå¤´\n\n\nKV ç»„æ•°\n8\n2\næ¯ç»„æœåŠ¡ 4 ä¸ª Q å¤´\n\n\nå¤´ç»´ \\(D\\)\n128\n128\nç”¨äº \\(1/\\sqrt{D}\\)\n\n\næœ¬å¡æ³¨æ„åŠ›è¾“å‡ºï¼ˆæ‹¼å¤´åï¼‰\nâ€“\n[B,S,1024]\nè¿›å…¥è¾“å‡ºæŠ•å½±\n\n\næœ€ç»ˆè¾“å‡ºï¼ˆall-reduce åï¼‰\n[B,S,4096]\n[B,S,4096]\nRow-Parallel + sum\n\n\n\nï¼ˆè‹¥å¯ç”¨ Sequence Parallelï¼Œåªä¼šæ²¿ S å†åˆ‡ä¸€ç»´ï¼Œä¸å½±å“ä¸Šè¿°å¤´/é€šé“ç»´é€»è¾‘ã€‚åˆ—/è¡Œå¹¶è¡Œä¸ä¸€æ¬¡é€šä¿¡çš„ç»“æ„æ˜¯ Megatron-LM çš„â€œç»å…¸æ‹†åˆ†â€ã€‚ï¼‰(awsdocs-neuron.readthedocs-hosted.com, Better Tomorrow with Computer Science)\n\n6. Mermaidï¼šä¸€å¼ â€œç»´åº¦/å¹¶è¡Œæ–¹å¼â€å°å›¾\n%%&#123;init: &#123; &quot;flowchart&quot;: &#123; &quot;htmlLabels&quot;: true, &quot;wrap&quot;: true &#125; &#125;&#125;%%flowchart TB  X[&quot;Input X: [B,S,4096]&quot;] --&gt; QKV[&quot;Column-Parallel Q/K/V&lt;br/&gt;Q:[B,S,1024]  K/V:[B,S,256]&quot;]  QKV --&gt; Reshape[&quot;Reshape by heads&lt;br/&gt;Q:[B,8,S,128]&lt;br/&gt;K/V:[B,2,S,128]&quot;]  Reshape --&gt; RepeatKV[&quot;repeat_kv on head dim&lt;br/&gt;K/V:[B,8,S,128]&quot;]  RepeatKV --&gt; SDPA[&quot;SDPA per head&lt;br/&gt;ctx_local:[B,8,S,128]&lt;br/&gt;concat-&gt;[B,S,1024]&quot;]  SDPA --&gt; OutProj[&quot;Row-Parallel OutProj&lt;br/&gt;Y_local:[B,S,4096]&quot;]  OutProj --&gt; AllReduce[&quot;all-reduce(sum)&quot;]  AllReduce --&gt; Y[&quot;Final Y: [B,S,4096]&quot;]\n\n7. æç®€ä¼ªç ï¼ˆPyTorch é£æ ¼ï¼‰\n# åˆ—å¹¶è¡Œçš„çº¿æ€§ï¼šæ¯å¡æ‹¿åˆ° Q/K/V çš„ä¸€æ®µè¾“å‡ºåˆ—Q_local = linear_col_parallel_Q(X)   # [B,S,1024] -&gt; view [B,8,S,128]K_local = linear_col_parallel_K(X)   # [B,S,256]  -&gt; view [B,2,S,128]V_local = linear_col_parallel_V(X)   # [B,S,256]  -&gt; view [B,2,S,128]Q = Q_local.view(B, S, 8, 128).transpose(1, 2)  # [B,8,S,128]K = K_local.view(B, S, 2, 128).transpose(1, 2)  # [B,2,S,128]V = V_local.view(B, S, 2, 128).transpose(1, 2)  # [B,2,S,128]# GQA: è®© 2 ä¸ª KV ç»„åŒ¹é… 8 ä¸ª Q å¤´ï¼ˆé€»è¾‘ repeat/expandï¼‰K = repeat_kv(K, n_rep=4)   # [B,8,S,128]V = repeat_kv(V, n_rep=4)   # [B,8,S,128]# SDPAï¼ˆæ¯å¡åªç®—è‡ªå·±çš„ 8 ä¸ªå¤´ï¼‰ctx = torch.nn.functional.scaled_dot_product_attention(Q, K, V)  # [B,8,S,128]ctx = ctx.transpose(1, 2).reshape(B, S, 1024)                    # [B,S,1024]# è¡Œå¹¶è¡Œè¾“å‡º + ä¸€æ¬¡ all-reduce(sum)Y_local = linear_row_parallel_out(ctx)   # partial: [B,S,4096]Y = all_reduce_sum(Y_local)              # final:   [B,S,4096]\n\nSDPA çš„æ¥å£ä¸è¯­ä¹‰è§ PyTorch æ–‡æ¡£ï¼›repeat_kv çš„è¯­ä¹‰ä¸ GQA çš„é…ç½®åœ¨ HF æ–‡æ¡£/å®ç°ä¸­æœ‰æ˜ç¡®å®šä¹‰ã€‚(PyTorch, Hugging Face)\n\n\n8. æ­£ç¡®æ€§ Checklistï¼ˆå®è·µä¸­æœ€å¸¸è§çš„å‘ï¼‰\n\næ•´é™¤å…³ç³»ï¼š num_attention_heads % TP == 0ï¼Œnum_query_groups % TP == 0ï¼Œä¸” num_attention_heads % num_query_groups == 0ï¼ˆGQAï¼‰ã€‚(Hugging Face)\næ˜¾å¼ head ç»´ï¼šå½¢çŠ¶åº”ä¸º [B,H,S,D] æˆ–å±•å¹³ä¸º [BÂ·H,S,D]ï¼Œä»¥å¥‘åˆ SDPA/FlashAttention ä¸ repeat_kvã€‚(PyTorch)\né€šä¿¡ä½ç½®ï¼šè‡ªæ³¨æ„åŠ›æœ¬ä½“æ— è·¨å¡é€šä¿¡ï¼›ä»…è¾“å‡ºæŠ•å½±éœ€è¦ä¸€æ¬¡ all-reduceã€‚(arXiv)\n\n\nå‚è€ƒä¸å»¶ä¼¸é˜…è¯»\n\nMegatron-LM è®ºæ–‡ï¼šæå‡ºå±‚å†…ï¼ˆå¼ é‡ï¼‰å¹¶è¡Œï¼Œæ³¨æ„åŠ›ç”¨åˆ—å¹¶è¡Œï¼Œè¾“å‡ºç”¨è¡Œå¹¶è¡Œï¼Œå‰å‘ä»…ä¸€å¤„é€šä¿¡ã€‚(arXiv, ar5iv)\nMegatron-Core æ–‡æ¡£ï¼šTensor Parallel API/ç”¨æˆ·æŒ‡å—ï¼ˆNVIDIA å®˜æ–¹ï¼‰ã€‚(NVIDIA Docs)\nPyTorch SDPA æ–‡æ¡£/æ•™ç¨‹ï¼šå®˜æ–¹çš„ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›æ¥å£ä¸é«˜æ€§èƒ½å®ç°ã€‚(PyTorch, PyTorch Docs)\nHF æ–‡æ¡£ï¼ˆLlama/Qwen ç³»åˆ—ï¼‰ï¼šnum_key_value_heads çš„å®šä¹‰ã€GQA/MQA/MHA çš„å…³ç³»ï¼›å®ç°é‡Œ repeat_kv çš„ç”¨æ³•ã€‚(Hugging Face)\nåˆ—å¹¶è¡Œ/è¡Œå¹¶è¡Œå¯è§†åŒ–è®²è§£ï¼šå¯¹ ColumnParallelLinear / RowParallelLinear çš„ç›´è§‚å›¾è§£ã€‚(awsdocs-neuron.readthedocs-hosted.com, Better Tomorrow with Computer Science)\n\n\n","categories":["åˆ†å¸ƒå¼åŸºç¡€"],"tags":["attention"]},{"title":"pytorch devicemesh","url":"/2025/06/14/distribute/device_mesh/","content":"\n\nä¸€ã€ä¸ºä½•ä½¿ç”¨ DeviceMeshï¼Ÿ\nåœ¨æ··åˆå¹¶è¡Œï¼ˆDP/TP/PP/HSDP/â€¦ï¼‰ä¸­ï¼Œéœ€è¦ç®¡ç†å¤šä¸ªå­é€šä¿¡ç»„ï¼ˆProcessGroupï¼‰ï¼Œå¯¹åº”å¤æ‚çš„è®¾å¤‡æ‹“æ‰‘ç»“æ„ã€‚DeviceMesh æä¾›äº†ï¼š\n\nç†è®ºä¸Šæ— ç¼æ”¯æŒä»»æ„ç»´åº¦çš„å¤šç»´æ‹“æ‰‘ï¼›\nè‡ªåŠ¨æ‹†åˆ†è¿›ç¨‹ç»„(new_group/split_group)ï¼›\nçµæ´»åˆ‡ç‰‡å­ Meshï¼›\nç»å†è®¾è®¡å‘¨å…¨çš„é«˜æ•ˆåˆå§‹åŒ–æ–¹æ¡ˆ (docs.pytorch.org, pytorch.org)ã€‚\n\n\näºŒã€åˆå§‹åŒ–æµç¨‹\ninit_device_mesh(...) çš„ä½œç”¨\nä¸€ä¸ªä¸€è¡Œæå®šçš„æ–¹æ³•ï¼Œå®ƒä¼šï¼š\n\nåˆå§‹åŒ–å…¨å±€ init_process_group(...)ï¼ˆè‹¥æœªåˆå§‹åŒ–ï¼‰ï¼›\næ ¹æ® mesh_shape è‡ªåŠ¨æ„é€  CPU ä¸Šçš„ torch.arange(...).view(...)ï¼›\nåˆ›å»º DeviceMesh(...)ã€‚å†…éƒ¨å®Œæˆå­ç»„æ‹†åˆ†åŸç†ï¼ˆè§ä¸‹ä¸€èŠ‚ï¼‰ã€‚\n\n\nDeviceMesh.__init__() + _init_process_groups()\n\nå­˜å‚¨ï¼šdevice_typeã€meshã€mesh_dim_namesï¼›\né€šä¿¡ç»„æ‹†åˆ†ï¼šéå†æ¯ä¸ªç»´åº¦ dimï¼š\n\nä½¿ç”¨ mesh.swapdims(-1, dim).reshape(-1, size(dim)) åˆ—å‡ºè¯¥ç»´æ‰€æœ‰å­ç»„ rankï¼›\nè‹¥ NCCL å·²ç»‘å®š GPUï¼Œå³å¯ç”¨ split_group ä¸€æ¬¡æ‹†å‡ºå…¨éƒ¨å­ç»„ï¼›\nå¦åˆ™ä½¿ç”¨ new_group() åˆ† group æ‹†ï¼›\nå¹¶å°†å½“å‰ rank å±äºçš„é‚£ç»„ä¿¡æ¯æ”¾å…¥ self._dim_group_infos[dim]ï¼›\n\nç»“æœï¼šæ¯ä¸ªç»´åº¦å¯¹åº”ä¸€ä¸ªåŒ…å«å½“å‰ rank çš„ ProcessGroup ä¿¡æ¯åˆ—è¡¨ã€‚\n\n#ppmesh = torch.tensor([  [0, 1],  # pp=0  [2, 3],  # pp=1  [4, 5],  # pp=2  [6, 7]   # pp=3])mesh.swapdims(-1, 0)tensor([[0,2,4,6],        [1,3,5,7]])pg_ranks_by_dim = tmp.reshape(-1, mesh.size(0))[  [0,2,4,6],  # å¯¹åº” tp è¡Œ 0 å„ pp æ®µ  [1,3,5,7]   # å¯¹åº” tp è¡Œ 1 å„ pp æ®µ]#tptmp = mesh.swapdims(-1, 1)  # ç­‰äº transpose(1,1)ï¼Œæœ¬èº«æ— å˜åŒ–pg_ranks_by_dim = tmp.reshape(-1, mesh.size(1))[  [0,1],  # pp=0  [2,3],  [4,5],  [6,7]]\n\nä¸‰ã€æ ¸å¿ƒæ¥å£ä¸å†…éƒ¨å®ç°è§£æ\n1. å±æ€§ä¸æ–¹æ³•\nmesh.shape  # tuple(self.mesh.shape)mesh.ndim   # int(self.mesh.ndim)mesh.size(dim=None)  # æ€»å…ƒç´ æ•° or self.mesh.size(dim)\nç”¨äºè·å– mesh å…ƒç»“æ„å’Œè§„æ¨¡ï¼Œé€‚ç”¨äºåˆ¤æ–­ç»´åº¦æ•°é‡ã€å¾ªç¯è¿­ä»£ã€å¹¶è¡Œç­–ç•¥é…ç½®ç­‰åœºæ™¯ã€‚\n\n2. Rank ä¸åæ ‡\n\nget_rank()ï¼šç­‰ä»·äº torch.distributed.get_rank()ï¼Œè¿”å›å…¨å±€ rankï¼›\nget_local_rank(mesh_dim)ï¼šå†…éƒ¨è°ƒç”¨ get_rank(self.get_group(mesh_dim)) â†’ å½“å‰ç»´åº¦çš„å°ç»„å†…ç¼–å·ï¼›\nget_coordinate()ï¼šè¿”å› self._coordinate_on_dimï¼Œå…¶åœ¨åˆå§‹åŒ–ä¸­é€šè¿‡ (self.mesh==global_rank).nonzero() è·å¾—ã€‚\n\nç¤ºä¾‹ï¼šmesh_shape=(4,2)ï¼Œrank=5 â†’ local_pp=2ã€local_tp=1ï¼Œcoordinate [2,1]ã€‚\n\n3. é€šä¿¡ç»„è·å–\n\nget_group(mesh_dim)ï¼š\n\nè‹¥ 1D ä¸”ä¸ä¼ å‚ï¼Œç›´æ¥è¿”å›å”¯ä¸€å­è¿›ç¨‹ç»„ï¼›\nå¤šç»´åˆ™æ ¹æ® mesh_dimï¼ˆç´¢å¼•æˆ–åå­—ï¼‰æ£€ç´¢ self._dim_group_infos[dim]ï¼Œç”¨ _find_pg_by_ranks_and_tag() è·å–å¯¹åº” ProcessGroupã€‚\n\nget_all_groups()ï¼šè¿”å›æ‰€æœ‰ç»´åº¦çš„ group åˆ—è¡¨ï¼›\n__getitem__(dims)ï¼šåˆ‡ç‰‡æ¥å£è°ƒç”¨ _mesh_resources._get_slice_mesh_dims(...)ï¼Œåˆ›å»ºæ–°çš„å­ meshï¼Œä¿ç•™åº•å±‚ communicatorï¼Œä½†ç»´åº¦é™ã€‚\n\næ”¯æŒå•ç»´æˆ–å¤šç»´åˆ‡ç‰‡ï¼Œä¸”è¿”å›çš„ submesh é¡ºåºæŒ‰ä¼ å…¥é¡ºåºæ’åˆ— (discuss.ray.io, gemfury.com, pytorch.org)ã€‚\n\n\n\n4. from_group(...) æ–¹æ³•\n\nå¯æ¥å—å• group æˆ– group åˆ—è¡¨ï¼›\nåˆ›å»ºæ–°çš„ DeviceMesh æ—¶ä¸ä¼šè°ƒç”¨ backend åˆå§‹åŒ–ï¼›\nä¼šå¤ç”¨ç°æœ‰ ProcessGroupï¼Œå¹¶å¡«å…… _dim_group_infosï¼Œå› æ­¤ get_group(...) å°†ç›´æ¥è¿”å›ä¼ å…¥çš„å®ä¾‹ï¼Œé¿å…é‡å¤åˆ›å»º groupã€‚\n\n\nå››ã€å®Œæ•´å•æœº 8 å¡ Demoï¼štp=2, pp=4\nä¸‹é¢æ¼”ç¤ºå¦‚ä½•è°ƒç”¨æ‰€æœ‰æ¥å£å¹¶è¾“å‡ºç»“æœã€‚æ³¨æ„ï¼šéœ€åœ¨ torchrun --nproc_per_node=8 ä¸‹è¿è¡Œã€‚\nimport os, torch, torch.distributed as distfrom torch.distributed.device_mesh import init_device_meshdef run_device_mesh_demo():    dist.init_process_group(&quot;nccl&quot;)    # â¬‡ï¸ åˆå§‹åŒ– 2-ç»´ meshï¼špp=4, tp=2    mesh = init_device_mesh(&quot;cuda&quot;, mesh_shape=(4, 2), mesh_dim_names=(&quot;pp&quot;, &quot;tp&quot;))        # âœ… rank å’Œåæ ‡    gr = mesh.get_rank()            # å…¨å±€ rank    coord = mesh.get_coordinate()   # [pp_idx, tp_idx]    local_pp = mesh.get_local_rank(&quot;pp&quot;)    local_tp = mesh.get_local_rank(&quot;tp&quot;)        # â¬‡ï¸ mesh åŸºæœ¬ç»“æ„    total = mesh.size()    pp_size, tp_size = mesh.size(&quot;pp&quot;), mesh.size(&quot;tp&quot;)    ndim = mesh.ndim    shape = mesh.shape        # â¬‡ï¸ è·å–é€šä¿¡ç»„    pp_group = mesh.get_group(&quot;pp&quot;)    tp_group = mesh.get_group(&quot;tp&quot;)    all_groups = mesh.get_all_groups()        # â¬‡ï¸ åˆ‡ç‰‡å‡ºå­ mesh    tp_mesh = mesh[&quot;tp&quot;]    pp_mesh = mesh[&quot;pp&quot;]        # â¬‡ï¸ è¾“å‡ºç»“æœ    print(f&quot;rank=&#123;gr&#125;, coord=&#123;coord&#125;, local_pp=&#123;local_pp&#125;, local_tp=&#123;local_tp&#125;&quot;)    print(f&quot;ndim=&#123;ndim&#125;, shape=&#123;shape&#125;, total=&#123;total&#125;, pp=&#123;pp_size&#125;, tp=&#123;tp_size&#125;&quot;)    print(&quot;pp_group ranks:&quot;, dist.get_process_group_ranks(pp_group))    print(&quot;tp_group ranks:&quot;, dist.get_process_group_ranks(tp_group))    print(&quot;all_groups sizes:&quot;, [len(dist.get_process_group_ranks(g)) for g in all_groups])    print(&quot;tp_mesh ndim, shape:&quot;, tp_mesh.ndim, tp_mesh.shape)    print(&quot;pp_mesh ndim, shape:&quot;, pp_mesh.ndim, pp_mesh.shape)if __name__ == &quot;__main__&quot;:    run_device_mesh_demo()\nğŸ’¬ é¢„æœŸè¾“å‡ºï¼ˆä¾‹å¦‚ rank = 5ï¼‰ï¼š\nrank=5, coord=[2,1], local_pp=2, local_tp=1 ndim=2, shape=(4,2), total=8, pp=4, tp=2 pp_group ranks: [4,5,6,7] tp_group ranks: [5,7] all_groups sizes: [4,2] tp_mesh ndim, shape: 1 (2,) pp_mesh ndim, shape: 1 (4,)\nè¯´æ˜ï¼š - rank=5 ä½äº pipeline æ®µ 2ï¼Œtp å†…ç¼–å· 1ï¼› - pp_group åŒ…å«ä¸å…¶åŒ segment çš„ 4 å¼ å¡ï¼› - tp_group åŒ…å«åŒ segment tp ç»´åº¦çš„ä¸¤å¼ å¡ï¼› - åˆ‡ç‰‡å tp_meshã€pp_mesh æˆä¸º 1 ç»´ç»“æ„ï¼Œç”¨äºåç»­ parallelizationã€‚\n\nğŸ‘ æ€»ç»“\n\nDeviceMesh æ„å»ºè‡ªèº«é€šè¿‡ init_device_mesh() å®Œæˆåˆå§‹åŒ–ä¸å­ç»„æ‹†åˆ†ï¼›\næ¥å£å†…éƒ¨å®ç°é€»è¾‘ä¸ Group ç®¡ç†æœºåˆ¶æ¸…æ™°ã€é«˜æ•ˆï¼›\n__getitem__ä¸ºå¤šç»´å¹¶è¡Œä¸‹å­ Mesh åˆ‡ç‰‡å…³é”®å·¥å…·ï¼Œå¯¹é›†æˆ parallel APIs è‡³å…³é‡è¦ï¼›\né€šè¿‡è¯¥æœºåˆ¶ï¼Œå¯ä»¥ç®€å•åœ°ç»„ç»‡å¤æ‚çš„ hybrid-parallel pipelinesï¼ŒåŒæ—¶å……åˆ†å¤ç”¨ communicator èµ„æºå¹¶ç®€åŒ–å¼€å‘æµç¨‹ã€‚\n\n","categories":["åˆ†å¸ƒå¼åŸºç¡€"],"tags":["devicemesh"]},{"title":"pytorch send and recv","url":"/2025/06/14/distribute/send_recv/","content":"\n\n1. åŸºæœ¬æ¦‚å¿µä¸è¿›ç¨‹ç»„\n2. åŸºæœ¬å¼ é‡é€šä¿¡\n3. å¯¹è±¡åˆ—è¡¨é€šä¿¡\n4. æ˜“é”™ç‚¹ä¸å¸¸è§é—®é¢˜\n5. æ‰¹é‡ç‚¹å¯¹ç‚¹é€šä¿¡æ¥å£\n6. æ€»ç»“è¡¥å……\n7. å‚è€ƒèµ„æ–™\n\n\n1. åŸºæœ¬æ¦‚å¿µä¸è¿›ç¨‹ç»„\n\ngroupï¼ˆé€šä¿¡ç»„ï¼‰ï¼šåˆ†å¸ƒå¼é€šä¿¡æ—¶çš„ã€Œå­é›†ã€ï¼Œå…è®¸åªåœ¨ä¸€éƒ¨åˆ† rank ä¹‹é—´é€šä¿¡ã€‚\nglobal rankï¼šå…¨å±€è¿›ç¨‹ç¼–å·ï¼ˆè¿›ç¨‹å¯åŠ¨æ—¶åˆ†é…çš„ç¼–å·ï¼‰ã€‚\ngroup rankï¼šç»„å†…è¿›ç¨‹ç¼–å·ï¼Œç»„å†…ç¬¬å‡ ä¸ªè¿›ç¨‹ï¼ˆä¸ global rank æ— å¿…ç„¶å¯¹åº”å…³ç³»ï¼‰ã€‚\nsrc/dstï¼šé€šä¿¡ç›®æ ‡ï¼ˆæº/ç›®çš„ï¼‰rankï¼Œæ³¨æ„ï¼šå¦‚æœæŒ‡å®š groupï¼Œè¿™é‡Œæ˜¯ç»„å†…ç¼–å·ï¼Œä¸æ˜¯å…¨å±€ç¼–å·ã€‚\n\nè¿›ç¨‹ç»„ä¸¾ä¾‹\nå‡å¦‚ group = [2, 4, 6, 8, 10]ï¼š\n\n\n\ngroup_rank\nglobal_rank\n\n\n\n\n0\n2\n\n\n1\n4\n\n\n2\n6\n\n\n3\n8\n\n\n4\n10\n\n\n\n\n2. åŸºæœ¬å¼ é‡é€šä¿¡\n2.1 send / recv / isend / irecv\nå‚æ•°è¯´æ˜\n\nsend(tensor, dst, group=None, tag=0) å‘é€ tensor åˆ°ç»„å†… rank=dst çš„è¿›ç¨‹ã€‚\nrecv(tensor, src, group=None, tag=0) ä»ç»„å†… rank=src çš„è¿›ç¨‹æ¥æ”¶ tensorã€‚\nisend/irecv å¼‚æ­¥ç‰ˆæœ¬ï¼Œè¿”å› Work å¥æŸ„ï¼Œéœ€è¦ work.wait()ã€‚\n\ntag\n\ntag æ˜¯æ¶ˆæ¯ç¼–å·/æ ‡ç­¾ï¼Œç”¨äºåŒºåˆ†å¤šæ¡å¹¶å‘æ¶ˆæ¯ï¼Œåªæœ‰ tag ä¸€è‡´æ‰èƒ½æ­£ç¡®é…å¯¹ã€‚\n\ngroup_dst/group_src\n\nä¸€èˆ¬ä¸ç”¨æ‰‹åŠ¨ä¼ ï¼Œæ¡†æ¶ä¼šæ ¹æ® dst/src å’Œ group è‡ªåŠ¨æ¨ç®—ã€‚\n\n\n2.2 é€šä¿¡æµç¨‹ç¤ºæ„å›¾\nä»¥ group = [2, 4, 6, 8, 10]ï¼Œè®© rank=2 å‘ï¼Œrank=10 æ”¶ä¸ºä¾‹ï¼š\ngraph TD    subgraph group [group: [2, 4, 6, 8, 10]]        A[&quot;global_rank=2&lt;br&gt;group_rank=0&quot;]        B[&quot;global_rank=10&lt;br&gt;group_rank=4&quot;]    end    A -- send(tensor, dst=4, group=group) --&gt; B    B -- recv(tensor, src=0, group=group) --&gt; A\n\nå‘é€ç«¯ï¼ˆglobal_rank=2ï¼Œgroup_rank=0ï¼‰ï¼šsend(tensor, dst=4, group=group)\næ¥æ”¶ç«¯ï¼ˆglobal_rank=10ï¼Œgroup_rank=4ï¼‰ï¼šrecv(tensor, src=0, group=group)\n\n\n2.3 ä»£ç å®ä¾‹\n# å‘é€ç«¯ï¼ˆglobal_rank=2ï¼‰group = dist.new_group([2, 4, 6, 8, 10])tensor = torch.tensor([123])dist.send(tensor, dst=4, group=group)   # dst=4 æ˜¯ group å†… rank=4 â†’ global_rank=10# æ¥æ”¶ç«¯ï¼ˆglobal_rank=10ï¼‰group = dist.new_group([2, 4, 6, 8, 10])tensor = torch.zeros(1, dtype=torch.int)dist.recv(tensor, src=0, group=group)   # src=0 æ˜¯ group å†… rank=0 â†’ global_rank=2print(tensor)\n\nâš ï¸ åªè¦ç”¨äº† groupï¼Œsrc/dst éƒ½æ˜¯ç»„å†… rankï¼Œä¸æ˜¯ global rankï¼\n\n\n2.4 å¼‚æ­¥é€šä¿¡ï¼ˆisend/irecvï¼‰\nwork = dist.isend(tensor, dst=4, group=group)work.wait()  # ç­‰å¾…å‘é€å®Œæˆ\nå¼‚æ­¥ recv åŒç†ã€‚\n\n3. å¯¹è±¡åˆ—è¡¨é€šä¿¡\n3.1 send_object_list / recv_object_list ç”¨æ³•\n\nç”¨äºå‘é€/æ¥æ”¶åŒ…å«ä»»æ„ Python å¯¹è±¡çš„ listï¼Œåº•å±‚é€šè¿‡åºåˆ—åŒ–å®ç°ã€‚\nå‘é€è¿‡ç¨‹æ‹†ä¸ºä¸¤æ­¥ï¼šå…ˆå‘æ¯ä¸ªå¯¹è±¡åºåˆ—åŒ–åçš„ sizeï¼Œå†å‘æ‰€æœ‰å†…å®¹æ‹¼æ¥åçš„ tensorã€‚\n\n\n3.2 å¯¹è±¡é€šä¿¡æµç¨‹å›¾\nsequenceDiagram    participant Sender    participant Receiver    Sender-&gt;&gt;Receiver: send(object_sizes_tensor)    Sender-&gt;&gt;Receiver: send(object_tensor)    Receiver-&gt;&gt;Receiver: 1. è¯»å– object_sizes_tensor    Receiver-&gt;&gt;Receiver: 2. æŒ‰ size æ‹† object_tensor    Receiver-&gt;&gt;Receiver: 3. ååºåˆ—åŒ–ä¸ºå¯¹è±¡\n\n3.3 å…¸å‹ä»£ç ç¤ºä¾‹\nå‘é€ç«¯\nobject_list = [&quot;hello&quot;, 123, [1, 2, 3]]dist.send_object_list(object_list, dst=4, group=group)\næ¥æ”¶ç«¯\nrecv_list = [None, None, None]dist.recv_object_list(recv_list, src=0, group=group)print(recv_list)  # [&#x27;hello&#x27;, 123, [1, 2, 3]]\n\n3.4 æ¥å£å®ç°æ ¸å¿ƒä»£ç \n# æ¥æ”¶ç«¯åˆ†å‰²ååºåˆ—åŒ–offset = 0for i, obj_size in enumerate(object_sizes_tensor):    obj_view = object_tensor[offset : offset + obj_size]    object_list[i] = _tensor_to_object(obj_view, obj_size, group)    offset += obj_size\n\nobject_sizes_tensor è®°å½•æ¯ä¸ªå¯¹è±¡çš„åºåˆ—åŒ–é•¿åº¦\nobject_tensor æ˜¯æ‰€æœ‰å†…å®¹æ‹¼èµ·æ¥çš„ä¸€ç»´ tensor\næŒ‰é¡ºåºåˆ‡ç‰‡å’Œååºåˆ—åŒ–ï¼Œå¡«å› object_list\n\n\n3.5 å…³äº rank_objects\n\nrank_objects æ˜¯ recv çš„è¿”å›å€¼ï¼Œè¡¨ç¤ºæ¶ˆæ¯æ¥è‡ªå“ªä¸ª rankï¼ˆä¸€èˆ¬ç­‰äº srcï¼‰\nåœ¨å¤šå¯¹å¤šé€šä¿¡æˆ– src=ANY_SOURCE æ—¶ç”¨æ¥ç¡®è®¤æ¶ˆæ¯æ¥æºï¼Œå’Œå®é™…å¯¹è±¡å†…å®¹è¿˜åŸæ— å…³\n\n\n4. æ˜“é”™ç‚¹ä¸å¸¸è§é—®é¢˜\n\nåªè¦ç”¨äº† groupï¼Œsrc/dst éƒ½æ˜¯ç»„å†… rankï¼Œä¸æ˜¯ global rankã€‚\ntag ç”¨äºåŒºåˆ†å¤šæ¡æ¶ˆæ¯ï¼Œå¿…é¡» send å’Œ recv ä¸€è‡´ã€‚\nsend_object_list/recv_object_list å¿…é¡» object_list é•¿åº¦ã€é¡ºåºä¸€è‡´ã€‚\ngroup_src/group_dst æ­£å¸¸ä¸šåŠ¡ä¸éœ€è¦è‡ªå·±ä¼ ã€‚\n\n4.1. groupã€src/dstã€group_src/group_dst å‚æ•°å…³ç³»\n\ngroup å†³å®šé€šä¿¡å­é›†ï¼Œsrc/dst å†³å®šæ”¶å‘ç›®æ ‡ç¼–å·ã€‚\nå¦‚æœæŒ‡å®š groupï¼Œåˆ™ src/dst ä¸ºç»„å†… rankï¼Œä¸æ˜¯ global rankã€‚\ngroup_src/group_dst ä¸€èˆ¬ä¸ç”¨æ‰‹åŠ¨ä¼ ï¼Œæ¡†æ¶è‡ªåŠ¨æ¨ç®—ã€‚\næ˜ å°„å…³ç³»ï¼š\n\nå…¨å±€è½¬ç»„å†…ï¼šgroup_ranks.index(global_rank)\nç»„å†…è½¬å…¨å±€ï¼šgroup_ranks[group_rank]\n\n\n\n5. æ‰¹é‡ç‚¹å¯¹ç‚¹é€šä¿¡æ¥å£\n5.1 æ¥å£ç®€ä»‹\ntorch.distributed.batch_isend_irecv æ”¯æŒåŒæ—¶å‘èµ·å¤šç»„å¼‚æ­¥ç‚¹å¯¹ç‚¹é€šä¿¡æ“ä½œï¼ˆisend/irecvï¼‰ï¼Œæ˜¾è‘—æé«˜å¤§æ‰¹é‡æ•°æ®åˆ†å‘/æ”¶é›†çš„æ•ˆç‡ã€‚ åº•å±‚æ”¯æŒ NCCLã€Glooã€UCC ç­‰åˆ†å¸ƒå¼åç«¯ï¼Œå¸¸ç”¨äºåˆ†å¸ƒå¼æ·±åº¦å­¦ä¹ çš„ pipeline/é€šä¿¡ pattern ä¼˜åŒ–ã€‚\nå‡½æ•°ç­¾å\ntorch.distributed.batch_isend_irecv(p2p_op_list: list[P2POp]) -&gt; list[Work]\n\np2p_op_listï¼šä¸€ç»„ torch.distributed.P2POp å®ä¾‹ï¼Œæ¯ä¸ªå®ä¾‹æè¿°ä¸€æ¬¡ isend/irecvã€‚\nè¿”å›ï¼šæ‰€æœ‰æ“ä½œçš„ request å¥æŸ„ï¼ˆWork å¯¹è±¡ï¼‰åˆ—è¡¨ï¼Œå¯é€šè¿‡ .wait() åŒæ­¥ã€‚\n\n\n5.2 å…¸å‹ä½¿ç”¨åœºæ™¯\n\nå¤§æ‰¹é‡ç‚¹å¯¹ç‚¹é€šä¿¡ï¼Œä¾‹å¦‚ pipeline å¹¶è¡Œã€ç¯å½¢ allreduce æ‰‹å†™ä¼˜åŒ–ç­‰åœºæ™¯ã€‚\næ”¯æŒ isend/irecv æ··åˆï¼Œèƒ½æ‰¹é‡æå‡ååé‡ã€‚\n\n\n5.3 è°ƒç”¨æµç¨‹ä¸å‚æ•°è¯´æ˜\nP2POp ç”¨æ³•\næ¯ä¸ª P2POp å®šä¹‰ä¸€æ¬¡é€šä¿¡æ“ä½œï¼Œå¦‚ä¸‹ï¼š\nP2POp(op, tensor, peer, group=None, tag=0)\n\nopï¼šæ“ä½œç±»å‹ï¼ˆdist.isend æˆ– dist.irecvï¼‰\ntensorï¼šè¦å‘é€/æ¥æ”¶çš„ tensor\npeerï¼šç›®æ ‡ peer çš„ç¼–å·ï¼ˆç»„å†… rankï¼‰\ngroupï¼ˆå¯é€‰ï¼‰ï¼šé€šä¿¡ç»„ï¼ˆé»˜è®¤ä¸º worldï¼‰\ntagï¼ˆå¯é€‰ï¼‰ï¼šæ¶ˆæ¯ç¼–å·/æ ‡ç­¾\n\n\n5.4 ä»£ç å®ä¾‹\nå‡è®¾ world_size=2ï¼Œrank 0 å’Œ rank 1 åšä¸€ä¸ªç¯å½¢é€šä¿¡ï¼š\nimport torchimport torch.distributed as distrank = dist.get_rank()world_size = dist.get_world_size()send_tensor = torch.arange(2, dtype=torch.float32) + 2 * rankrecv_tensor = torch.zeros(2, dtype=torch.float32)send_op = dist.P2POp(dist.isend, send_tensor, (rank + 1) % world_size)recv_op = dist.P2POp(dist.irecv, recv_tensor, (rank - 1 + world_size) % world_size)reqs = dist.batch_isend_irecv([send_op, recv_op])for req in reqs:    req.wait()print(f&quot;Rank &#123;rank&#125; æ”¶åˆ°: &#123;recv_tensor&#125;&quot;)\nè¿è¡Œç»“æœï¼š\nRank 0 æ”¶åˆ°: tensor([2., 3.])Rank 1 æ”¶åˆ°: tensor([0., 1.])\n\n5.5 é€šä¿¡æµç¨‹å›¾\nsequenceDiagram    participant Rank0    participant Rank1    Rank0-&gt;&gt;Rank1: isend(send_tensor, dst=1)    Rank1-&gt;&gt;Rank0: isend(send_tensor, dst=0)    Rank0-&gt;&gt;Rank0: irecv(recv_tensor, src=1)    Rank1-&gt;&gt;Rank1: irecv(recv_tensor, src=0)    Note over Rank0,Rank1: batch_isend_irecv([send_op, recv_op])&lt;br&gt;å¹¶å‘å‘èµ·é€šä¿¡å¹¶ç­‰å¾…å®Œæˆ\n\n5.6 é‡è¦æ³¨æ„äº‹é¡¹\n\næ³¨æ„\n\nå¦‚æœä½¿ç”¨ NCCL åç«¯ï¼Œå¿…é¡»æå‰ç”¨ torch.cuda.set_device è®¾ç½®å¥½å½“å‰ GPUï¼\nå¦‚æœè¿™æ˜¯æŸä¸ª group çš„ç¬¬ä¸€æ¬¡é€šä¿¡ï¼Œgroup é‡Œçš„æ‰€æœ‰ rank å¿…é¡»éƒ½è°ƒç”¨ batch_isend_irecvï¼Œå¦åˆ™è¡Œä¸ºæœªå®šä¹‰ã€‚\nä»¥ååªè¦ä¸æ˜¯ç¬¬ä¸€æ¬¡ collectiveï¼Œå…è®¸åªç”¨éƒ¨åˆ† rank å‚ä¸ã€‚\n\n\n\n5.7 æºç å®ç°è¦ç‚¹\n\nè‡ªåŠ¨åˆ¤æ–­é€šä¿¡åç«¯æ˜¯å¦æ”¯æŒæ“ä½œåˆå¹¶ï¼ˆcoalescingï¼‰ï¼Œå¦‚ NCCL ä¼šåœ¨åŒä¸€ä¸ªä¸Šä¸‹æ–‡ä¸‹æ‰¹é‡å¯åŠ¨ï¼Œæå‡æ€§èƒ½ã€‚\nè¿”å›æ‰€æœ‰ requestï¼ˆWorkï¼‰å¯¹è±¡ï¼Œç”¨æˆ·å¯ wait()ã€‚\n\n\n5.8 API æ–‡æ¡£é“¾æ¥\n\nPyTorch å®˜æ–¹ batch_isend_irecv æ–‡æ¡£\nP2POp å®˜æ–¹è¯´æ˜\n\n\n6. æ€»ç»“è¡¥å……\n\nå¼ é‡ç‚¹å¯¹ç‚¹é€šä¿¡ï¼šsend/recv/isend/irecv/batch_isend_irecv\nå¯¹è±¡é€šä¿¡ï¼šsend_object_list/recv_object_list\næ‰¹é‡ç‚¹å¯¹ç‚¹é€šä¿¡èƒ½æå¤§æå‡ pipeline é€šä¿¡æ•ˆç‡\nç»Ÿä¸€è¿”å› Work å¥æŸ„ï¼Œæ”¯æŒåŒæ­¥æˆ–å¼‚æ­¥\ngroup/src/dst ä½¿ç”¨æ–¹å¼åŒä¸Šæ–‡æè¿°\n\n\n7. å‚è€ƒèµ„æ–™\n\nPyTorch Distributed å®˜æ–¹æ–‡æ¡£\nPyTorch distributed_c10d.py æºç \nMermaid Live Editor\n\n\n","categories":["åˆ†å¸ƒå¼åŸºç¡€"],"tags":["send recv"]},{"title":"pytorch Shard","url":"/2025/06/20/distribute/shard/","content":"\n\n1. _split_tensoråˆ†æ\n1.1 ä»£ç å®ç°æµç¨‹å›¾ï¼ˆMermaidï¼‰\nflowchart TD  A[&quot;è¾“å…¥ï¼štensor, num_chunks, with_padding, contiguous&quot;] --&gt; B&#123;&quot;dim â‰¤ tensor.ndim?&quot;&#125;  B -- å¦ --&gt; E[&quot;AssertionError æŠ›å‡º&quot;]  B -- æ˜¯ --&gt; C[&quot;è°ƒç”¨ torch.chunk æ²¿ dim åˆ†å—&quot;]  C --&gt; D[&quot;tensor_list, è®¡ç®— num_empty_tensors = num_chunks - len(tensor_list)&quot;]  D --&gt; F&#123;&quot;æ— éœ€ padding æˆ– å‡åŒ€å¯åˆ†?&quot;&#125;  F -- æ˜¯ --&gt; G[&quot;(å¯é€‰) å¯¹æ¯å—è°ƒç”¨ .contiguous()&quot;]  G --&gt; H[&quot;è°ƒç”¨ fill_empty_tensor_to_shards è¡¥ç©º shard&quot;]  H --&gt; I[&quot;è¿”å› shards åˆ—è¡¨ å’Œ ç©º pad_sizes []&quot;]  F -- å¦ --&gt; J[&quot;è®¡ç®— full_chunk_size = ceil(dim_size / num_chunks)&quot;]  J --&gt; K[&quot;æ”¶é›†åŸå§‹ chunk_sizes&quot;]  K --&gt; L[&quot;pad_sizes = full_chunk_size - chunk_size&quot;]  L --&gt; M[&quot;è°ƒç”¨ fill_empty_tensor_to_shards è¡¥ç©º shard&quot;]  M --&gt; N[&quot;å¯¹æ¯ä¸ª shardï¼šè‹¥ pad_size &gt; 0ï¼Œåˆ™ pad_tensor(shard, dim, pad_size)&quot;]  N --&gt; O[&quot;(å¯é€‰) shard.contiguous()&quot;]  O --&gt; P[&quot;æ”¶é›† shard_list å’Œ pad_sizes&quot;]  P --&gt; Q[&quot;è¿”å› shard_list å’Œ pad_sizes&quot;]\n\n1.2 å…³é”®ç‚¹è¯¦è§£\nğŸ§  ä¸ºä»€ä¹ˆè¦ Paddingï¼Ÿ\nç”¨äºä¿è¯åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸­ï¼ˆæ¯”å¦‚ scatterã€all_gather ç­‰ collective æ“ä½œï¼‰æ¯ä¸ª rank çš„ shard å¤§å°ä¸€è‡´ï¼Œé¿å…å› ä¸ºå°ºå¯¸ä¸å¯¹é½å¯¼è‡´é€šä¿¡å¤±è´¥ã€‚åªæœ‰ tensor.size(dim) % num_chunks â‰  0 ä¸” with_padding=True æ—¶ï¼Œæ‰ä¼šè¿›è¡Œ paddingã€‚\nğŸ§© fill_empty_tensor_to_shards\ntorch.chunk åœ¨å°ºå¯¸è¾ƒå°æˆ– num_chunks æ›´å¤§æ—¶ä¸ä¼šè¾“å‡ºç©º tensorã€‚è¯¥å‡½æ•°ç”¨äºè¡¥å…¨ï¼šåœ¨ tensor_list å°‘äº num_chunks æ—¶ï¼Œè¡¥å……å½¢çŠ¶åˆæ³•ä½† dim ä¸Šä¸º 0 çš„ç©º tensorï¼Œä½¿ shard æ•°ç›®ä¸€è‡´ï¼Œä¾¿äºåç»­ç»Ÿä¸€å¤„ç†ã€‚\nğŸ§¼ pad_tensor\nè‹¥å½“å‰ shard å°äº full_chunk_sizeï¼Œåˆ™åœ¨æŒ‡å®šç»´åº¦æœ«å°¾è¡¥é›¶ï¼Œç¡®ä¿æ‰€æœ‰ shard çš„å½¢çŠ¶ä¸€è‡´ã€‚\nğŸ§± contiguous\nä¸ºæå‡å†…å­˜è¿è´¯æ€§å’Œé€šä¿¡æ•ˆç‡ï¼Œå¯è°ƒç”¨ .contiguous() é‡æ’å†…å­˜å¸ƒå±€ã€‚\n\n1.3 å®é™…è°ƒç”¨ç¤ºä¾‹ï¼ˆéœ€ Paddingï¼‰\nä»¥ä¸‹ä¸ºæ— æ³•å‡åŒ€åˆ†ç‰‡ï¼Œå›  num_chunks=4 è€Œè§¦å‘ pad çš„åœºæ™¯ï¼š\nimport torchfrom torch.distributed.tensor.placement_types import Shard# æ„é€ å¼ é‡tensor = torch.arange(1, 13).reshape(2, 6)  # shape [2, 6]# åœ¨ dim=1 ä¸Šæ‹†ä¸º 4 ä»½ï¼Œä¸æ•´é™¤å°†è§¦å‘ paddingsharder = Shard(dim=1)shards, pad_sizes = sharder._split_tensor(tensor, num_chunks=4, with_padding=True)print(&quot;Pad sizes:&quot;, pad_sizes)for i, (sh, pad) in enumerate(zip(shards, pad_sizes)):    print(f&quot;Shard &#123;i&#125; shape: &#123;tuple(sh.shape)&#125;, pad: &#123;pad&#125;&quot;)    print(sh)\nâœ… é¢„æœŸç»“æœ\n\ntensor.size(1)=6, num_chunks=4 â‡’ full_chunk_size = ceil(6/4) = 2\ntorch.chunk ä¼šå‡º 4 å—ï¼Œä½†æœ€åä¸€ä¸¤å—å¯èƒ½ä¸º empty\npad_sizes å¯èƒ½ä¸º [0, 0, 0, 2]\næœ€ç»ˆæ¯å—å¤§å°éƒ½æ˜¯ [2] (dim=1)ï¼Œpadding è¡¥é½\n\nPad sizes: [0, 0, 0, 2]Shard 0 shape: (2, 2), pad: 0tensor([[1, 2],        [7, 8]])Shard 1 shape: (2, 2), pad: 0tensor([[ 3,  4],        [ 9, 10]])Shard 2 shape: (2, 2), pad: 0tensor([[ 5,  6],        [11, 12]])Shard 3 shape: (2, 2), pad: 2tensor([[0, 0],        [0, 0]])\n\n1.4 æ€»ç»“\n\n_split_tensor çš„ä½œç”¨æ˜¯å°†ä¸€ä¸ª Tensor æ²¿æŒ‡å®šç»´åº¦åˆ‡åˆ†ä¸ºå›ºå®šä»½æ•°ï¼Œå¹¶åœ¨ ä¸èƒ½æ•´é™¤æ—¶è‡ªåŠ¨è¡¥é½ã€‚\nå®ƒä¿éšœäº†å„ shard åœ¨é€šä¿¡é˜¶æ®µå°ºå¯¸ä¸€è‡´ï¼Œé€‚ç”¨äºåˆ†å¸ƒå¼å¼ é‡å¹¶è¡Œåœºæ™¯ã€‚\nå®é™…ä»£ç é€šè¿‡ torch.chunkã€fill_empty_tensor_to_shardsã€pad_tensor ç­‰æ‰‹æ®µï¼Œè½»æ¾å®ç°è¿™ä¸€ç›®æ ‡ã€‚\n\n\n","categories":["åˆ†å¸ƒå¼åŸºç¡€"],"tags":["shard"]},{"title":"pytorchä¸­TCPStore Rendezvousæœºåˆ¶","url":"/2025/06/14/distribute/tcpstore_rendezvous/","content":"\n\nğŸ§  èƒŒæ™¯æ¦‚è¿°\n\nç›®æ ‡ï¼šåœ¨ init_process_group ä¸­å®ç°è·¨è¿›ç¨‹æ³¨å†Œã€æ’åºåŠ barrier åŒæ­¥ï¼Œä¸º NCCL/Gloo é€šä¿¡ç»„æ„å»ºåˆ›å»ºä¸€è‡´ä¸Šä¸‹æ–‡ã€‚\næ—¶åºï¼šæ‰€æœ‰ set/get/wait æ“ä½œå‡å‘ç”Ÿåœ¨ NCCL é€šä¿¡åˆå§‹åŒ–ä¹‹å‰ï¼ˆå³ rendezvous é˜¶æ®µï¼‰ã€‚\næœºåˆ¶ï¼šsocket å®¢æˆ·ç«¯â€”æœåŠ¡å™¨æ¨¡å‹ + backend æ§åˆ¶åŒæ­¥é€»è¾‘ã€‚\n\n\n1. æ¶ˆæ¯åè®®æ ¼å¼\nå®¢æˆ·ç«¯å‘ master å‘é€çš„åŒ…æ ¼å¼ä¸ºï¼š\n\\[4â€¯B æ€»é•¿åº¦]\\[1â€¯B æ“ä½œç ]\\[4â€¯B key\\_len]\\[4â€¯B value\\_len]\\[key]\\[value]\n\næ€»é•¿åº¦ï¼šç½‘ç»œå­—èŠ‚åºï¼Œä¸å«è‡ªèº«ï¼›\næ“ä½œç ï¼š1=SET, 2=GET, 3=WAITï¼›\nkey_len, value_lenï¼šåç»­å­—æ®µé•¿åº¦ï¼›\nkey, valueï¼šå®é™…æ•°æ®ï¼›\nMaster è§£æåï¼Œå›å¤ï¼šOK / value å†…å®¹ / READY ç­‰ã€‚\n\n\n2. Rendezvous é˜¶æ®µæµç¨‹ï¼ˆ2 æœºï¼Œ4 å¡ eachï¼Œèšç„¦ rank1 &amp; rank5ï¼‰\nflowchart TB  subgraph A[&quot;Machine A (rank0-3)&quot;]    master[&quot;TCPStoreBackend (master)&quot;]    r1[Worker rank1]    master --- r1  end  subgraph B[&quot;Machine B (rank4-7)&quot;]    r5[Worker rank5]    master --- r5  end  r1 --&gt;|SET key rank1_addr| master  r5 --&gt;|SET key rank5_addr| master  r1 --&gt;|WAIT  rendezvous_done| master  r5 --&gt;|WAIT  rendezvous_done| master  %% Server: waits until all ranks set, then:  master --&gt;|write READY| r1  master --&gt;|write READY| r5  %% å®Œæˆ WAIT è¿”å›ï¼Œè¿›å…¥ NCCL åˆå§‹åŒ–  r1 --&gt;|recv READY â†’ NCCL init| NCCL_1[NCCL Init rank1]  r5 --&gt;|recv READY â†’ NCCL init| NCCL_5[NCCL Init rank5]\nğŸ§© æ­¥éª¤è§£æ\n\nMaster åœ¨ç«¯å£ï¼ˆå¦‚ 29500ï¼‰ä¾¦å¬ï¼Œæ¥æ”¶è¿æ¥ï¼›\nrank1 / rank5 åˆ†åˆ«å‘é€ SETï¼ˆæ³¨å†Œåœ°å€ï¼‰ï¼›\néšåå‘é€ WAIT(\"rendezvous_done\")ï¼ŒSocket å¤„äºé˜»å¡çŠ¶æ€ï¼›\nMaster æ”¶é›†æ‰€æœ‰ 8 ä¸ª rank çš„ SET åï¼Œéå† wait é˜»å¡çš„è¿æ¥ï¼Œé€ä¸€å†™å…¥ READYï¼›\nWorker æ”¶åˆ° READYï¼Œé€€å‡ºé˜»å¡ï¼Œè¿›å…¥ NCCL åˆå§‹åŒ–é˜¶æ®µï¼›\néšååœ¨è¿™ä¸€é˜¶æ®µå†…ï¼šäº¤æ¢ ncclUniqueId (via store), è°ƒç”¨ ncclCommInitRank æ„å»ºé€šä¿¡ç»„ (github.com, pytorch.org)ã€‚\n\n\n3. Backend ç»†èŠ‚å¯¹æ¯”\n\n\n\n\n\n\n\n\nBackend\nI/O æ¨¡å‹\nç‰¹ç‚¹ä¸é€‚åº”æ€§\n\n\n\n\nç»å…¸ TCPStoreBackend\naccept() + per-conn é˜»å¡/POLL\nç®€å•ï¼Œè¿æ¥è¾ƒå¤šæ—¶æ‰©å±•æ€§å·®\n\n\nlibuv å¼‚æ­¥ Backend\nå•çº¿ç¨‹ event-loop, readable/writeable\né»˜è®¤å¯ç”¨ï¼ˆv2.4+ï¼‰ï¼Œé«˜å¹¶å‘æ›´ä¼˜ (docs.pytorch.org)\n\n\n\n\nlibuv backend ä½¿ç”¨ uv_read_start è‡ªåŠ¨åˆ†å—è¯»å–ï¼Œæ ¹æ® header æ§åˆ¶æ‹¼åŒ…ï¼›\næ³¨å†Œ WAIT æ—¶ï¼Œå°† conn ä¿å­˜åœ¨ map ä¸­ï¼Œä¸ç«‹å³å›å†™ï¼›å½“æ¡ä»¶æ»¡è¶³ï¼Œè§¦å‘ uv_write() â†’ uv_write_cb å®ç°å”¤é†’ã€‚\n\n\n4. partial-key WAIT æœºåˆ¶\n\nå®¢æˆ·ç«¯å¯ä»¥æ‰§è¡Œ store.wait([\"kA\", \"kB\"])ï¼›\nMaster å°†æ­¤ç­‰å¾…ç™»è®°è‡³ MultiWaitRegistryï¼›\nå½“ æ‰€æœ‰ç›¸å…³ key å‡è¢« SET åï¼Œæ‰ç»Ÿä¸€å‘è¯¥è¿æ¥å†™ READYï¼Œè§¦å‘å”¤é†’ã€‚\n\n\n5. â€œå¹¿æ’­ READYâ€ çš„å®ç°æœºåˆ¶\n\nä¸æ˜¯é€šè¿‡ NCCL/Gloo broadcast ç®—å­ï¼›\nMaster éå†æŒ‚èµ·çš„ WAIT socketsï¼Œé€ä¸ªå†™ READYï¼›\nä¸º rendezvous è¿‡ç¨‹è‡ªèº«æä¾›åŒæ­¥æœºåˆ¶ï¼Œé€šä¿¡ç»„å°šæœªåˆ›å»ºã€‚\n\n\n6. æ—¶é—´çº¿æ¦‚è§ˆ\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚ SET/WAIT via TCP Store   â”‚  # rendezvous é˜¶æ®µâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â†“â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚ recv READY â†’ wait returnsâ”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â†“â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚ NCCL Init                â”‚  # è°ƒç”¨ ncclUniqueId, CommInitRankâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â†“â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚ Collective Ops (DDP)     â”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nâœ… æ€»ç»“è¦ç‚¹\n\næ ‡æ³¨ rank1 / rank5 çš„æµç¨‹å›¾ï¼Œæ›´ç›´è§‚ï¼›\nSET + WAIT æ“ä½œå…¨éƒ¨å‘ç”Ÿäº rendezvous é˜¶æ®µï¼Œè§å›¾ï¼›\nMaster â€œå¹¿æ’­ READYâ€ æ˜¯ socket å†™æ“ä½œï¼Œä¸æ˜¯é€šä¿¡åº“å¹¿æ’­ï¼›\nNCCL åˆå§‹åŒ–åœ¨ rendezvous å®Œæˆåè¿›è¡Œï¼›\nlibuv backend æä¾›æ›´é«˜æ•ˆ I/O å¤„ç†åŠ message æ‹¼æ¥å¤„ç†èƒ½åŠ› (docs.pytorch.org, pytorch.org, github.com)ã€‚\n\n\n","categories":["åˆ†å¸ƒå¼åŸºç¡€"],"tags":["tcpstore"]},{"title":"ubuntuå¸¸è§shellå‘½ä»¤","url":"/2025/08/17/other/shell/","content":"\n\n1. ç£ç›˜å ç”¨ä¸æ’åºï¼ˆdu/sortï¼‰\nå¸¸ç”¨å†™æ³•\n# æŒ‰â€œå½“å‰ç›®å½•çš„ç›´æ¥å­é¡¹â€æ±‡æ€»ï¼ˆäººç±»å¯è¯»ï¼‰ï¼Œå¹¶æŒ‰å¤§å°å€’åºdu -h --max-depth=1 . | sort -hr# ä»…ç»Ÿè®¡æ¯ä¸ªæ¡ç›®æ€»å¤§å°ï¼ˆä¸æ˜¾ç¤ºå­å±‚çº§ï¼‰ï¼Œå¹¶å¯¹æ¡ç›®æ’åºdu -sh -- * | sort -h\n2. æ–‡æœ¬æœç´¢ï¼ˆgrepï¼‰\nåŸºç¡€\ngrep &quot;keyword&quot; file.txt          # åœ¨å•ä¸ªæ–‡ä»¶ä¸­æŸ¥æ‰¾grep -n &quot;keyword&quot; file.txt       # æ˜¾ç¤ºè¡Œå·grep -i &quot;keyword&quot; file.txt       # å¿½ç•¥å¤§å°å†™\nç›®å½•é€’å½’ä¸ä¸Šä¸‹æ–‡\ngrep -rin --color=auto &quot;keyword&quot; .      # é€’å½’ã€å¿½ç•¥å¤§å°å†™ã€è¡Œå·ã€é«˜äº®grep -nC 3 &quot;keyword&quot; file.txt           # ä¸Šä¸‹å„ 3 è¡Œgrep -nA 2 &quot;keyword&quot; file.txt           # å 2 è¡Œgrep -nB 2 &quot;keyword&quot; file.txt           # å‰ 2 è¡Œ\nç²¾ç¡®åŒ¹é…ä¸æ­£åˆ™\ngrep -rw &quot;\\&lt;token\\&gt;&quot; .                  # æŒ‰â€œæ•´è¯â€åŒ¹é…grep -E &quot;err(or)?|fail(ed)?&quot; app.log    # æ‰©å±•æ­£åˆ™grep -rF &quot;literal*text&quot; .               # çº¯å­—ç¬¦ä¸²ï¼ˆä¸å½“æ­£åˆ™ï¼‰ï¼Œæ›´å¿«\næ’é™¤æ–‡ä»¶/ç›®å½•\ngrep -rin &quot;keyword&quot; . \\  --exclude-dir=&#123;.git,node_modules,dist&#125; \\  --exclude=&quot;*.min.js&quot;\n\n3. æ–‡ä»¶è·¯å¾„æŸ¥æ‰¾ï¼ˆfind/locateï¼‰\nfindï¼šçµæ´»ä½†å®æ—¶æ‰«æï¼ˆæ…¢ï¼‰\n# æŒ‰æ–‡ä»¶åï¼ˆå¤§å°å†™ä¸æ•æ„Ÿï¼‰find /path -type f -iname &quot;*name*&quot;# é™åˆ¶æœç´¢æ·±åº¦find . -maxdepth 2 -type d -name &quot;build&quot;# æŸ¥æ‰¾å¤§æ–‡ä»¶ï¼ˆ&gt; 100MBï¼‰å¹¶æŒ‰å¤§å°é™åºåˆ—å‡ºå‰ 20 ä¸ªfind /var -type f -size +100M -printf &#x27;%s\\t%p\\n&#x27; | sort -nr | head -20# æŸ¥æ‰¾æœ€è¿‘ 1 å¤©å†…ä¿®æ”¹çš„æ–‡ä»¶find . -type f -mtime -1# å¯¹ç»“æœæ‰§è¡Œå‘½ä»¤ï¼ˆå®‰å…¨å¤„ç†ç©ºæ ¼ï¼‰find . -type f -name &quot;*.log&quot; -print0 | xargs -0 gzip\n\nè·³è¿‡ç³»ç»Ÿç›®å½•ä¸”å‹åˆ¶æŠ¥é”™\n\nfind / \\( -path /proc -o -path /sys -o -path /run \\) -prune -o \\  -type f -name &quot;*.conf&quot; -print 2&gt;/dev/null\nlocate/plocateï¼šåŸºäºç´¢å¼•ï¼ˆå¿«ï¼‰\nsudo apt-get install -y plocatesudo updatedb                 # é€šå¸¸è‡ªåŠ¨å®šæ—¶æ›´æ–°locate filename_or_pattern\n\n4. å¸¸è§ç½‘ç»œå·¥å…·å®‰è£…åŒ…\n# pingsudo apt-get install -y iputils-ping# ifconfigï¼ˆè€å·¥å…·ï¼Œä»å¸¸è§ï¼‰sudo apt-get install -y net-tools# ç°ä»£æ›¿ä»£ï¼šipï¼ˆé€šå¸¸å·²è‡ªå¸¦äº iproute2ï¼‰ip addrip linkip route# killallsudo apt-get install -y psmisc\n\n5. è¿›ç¨‹æŸ¥æ€ï¼ˆkill/pkill/killallï¼‰\nps -ef | grep python3 | awk &#x27;&#123;print $2&#125;&#x27; | xargs kill -9\næ›´å®‰å…¨çš„åšæ³•\n# ä¼˜é›…ç»ˆæ­¢ï¼ˆSIGTERMï¼‰ï¼›æ—  PID æ—¶ä¸æ‰§è¡Œ (-r)pgrep -f python3 | xargs -r kill# ç›´æ¥æŒ‰åç§°åŒ¹é…ï¼ˆä¼˜é›…ç»ˆæ­¢ï¼‰ï¼Œå¿…è¦æ—¶å† -9pkill -f python3pkill -9 -f python3# é¿å…åŒ¹é…åˆ° grep è‡ªèº«ps -ef | grep &#x27;[p]ython3&#x27; | awk &#x27;&#123;print $2&#125;&#x27; | xargs -r kill\n\nå»ºè®®å…ˆå°è¯• SIGTERMï¼ˆé»˜è®¤ï¼‰ï¼Œæ— å“åº”å†ç”¨ SIGKILLï¼ˆ-9ï¼‰ã€‚\n\n\n6. é«˜é¢‘å‘½ä»¤æ¸…å•ä¸ç¤ºä¾‹\nç³»ç»Ÿ/èµ„æº\ntop                     # å®æ—¶æ¦‚è§ˆhtop                    # æ›´å‹å¥½ï¼ˆéœ€ï¼šsudo apt-get install -y htopï¼‰free -h                 # å†…å­˜df -h                   # ç£ç›˜åˆ†åŒºå®¹é‡du -sh * | sort -h      # ç›®å½•å ç”¨uname -a                # å†…æ ¸ä¿¡æ¯lsb_release -a          # å‘è¡Œç‰ˆä¿¡æ¯\nè¿›ç¨‹/ç½‘ç»œ\nps aux | lesspstree -p               # è¿›ç¨‹æ ‘ï¼ˆéœ€ï¼šsudo apt-get install -y psmiscï¼‰lsof -i :8080           # ç«¯å£å ç”¨ï¼ˆéœ€ï¼šsudo apt-get install -y lsofï¼‰ss -lntp                # ç›‘å¬ç«¯å£ + è¿›ç¨‹\næ–‡æœ¬/æ—¥å¿—\nless file.logtail -f file.logwc -l file.txtsort file | uniq -c | sort -nrcut -d&#x27;,&#x27; -f1,3 file.csvsed -n &#x27;1,20p&#x27; file.txtawk -F: &#x27;&#123;print $1,$3&#125;&#x27; /etc/passwd\næ–‡ä»¶/å½’æ¡£/ä¼ è¾“\ntar -czf logs.tgz logs/        # å‹ç¼©tar -xzf logs.tgz              # è§£å‹zip -r src.zip src/            # zipï¼ˆéœ€ï¼šsudo apt-get install -y zip unzipï¼‰rsync -av --progress src/ dst/scp file user@host:/path/\næƒé™/é“¾æ¥\nchmod +x run.shchown user:group fileln -s /real/path link_name\næœåŠ¡ä¸æ—¥å¿—ï¼ˆsystemdï¼‰\nsystemctl status nginxsudo systemctl start nginxjournalctl -u nginx --since &quot;1 hour ago&quot;\nå…¶ä»–\nwhich python3command -v nodedate &quot;+%F %T&quot;nohup python3 app.py &gt;out.log 2&gt;&amp;1 &amp;tmux new -s work              # ç»ˆç«¯å¤ç”¨ï¼ˆéœ€ï¼šsudo apt-get install -y tmuxï¼‰\n\n7. å°è´´å£«ä¸å¸¸è§å‘\n\néšè—æ–‡ä»¶ï¼š* ä¸åŒ¹é…éšè—é¡¹ï¼Œå¯ç”¨ .* * ç»„åˆæˆ–å¼€å¯ dotglobã€‚\né˜²æ­¢å‚æ•°è¢«å½“ä½œé€‰é¡¹ï¼šå½“æ–‡ä»¶åä»¥ - å¼€å¤´æ—¶åŠ  --ï¼Œå¦‚ rm -- -weirdfileã€‚\nxargs å®‰å…¨ï¼šäºŒè¿›åˆ¶æ–‡ä»¶/ç©ºæ ¼ç”¨ -0 é…åˆ -print0ï¼›æ— ç»“æœæ—¶ä¸æ‰§è¡Œç”¨ -rã€‚\nä¼˜é›…åœæœåŠ¡ä¼˜å…ˆï¼škill -TERM â†’ ä¸è¡Œå† kill -KILLã€‚\næƒé™ï¼šç³»ç»Ÿç›®å½•æ“ä½œæ…ç”¨ sudoï¼Œå†™å‰å…ˆ ls/du/stat ç¡®è®¤ã€‚\ngrep æ­£åˆ™ vs å­—ç¬¦ä¸²ï¼šçº¯æ–‡æœ¬åŒ¹é…æ›´ç¨³æ›´å¿«ç”¨ -Fã€‚\nfind æ€§èƒ½ï¼šå¤§ç›®å½•ç”¨ -maxdepth é™åˆ¶å±‚çº§æˆ–æ”¹ç”¨ locate/plocateã€‚\n\n\n","categories":["å…¶å®ƒ"],"tags":["shell"]},{"title":"token ç®€ä»‹","url":"/2025/09/07/other/token/","content":"\n\nğŸ§  ä»€ä¹ˆæ˜¯ Tokenï¼Ÿ\nåœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­ï¼ŒToken æ˜¯æ–‡æœ¬çš„åŸºæœ¬å•ä½ã€‚å®ƒå¯ä»¥æ˜¯ä¸€ä¸ªå­—ç¬¦ã€ä¸€ä¸ªè¯ã€ä¸€ä¸ªå­è¯ï¼Œç”šè‡³æ˜¯ä¸€ä¸ªæ ‡ç‚¹ç¬¦å·ã€‚Token çš„å®šä¹‰å–å†³äºæ‰€é‡‡ç”¨çš„æ ‡è®°åŒ–ï¼ˆtokenizationï¼‰æ–¹æ³•ã€‚\n\nğŸ”„ æ–‡æœ¬å¦‚ä½•è½¬æ¢ä¸ºæ•°å­—ï¼Ÿ\nåœ¨è®­ç»ƒè¯­è¨€æ¨¡å‹æ—¶ï¼Œæ–‡æœ¬éœ€è¦è¢«è½¬æ¢ä¸ºæ•°å­—å½¢å¼ã€‚è¿™ä¸€è¿‡ç¨‹é€šå¸¸åŒ…æ‹¬ä»¥ä¸‹æ­¥éª¤ï¼š\n\næ ‡è®°åŒ–ï¼ˆTokenizationï¼‰ï¼šå°†æ–‡æœ¬åˆ†è§£ä¸º tokensã€‚\næ„å»ºè¯æ±‡è¡¨ï¼ˆVocabularyï¼‰ï¼šä¸ºæ¯ä¸ª token åˆ†é…ä¸€ä¸ªå”¯ä¸€çš„æ•°å­— IDã€‚\næ•°å­—åŒ–ï¼ˆNumericalizationï¼‰ï¼šå°†æ–‡æœ¬ä¸­çš„ tokens æ›¿æ¢ä¸ºå¯¹åº”çš„æ•°å­— IDã€‚\n\nä¾‹å¦‚ï¼Œå¥å­ \"hello world\" å¯èƒ½è¢«æ ‡è®°åŒ–ä¸º [\"hello\", \"world\"]ï¼Œç„¶åæ ¹æ®è¯æ±‡è¡¨è½¬æ¢ä¸º [1, 2]ã€‚\n\nğŸ”¤ å¸¸è§çš„æ ‡è®°åŒ–æ–¹æ³•\n1. Word-based Tokenizationï¼ˆåŸºäºè¯çš„æ ‡è®°åŒ–ï¼‰\nå°†æ–‡æœ¬æŒ‰ç©ºæ ¼æˆ–æ ‡ç‚¹ç¬¦å·åˆ†å‰²æˆå•è¯ã€‚è¿™ç§æ–¹æ³•ç®€å•ç›´è§‚ï¼Œä½†å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š\n\nè¯æ±‡è¡¨è¿‡å¤§ï¼šéœ€è¦ä¸ºæ¯ä¸ªå•è¯åˆ†é…ä¸€ä¸ªå”¯ä¸€çš„ IDï¼Œå¯¼è‡´è¯æ±‡è¡¨åºå¤§ã€‚\nå¤„ç†æœªç™»å½•è¯å›°éš¾ï¼šå¯¹äºè®­ç»ƒæ•°æ®ä¸­æœªå‡ºç°çš„å•è¯ï¼Œæ¨¡å‹éš¾ä»¥å¤„ç†ã€‚\n\nç¤ºä¾‹ï¼š\n\nè¾“å…¥æ–‡æœ¬ï¼š\"I love NLP\"\næ ‡è®°åŒ–ç»“æœï¼š[\"I\", \"love\", \"NLP\"]\næ•°å­—åŒ–è¡¨ç¤ºï¼š[1, 2, 3]\n\n2. Character-based Tokenizationï¼ˆåŸºäºå­—ç¬¦çš„æ ‡è®°åŒ–ï¼‰\nå°†æ–‡æœ¬åˆ†è§£ä¸ºå•ä¸ªå­—ç¬¦ã€‚è¿™ç§æ–¹æ³•å¯ä»¥æœ‰æ•ˆå‡å°‘è¯æ±‡è¡¨å¤§å°ï¼Œä½†å¯èƒ½å¯¼è‡´ä»¥ä¸‹é—®é¢˜ï¼š\n\nä¿¡æ¯ä¸¢å¤±ï¼šå­—ç¬¦çº§åˆ«çš„è¡¨ç¤ºå¯èƒ½æ— æ³•æ•æ‰åˆ°è¯æ±‡çš„å®Œæ•´è¯­ä¹‰ã€‚\nåºåˆ—é•¿åº¦å¢åŠ ï¼šåŒä¸€æ–‡æœ¬çš„ token æ•°é‡å¢åŠ ï¼Œå¯èƒ½å½±å“æ¨¡å‹çš„å¤„ç†æ•ˆç‡ã€‚\n\nç¤ºä¾‹ï¼š\n\nè¾“å…¥æ–‡æœ¬ï¼š\"I love NLP\"\næ ‡è®°åŒ–ç»“æœï¼š[\"I\", \" \", \"l\", \"o\", \"v\", \"e\", \" \", \"N\", \"L\", \"P\"]\næ•°å­—åŒ–è¡¨ç¤ºï¼š[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n\nğŸ”¬ Subword-based Tokenizationï¼šBPEï¼ˆå­—èŠ‚å¯¹ç¼–ç ï¼‰\nBPE æ˜¯ä¸€ç§å­è¯çº§åˆ«çš„æ ‡è®°åŒ–æ–¹æ³•ï¼Œæ—¨åœ¨å¹³è¡¡è¯æ±‡è¡¨å¤§å°å’Œè¯­ä¹‰è¡¨è¾¾èƒ½åŠ›ã€‚å®ƒé€šè¿‡è¿­ä»£åœ°åˆå¹¶æœ€é¢‘ç¹çš„å­—ç¬¦å¯¹æ¥æ„å»ºå­è¯å•å…ƒï¼Œå¹¶è¢«å¹¿æ³›åº”ç”¨äº GPTã€BERT ç­‰å¤§è¯­è¨€æ¨¡å‹ã€‚BPE çš„è¿‡ç¨‹å¯ä»¥æ¦‚æ‹¬ä¸ºä»¥ä¸‹äº”ä¸ªé˜¶æ®µï¼š\n1. åˆå§‹åŒ–è¯æ±‡è¡¨\n\næ‹†åˆ†å­—ç¬¦ï¼šé¦–å…ˆå°†è¯­æ–™åº“æ‹†åˆ†ä¸ºæœ€å°å•ä½â€”â€”å•ä¸ªå­—ç¬¦ã€‚ä¾‹å¦‚ï¼Œå¯¹å•è¯ lower æ‹†åˆ†å¾—åˆ° l o w e r&lt;/w&gt;ï¼Œå¹¶åœ¨æ¯ä¸ªè¯å°¾æ·»åŠ ç‰¹æ®Šç»“æŸç¬¦ï¼ˆå¦‚ &lt;/w&gt;ï¼‰ï¼Œä»¥åŒºåˆ†ä¸åŒè¯ã€‚\næ„å»ºåˆå§‹è¯è¡¨ï¼šè®°å½•æ‰€æœ‰å‡ºç°è¿‡çš„å­—ç¬¦ï¼Œä½œä¸ºåˆå§‹ token é›†ã€‚\n\n2. ç»Ÿè®¡ç›¸é‚»å­—ç¬¦å¯¹é¢‘ç‡\néå†æ‰€æœ‰è¯ï¼Œç»Ÿè®¡æ¯ä¸ªç›¸é‚»å­—ç¬¦ï¼ˆæˆ–å·²åˆå¹¶çš„å­è¯ï¼‰å¯¹çš„å‡ºç°æ¬¡æ•°ã€‚BPE é€šè¿‡è¿™ä¸€ç»Ÿè®¡æ¥è¯†åˆ«è¯­è¨€ä¸­æœ€å¸¸è§çš„æ¨¡å¼ï¼Œä»¥å†³å®šæ¥ä¸‹æ¥è¦åˆå¹¶çš„ç¬¦å·å¯¹ã€‚\n3. åˆå¹¶æœ€é¢‘ç¹çš„ç¬¦å·å¯¹\næ‰¾åˆ°å‡ºç°é¢‘ç‡æœ€é«˜çš„å­—ç¬¦å¯¹ï¼Œå¹¶å°†å®ƒä»¬åœ¨æ•´ä¸ªæ•°æ®é›†ä¸­åˆå¹¶æˆæ–°çš„å­è¯ã€‚ä¾‹å¦‚ï¼Œå¦‚æœ (w, e) æ˜¯æœ€é«˜é¢‘ç»„åˆï¼Œåˆ™å°†å…¶åˆå¹¶ä¸º weï¼›æ›´æ–°æ‰€æœ‰ç›¸å…³è¯ï¼Œå¹¶æŠŠæ–°å­è¯åŠ å…¥è¯æ±‡è¡¨ã€‚\n4. é‡å¤æ­¥éª¤ç›´åˆ°è¾¾åˆ°è¯è¡¨å¤§å°\nBPE æ˜¯ä¸€ä¸ªè¿­ä»£è¿‡ç¨‹ã€‚æ¯æ¬¡åˆå¹¶åï¼Œç»Ÿè®¡æ–°çš„ç›¸é‚»ç¬¦å·å¯¹å¹¶ç»§ç»­åˆå¹¶ï¼Œç›´åˆ°è¯æ±‡è¡¨è¾¾åˆ°é¢„è®¾å¤§å°æˆ–ä¸å†æœ‰éœ€è¦åˆå¹¶çš„ç¬¦å·å¯¹ã€‚\n5. æ„å»ºæœ€ç»ˆè¯æ±‡è¡¨å¹¶åº”ç”¨åˆ°æ–‡æœ¬\næœ€ç»ˆè¯æ±‡è¡¨æ—¢åŒ…å«åˆå§‹çš„å­—ç¬¦ï¼ŒåˆåŒ…å«æ‰€æœ‰åˆå¹¶å¾—åˆ°çš„é«˜é¢‘å­è¯ã€‚æ–°è¯å¯ä»¥é€šè¿‡è¿™äº›å­è¯ç»„åˆè¡¨ç¤ºï¼Œå› æ­¤ä»»ä½•æ–°è¯éƒ½èƒ½æ‹†è§£ä¸ºå·²çŸ¥çš„å­è¯åºåˆ—ã€‚\nç¤ºä¾‹ï¼šBPE åˆ†è¯è¿‡ç¨‹æ¼”ç¤º\nä»¥ä»¥ä¸‹è¯æ±‡é›†ä¸ºä¾‹ï¼šhuggingfaceã€huggingã€faceã€hugã€huggerã€learningã€learnerã€learnã€‚å°†æ¯ä¸ªè¯æ‹†åˆ†ä¸ºå­—ç¬¦å¹¶åŠ ä¸Šç»“æŸç¬¦ï¼Œç„¶åæ‰§è¡Œé¢‘æ¬¡ç»Ÿè®¡å’Œåˆå¹¶ã€‚ä»¥ä¸‹æ˜¯å‰å‡ æ¬¡åˆå¹¶ï¼š\n\n(h, u) â†’ hu\n(hu, g) â†’ hug\n(hug, g) â†’ hugg\n(i, n) â†’ in\n(in, g) â†’ ing\n(l, e) â†’ le\n(le, a) â†’ lea\n(lea, r) â†’ lear\n\næ‰§è¡Œ 8 æ¬¡åˆå¹¶åï¼Œè¯è¡¨æ‰©å¤§è‡³ 20 ä¸ª tokenï¼Œå…¶ä¸­åŒ…æ‹¬åŸºæœ¬å­—ç¬¦ï¼ˆh,u,g,i ç­‰ï¼‰å’Œæ–°åˆæˆçš„å­è¯ï¼ˆhug,hugg,ing,lear ç­‰ï¼‰ã€‚è¯ huggingface ç»è¿‡æ ‡è®°åŒ–åä¸º hugg ing f a c e &lt;/w&gt;ï¼Œlearning åˆ™ä¸º lear n ing &lt;/w&gt;ï¼Œå…¶ä½™è¯ä¹Ÿå¯ä»¥ç”¨ç±»ä¼¼æ–¹å¼è¡¨ç¤ºã€‚\nğŸ§ª BPE çš„ä¼˜ç¼ºç‚¹\nä¼˜ç‚¹ï¼š\n\nå¤„ç†æœªç™»å½•è¯ï¼šé€šè¿‡æŠŠè¯æ‹†è§£ä¸ºå­è¯ï¼ŒBPE å¯ä»¥ç”¨å·²æœ‰çš„å­è¯ç»„åˆæ¥è¡¨ç¤ºè®­ç»ƒé›†ä¸­æœªå‡ºç°çš„è¯æ±‡ã€‚\nå‡å°‘è¯æ±‡è¡¨å¤§å°ï¼šç›¸æ¯”åŸºäºè¯çš„æ ‡è®°åŒ–ï¼ŒBPE å¯ä»¥æ˜¾è‘—ç¼©å°è¯è¡¨è§„æ¨¡ï¼Œä½¿æ¨¡å‹æ›´é«˜æ•ˆã€‚\næå‡æ³›åŒ–èƒ½åŠ›ï¼šå­è¯çº§è¡¨ç¤ºå…è®¸æ¨¡å‹å­¦ä¹ æ›´ç»†ç²’åº¦çš„è¯­è¨€ç»“æ„ï¼Œå¯¹ä¸åŒé¢†åŸŸã€ä¸åŒè¯­è¨€å…·æœ‰æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚\n\nç¼ºç‚¹ï¼š\n\nåˆå¹¶è§„åˆ™ä¾èµ–è¯­æ–™ï¼šä¸åŒè¯­æ–™å¾—åˆ°çš„åˆå¹¶è§„åˆ™å·®å¼‚è¾ƒå¤§ï¼Œå¤šè¯­è¨€åœºæ™¯ä¸‹å¯èƒ½éœ€è¦å¤æ‚çš„å¤„ç†ã€‚\nè¯­ä¹‰å®Œæ•´æ€§å¯èƒ½å—æŸï¼šå¦‚æœåˆå¹¶è¿‡åº¦ï¼ŒæŸäº›åˆæˆè¯çš„è¯­ä¹‰ä»å¯èƒ½åˆ†å‰²ï¼Œéœ€æ ¹æ®ä»»åŠ¡é€‰æ‹©åˆé€‚çš„è¯è¡¨å¤§å°ã€‚\n\n\nğŸ“ æ€»ç»“\næ ‡è®°åŒ–æ˜¯è‡ªç„¶è¯­è¨€å¤„ç†çš„æ ¸å¿ƒæ­¥éª¤ï¼Œå®ƒå°†æ–‡æœ¬è½¬æ¢ä¸ºæ¨¡å‹å¯å¤„ç†çš„æ•°å­—å½¢å¼ã€‚åŸºäºè¯å’ŒåŸºäºå­—ç¬¦çš„æ ‡è®°åŒ–æ–¹æ³•ç®€å•æ˜“ç†è§£ï¼Œä½†åˆ†åˆ«å­˜åœ¨è¯æ±‡è¡¨è¿‡å¤§å’Œåºåˆ—è¿‡é•¿çš„é—®é¢˜ã€‚BPE ä½œä¸ºä¸€ç§å­è¯çº§æ ‡è®°åŒ–ç®—æ³•ï¼Œä»¥åˆå§‹åŒ–å­—ç¬¦é›†ä¸ºåŸºç¡€ï¼Œé€šè¿‡è¿­ä»£åˆå¹¶é«˜é¢‘ç¬¦å·å¯¹æ„å»ºæ–°çš„å­è¯å•å…ƒã€‚è¿™ç§æ–¹æ³•å…¼é¡¾äº†è¯è¡¨å¤§å°å’Œè¯­ä¹‰è¡¨è¾¾èƒ½åŠ›ï¼Œæ—¢èƒ½å¤„ç†æœªç™»å½•è¯ï¼Œä¹Ÿèƒ½ä¿ç•™è¶³å¤Ÿçš„è¯­ä¹‰ä¿¡æ¯ã€‚å› æ­¤ï¼Œç°ä»£å¤§è¯­è¨€æ¨¡å‹é€šå¸¸é‡‡ç”¨ BPE æˆ–å…¶å˜ç§ï¼ˆå¦‚ WordPieceã€SentencePieceï¼‰ä½œä¸ºé»˜è®¤çš„æ ‡è®°åŒ–æ–¹æ¡ˆã€‚\n","categories":["å…¶å®ƒ"],"tags":["token"]},{"title":"ubuntuæ­å»ºæŠ€æœ¯åšå®¢æŒ‡å—","url":"/2025/06/14/other/web_init/","content":"\n\n1. å®‰è£… Hexo ç¯å¢ƒ\n2. é€‰æ‹©ä¸é…ç½® Hexo ä¸»é¢˜\n3. æ’°å†™ä¸ç®¡ç†åšå®¢å†…å®¹\n4. SEO ä¼˜åŒ–\n5. åšå®¢éƒ¨ç½²\n6. ç»´æŠ¤ä¸ä¼˜åŒ–\n\næœ¬æŒ‡å—è¯¦ç»†ä»‹ç»äº†å¦‚ä½•åœ¨ Ubuntu æœåŠ¡å™¨ä¸Šæ­å»ºå¹¶éƒ¨ç½²ä¸€ä¸ª Hexo æŠ€æœ¯åšå®¢ï¼ŒåŒ…æ‹¬ä»ç¯å¢ƒå®‰è£…åˆ°åæœŸç»´æŠ¤çš„å®Œæ•´æ­¥éª¤ã€‚\n1. å®‰è£… Hexo ç¯å¢ƒ\næ­å»º Hexo åšå®¢é¦–å…ˆéœ€è¦å®‰è£… Node.jsï¼ˆHexo åŸºäº Node.jsï¼‰ã€npmã€Git ä»¥åŠ Hexo CLI å·¥å…·ã€‚è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤é…ç½®ç¯å¢ƒï¼š\nå®‰è£… Node.js å’Œ npmï¼š\nåœ¨ Ubuntu ä¸Šï¼Œé€šè¿‡åŒ…ç®¡ç†å™¨æˆ– Node å®˜æ–¹ä»“åº“å®‰è£… Node.jsã€‚å»ºè®®å®‰è£… LTS ç‰ˆæœ¬ï¼ˆå¦‚ Node 14+ï¼‰ã€‚æ‰§è¡Œä»¥ä¸‹å‘½ä»¤æ·»åŠ  NodeSource ä»“åº“å¹¶å®‰è£… Node.jsï¼š\ncurl -sL https://deb.nodesource.com/setup_18.x | sudo -E bash -sudo apt-get install -y nodejs\nå®‰è£…å®Œæˆåï¼Œæ£€æŸ¥ç‰ˆæœ¬ä»¥ç¡®ä¿ Node æ­£å¸¸å¯ç”¨ï¼š\nnode -v  # åº”è¿”å›ç±»ä¼¼ v18.20.6 çš„ç‰ˆæœ¬å·npm -v   # éªŒè¯ npm æ˜¯å¦æ­£å¸¸å®‰è£…\nå®‰è£… Gitï¼š\nGit æ˜¯ Hexo éƒ¨ç½²å’Œå¤‡ä»½çš„å¸¸ç”¨å·¥å…·ã€‚Ubuntu é€šå¸¸é¢„è£… Gitï¼Œè‹¥æœªå®‰è£…ï¼Œè¯·æ‰§è¡Œï¼š\nsudo apt-get install -y git\nå®‰è£…åï¼Œé…ç½® Git çš„å…¨å±€ç”¨æˆ·åå’Œé‚®ç®±ï¼š\ngit config --global user.name &quot;Your Name&quot;git config --global user.email &quot;youremail@example.com&quot;\nå®‰è£… Hexo CLIï¼š\né€šè¿‡ npm å…¨å±€å®‰è£… Hexo CLIï¼š\nsudo npm install -g hexo-cli\nå®‰è£…æˆåŠŸåï¼Œé€šè¿‡ hexo -v æ£€æŸ¥ç‰ˆæœ¬ï¼Œç¡®ä¿ Hexo CLI å¯ç”¨ã€‚\nåˆå§‹åŒ– Hexo åšå®¢ï¼š\né€‰æ‹©åšå®¢æ–‡ä»¶å¤¹ï¼ˆä¾‹å¦‚ /var/www/hexo æˆ–å½“å‰ç”¨æˆ·ä¸»ç›®å½•ä¸‹çš„ my-blog æ–‡ä»¶å¤¹ï¼‰ï¼Œå¹¶åœ¨è¯¥ç›®å½•ä¸‹åˆå§‹åŒ– Hexo åšå®¢ï¼š\nsudo mkdir -p /var/www/hexo &amp;&amp; sudo chown $USER:$USER /var/www/hexocd /var/www/hexohexo initnpm install\nåˆå§‹åŒ–å®Œæˆåï¼ŒHexo ä¼šç”Ÿæˆé»˜è®¤çš„åšå®¢ç»“æ„ï¼ŒåŒ…æ‹¬ _config.yml é…ç½®æ–‡ä»¶ã€scaffolds/ æ¨¡æ¿ç›®å½•ã€source/ å†…å®¹ç›®å½•å’Œ themes/ ä¸»é¢˜ç›®å½•ç­‰ã€‚å¯ä»¥é€šè¿‡è¿è¡Œ hexo server é¢„è§ˆæœ¬åœ°åšå®¢ã€‚\nå¼€å¯é˜²ç«å¢™ï¼š\nä¸ºäº†ç¡®ä¿æœåŠ¡å™¨å®‰å…¨ï¼Œå»ºè®®å¼€å¯é˜²ç«å¢™ã€‚Ubuntu è‡ªå¸¦ UFW é˜²ç«å¢™ï¼Œå¯ä»¥å¼€å¯ SSHã€HTTP(S) ä»¥åŠ Hexo é»˜è®¤é¢„è§ˆç«¯å£ 4000ï¼š\nsudo apt-get install ufw  sudo ufw allow &quot;OpenSSH&quot;  sudo ufw allow 4000  sudo ufw allow http  sudo ufw allow https  sudo ufw enable\n2. é€‰æ‹©ä¸é…ç½® Hexo ä¸»é¢˜\nHexo é»˜è®¤ä¸»é¢˜ä¸º Landscapeï¼Œä½†ä¸ºäº†æ‰“é€ ä¸€ä¸ªç®€æ´ç¾è§‚çš„æŠ€æœ¯åšå®¢ï¼Œæˆ‘ä»¬æ¨èä½¿ç”¨ NexT ä¸»é¢˜ï¼Œå®ƒåŠŸèƒ½å¼ºå¤§ä¸”å¤–è§‚ä¼˜é›…ã€‚ä»¥ä¸‹æ˜¯ä¸»é¢˜çš„å®‰è£…å’Œé…ç½®æ­¥éª¤ï¼š\nè·å– NexT ä¸»é¢˜ï¼š\nåœ¨ Hexo åšå®¢æ ¹ç›®å½•ä¸‹æ‰§è¡Œä»¥ä¸‹å‘½ä»¤æ¥å…‹éš† NexT ä¸»é¢˜ï¼š\ncd /var/www/hexogit clone https://github.com/theme-next/hexo-theme-next themes/next\nä¿®æ”¹ä¸»é¢˜é…ç½®ï¼š\nå…‹éš†å®Œæˆåï¼Œæ‰“å¼€ _config.yml é…ç½®æ–‡ä»¶ï¼Œå°† theme é…ç½®ä»é»˜è®¤çš„ landscape æ”¹ä¸º nextï¼š\n# _config.ymltheme: next\nå®‰è£…ä¸»é¢˜ä¾èµ–ï¼š\næ ¹æ®éœ€è¦å®‰è£… NexT ä¸»é¢˜çš„ä¾èµ–ï¼Œå¹¶å¯ç”¨ä½ æ‰€éœ€çš„åŠŸèƒ½ã€‚\nç”Ÿæˆå¸¸ç”¨é¡µé¢ï¼š\nä¸ºäº†å®Œå–„ç½‘ç«™ç»“æ„ï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ç”Ÿæˆæ ‡ç­¾ã€åˆ†ç±»ã€å½’æ¡£ç­‰é¡µé¢ï¼š\nhexo new page &quot;tags&quot;hexo new page &quot;categories&quot;hexo new page &quot;archives&quot;hexo new page &quot;about&quot;\nç¼–è¾‘æ¯ä¸ªé¡µé¢çš„ index.mdï¼Œåœ¨ Front-matter ä¸­æŒ‡å®šé¡µé¢ç±»å‹ï¼š\ntitle: æ ‡ç­¾date: 2025-03-06 15:00:00type: &quot;tags&quot;\nå¯¼èˆªæ èœå•å®šåˆ¶ï¼š\nåœ¨ themes/next/_config.yml ä¸­æ‰¾åˆ° menu è®¾ç½®ï¼Œå¹¶æ·»åŠ æ–°åˆ›å»ºçš„é¡µé¢ï¼š\nmenu:  home: / || home  categories: /categories/ || th  tags: /tags/ || tags  archives: /archives/ || archive  about: /about/ || user\nä¿å­˜ä¿®æ”¹åï¼Œé‡æ–°ç”Ÿæˆç«™ç‚¹ï¼Œæ–°çš„å¯¼èˆªæ èœå•å³ä¼šæ˜¾ç¤ºã€‚\n3. æ’°å†™ä¸ç®¡ç†åšå®¢å†…å®¹\nHexo ä½¿ç”¨ Markdown æ ¼å¼æ¥æ’°å†™æ–‡ç« ï¼Œéå¸¸é€‚åˆæŠ€æœ¯åšå®¢ã€‚ä»¥ä¸‹æ˜¯å¦‚ä½•ç®¡ç†å’Œç¼–å†™æ–‡ç« çš„æ­¥éª¤ï¼š\næ–°å»ºåšæ–‡ï¼š\nä½¿ç”¨ Hexo CLI åˆ›å»ºæ–°çš„æ–‡ç« ï¼š\nhexo new &quot;æ–‡ç« æ ‡é¢˜&quot;\nè¿™å°†åœ¨ source/_posts/ ç›®å½•ä¸‹åˆ›å»ºä¸€ä¸ª Markdown æ–‡ä»¶ï¼Œæ–‡ä»¶çš„å¼€å¤´æ˜¯ Front-matterï¼Œç”¨äºé…ç½®æ–‡ç« çš„å…ƒæ•°æ®ï¼ˆå¦‚æ ‡é¢˜ã€æ—¥æœŸã€åˆ†ç±»å’Œæ ‡ç­¾ç­‰ï¼‰ï¼š\ntitle: æ·±åº¦å­¦ä¹ å…¥é—¨æŒ‡å—  date: 2025-03-06 15:00:00  categories:    - äººå·¥æ™ºèƒ½    - æ·±åº¦å­¦ä¹   tags:    - ç¥ç»ç½‘ç»œ    - å…¥é—¨æ•™ç¨‹ \nä½¿ç”¨ Markdown æ’°å†™å†…å®¹ï¼š\nåœ¨ Front-matter ä¸‹æ–¹ï¼Œç”¨ Markdown è¯­æ³•æ’°å†™æ­£æ–‡ã€‚Hexo é»˜è®¤æ”¯æŒ GFMï¼ˆGitHub Flavored Markdownï¼‰ï¼Œå¯ä»¥æ–¹ä¾¿åœ°ä¹¦å†™æ ¼å¼ï¼Œä¾‹å¦‚ï¼š\n# ä¸€çº§æ ‡é¢˜## äºŒçº§æ ‡é¢˜**ç²—ä½“**ã€*æ–œä½“*å¼ºè°ƒ\næ’å…¥å›¾ç‰‡å’Œèµ„æºï¼š\nå¯ç”¨ post_asset_folder: true åï¼Œæ¯ç¯‡æ–‡ç« ä¼šæœ‰ç‹¬ç«‹çš„èµ„æºç›®å½•ã€‚å¯ä»¥å°†å›¾ç‰‡æ–‡ä»¶æ”¾å…¥è¯¥æ–‡ä»¶å¤¹ï¼Œå¹¶åœ¨æ–‡ç« ä¸­å¼•ç”¨ï¼š\n![](my-post/images/example.png)\nè‰ç¨¿ç®¡ç†ä¸å‘å¸ƒï¼š\nå¯ç”¨è‰ç¨¿åŠŸèƒ½åï¼Œæ–°åˆ›å»ºçš„æ–‡ç« ä¼šå…ˆæ”¾åœ¨ _drafts/ ä¸‹ã€‚å®Œæˆåï¼Œä½¿ç”¨ hexo publish \"æ–‡ç« æ ‡é¢˜\" å°†å…¶å‘å¸ƒã€‚\næ–‡ç« ç»“æ„å’Œåˆ†é¡µï¼š\nHexo æ”¯æŒæ–‡ç« åˆ†ç±»å’Œæ ‡ç­¾è‡ªåŠ¨æ•´ç†ã€‚ä½ ä¹Ÿå¯ä»¥é€šè¿‡ &lt;!-- more --&gt; æ¥æ‰‹åŠ¨æˆªæ–­æ‘˜è¦ï¼Œæé«˜é¦–é¡µåŠ è½½é€Ÿåº¦ã€‚\n4. SEO ä¼˜åŒ–\nä¸ºäº†è®©æ›´å¤šäººçœ‹åˆ°ä½ çš„æŠ€æœ¯åšå®¢ï¼Œè¿›è¡Œ SEOï¼ˆæœç´¢å¼•æ“ä¼˜åŒ–ï¼‰éå¸¸é‡è¦ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›ä¼˜åŒ–æªæ–½ï¼š\nç«™ç‚¹æ ‡é¢˜ä¸å…ƒä¿¡æ¯ï¼š\nåœ¨ _config.yml ä¸­å¡«å†™æœ‰åŠ©äº SEO çš„ç«™ç‚¹åŸºæœ¬ä¿¡æ¯ï¼ŒåŒ…æ‹¬ titleï¼ˆæ ‡é¢˜ï¼‰ã€descriptionï¼ˆæè¿°ï¼‰å’Œ keywordsï¼ˆå…³é”®è¯ï¼‰ã€‚\né“¾æ¥ä¼˜åŒ–ï¼š\nä¿®æ”¹æ°¸ä¹…é“¾æ¥æ ¼å¼ï¼Œç®€åŒ– URL ç»“æ„ï¼š\npermalink: :category/:title/\nç«™ç‚¹åœ°å›¾ï¼š\nç”Ÿæˆç«™ç‚¹åœ°å›¾å¸®åŠ©æœç´¢å¼•æ“æŠ“å–æ‰€æœ‰é¡µé¢ï¼š\nnpm install hexo-generator-sitemap hexo-generator-baidu-sitemap --save\nå¹¶åœ¨ _config.yml ä¸­æ·»åŠ é…ç½®ï¼š\nsitemap:  path: sitemap.xmlbaidusitemap:  path: baidusitemap.xml\næœºå™¨äººåè®®ï¼š\nåœ¨ source/ ç›®å½•ä¸‹åˆ›å»º robots.txt æ–‡ä»¶ï¼Œå¹¶å†™å…¥è§„åˆ™ï¼š\nUser-agent: *Allow: /Disallow: /admin/Sitemap: https://ä½ çš„åŸŸå/sitemap.xml\nå¥½çš„ï¼Œä»¥ä¸‹æ˜¯æˆ‘é‡æ–°ç”Ÿæˆå¹¶ä¿æŒå®Œæ•´çš„ Hexo Deploy è‡ªåŠ¨éƒ¨ç½²éƒ¨åˆ†ï¼Œç¡®ä¿æ²¡æœ‰çœç•¥ä»»ä½•ç»†èŠ‚ï¼š\n\n5. åšå®¢éƒ¨ç½²\nå®Œæˆå†…å®¹åˆ›ä½œå’Œä¼˜åŒ–åï¼Œå°±éœ€è¦å°†åšå®¢éƒ¨ç½²ä¸Šçº¿ã€‚Hexo ç”Ÿæˆçš„æ˜¯çº¯é™æ€ç½‘é¡µï¼Œå¯ä»¥éƒ¨ç½²åœ¨ä»»æ„é™æ€æœåŠ¡å™¨æˆ–æ‰˜ç®¡å¹³å°ä¸Šã€‚è¿™é‡Œä»‹ç»åœ¨ Ubuntu æœåŠ¡å™¨ä¸Šä½¿ç”¨ Nginx éƒ¨ç½²çš„æ–¹æ¡ˆï¼Œå¹¶è®¨è®º Nginx é…ç½®å’Œ Git è‡ªåŠ¨éƒ¨ç½²æ–¹æ³•ã€‚\næœ¬åœ°ç”Ÿæˆé™æ€æ–‡ä»¶ï¼š\nHexo æä¾›å‘½ä»¤å°† Markdown å†…å®¹ç”Ÿæˆé™æ€ç½‘é¡µã€‚ä¸€èˆ¬åœ¨æœ¬åœ°æˆ–æœåŠ¡å™¨ä¸Šè¿è¡Œï¼š\nhexo clean        # æ¸…ç†ä¸Šæ¬¡ç”Ÿæˆçš„æ–‡ä»¶hexo generate (hexo g)   # ç”Ÿæˆæœ€æ–°é™æ€ç½‘é¡µ\nç”Ÿæˆçš„æ–‡ä»¶ä½äºåšå®¢ç›®å½•ä¸‹çš„ public/ æ–‡ä»¶å¤¹ï¼Œå…¶ä¸­åŒ…å«åšå®¢çš„æ‰€æœ‰ HTMLã€CSSã€JSã€å›¾ç‰‡ç­‰é™æ€èµ„æºã€‚è¿™ä¸ª public æ–‡ä»¶å¤¹å³æ˜¯æœ€ç»ˆéƒ¨ç½²çš„ç½‘ç«™å†…å®¹ã€‚\nNginx éƒ¨ç½²é™æ€ç«™ç‚¹ï¼š\nåœ¨æœåŠ¡å™¨ä¸Šå®‰è£… Nginx å¹¶é…ç½®ç«™ç‚¹ï¼Œä»¥æä¾› Web æœåŠ¡ï¼š\nå®‰è£… Nginxï¼š\nsudo apt-get install -y nginx\nå®‰è£…åå¯åŠ¨ Nginx æœåŠ¡ï¼š\nsudo systemctl start nginx  # å¯è®¾ç½®å¼€æœºè‡ªå¯\né…ç½®ç«™ç‚¹ï¼šåœ¨ /etc/nginx/sites-available/ ç›®å½•ä¸‹åˆ›å»ºé…ç½®æ–‡ä»¶ï¼Œå¦‚ hexo.confï¼Œå†…å®¹å¦‚ä¸‹ï¼š\nserver &#123;    listen 80;    server_name example.com;  # å°†æ­¤æ›¿æ¢ä¸ºä½ çš„åŸŸåæˆ–æœåŠ¡å™¨IP    root /var/www/hexo/public;    index index.html index.htm;    location / &#123;        try_files $uri $uri/ =404;    &#125;&#125;\nä¸Šè¿°é…ç½®æŒ‡å®šæœåŠ¡å™¨ç›‘å¬ 80 ç«¯å£ï¼Œserver_name ä¸ºä½ çš„åŸŸåï¼ˆéœ€è¦å°†åŸŸåè§£ææŒ‡å‘è¯¥æœåŠ¡å™¨ï¼‰ã€‚root æŒ‡å‘ Hexo ç”Ÿæˆçš„ public ç›®å½•ï¼Œindex å£°æ˜é»˜è®¤é¦–é¡µæ–‡ä»¶ã€‚\nå¯ç”¨ç«™ç‚¹é…ç½®ï¼šå°†é…ç½®æ–‡ä»¶é“¾æ¥åˆ° sites-enabledï¼š\nln -s /etc/nginx/sites-available/hexo.conf /etc/nginx/sites-enabled/nginx -t  # æµ‹è¯•é…ç½®è¯­æ³•æ­£ç¡®æ€§systemctl reload nginx  # é‡æ–°åŠ è½½ Nginx é…ç½®\næ‰§è¡Œä»¥ä¸Šå‘½ä»¤åï¼Œåšå®¢ç«™ç‚¹å³å¯é€šè¿‡åŸŸåè®¿é—®ã€‚å¦‚æœæš‚æ—¶æ²¡æœ‰åŸŸåï¼Œä½¿ç”¨æœåŠ¡å™¨ IP ä¹Ÿèƒ½è®¿é—®ï¼ˆæ­¤æ—¶å¯å°† server_name æ”¹ä¸º _ é€šé…ç¬¦ï¼‰ã€‚\né…ç½® HTTPSï¼ˆå¯é€‰ï¼‰ï¼š\nå»ºè®®ä¸ºåšå®¢é…ç½® SSL è¯ä¹¦ã€‚å¯ä»¥ä½¿ç”¨ Certbot è·å– Letâ€™s Encrypt å…è´¹è¯ä¹¦ã€‚æ­¥éª¤å¦‚ä¸‹ï¼š\napt-get install -y certbot python3-certbot-nginx  certbot --nginx -d example.com -d www.example.com\næŒ‰æç¤ºå®ŒæˆåŸŸåæ‰€æœ‰æƒéªŒè¯åï¼ŒCertbot ä¼šè‡ªåŠ¨ç”Ÿæˆè¯ä¹¦å¹¶é…ç½® Nginx å°†ç«™ç‚¹å‡çº§ä¸º HTTPSã€‚\nHexo Deploy è‡ªåŠ¨éƒ¨ç½²ï¼š\næ¯æ¬¡æ›´æ–°å†…å®¹åéƒ½è¦é‡æ–°ç”Ÿæˆå¹¶ä¸Šä¼ æ–‡ä»¶ï¼Œä½¿ç”¨ Hexo çš„éƒ¨ç½²åŠŸèƒ½å¯ä»¥ç®€åŒ–æµç¨‹ã€‚Hexo æ”¯æŒå¤šç§éƒ¨ç½²æ–¹å¼ï¼Œå…¶ä¸­ Git éƒ¨ç½²æ˜¯å¸¸ç”¨æ–¹æ¡ˆä¹‹ä¸€ã€‚åŸºæœ¬æ€è·¯æ˜¯åˆ©ç”¨ Git æŠŠç”Ÿæˆçš„é™æ€æ–‡ä»¶æ¨é€åˆ°æœåŠ¡å™¨æˆ–æ‰˜ç®¡æœåŠ¡ã€‚æ¦‚æ‹¬äº†è¿™ç§æ€è·¯ï¼šåœ¨æœåŠ¡å™¨ä¸Šå®‰è£… Nginx æä¾›ç½‘é¡µæœåŠ¡ï¼Œç”¨ Git å®ç°ä»£ç ä¸Šä¼ è‡ªåŠ¨åŒ–ï¼Œè¿™æ ·æœ¬åœ°æ‰§è¡Œä¸€æ¬¡ hexo dï¼ˆdeployï¼‰å°±èƒ½è®©ç½‘ç«™æ›´æ–°ã€‚\næ¨é€åˆ°è¿œç¨‹æ‰˜ç®¡ï¼š\nå°†åšå®¢é™æ€æ–‡ä»¶éƒ¨ç½²åˆ°åƒ GitHub Pagesã€Coding Pages è¿™ç±»å¹³å°ã€‚è¿™éœ€è¦åœ¨ _config.yml ä¸­é…ç½®ï¼š\ndeploy:  type: git  repo: https://github.com/yourname/yourrepo.git  branch: main  # æˆ– gh-pages åˆ†æ”¯ç­‰\nç„¶åè¿è¡Œ hexo generate &amp;&amp; hexo deployï¼ŒHexo ä¼šæŠŠ public æ–‡ä»¶å¤¹å†…å®¹æ¨é€åˆ°æŒ‡å®šä»“åº“çš„åˆ†æ”¯ã€‚å¯¹äº GitHub Pagesï¼Œå¦‚æœ repo æ˜¯ yourname.github.io åˆ™ç›´æ¥ç”¨ä¸»åˆ†æ”¯ï¼›è‹¥æ˜¯é¡¹ç›®ä»“åº“ï¼Œå¯ä»¥ç”¨ gh-pages åˆ†æ”¯æ‰˜ç®¡ã€‚\néƒ¨ç½²åï¼ŒGitHub Pages æœåŠ¡å°†æ‰˜ç®¡ä½ çš„é™æ€åšå®¢ï¼Œä½ å¯ä»¥ä½¿ç”¨è‡ªå®šä¹‰åŸŸåç»‘å®šå®ƒã€‚ä½†æ³¨æ„ï¼šå¦‚æœä½ å¸Œæœ›åšå®¢è¿è¡Œåœ¨è‡ªå·±çš„æœåŠ¡å™¨ä¸Šï¼ˆè€Œéç¬¬ä¸‰æ–¹å¹³å°ï¼‰ï¼Œåˆ™è¿™ç§æ–¹æ¡ˆä¸æ¶‰åŠä½ çš„æœåŠ¡å™¨ Nginxã€‚å¦å¤–ï¼Œå›½å†…è®¿é—® GitHub Pages å¯èƒ½ä¸ç¨³å®šï¼Œéœ€ç»“åˆå®é™…æƒ…å†µè€ƒè™‘ã€‚\næ¨é€åˆ°è‡ªå·±æœåŠ¡å™¨ï¼š\næ­å»ºå±äºè‡ªå·±çš„ Git è‡ªåŠ¨åŒ–éƒ¨ç½²æµç¨‹ï¼Œå®ç°å°†æœ¬åœ°æ›´æ–°ä¸€é”®éƒ¨ç½²åˆ°æœåŠ¡å™¨ã€‚æ­¥éª¤å¦‚ä¸‹ï¼š\n\nåœ¨æœåŠ¡å™¨ä¸Šåˆ›å»ºä¸€ä¸ªè£¸ä»“åº“ï¼ˆbare repositoryï¼‰ï¼Œç”¨äºæ¥æ”¶æ¨é€ã€‚ä¾‹å¦‚åˆ›å»º /home/git/hexo.git è£¸ä»“åº“ã€‚\nç¼–å†™ Git é’©å­ï¼ˆpost-receiveï¼‰ï¼šè£¸ä»“åº“çš„ hooks/post-receive è„šæœ¬ä¼šåœ¨æ”¶åˆ°æ–°æ¨é€æ—¶æ‰§è¡Œã€‚è„šæœ¬å†…å®¹å¯ä»¥æ˜¯å°†æ›´æ–°çš„å†…å®¹æ£€å‡ºåˆ° Nginx ç›®å½•ã€‚ä¾‹å¦‚ï¼š\nGIT_WORK_TREE=/var/www/hexo git checkout -f  # å°†ä»“åº“å†…å®¹å¼ºåˆ¶æ£€å‡ºåˆ° /var/www/hexocd /var/www/hexo &amp;&amp; hexo generate            # ï¼ˆè‹¥æ¨é€çš„æ˜¯æºç è€Œéç”Ÿæˆæ–‡ä»¶ï¼Œåˆ™éœ€è¦åœ¨æœåŠ¡å™¨æ‰§è¡Œç”Ÿæˆï¼‰\nç»™è„šæœ¬å¯æ‰§è¡Œæƒé™ï¼š\nchmod +x post-receive\nè¿™æ ·ï¼Œæ¯å½“æ¨é€åˆ°è¯¥ä»“åº“æ—¶ï¼Œå®ƒå°±ä¼šæŠŠæ›´æ–°éƒ¨ç½²åˆ°åšå®¢ç›®å½•å¹¶ç”Ÿæˆæœ€æ–°é¡µé¢ã€‚\næœ¬åœ° Hexo é…ç½®éƒ¨ç½²ï¼šå°† _config.yml ä¸­çš„ deploy.repo è®¾ç½®ä¸ºä¸Šè¿°è£¸ä»“åº“çš„åœ°å€ï¼ˆé€šè¿‡ SSHï¼‰ã€‚ä¾‹å¦‚ï¼š\ndeploy:  type: git  repo: ssh://[emailÂ protected]/home/git/hexo.git  branch: master\nç„¶åæ‰§è¡Œ hexo clean &amp;&amp; hexo deployã€‚Hexo ä¼šé€šè¿‡ Git æ¨é€åˆ°æœåŠ¡å™¨ä»“åº“ï¼Œè§¦å‘ post-receive é’©å­ï¼Œå®ç°è‡ªåŠ¨éƒ¨ç½²ã€‚å®Œæˆåï¼ŒNginx ä¼šç«‹åˆ»æä¾›æ–°å†…å®¹æœåŠ¡ï¼Œæ— éœ€æ‰‹åŠ¨ç™»å½•æœåŠ¡å™¨æ“ä½œã€‚\n\né€šè¿‡è¿™ç§æ–¹æ¡ˆï¼Œå¯ä»¥åœ¨æœ¬åœ°å†™å¥½æ–‡ç« åä¸€æ¡å‘½ä»¤å®Œæˆéƒ¨ç½²ï¼Œéå¸¸é«˜æ•ˆã€‚è®¸å¤šå¼€æºåšå®¢éƒ¨ç½²è„šæœ¬å’Œå·¥å…·ä¹Ÿæ˜¯åŸºäºç±»ä¼¼åŸç†å®ç°çš„ã€‚åˆæ¬¡è®¾ç½®å¯èƒ½ç¨æ˜¾ç¹çï¼Œä½†ä¸€æ—¦é…ç½®æˆåŠŸï¼Œæ—¥å¸¸æ›´æ–°å°†éå¸¸ä¾¿æ·ã€‚\næç¤ºï¼š ä½¿ç”¨ Git è‡ªåŠ¨éƒ¨ç½²éœ€ç¡®ä¿æœåŠ¡å™¨å¼€æ”¾ Git æ‰€ç”¨çš„ SSH ç«¯å£ï¼ˆé»˜è®¤ä¸º 22ï¼‰ï¼Œå¹¶é…ç½®å¥½å…¬é’¥å…å¯†ç™»å½•ï¼Œä»¥ä¾¿ Hexo åœ¨æœ¬åœ°èƒ½é¡ºåˆ©æ¨é€åˆ°æœåŠ¡å™¨ã€‚å¦‚æœä½ çš„æœåŠ¡å™¨ SSH ç«¯å£ä¸æ˜¯ 22ï¼Œå¯åœ¨éƒ¨ç½²é…ç½®ä¸­åŠ å…¥ç«¯å£å·æˆ–åœ¨ .ssh/config ä¸­é…ç½®åˆ«åã€‚å¯¹äºä¸ç†Ÿæ‚‰ Git é’©å­çš„æ–°æ‰‹ï¼Œä¹Ÿå¯ä»¥è€ƒè™‘ä½¿ç”¨ç®€å•çš„ rsync è„šæœ¬åŒæ­¥æ–‡ä»¶æˆ–å€ŸåŠ© CI å¹³å°å®ç°éƒ¨ç½²ï¼Œä½†åŸç†ç±»ä¼¼ã€‚\n\n6. ç»´æŠ¤ä¸ä¼˜åŒ–\nåšå®¢æ­å»ºå®Œæˆå¹¶ä¸æ„å‘³ç€ä¸€åŠ³æ°¸é€¸ï¼Œå®šæœŸçš„ç»´æŠ¤å’Œä¼˜åŒ–èƒ½ä¿è¯åšå®¢ç¨³å®šã€å®‰å…¨ï¼Œå¹¶æŒç»­æå‡ç”¨æˆ·ä½“éªŒã€‚\n\næ’ä»¶æ‰©å±•ï¼š Hexo æ‹¥æœ‰ä¸°å¯Œçš„æ’ä»¶ç”Ÿæ€ï¼Œå¯æ ¹æ®éœ€è¦å®‰è£…æ’ä»¶ä»¥å¢å¼ºåŠŸèƒ½ã€‚\nå¤‡ä»½ä¸ç‰ˆæœ¬æ§åˆ¶ï¼š ä½¿ç”¨ Git ç®¡ç†åšå®¢æºç ï¼Œå®šæœŸå¤‡ä»½ã€‚\næ›´æ–°ä¸å‡çº§ï¼š å…³æ³¨ Hexo çš„ç‰ˆæœ¬æ›´æ–°ã€æ’ä»¶æ›´æ–°ç­‰ã€‚\n\n","categories":["å…¶å®ƒ"]},{"title":"InstructCoder: Instruction Tuning Large Language Models for Code Editing","url":"/2025/11/22/paper/InstructCoder/","content":"\n\nä¸€ã€è®ºæ–‡é€Ÿè§ˆ\nInstructCoder å…³æ³¨çš„æ˜¯ã€Œæ ¹æ®è‡ªç„¶è¯­è¨€æŒ‡ä»¤å¯¹ç°æœ‰ä»£ç è¿›è¡Œä¿®æ”¹ã€è¿™ä¸€ç±»ä»£ç ç¼–è¾‘ä»»åŠ¡ï¼Œè€Œä¸æ˜¯ä»é›¶ç”Ÿæˆä»£ç ã€‚ä½œè€…å‘ç°ï¼Œå³ä¾¿æ˜¯ GPT-4 çº§åˆ«çš„æ¨¡å‹ï¼Œåœ¨ä¸¥æ ¼çš„æ‰§è¡Œæµ‹è¯•ä¸‹ä¹Ÿç»å¸¸æ— æ³•æ­£ç¡®å®Œæˆç¼–è¾‘ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡æ„å»ºäº†ä¸€ä¸ªæ–°çš„æ‰§è¡Œå¼è¯„æµ‹åŸºå‡† EditEvalï¼Œå¹¶æå‡ºä¸“é—¨ä¸ºä»£ç ç¼–è¾‘è®¾è®¡çš„æŒ‡ä»¤å¾®è°ƒæ•°æ®é›† InstructCoderï¼ŒåŒ…å« 11 ä¸‡+ çœŸå®åœºæ™¯é£æ ¼çš„ä»£ç ç¼–è¾‘æ ·æœ¬ã€‚å®éªŒè¡¨æ˜ï¼šåœ¨ LLaMA / BLOOM ç­‰å¼€æºæ¨¡å‹ä¸Šä½¿ç”¨ LoRA æ–¹å¼ï¼ŒåŸºäº InstructCoder è¿›è¡ŒæŒ‡ä»¤å¾®è°ƒåï¼Œæ¨¡å‹åœ¨ EditEval ä¸Šçš„å‡†ç¡®ç‡å¯ä»¥ä»ä¸ªä½æ•°ç›´æ¥æå‡åˆ°å‡ åä¸ªç™¾åˆ†ç‚¹ï¼Œç”šè‡³è®© Code LLaMA-13B çš„è¡¨ç°æ¥è¿‘ ChatGPTã€‚(arXiv)\näºŒã€è®ºæ–‡ç»“æ„\n\nå¼•è¨€ä¸åŠ¨æœº è¯´æ˜ä»£ç ç¼–è¾‘ä¸ä»£ç è¡¥å…¨çš„å·®å¼‚ï¼ŒæŒ‡å‡ºå½“å‰ç¼ºä¹é’ˆå¯¹ã€Œè‡ªç„¶è¯­è¨€æŒ‡ä»¤ + ä»£ç ç¼–è¾‘ã€çš„ç³»ç»Ÿæ€§æ•°æ®ä¸è¯„æµ‹ï¼Œç»™å‡º InstructCoder ä¸ EditEval çš„æ•´ä½“ç›®æ ‡ã€‚(arXiv)\nç›¸å…³å·¥ä½œ å›é¡¾é€šç”¨ LLMã€ä»£ç  LLMã€æŒ‡ä»¤å¾®è°ƒã€è‡ªæŒ‡ä»¤ï¼ˆSelf-Instructï¼‰å’Œå·²æœ‰çš„ä»£ç ä»»åŠ¡æ•°æ®é›†ï¼ˆå¦‚ HumanEvalã€MBPPã€PIE ç­‰ï¼‰ï¼Œå¯¹æ¯”å®ƒä»¬åœ¨ã€Œæ˜¯å¦é¢å‘ä»£ç ç¼–è¾‘ã€ã€Œæ˜¯å¦æ‰§è¡Œè¯„æµ‹ã€ç­‰ç»´åº¦ä¸Šçš„ä¸è¶³ï¼Œä¸ºæœ¬æ–‡å®šä½åšé“ºå«ã€‚(arXiv)\nEditEvalï¼šä»£ç ç¼–è¾‘è¯„æµ‹åŸºå‡† ä»‹ç» EditEval çš„æ„é€ æ–¹å¼ï¼šä» GitHub commitsã€MBPPã€HumanEval ä¸­æŠ½å–ä»£ç ï¼Œå¯¹æ¯ä¸ªæ ·æœ¬æ„é€ è‡ªç„¶è¯­è¨€ç¼–è¾‘æŒ‡ä»¤å’Œã€Œç¼–è¾‘åçš„å‚è€ƒå®ç°ã€ï¼Œå¹¶é…å¥—è‡ªåŠ¨æµ‹è¯•ç”¨ä¾‹ï¼Œç”¨ã€Œæ˜¯å¦é€šè¿‡æ‰€æœ‰æµ‹è¯•ã€ä½œä¸ºå‡†ç¡®ç‡æŒ‡æ ‡ã€‚è¿™éƒ¨åˆ†é€‚åˆå¸Œæœ›è‡ªå·±å¤ç°è¯„æµ‹ç¯å¢ƒã€æ‰©å±•æ–°æ¨¡å‹æ—¶é‡ç‚¹é˜…è¯»ã€‚(arXiv)\nInstructCoderï¼šæŒ‡ä»¤å¾®è°ƒæ•°æ®æ„å»ºæµç¨‹ è¯¦ç»†è¯´æ˜ä» GitHub commits æŠ½å– seed æ•°æ®ã€ç”¨ ChatGPT è¿›è¡Œè‡ªæŒ‡ä»¤æ‰©å±•ã€å¼•å…¥ã€Œåœºæ™¯æ¡ä»¶ç”Ÿæˆã€ã€ä»¥åŠç”¨ ROUGE-L + MinHash/LSH åšå»é‡å’Œæ¸…æ´—çš„å®Œæ•´æµæ°´çº¿ã€‚è¿™éƒ¨åˆ†å¯¹åšæ•°æ®å·¥ç¨‹ã€æƒ³ä»¿ç…§æ„å»ºè‡ªå®¶ä»£ç ç¼–è¾‘æ•°æ®çš„è¯»è€…éå¸¸å…³é”®ã€‚(arXiv)\næ•°æ®åˆ†æ ä»ä»»åŠ¡å¤šæ ·æ€§ï¼ˆintent / verbï¼‰ã€åœºæ™¯å¤šæ ·æ€§ã€å¤æ‚åº¦ï¼ˆç¼–è¾‘è¡Œæ•°ä¸ç¼–è¾‘æ¯”ä¾‹ï¼‰ã€ä»¥åŠäººå·¥è´¨æ£€ç»“æœç­‰è§’åº¦åˆ†æ InstructCoder çš„æ•°æ®ç‰¹æ€§ã€‚è¿™ä¸€èŠ‚å¸®åŠ©ä½ åˆ¤æ–­ã€Œè¿™ç±»æ•°æ®æ˜¯å¦é€‚åˆç›´æ¥æ‹¿æ¥å¾®è°ƒã€ä»¥åŠã€Œéœ€è¦ä¸è¦å†é¢å¤–è¡¥å……è‡ªå·±çš„åœºæ™¯ã€ã€‚(arXiv)\nå®éªŒä¸ç»“æœ è¯´æ˜ä½¿ç”¨çš„åŸºç¡€æ¨¡å‹å®¶æ—ï¼ˆLLaMA / LLaMA-2 / Code LLaMA / BLOOM ç­‰ï¼‰ã€LoRA å¾®è°ƒè®¾ç½®ã€åŸºçº¿æ¨¡å‹ï¼ˆChatGPTã€GPT-4ã€Alpacaã€CodeAlpaca ç­‰ï¼‰ï¼Œå¹¶ç»™å‡ºåœ¨ EditEval ä¸Šã€Œå¾®è°ƒå‰/åã€çš„å‡†ç¡®ç‡å¯¹æ¯”ã€æ•°æ®è§„æ¨¡ç¼©æ”¾å®éªŒã€ä¸åŒç¼–è¾‘æ¯”ä¾‹ä¸‹çš„è¡¨ç°ã€‚é€‚åˆå¸Œæœ›çœ‹åˆ°ã€ŒæŠ•å…¥å¤šå°‘ç®—å€¼å¾—ã€çš„å·¥ç¨‹åŒå­¦é˜…è¯»ã€‚(arXiv)\nç»“è®ºä¸å±€é™ æ€»ç»“ InstructCoder + EditEval çš„è´¡çŒ®ï¼Œå¹¶å¦é™ˆå½“å‰åªè¦†ç›– Python å•æ–‡ä»¶ã€å°è§„æ¨¡ç¼–è¾‘ã€ä¸å«å¤šæ–‡ä»¶ä¸Šä¸‹æ–‡ç­‰å±€é™ï¼Œä¸ºåç»­æ‰©å±•æŒ‡æ˜æ–¹å‘ã€‚(arXiv)\n\n\næ ¸å¿ƒæ€æƒ³ï¼šé’ˆå¯¹ã€Œè‡ªç„¶è¯­è¨€æŒ‡ä»¤é©±åŠ¨çš„ä»£ç ç¼–è¾‘ã€è¿™ä¸€å®é™…å¼€å‘åœºæ™¯ï¼ŒInstructCoder é€šè¿‡è‡ªæŒ‡ä»¤ç”Ÿæˆ + åœºæ™¯æ¡ä»¶ç”Ÿæˆæ„å»ºå‡ºé«˜è´¨é‡æŒ‡ä»¤å¾®è°ƒæ•°æ®ï¼Œå¹¶é…å¥—æ‰§è¡Œå¼è¯„æµ‹åŸºå‡† EditEvalï¼Œç³»ç»ŸéªŒè¯äº†åœ¨åˆé€‚çš„æ•°æ®å’Œè½»é‡å¾®è°ƒç­–ç•¥ä¸‹ï¼Œå¼€æºä»£ç æ¨¡å‹çš„ä»£ç ç¼–è¾‘èƒ½åŠ›å¯ä»¥è¢«å¤§å¹…æ¿€å‘ï¼Œé€¼è¿‘å•†ä¸šé—­æºæ¨¡å‹çš„æ°´å¹³ã€‚(arXiv)\n\n\nä¸‰ã€æ–¹æ³•ä¸ç³»ç»Ÿè®¾è®¡\nInstructCoder çš„æ ¸å¿ƒæ€è·¯å¯ä»¥æ¦‚æ‹¬ä¸ºï¼šå…ˆé€ ä¸€ä¸ªä¸¥æ ¼ã€æ‰§è¡Œé©±åŠ¨çš„è¯„æµ‹åŸºå‡† EditEvalï¼Œç„¶åå›´ç»•è¿™ä¸ªè¯„æµ‹ç›®æ ‡ï¼Œç”¨è‡ªæŒ‡ä»¤æ–¹æ³•æ„å»ºå¤§é‡é«˜å¤šæ ·æ€§ã€é«˜å¤æ‚åº¦çš„ä»£ç ç¼–è¾‘æŒ‡ä»¤æ•°æ®ï¼Œç”¨ LoRA æ–¹å¼å¯¹ç°æœ‰ä»£ç  LLM åšä¸“é—¨çš„æŒ‡ä»¤å¾®è°ƒã€‚ä»å·¥ç¨‹è§†è§’çœ‹ï¼Œå®ƒæ›´åƒæ˜¯ã€Œä¸€ä¸ªæ•°æ®ä¸è®­ç»ƒæµæ°´çº¿è®¾è®¡ã€ï¼Œè€Œä¸æ˜¯æ–°æ¨¡å‹ç»“æ„ã€‚(arXiv)\n3.0 è¦è§£å†³çš„å­é—®é¢˜\n\nå­é—®é¢˜ 1ï¼šå¦‚ä½•æ„é€ ä¸€ä¸ªæ‰§è¡Œå¯éªŒè¯ã€è¦†ç›–å¤šç§ä»£ç ç¼–è¾‘åœºæ™¯çš„è¯„æµ‹åŸºå‡†ï¼Œè€Œä¸æ˜¯åªçœ‹ token çº§åˆ«ç›¸ä¼¼åº¦ï¼Ÿ\nå­é—®é¢˜ 2ï¼šåœ¨æ²¡æœ‰å¤§é‡äººå·¥æ ‡æ³¨çš„å‰æä¸‹ï¼Œå¦‚ä½•æ‰¹é‡è·å¾—ã€Œè‡ªç„¶è¯­è¨€ç¼–è¾‘æŒ‡ä»¤ + è¾“å…¥ä»£ç  + ç¼–è¾‘åä»£ç ã€ä¸‰å…ƒç»„ï¼Ÿ\nå­é—®é¢˜ 3ï¼šå¦‚ä½•ä¿è¯è‡ªåŠ¨ç”Ÿæˆæ•°æ®çš„å¤šæ ·æ€§ä¸æ­£ç¡®æ€§ï¼Œé¿å…æ¨¡å‹å­¦åˆ°ä¸€å †ã€Œæ”¹å˜é‡åã€ã€ŒåŠ  printã€å¼çš„å»‰ä»·ç¼–è¾‘æ¨¡å¼ï¼Ÿ\nå­é—®é¢˜ 4ï¼šå¦‚ä½•ç”¨è¾ƒä½è®¡ç®—æˆæœ¬ï¼Œå°†è¿™ç±»æ•°æ®æœ‰æ•ˆæ³¨å…¥åˆ°ç°æœ‰ä»£ç  LLMï¼Œè€Œä¸å¿…åšä»å¤´ full finetuneï¼Ÿ\n\n3.1 æ ¸å¿ƒæ¨¡å—ä¸€è§ˆ\n\nEditEval æ„é€ æ¨¡å—ï¼šä» GitHubã€MBPPã€HumanEval æŠ½å–ä»£ç ç‰‡æ®µï¼Œäººå·¥ç¼–å†™/æ¶¦è‰²è‡ªç„¶è¯­è¨€ç¼–è¾‘æŒ‡ä»¤ä¸å‚è€ƒç­”æ¡ˆï¼ŒåŠ ä¸Šè‡ªåŠ¨æµ‹è¯•ç”¨ä¾‹ï¼Œå½¢æˆæ‰§è¡Œå¼è¯„æµ‹ä»»åŠ¡ã€‚å¯¹åº”å­é—®é¢˜ 1ã€‚(arXiv)\nSeed æ•°æ®é‡‡é›†æ¨¡å—ï¼šåŸºäº BigQuery æœé›† Python ä»“åº“ä¸­çš„ commitï¼Œç­›é€‰å‡ºå•æ–‡ä»¶ã€å•ä»£ç å—å˜æ›´çš„è®°å½•ï¼Œç”¨ Codex è¾…åŠ©ä¿®æ­£å«ç³Šçš„ commit messageï¼Œæœ€ç»ˆå¾—åˆ°çº¦ 634 æ¡é«˜è´¨é‡åˆå§‹ç¼–è¾‘æ ·æœ¬ï¼Œå†åŠ ä¸Šä¸€æ‰¹äººå·¥ç­›é€‰çš„ ChatGPT ç”Ÿæˆæ ·æœ¬ã€‚å¯¹åº”å­é—®é¢˜ 2ã€‚(arXiv)\nSelf-Instruct å¼æŒ‡ä»¤è‡ªä¸¾æ¨¡å—ï¼šåœ¨æ¯ä¸€è½®è‡ªä¸¾ä¸­ï¼Œä» seed ä¸å·²æœ‰ç”Ÿæˆæ ·æœ¬ä¸­é‡‡æ ·è‹¥å¹²æŒ‡ä»¤ï¼Œé€šè¿‡ few-shot prompt è®© ChatGPT ç”Ÿæˆæ–°æŒ‡ä»¤ï¼Œé€æ­¥æ‰©å±•ä»»åŠ¡ç©ºé—´ã€‚å¯¹åº”å­é—®é¢˜ 2ã€3ã€‚(arXiv)\nåœºæ™¯æ¡ä»¶ä»£ç ç”Ÿæˆæ¨¡å—ï¼šå…ˆè®© LLM ç”Ÿæˆã€ŒçœŸå®ä¸–ç•Œåœºæ™¯ã€æè¿°ï¼Œå†åŸºäºåœºæ™¯ + æŒ‡ä»¤ç”Ÿæˆæˆå¯¹çš„è¾“å…¥/è¾“å‡ºä»£ç ï¼Œä½¿æ ·æœ¬åœ¨é¡¹ç›®ç»“æ„ã€å˜é‡å‘½åç­‰å±‚é¢æ›´è´´è¿‘çœŸå®å·¥ç¨‹ã€‚å¯¹åº”å­é—®é¢˜ 3ã€‚(arXiv)\nå»é‡ä¸è´¨é‡æ§åˆ¶æ¨¡å—ï¼šå¯¹æŒ‡ä»¤ä½¿ç”¨ ROUGE-L é˜ˆå€¼å»é‡ï¼Œå¯¹ä»£ç ä½¿ç”¨ MinHash + LSH æ§åˆ¶ Jaccard ç›¸ä¼¼åº¦ï¼Œå¹¶é€šè¿‡äººå·¥æŠ½æ ·æ£€éªŒæŒ‡ä»¤æœ‰æ•ˆæ€§ä¸è¾“å‡ºæ­£ç¡®æ€§ã€‚å¯¹åº”å­é—®é¢˜ 3ã€‚(arXiv)\nLoRA å¾®è°ƒæ¨¡å—ï¼šåœ¨ LLaMA / LLaMA-2 / Code LLaMA / BLOOM ç­‰åŸºç¡€æ¨¡å‹ä¸Šï¼Œä»…åœ¨ Q/K/V/O ç­‰çº¿æ€§å±‚ä¸Šæ’å…¥ LoRA ä½ç§©çŸ©é˜µï¼Œä»¥è¾ƒä½æ˜¾å­˜æˆæœ¬å®ŒæˆæŒ‡ä»¤å¾®è°ƒã€‚å¯¹åº”å­é—®é¢˜ 4ã€‚(arXiv)\n\n3.2 æ•°æ®æµä¸æ§åˆ¶æµ\næŒ‰ç…§ã€Œæ•°æ® â†’ ä»»åŠ¡ â†’ è®­ç»ƒ â†’ è¯„æµ‹ã€è§†è§’ï¼Œå¯ä»¥æŠŠæ•´ä¸ªæµç¨‹æ‹†æˆä»¥ä¸‹æ­¥éª¤ï¼š\n\nåŸå§‹ä»£ç æ•°æ®æ”¶é›†\n\n\n1.1 ä½¿ç”¨ BigQuery æŠ½å–æ»¡è¶³ã€ŒPythonã€æ˜Ÿæ ‡æ•°â‰¥100ã€å¼€æºè®¸å¯ã€çº¦æŸçš„ä»“åº“æäº¤è®°å½•ã€‚\n1.2 ä½¿ç”¨ git diff æ£€æµ‹å•æ–‡ä»¶ã€å•ä»£ç å—çš„ä¿®æ”¹ï¼Œè¿‡æ»¤æ‰å·¨å¤§æˆ–è·¨å¤šæ–‡ä»¶çš„ commitsã€‚(arXiv)\n\n\nSeed æ ·æœ¬æ„å»º\n\n\n2.1 å¯¹äºè¯­ä¹‰ä¸æ¸…çš„ commit messageï¼Œç”¨ Codex è‡ªåŠ¨ç”Ÿæˆæ›´ç²¾ç¡®çš„æè¿°ï¼Œç„¶åäººå·¥ä¿®è®¢ã€‚\n2.2 å°†ã€Œcommit message â†’ ç¼–è¾‘å‰ä»£ç  â†’ ç¼–è¾‘åä»£ç ã€ç»Ÿä¸€è½¬æ¢ä¸ºã€Œè‡ªç„¶è¯­è¨€æŒ‡ä»¤ â†’ è¾“å…¥ä»£ç  â†’ è¾“å‡ºä»£ç ã€å½¢å¼ã€‚\n2.3 é¢å¤–è®© ChatGPT ç”Ÿæˆä¸€æ‰¹é«˜è´¨é‡ç¼–è¾‘æ ·æœ¬ï¼Œç»äººå·¥ç­›é€‰ååŠ å…¥ seed é›†ã€‚(arXiv)\n\n\nè‡ªæŒ‡ä»¤æ‰©å±•\n\n\n3.1 åœ¨æ¯æ¬¡è¿­ä»£ä¸­ï¼ŒéšæœºæŠ½å–è‹¥å¹² seed æŒ‡ä»¤ä¸éƒ¨åˆ†å·²æœ‰ç”ŸæˆæŒ‡ä»¤ï¼Œæ„é€ æˆ few-shot æç¤ºã€‚\n3.2 ç”¨ ChatGPT ç”Ÿæˆæ–°çš„ä»£ç ç¼–è¾‘æŒ‡ä»¤ï¼Œè¦†ç›–å¤šç§ç¼–è¾‘æ„å›¾ï¼ˆæ·»åŠ åŠŸèƒ½ã€æ€§èƒ½ä¼˜åŒ–ã€é‡æ„ã€å¢åŠ æ³¨é‡Šç­‰ï¼‰ã€‚\n3.3 æŠŠæ–°æŒ‡ä»¤åŠ å…¥å€™é€‰æŒ‡ä»¤æ± ã€‚(arXiv)\n\n\nåœºæ™¯æ¡ä»¶æ ·æœ¬ç”Ÿæˆ\n\n\n4.1 å¯¹æ¯æ¡æŒ‡ä»¤ï¼Œè®© LLM å…ˆç”Ÿæˆè‹¥å¹²ã€Œåœºæ™¯æè¿°ã€ï¼ˆä¾‹å¦‚ï¼šweb åç«¯æœåŠ¡ã€å›¾åƒå¤„ç†è„šæœ¬ã€å®‰å…¨æ‰«æå·¥å…·ç­‰ï¼‰ã€‚\n4.2 éšæœºé€‰æ‹©ä¸€ä¸ªåœºæ™¯ï¼Œå† prompt LLM æ ¹æ®ã€Œåœºæ™¯ + æŒ‡ä»¤ã€ç”Ÿæˆè¾“å…¥/è¾“å‡ºä»£ç å¯¹ã€‚\n4.3 å¯¹ç”Ÿæˆæ ·æœ¬åšåŸºæœ¬åˆæ³•æ€§æ£€æŸ¥ï¼ˆèƒ½å¦è§£æã€æ˜¯å¦åŒ…å«æ ¸å¿ƒæ”¹åŠ¨ï¼‰ã€‚(arXiv)\n\n\nå»é‡ä¸è´¨é‡æ§åˆ¶\n\n\n5.1 å¯¹æŒ‡ä»¤æ–‡æœ¬ï¼šè®¡ç®— ROUGE-Lï¼Œç›¸ä¼¼åº¦è¶…è¿‡ 0.7 çš„æ ·æœ¬åªä¿ç•™ä¸€ä¸ªã€‚\n5.2 å¯¹ä»£ç ï¼šä½¿ç”¨ MinHash + LSH åšè¿‘é‡å¤æ£€æŸ¥ï¼ŒJaccard ç›¸ä¼¼åº¦è¶…è¿‡ 0.75 çš„æ ·æœ¬å»é‡ã€‚\n5.3 éšæœºæŠ½æ · 200 æ¡æ•°æ®ï¼Œè®©äººå·¥è¯„ä¼°ã€ŒæŒ‡ä»¤æ˜¯å¦æ¸…æ™°ã€ä¸ã€Œè¾“å‡ºæ˜¯å¦ç¬¦åˆæŒ‡ä»¤ã€ï¼Œä¿è¯æ•°æ®æ•´ä½“å¯é æ€§ã€‚(arXiv)\n\n\næ•°æ®åˆ’åˆ†ä¸è®­ç»ƒå‡†å¤‡\n\n\n6.1 å°†æœ€ç»ˆçº¦ 11.4 ä¸‡æ¡æ ·æœ¬æŒ‰ 95%/5% åˆ’åˆ†ä¸ºè®­ç»ƒé›†/éªŒè¯é›†ã€‚\n6.2 ç»Ÿä¸€æ ¼å¼ä¸ºã€Œè‡ªç„¶è¯­è¨€æŒ‡ä»¤ + è¾“å…¥ä»£ç ã€ä½œä¸ºä¸Šä¸‹æ–‡ï¼Œã€Œè¾“å‡ºä»£ç ã€ä½œä¸ºæ¨¡å‹éœ€è¦é¢„æµ‹çš„ç›®æ ‡åºåˆ—ã€‚\n\n\nLoRA æŒ‡ä»¤å¾®è°ƒ\n\n\n7.1 åœ¨é€‰å®šçš„åŸºç¡€æ¨¡å‹ï¼ˆå¦‚ Code LLaMA-13Bï¼‰ä¸Šï¼Œä¸º Q/K/V/O ç­‰å±‚æ’å…¥ LoRA ä½ç§©çŸ©é˜µï¼Œåªè®­ç»ƒæ–°å¢å‚æ•°ã€‚\n7.2 ä½¿ç”¨æ ‡å‡†è‡ªå›å½’æŸå¤±ï¼Œå¯¹è¾“å‡ºä»£ç  tokens è®¡ç®—äº¤å‰ç†µï¼Œè®­ç»ƒç›´åˆ°åœ¨éªŒè¯é›†ä¸Šæ”¶æ•›ã€‚(arXiv)\n\n\nEditEval è¯„æµ‹\n\n\n8.1 å¯¹æ¯ä¸ª EditEval ä»»åŠ¡ï¼ŒæŠŠã€ŒæŒ‡ä»¤ + è¾“å…¥ä»£ç ã€ç»™åˆ°æ¨¡å‹ï¼Œè®©å…¶ç”Ÿæˆå€™é€‰è¾“å‡ºä»£ç ã€‚\n8.2 å°†å€™é€‰ä»£ç ä¸å‚è€ƒå®ç°ä¸€èµ·ç¼–è¯‘/æ‰§è¡Œï¼Œä½¿ç”¨é¢„å…ˆç¼–å†™çš„å•å…ƒæµ‹è¯•åˆ¤æ–­æ˜¯å¦æ­£ç¡®ã€‚\n8.3 ç»Ÿè®¡æ‰€æœ‰ä»»åŠ¡ä¸Šé€šè¿‡ç‡ï¼Œå¾—åˆ° accuracy æŒ‡æ ‡ã€‚(arXiv)\n\n\næ‰©å±•å®éªŒä¸åˆ†æ\n\n\n9.1 åšã€Œè®­ç»ƒé›†è§„æ¨¡ç¼©æ”¾ã€å®éªŒï¼ˆ1% / 10% / 100%ï¼‰è§‚å¯Ÿæ€§èƒ½ä¸æ•°æ®é‡çš„å…³ç³»ã€‚\n9.2 æŒ‰ç¼–è¾‘æ¯”ä¾‹åˆ†æ¡¶ï¼Œç”¨ GPT-4 å¯¹ç¼–è¾‘è´¨é‡æ‰“åˆ†ï¼Œçœ‹ã€Œæ”¹åŠ¨å¤šå°‘è¡Œã€ä¸æ¨¡å‹éš¾åº¦çš„å…³ç³»ã€‚(arXiv)\n\n3.3 å…³é”®å‡è®¾ä¸é€‚ç”¨èŒƒå›´\n\nå•æ–‡ä»¶ã€å•ä»£ç å—ä¸Šä¸‹æ–‡è¶³ä»¥è¦†ç›–ä¸»è¦ç¼–è¾‘éœ€æ±‚\n\nå‡è®¾ï¼šå¾ˆå¤šæœ‰ä»£è¡¨æ€§çš„ä»£ç ç¼–è¾‘ä»»åŠ¡ï¼ˆå¢åŠ æ³¨é‡Šã€é‡æ„å‡½æ•°ã€ä¼˜åŒ–é€»è¾‘ï¼‰å¯ä»¥åœ¨å•æ–‡ä»¶ã€å•ç‰‡æ®µä¸Šä¸‹æ–‡ä¸­å®Œæˆã€‚\nå¯èƒ½å¤±æ•ˆçš„åœºæ™¯ï¼šæ¶‰åŠè·¨æ¨¡å—é‡æ„ã€å…¬å…±åº“ API è¿ç§»ã€å¤§å‹é‡æ„ï¼ˆä¾‹å¦‚ã€ŒæŠŠé¡¹ç›®çš„åŒæ­¥ IO æ¢æˆ asyncã€ï¼‰æ—¶ï¼Œå•æ–‡ä»¶è§†è§’ä¸å¤Ÿï¼Œæ¨¡å‹å¯èƒ½åœ¨å…¨å±€ä¸€è‡´æ€§ä¸Šå‡ºé”™ã€‚(arXiv)\n\nPython è¯­è¨€å…·æœ‰ä»£è¡¨æ€§ï¼Œå¯è¿ç§»åˆ°å…¶ä»–è¯­è¨€\n\nå‡è®¾ï¼šä»¥ Python ä¸ºä¸»æ„å»ºç¼–è¾‘æ•°æ®ï¼Œä¾ç„¶èƒ½ç»™æ¨¡å‹æä¾›é€šç”¨çš„ã€Œç¼–è¾‘èƒ½åŠ›æ¨¡å¼ã€ï¼Œä¹‹åå¯ä»¥è¿ç§»åˆ°å…¶ä»–è¯­è¨€ã€‚\nå¯èƒ½å¤±æ•ˆçš„åœºæ™¯ï¼šå¼ºç±»å‹è¯­è¨€ï¼ˆC++/Rust/Javaï¼‰ä¸­ï¼Œç±»å‹ç³»ç»Ÿä¸æ„å»ºç³»ç»Ÿçº¦æŸæ›´å¼ºï¼Œã€Œåªæ”¹ä¸€å¤„ã€å¯èƒ½åœ¨ç¼–è¯‘æœŸå°±æŒ‚ï¼Œè¿ç§»æ•ˆæœä¸ä¸€å®šå¥½ï¼Œéœ€è¦ç»“åˆè¯­è¨€ç‰¹æ€§è¿›ä¸€æ­¥å¾®è°ƒã€‚(arXiv)\n\nè‡ªæŒ‡ä»¤ç”Ÿæˆ + å¤§æ¨¡å‹åˆæˆæ•°æ®çš„è´¨é‡è¶³å¤Ÿé«˜\n\nå‡è®¾ï¼šåœ¨æœ‰ seed æ•°æ®çº¦æŸçš„å‰æä¸‹ï¼Œè®© ChatGPT è¿™ç±»æ¨¡å‹æ‰©å†™æŒ‡ä»¤ä¸æ ·æœ¬ï¼Œå¯ä»¥è·å¾—åˆ†å¸ƒä¸çœŸå®å¼€å‘ç›¸è¿‘çš„æ•°æ®ã€‚\nå¯èƒ½å¤±æ•ˆçš„åœºæ™¯ï¼šå¦‚æœç›®æ ‡åœºæ™¯ä¸­æœ‰å¤§é‡é¢†åŸŸç‰¹å®šæ¡†æ¶ï¼ˆé‡‘èé£æ§ DSLã€å†…éƒ¨æœåŠ¡æ¡†æ¶ç­‰ï¼‰æˆ–å¤æ‚éåŠŸèƒ½çº¦æŸï¼ˆæ€§èƒ½ SLAã€å®‰å…¨åˆè§„ï¼‰ï¼Œç¼ºä¹çœŸå®é¡¹ç›®ä»£ç ï¼Œä¼šå‡ºç° domain gapï¼Œå¾®è°ƒåæ¨¡å‹åœ¨çœŸå®åº“ä¸Šçš„è¡¨ç°å¯èƒ½å¤§å¹…ä¸‹é™ã€‚(arXiv)\n\nLoRA è¶³ä»¥å­¦ä¹ ä»£ç ç¼–è¾‘èƒ½åŠ›ï¼Œè€Œä¸ç ´ååŸºç¡€æ¨¡å‹çš„é€šç”¨èƒ½åŠ›\n\nå‡è®¾ï¼šåªåœ¨å°‘é‡å±‚ä¸Šæ’å…¥ LoRAï¼Œé’ˆå¯¹ä»£ç ç¼–è¾‘ä»»åŠ¡å¾®è°ƒï¼Œå¯ä»¥åœ¨ä¿ç•™åŸºç¡€æ¨¡å‹é€šç”¨ä»£ç ç†è§£/ç”Ÿæˆèƒ½åŠ›çš„åŒæ—¶ï¼Œå¢å¼ºç¼–è¾‘èƒ½åŠ›ã€‚\nå¯èƒ½å¤±æ•ˆï¼šå¦‚æœ InstructCoder çš„åˆ†å¸ƒä¸åŸå§‹é¢„è®­ç»ƒè¯­æ–™å·®å¼‚è¾ƒå¤§ï¼Œä¸”ç¼–è¾‘ä»»åŠ¡æœ‰æ˜æ˜¾ã€Œé£æ ¼åå·®ã€ï¼ˆæ¯”å¦‚å¤§é‡æ•™å­¦é£æ ¼æ³¨é‡Šï¼‰ï¼ŒLoRA å±‚å¯èƒ½ä¼šå¯¹è¾“å‡ºé£æ ¼é€ æˆæ˜æ˜¾åç§»ï¼Œåœ¨éƒ¨åˆ†è¯„æµ‹ä¸­è¢«è§†ä¸ºã€Œé€€åŒ–ã€ã€‚\n\næ‰§è¡Œå¼è¯„æµ‹å¯ä½œä¸ºä¸»è¦æŒ‡æ ‡è¡¡é‡ç¼–è¾‘è´¨é‡\n\nå‡è®¾ï¼šåªè¦æ–°ä»£ç é€šè¿‡äº†æ‰€æœ‰è‡ªåŠ¨æµ‹è¯•ï¼Œå°±å¯ä»¥è®¤ä¸ºç¼–è¾‘æ˜¯æ­£ç¡®çš„ã€‚\nå¯èƒ½å¤±æ•ˆï¼šæµ‹è¯•è¦†ç›–ä¸è¶³æ—¶ï¼Œæ¨¡å‹å¯èƒ½é€šè¿‡æ·»åŠ å¤šä½™ä»£ç æˆ–ç¡¬ç¼–ç  hack çš„æ–¹å¼é€šè¿‡æµ‹è¯•ï¼Œä½†ä»å·¥ç¨‹è§†è§’çœ‹å±äºã€Œç³Ÿç³•å®ç°ã€ã€‚\n\n\n3.4 æ•°å­¦å…¬å¼ä¸ç®—æ³•è§£è¯»\nè¿™ç¯‡å·¥ä½œæ•´ä½“ä¸Šæ˜¯ä¸€ä¸ªåç³»ç»Ÿä¸æ•°æ®å·¥ç¨‹çš„è®¾è®¡ï¼Œå¹¶æ²¡æœ‰å¤æ‚çš„ä¼˜åŒ–ç®—æ³•æˆ–æ–°ç›®æ ‡å‡½æ•°ã€‚æ–¹æ³•éƒ¨åˆ†çš„æ•°å­¦ç¬¦å·ä¸»è¦å‡ºç°åœ¨æ•°æ®åˆ†æä¸­ï¼Œç”¨äºå®šä¹‰ï¼š\n\nä¸åŒçš„è¡Œæ•°ï¼ˆdiffering linesï¼‰ï¼šåŸºäº difflib å¯¹è¾“å…¥/è¾“å‡ºä»£ç åšè¡Œçº§ diffï¼Œç»Ÿè®¡å‘ç”Ÿå˜åŒ–çš„è¡Œæ•°ã€‚\nç¼–è¾‘æ¯”ä¾‹ï¼ˆedit ratioï¼‰ï¼šç”¨ã€Œå‘ç”Ÿå˜åŒ–çš„è¡Œæ•°ã€ç›¸å¯¹æ•´ä¸ªä»£ç é•¿åº¦çš„æ¯”å€¼ï¼Œè¡¡é‡ä¸€æ¬¡ç¼–è¾‘çš„è§„æ¨¡å¤§å°ã€‚(arXiv)\n\nä½œè€…å¹¶æœªåœ¨æ­£æ–‡ä¸­ç»™å‡ºå¤æ‚æ¨å¯¼ï¼Œåªæ˜¯ç”¨è¿™äº›æŒ‡æ ‡åšç»Ÿè®¡åˆ†æï¼Œå› æ­¤è¿™é‡Œä¸å†å¼ºè¡Œå†™å‡ºå…¬å¼ç»†èŠ‚ï¼›ä»å·¥ç¨‹è§’åº¦ç†è§£ä¸ºï¼š\n\næŠŠæ¯ä¸ªæ ·æœ¬çš„ã€Œæ”¹åŠ¨è¡Œæ•°ã€å’Œã€Œæ”¹åŠ¨å æ¯”ã€å½“ä½œéš¾åº¦ proxyï¼Œç”¨æ¥è¡¡é‡ InstructCoder çš„ä»»åŠ¡å¤æ‚åº¦æ˜¯å¦è¿‡äºç®€å•æˆ–æç«¯ã€‚\n\nä¸å¸¸è§è®­ç»ƒæ ˆçš„å¯¹åº”å…³ç³»\n\nEditEval + InstructCoder çš„æ•´ä½“è®¾è®¡ï¼Œå¯¹åº”æˆ‘ä»¬è®­ç»ƒæ ˆä¸­çš„ï¼š\n\næ•°æ®æ‰“åŒ…ä¸é¢„å¤„ç†å±‚ï¼šä»ä»“åº“ commit / è„šæœ¬ / benchmark ä¸­æŠ½æ ·ã€æ¸…æ´—ã€æ„é€ æˆã€ŒæŒ‡ä»¤ + ä¸Šä¸‹æ–‡ + ç›®æ ‡ã€ä¸‰å…ƒç»„ã€‚\nä»»åŠ¡å®šä¹‰ä¸æŸå¤±å±‚ï¼šæŠŠã€Œç¼–è¾‘ã€å½’çº¦ä¸ºæ¡ä»¶ç”Ÿæˆä»»åŠ¡ P(code_after | instruction, code_before)ï¼Œç”¨æ ‡å‡†è‡ªå›å½’ loss è®­ç»ƒã€‚\nå‚æ•°é«˜æ•ˆåŒ–å±‚ï¼šç”¨ LoRA/adapter ç±»æ–¹æ³•å®ç°ä½æˆæœ¬æŒ‡ä»¤å¾®è°ƒã€‚\nè¯„æµ‹ä¸ç›‘æ§å±‚ï¼šé€šè¿‡æ‰§è¡Œæµ‹è¯•å’Œ GPT-4 æ‰“åˆ†ï¼Œç›‘æ§ edit accuracy ä¸ edit ratio ä¸Šçš„è¡¨ç°ã€‚\n\n\n\nå››ã€å»ºæ¨¡æ–¹å¼ä¸è¯„ä¼°æŒ‡æ ‡\n4.1 é—®é¢˜æ˜¯å¦‚ä½•å½¢å¼åŒ–çš„ï¼Ÿ\nè®ºæ–‡æŠŠä»£ç ç¼–è¾‘ä»»åŠ¡å½¢å¼åŒ–ä¸ºä¸€ä¸ªæ¡ä»¶ç”Ÿæˆé—®é¢˜ï¼šç»™å®šè‡ªç„¶è¯­è¨€æŒ‡ä»¤ (I) å’Œç°æœ‰ä»£ç ç‰‡æ®µ (C_{})ï¼Œæ¨¡å‹éœ€è¦ç”Ÿæˆä¿®æ”¹åçš„ä»£ç  (C_{})ã€‚ä¼˜åŒ–ç›®æ ‡å°±æ˜¯æœ€å¤§åŒ–åœ¨ InstructCoder æ•°æ®é›†ä¸Šçš„æ¡ä»¶å¯¹æ•°ä¼¼ç„¶ï¼š\n[ P(C_{} I, C_{})]\nå®ç°ä¸Šä½¿ç”¨æ ‡å‡†è‡ªå›å½’è¯­è¨€æ¨¡å‹ï¼Œè®­ç»ƒæ—¶æŠŠã€ŒæŒ‡ä»¤ + è¾“å…¥ä»£ç ã€æ‹¼åœ¨ä¸€èµ·ä½œä¸ºä¸Šä¸‹æ–‡ï¼Œè®©æ¨¡å‹åªåœ¨ã€Œè¾“å‡ºä»£ç ã€éƒ¨åˆ†ç´¯ç§¯ lossã€‚å¾®è°ƒç­–ç•¥é‡‡ç”¨ LoRAï¼Œåœ¨ Transformer çš„éƒ¨åˆ†çº¿æ€§å±‚ä¸Šæ’å…¥ä½ç§©çŸ©é˜µï¼Œä»…æ›´æ–°è¿™äº›æ–°å¢å‚æ•°ï¼Œä»¥æ˜¾è‘—é™ä½æ˜¾å­˜å’Œè®­ç»ƒæˆæœ¬ã€‚(arXiv)\nå»ºæ¨¡æ—¶çš„ç®€åŒ–åŒ…æ‹¬ï¼š\n\nä¸æ˜¾å¼å»ºæ¨¡ã€Œç¼–è¾‘æ“ä½œåºåˆ—ã€ï¼ˆå¦‚æ’å…¥/åˆ é™¤/æ›¿æ¢ï¼‰ï¼Œè€Œæ˜¯ç›´æ¥åœ¨ token åºåˆ—ç©ºé—´ç”Ÿæˆå®Œæ•´çš„ C_afterï¼›\nåªè€ƒè™‘å•è½®æŒ‡ä»¤ï¼Œæ²¡æœ‰å¯¹è¯å¼å¤šè½®æ¾„æ¸…ï¼›\nä¸å¯¹æ‰§è¡Œç»“æœæ˜¾å¼å»ºæ¨¡ï¼ˆä¾‹å¦‚ RL from executionï¼‰ï¼Œè€Œæ˜¯ç”¨æ‰§è¡Œæµ‹è¯•åªä½œä¸ºè¯„ä¼°ï¼Œä¸è¿›å…¥è®­ç»ƒé—­ç¯ã€‚\n\n4.2 æ ¸å¿ƒè¯„ä¼°æŒ‡æ ‡\nè®ºæ–‡ç”¨åˆ°çš„å…³é”®æŒ‡æ ‡åŒ…æ‹¬ï¼š(arXiv)\n\næ‰§è¡Œå‡†ç¡®ç‡ï¼ˆEditEval Accuracyï¼‰\n\nå®šä¹‰ï¼šåœ¨ EditEval ä¸Šï¼Œæ¨¡å‹ç”Ÿæˆçš„ä»£ç èƒ½é€šè¿‡æ‰€æœ‰å•å…ƒæµ‹è¯•çš„æ ·æœ¬æ¯”ä¾‹ã€‚\nå«ä¹‰ï¼šç›´æ¥è¡¡é‡ã€Œè¿™æ¬¡ç¼–è¾‘æ˜¯å¦çœŸçš„æŠŠåŠŸèƒ½æ”¹å¯¹äº†ã€ï¼Œæ˜¯æœ€è´´è¿‘å·¥ç¨‹å®è·µçš„æŒ‡æ ‡ã€‚\n\né›¶æ ·æœ¬ vs å¾®è°ƒå‰åå¢ç›Šï¼ˆÎ” Accuracyï¼‰\n\nå®šä¹‰ï¼šåŒä¸€ä¸ªåŸºç¡€æ¨¡å‹åœ¨ EditEval ä¸Šï¼Œå¾®è°ƒå‰åçš„å‡†ç¡®ç‡å·®å€¼ã€‚\nå«ä¹‰ï¼šè¡¡é‡ InstructCoder + LoRA çš„ã€Œçº¯å¾®è°ƒæ”¶ç›Šã€ï¼Œå¸®åŠ©æˆ‘ä»¬åˆ¤æ–­è¿™å¥—æ–¹æ¡ˆæ˜¯å¦å€¼å¾—åœ¨ç°æœ‰ Code LLM ä¸Šè½åœ°ã€‚\n\næ•°æ®è§„æ¨¡ç¼©æ”¾æ›²çº¿\n\nå®šä¹‰ï¼šåœ¨ä½¿ç”¨ 1% / 10% / 100% InstructCoder æ•°æ®å¾®è°ƒæ—¶ï¼Œåœ¨ EditEval ä¸Šçš„å‡†ç¡®ç‡æ›²çº¿ã€‚\nå«ä¹‰ï¼šå‘Šè¯‰æˆ‘ä»¬åœ¨è®­ç»ƒé¢„ç®—æœ‰é™çš„åœºæ™¯ä¸‹ï¼Œä½¿ç”¨å¤šå°‘æ•°æ®æœ€åˆ’ç®—ã€æ˜¯å¦å­˜åœ¨æ˜æ˜¾çš„æ”¶ç›Šé¥±å’Œç‚¹ã€‚\n\nç¼–è¾‘æ¯”ä¾‹åˆ†æ¡¶è¡¨ç°ï¼ˆby Edit Ratioï¼‰\n\nå®šä¹‰ï¼šæŒ‰ç¼–è¾‘æ¯”ä¾‹æŠŠéªŒè¯é›†æ ·æœ¬åˆ’åˆ†ä¸ºå¤šä¸ªåŒºé—´ï¼ˆå¦‚å°æ”¹åŠ¨/ä¸­ç­‰/å¤§æ”¹åŠ¨ï¼‰ï¼Œä½¿ç”¨ GPT-4 å¯¹ç”Ÿæˆç»“æœæ‰“åˆ†ï¼Œæ¯”è¾ƒä¸åŒ bucket ä¸Šçš„è¡¨ç°ã€‚\nå«ä¹‰ï¼šå¸®åŠ©åˆ†ææ¨¡å‹åœ¨ã€Œåªæ”¹å¾ˆå°‘å‡ è¡Œã€å’Œã€Œå¤§è§„æ¨¡ refactorã€æ—¶çš„ä¸åŒèƒ½åŠ›ï¼Œå¤šæ•°æ¨¡å‹åœ¨å°æ¯”ä¾‹ç¼–è¾‘ä¸Šå®¹æ˜“èµ°ã€Œç›´æ¥å¤åˆ¶è¾“å…¥ã€çš„æ·å¾„ã€‚\n\næ•°æ®è´¨é‡äººå·¥è¯„ä¼°é€šè¿‡ç‡\n\nå®šä¹‰ï¼šåœ¨äººç±»æŠ½æ ·è¯„å®¡ä¸­ï¼Œã€ŒæŒ‡ä»¤æœ‰æ•ˆã€å’Œã€Œè¾“å‡ºç¬¦åˆæŒ‡ä»¤ã€çš„æ¯”ä¾‹ã€‚\nå«ä¹‰ï¼šä¿è¯ InstructCoder æœ¬èº«ä¸æ˜¯ä¸€å †å™ªå£°ï¼Œå¦åˆ™åç»­æ‰€æœ‰å®éªŒç»“è®ºçš„å¯ä¿¡åº¦éƒ½ä¼šæ‰“æŠ˜ã€‚\n\n\n\näº”ã€ä¸»è¦å®éªŒå‘ç°\n\nå½“å‰é€šç”¨æŒ‡ä»¤æ¨¡å‹åœ¨ä»£ç ç¼–è¾‘ä¸Šè¿œæœªã€Œè§£å†³é—®é¢˜ã€ï¼šåœ¨ EditEval ä¸Šï¼ŒGPT-4 çš„å‡†ç¡®ç‡çº¦ 68.6%ï¼ŒChatGPT çº¦ 57.7%ï¼Œè€Œè®¸å¤šå¼€æºæŒ‡ä»¤æ¨¡å‹ï¼ˆAlpaca / LLaMA+CodeAlpacaï¼‰åœ¨ 7B / 13B è§„æ¨¡æ—¶ç”šè‡³ä½äº 20%ã€‚(arXiv)\nInstructCoder å¾®è°ƒå¸¦æ¥æ˜¾è‘—æ”¶ç›Šï¼šåœ¨ BLOOMã€LLaMAã€LLaMA-2ã€Code LLaMA ç­‰åŸºç¡€æ¨¡å‹ä¸Šï¼Œä½¿ç”¨ InstructCoder + LoRA å¾®è°ƒåï¼ŒEditEval å‡†ç¡®ç‡ä»ä¸ªä½æ•°ç›´æ¥æå‡åˆ° 20%â€“50% åŒºé—´ï¼Œå¢ç›Šå¹…åº¦å¸¸å¸¸åœ¨ 20â€“35 ä¸ªç™¾åˆ†ç‚¹ã€‚(arXiv)\nä»£ç é¢„è®­ç»ƒçš„é‡è¦æ€§éå¸¸çªå‡ºï¼šåŒæ ·æ˜¯å¾®è°ƒï¼ŒCode LLaMA ç³»åˆ—æ•´ä½“æ˜¾è‘—ä¼˜äº BLOOM / LLaMA-1 / LLaMA-2ï¼›Code LLaMA-13B + InstructCoder çš„è¡¨ç°è¾¾åˆ° 57.2%ï¼Œå·²ç»éå¸¸æ¥è¿‘ ChatGPTã€‚(arXiv)\næ•°æ®è§„æ¨¡è¶Šå¤§ï¼Œæ”¶ç›Šè¿‘ä¼¼éš log(æ ·æœ¬æ•°) çº¿æ€§å¢é•¿ï¼šåœ¨åªç”¨ 1% æ•°æ®å¾®è°ƒæ—¶ï¼Œæ¨¡å‹å°±èƒ½æ˜æ˜¾è¶…å‡ºé›¶æ ·æœ¬è¡¨ç°ï¼›å¢åŠ åˆ° 10%ã€100% æ—¶ï¼Œå‡†ç¡®ç‡æŒç»­æå‡ï¼Œå‘ˆç°å¹³æ»‘çš„ scaling æ›²çº¿ã€‚\nå°æ”¹åŠ¨åœºæ™¯åè€Œæ›´éš¾ï¼šåœ¨ GPT-4 è¾…åŠ©çš„è´¨é‡è¯„ä¼°ä¸­ï¼Œç¼–è¾‘æ¯”ä¾‹è¶Šå°ï¼Œæ¨¡å‹è¶Šå®¹æ˜“å·æ‡’ç›´æ¥å¤åˆ¶è¾“å…¥ï¼Œå¯¼è‡´ã€Œè¯¥æ”¹ä¸æ”¹ã€çš„é—®é¢˜ï¼›å¤§æ¨¡å‹åœ¨è¿™ä¸€ç‚¹ä¸Šæ¯”å°æ¨¡å‹æ›´é²æ£’ã€‚(arXiv)\n\n5.1 å…³é”®å›¾è¡¨è§£è¯»\n\nEditEval åŸºçº¿ç»“æœè¡¨ï¼ˆç±»ä¼¼ Table 1ï¼‰\n\nç°è±¡ï¼šGPT-4 &gt; GPT-4 Turbo &gt; ChatGPTï¼Œæ˜¾è‘—ä¼˜äºä¸€ä¼—å¼€æºæŒ‡ä»¤æ¨¡å‹ï¼›å¼€æºæ¨¡å‹ä¸­ï¼Œè§„æ¨¡è¶Šå¤§è¡¨ç°è¶Šå¥½ï¼Œä½†æ•´ä½“ä»ç„¶åä½ã€‚\næ”¯æ’‘ä¸»å¼ ï¼šè¯´æ˜ã€Œä»£ç ç¼–è¾‘ã€å¯¹æŒ‡ä»¤ç†è§£ + ä»£ç è¯­ä¹‰ç†è§£çš„è¦æ±‚å¾ˆé«˜ï¼Œç°æœ‰å¼€æºæŒ‡ä»¤æ¨¡å‹å°šæœªé’ˆå¯¹è¿™ç±»ä»»åŠ¡ä¼˜åŒ–ï¼Œå­˜åœ¨å·¨å¤§æå‡ç©ºé—´ã€‚(arXiv)\n\nInstructCoder å¾®è°ƒå‰åå¯¹æ¯”è¡¨ï¼ˆç±»ä¼¼ Table 3ï¼‰\n\nç°è±¡ï¼šä¾‹å¦‚ Code LLaMA-13B ä» 28.9% æå‡åˆ° 57.2%ï¼ŒBLOOM-7B ä» 1.0% æå‡åˆ° 19.6%ï¼ŒLLaMA-33B ä¹Ÿæœ‰ 30%+ çš„ç»å¯¹å¢ç›Šã€‚\næ”¯æ’‘ä¸»å¼ ï¼šè¯æ˜ä¸“é—¨çš„æŒ‡ä»¤å¾®è°ƒæ•°æ®å¯¹äºä»£ç ç¼–è¾‘èƒ½åŠ›è‡³å…³é‡è¦ï¼Œè€Œä¸”è·¨æ¨¡å‹å®¶æ—é€šç”¨ï¼Œåªè¦åŸºç¡€æ¨¡å‹æœ‰ä¸€å®šä»£ç é¢„è®­ç»ƒã€‚(arXiv)\n\næ•°æ®è§„æ¨¡ç¼©æ”¾å›¾ï¼ˆç±»ä¼¼ Figure 5ï¼‰\n\nç°è±¡ï¼š1% æ•°æ®å°±èƒ½å¸¦æ¥ç«‹ç«¿è§å½±çš„æ”¶ç›Šï¼Œ10% â†’ 100% ä¾ç„¶æœ‰ç¨³å®šæå‡ï¼Œä¸”åœ¨ log è½´ä¸Šè¿‘ä¼¼çº¿æ€§ã€‚\næ”¯æ’‘ä¸»å¼ ï¼šåªè¦æ ·æœ¬è´¨é‡é«˜ï¼Œé€‚é‡çš„æ•°æ®å°±èƒ½æ˜¾è‘—æ”¹å–„ä»£ç ç¼–è¾‘èƒ½åŠ›ï¼Œè€Œä¸”ç»§ç»­æ‰©å¢æ•°æ®ä»ç„¶æœ‰æ”¶ç›Šï¼Œä¸ºåç»­ã€Œæ›´å¤§è§„æ¨¡ä»£ç ç¼–è¾‘æŒ‡ä»¤è¯­æ–™ã€æä¾›æ­£å‘ä¿¡å·ã€‚(arXiv)\n\næŒ‰ç¼–è¾‘æ¯”ä¾‹åˆ†æ¡¶çš„è¡¨ç°å›¾ï¼ˆç±»ä¼¼ Figure 6ï¼‰\n\nç°è±¡ï¼šç¼–è¾‘æ¯”ä¾‹å¾ˆä½æ—¶å‡†ç¡®ç‡æ˜¾è‘—ä¸‹é™ï¼›ç¼–è¾‘æ¯”ä¾‹ä¸­é«˜æ—¶æ›´å®¹æ˜“è·å¾—é«˜åˆ†ã€‚\næ”¯æ’‘ä¸»å¼ ï¼šå•çº¯ä¼˜åŒ–ã€Œæ•´ä½“æ­£ç¡®ç‡ã€å¯èƒ½æ©ç›–ã€Œå°æ”¹åŠ¨ã€ä¸Šçš„å›°éš¾ï¼Œéœ€è¦åœ¨æ•°æ®æ„é€ å’ŒæŸå¤±è®¾è®¡ä¸Šæ›´æœ‰é’ˆå¯¹æ€§ï¼ˆæ¯”å¦‚å¢åŠ ã€Œåªæ”¹ä¸€ä¸¤è¡Œã€çš„é«˜æƒé‡æ ·æœ¬ï¼‰ã€‚(arXiv)\n\n\nç»“æœè§£è¯»ä¸è¾¹ç•Œ\næ•´ä½“æ¥çœ‹ï¼Œè®ºæ–‡åœ¨å¯æ§çš„å®éªŒæ¡ä»¶ä¸‹å±•ç¤ºäº†éå¸¸æ¸…æ™°çš„å› æœé“¾æ¡ï¼šé«˜è´¨é‡çš„ä»£ç ç¼–è¾‘æŒ‡ä»¤æ•°æ® + é€‚é…çš„æŒ‡ä»¤å¾®è°ƒç­–ç•¥ï¼Œç¡®å®èƒ½åœ¨æ‰§è¡Œå¼è¯„æµ‹ä¸Šæ˜¾è‘—æŠ¬å‡å¼€æºæ¨¡å‹çš„ä»£ç ç¼–è¾‘èƒ½åŠ›ã€‚ä¸è¿‡ï¼Œå®éªŒä»ç„¶ä¸»è¦é›†ä¸­åœ¨ï¼š\n\nPython å•è¯­è¨€ã€å•æ–‡ä»¶ã€å°åˆ°ä¸­ç­‰è§„æ¨¡çš„ç¼–è¾‘ï¼›\nç¦»çº¿æ‰¹å¤„ç†è¯„ä¼°ï¼Œè€Œä¸æ˜¯äº¤äº’å¼ IDE åœºæ™¯ï¼›\nä»¥ pass@1ã€æ‰§è¡Œé€šè¿‡ç‡ä¸ºä¸»çš„æŒ‡æ ‡ï¼Œå¯¹ä»£ç é£æ ¼ã€å¯ç»´æŠ¤æ€§ç­‰ç»´åº¦å…³æ³¨è¾ƒå°‘ã€‚\n\nåœ¨è¿™äº›è¾¹ç•Œå¤–ï¼ˆå¤šè¯­è¨€ã€å¤§é¡¹ç›®ã€å¤æ‚ refactorã€å¤šè½®å¯¹è¯å¼ç¼–è¾‘ã€å¼ºç±»å‹çº¦æŸç¯å¢ƒç­‰ï¼‰ï¼Œè¿˜éœ€è¦é¢å¤–å®éªŒä¸ç³»ç»ŸåŒ–å·¥ç¨‹å®è·µæ¥éªŒè¯æ³›åŒ–èƒ½åŠ›ã€‚\n\nå…­ã€ä¼˜ç‚¹ä¸å±€é™\näº®ç‚¹ï¼ˆStrengthsï¼‰\n\né—®é¢˜å®šä¹‰æ¸…æ™°ä¸”è´´è¿‘å®ç”¨ï¼šä¸“æ³¨äºã€Œè‡ªç„¶è¯­è¨€æŒ‡ä»¤é©±åŠ¨çš„ä»£ç ç¼–è¾‘ã€è¿™ä¸€å®é™…å¼€å‘ä¸­é«˜é¢‘ä½†é•¿æœŸè¢«å¿½è§†çš„ä»»åŠ¡ã€‚\nè¯„æµ‹è®¾è®¡æ‰å®ï¼šEditEval é‡‡ç”¨æ‰§è¡Œæµ‹è¯•ä½œä¸ºä¸»æŒ‡æ ‡ï¼Œé¿å…äº†ä»…å‡­æ–‡æœ¬ç›¸ä¼¼åº¦è¯„ä¼°ä»£ç è´¨é‡çš„åå·®ã€‚(arXiv)\næ•°æ®æ„å»ºç®¡çº¿å¯å¤ç”¨ï¼šç»“åˆ GitHub commitã€Self-Instructã€åœºæ™¯æ¡ä»¶ç”Ÿæˆå’Œå¤šé‡å»é‡ç­–ç•¥ï¼Œç»™å‡ºäº†ä¸€ä¸ªè¾ƒä¸ºå®Œæ•´çš„ã€Œé«˜è´¨é‡ä»£ç ç¼–è¾‘æŒ‡ä»¤æ•°æ®ã€æ„å»ºæ¨¡æ¿ã€‚(arXiv)\nå®éªŒç»“æœæœ‰æ˜ç¡®å·¥ç¨‹å«ä¹‰ï¼šå±•ç¤ºäº†ä¸åŒåŸºç¡€æ¨¡å‹å®¶æ—ã€ä¸åŒè§„æ¨¡ã€ä¸åŒæ•°æ®é‡ä¸‹çš„è¡¨ç°å·®å¼‚ï¼Œä¸ºå®é™…é€‰æ‹© base model å’Œæ•°æ®è§„æ¨¡æä¾›å‚è€ƒã€‚\nå…³æ³¨ error patternï¼šé€šè¿‡ edit ratio è§†è§’åˆ†ææ¨¡å‹è¡Œä¸ºï¼Œå‘ç°å°æ”¹åŠ¨åœºæ™¯æ›´å®¹æ˜“å‡ºé”™ï¼Œè¿™å¯¹åç»­æ”¹è¿›æŸå¤±å‡½æ•°å’Œæ•°æ®é‡‡æ ·ç­–ç•¥å¾ˆæœ‰æŒ‡å¯¼æ„ä¹‰ã€‚\n\nå±€é™ï¼ˆLimitationsï¼‰\n\nè¯­è¨€ä¸åœºæ™¯è¦†ç›–æœ‰é™ï¼šå½“å‰ä¸»è¦èšç„¦ Python å•è¯­è¨€ï¼Œä¸”å¤šä¸ºå•æ–‡ä»¶ã€å°è§„æ¨¡ç¼–è¾‘ï¼›å¯¹å¤šè¯­è¨€ã€å¤šæ¨¡å—é‡æ„çš„é€‚ç”¨æ€§ä»å¾…éªŒè¯ã€‚\nå¯¹çœŸå®å·¥ä¸šä»£ç åº“çš„è´´åˆåº¦æœ‰é™ï¼šè™½ç„¶ä½¿ç”¨äº† GitHub æ˜Ÿæ ‡ä»“åº“ï¼Œä½†ä»ç„¶æ˜¯æŠ½ç¦»åçš„ç‰‡æ®µï¼Œä¸å¤§å‹ monorepoã€å¤æ‚ä¾èµ–æ ‘é¡¹ç›®å­˜åœ¨å·®è·ã€‚\nåˆæˆæ•°æ®å æ¯”é«˜ï¼šå¤§é‡æ ·æœ¬ç”± ChatGPT ç­‰æ¨¡å‹ç”Ÿæˆï¼Œå³ä¾¿ç»è¿‡å»é‡å’Œäººå·¥æŠ½æ ·è´¨æ£€ï¼Œä¹Ÿéš¾ä»¥å®Œå…¨é¿å…ã€Œæ¨¡å‹è‡ªæˆ‘å¼ºåŒ–ã€çš„é£é™©ã€‚(arXiv)\nè¯„æµ‹ç»´åº¦å•ä¸€ï¼šä¸»è¦çœ‹æ‰§è¡Œæ­£ç¡®æ€§å’Œå°‘é‡äººç±»æ‰“åˆ†ï¼Œå¯¹ä»£ç å¯è¯»æ€§ã€æ€§èƒ½ã€é£æ ¼ä¸€è‡´æ€§ç­‰æŒ‡æ ‡ç¼ºä¹ç³»ç»Ÿè¯„ä¼°ã€‚\nè®­ç»ƒç­–ç•¥ç›¸å¯¹ç®€å•ï¼šä½¿ç”¨æ ‡å‡†è‡ªå›å½’ + LoRA å¾®è°ƒï¼Œæ²¡æœ‰å¼•å…¥ RL from executionã€ç¼–è¾‘æ“ä½œç©ºé—´å»ºæ¨¡ç­‰æ›´åŠ é’ˆå¯¹æ€§çš„ä¼˜åŒ–æ–¹å¼ï¼Œæœ‰è¿›ä¸€æ­¥æŒ–æ˜ç©ºé—´ã€‚\n\n\nä¸ƒã€ä¸šå†…ç›¸å…³å·¥ä½œå¯¹æ¯”\nè¿™é‡Œé€‰ä¸‰ç¯‡ä¸ã€Œä»£ç æŒ‡ä»¤æ•°æ® / ä»£ç ç¼–è¾‘ã€å¯†åˆ‡ç›¸å…³çš„å·¥ä½œåšå¯¹æ¯”ï¼šOctoPackã€Magicoderã€CANITEDITï¼ˆEDITCODERï¼‰ã€‚(arXiv)\n\n\n\n\n\n\n\n\n\nå·¥ä½œ\nå…³æ³¨é—®é¢˜\næ–¹æ³•è·¯çº¿\nè´¡çŒ®ä¸å®ç”¨ä»·å€¼ï¼ˆä¸»è§‚è¯„ä»·ï¼‰\n\n\n\n\nInstructCoder\né€šç”¨ä»£ç ç¼–è¾‘ï¼šæ ¹æ®è‡ªç„¶è¯­è¨€æŒ‡ä»¤ä¿®æ”¹ç°æœ‰ä»£ç å¹¶é€šè¿‡æµ‹è¯•\nåŸºäº GitHub commit çš„ seed + Self-Instruct + åœºæ™¯æ¡ä»¶ç”Ÿæˆï¼Œæ„å»º 11 ä¸‡+ æŒ‡ä»¤ç¼–è¾‘æ•°æ®ï¼›é…å¥— EditEval æ‰§è¡Œå¼è¯„æµ‹åŸºå‡†\nåœ¨ã€Œä»£ç ç¼–è¾‘ã€è¿™ä¸€å…·ä½“ä»»åŠ¡ä¸Šåšäº† end-to-end é—­ç¯ï¼Œå¯¹å®é™…æƒ³åšã€Œç¼–è¾‘åŠ©æ‰‹ã€çš„å›¢é˜Ÿéå¸¸æœ‰å‚è€ƒä»·å€¼\n\n\nOctoPack\nå¹¿ä¹‰ä»£ç æŒ‡ä»¤ä»»åŠ¡ï¼ŒåŒ…æ‹¬ä¿®å¤ã€è§£é‡Šã€ç”Ÿæˆç­‰\nåˆ©ç”¨ Git commits æ„å»ºå¤§è§„æ¨¡ CommitPackï¼Œè®­ç»ƒ OctoCoder ç³»åˆ—ï¼Œç€é‡æå‡ HumanEvalPack ç­‰å¤šä»»åŠ¡è¡¨ç°\né¢å‘ã€Œé€šç”¨ä»£ç åŠ©æ‰‹ã€ï¼Œæ›´å¼ºè°ƒå¤šè¯­è¨€ã€å¤šä»»åŠ¡è¦†ç›–ï¼Œå¯¹ç¼–è¾‘ä»»åŠ¡çš„ä¸“é—¨åˆ†æç›¸å¯¹è¾ƒå°‘ (arXiv)\n\n\nMagicoder\né¢å‘ä»£ç ç”Ÿæˆçš„é«˜è´¨é‡æŒ‡ä»¤æ•°æ® OSS-Instruct\nåˆ©ç”¨å¼€æºä»£ç ç‰‡æ®µæ„é€ å¤šæ ·åŒ–æŒ‡ä»¤æ•°æ®ï¼Œè®­ç»ƒ Magicoder ç³»åˆ—ï¼Œåœ¨ä»£ç ç”Ÿæˆ benchmark ä¸Šæ¥è¿‘æˆ–è¶…è¶Š ChatGPT\næ›´å¤šæ˜¯åœ¨ã€Œç”Ÿæˆã€è€Œéã€Œç¼–è¾‘ã€ç»´åº¦ä¸Š push SOTAï¼Œæ•°æ®æ„é€ æ€æƒ³ï¼ˆåˆ©ç”¨ OSS ç‰‡æ®µï¼‰å¯¹ç¼–è¾‘åœºæ™¯ä¹Ÿæœ‰å€Ÿé‰´æ„ä¹‰ (arXiv)\n\n\nCANITEDIT / EDITCODER\nç³»ç»ŸåŒ–è¯„ä¼°ä¸æå‡ä»£ç ç¼–è¾‘èƒ½åŠ›\næ„å»ºä¸“é—¨çš„ä»£ç ç¼–è¾‘æ•°æ®é›†å’Œæ–°çš„æŒ‡æ ‡ï¼ˆå¦‚ ExcessCodeï¼‰ï¼Œå¹¶åœ¨ DeepSeekCoder ç­‰æ¨¡å‹ä¸Šè¿›è¡Œç³»ç»Ÿè¯„ä¼°ä¸å¾®è°ƒ\næ›´å…³æ³¨ã€Œå¦‚ä½•è¡¡é‡å’Œä¼˜åŒ–ç¼–è¾‘è´¨é‡ã€æœ¬èº«ï¼Œä¸ InstructCoder åœ¨é—®é¢˜å®šä¹‰ä¸Šé«˜åº¦äº’è¡¥ï¼Œå¯è”åˆä½¿ç”¨ (arXiv)\n\n\n\næ•´ä½“æ¥çœ‹ï¼š\n\nåœ¨é—®é¢˜å®šä¹‰ä¸Šï¼ŒInstructCoder ä¸ CANITEDIT éƒ½ä¸“æ³¨äºã€Œç¼–è¾‘ã€ï¼Œè€Œ OctoPack / Magicoder æ›´åã€Œé€šç”¨ä»£ç æŒ‡ä»¤ã€ä¸ã€Œç”Ÿæˆã€ï¼›\nåœ¨æ–¹æ³•è·¯çº¿ä¸Šï¼Œå‡ è€…éƒ½é‡‡ç”¨ä¸åŒå½¢å¼çš„æŒ‡ä»¤æ•°æ®åˆæˆï¼Œä½† InstructCoder æ›´å¼ºè°ƒæ‰§è¡Œæµ‹è¯•ä¸ edit ratio ç­‰ç¼–è¾‘ç‰¹æœ‰è§†è§’ï¼›\nåœ¨å®ç”¨ä»·å€¼ä¸Šï¼Œå¦‚æœä½ çš„ç›®æ ‡æ˜¯ IDE æ’ä»¶é‡Œçš„ã€Œæ ¹æ®è‡ªç„¶è¯­è¨€æ”¹ä»£ç ã€ï¼ŒInstructCoder + CANITEDIT ç±»å‹çš„å·¥ä½œæ˜¯è®¾è®¡æ•°æ®ä¸è¯„æµ‹çš„é¦–é€‰å‚è€ƒï¼›å¦‚æœç›®æ ‡æ˜¯ã€Œä»éœ€æ±‚ç”Ÿæˆæ–°æ–‡ä»¶ã€ï¼ŒOctoPack / Magicoder æ›´æ¥è¿‘éœ€æ±‚ã€‚\n\n7.1 ä¸ªäººè§‚ç‚¹\nä»æ•´ä½“è®ºè¯æ–¹å¼çœ‹ï¼ŒInstructCoder åœ¨ã€Œæ•°æ®ä¸è¯„æµ‹é—­ç¯ã€ä¸Šåšå¾—æ¯”è¾ƒæ‰å®ï¼šå…ˆç»™å‡ºæ¸…æ™°çš„ EditEvalï¼Œå†è®¾è®¡ InstructCoder æ¥æå‡è¿™ä¸€è¯„æµ‹ï¼Œç„¶åç”¨ç³»ç»Ÿå®éªŒå±•ç¤ºæå‡çš„å¹…åº¦ã€‚è¿™ç§ç»“æ„å¯¹å·¥ç¨‹å›¢é˜Ÿå¾ˆå‹å¥½ï¼Œå› ä¸ºä½ å¯ä»¥ç›´æ¥ç…§æ¬ã€Œè¯„æµ‹æŒ‡æ ‡ + æ•°æ®æ„é€ é€»è¾‘ + è®­ç»ƒå¥—è·¯ã€ã€‚\næœ‰ä¸¤ä¸ªæˆ‘è§‰å¾—å¯ä»¥è¿›ä¸€æ­¥åŠ å¼ºçš„ç‚¹ï¼š\n\nåŸºçº¿ä¸ ablation è®¾è®¡ è®ºæ–‡å·²ç»åšäº† InstructCoder æ•°æ®é‡ç¼©æ”¾å®éªŒï¼Œä½†å¦‚æœèƒ½å¢åŠ æ›´å¤šã€Œæ•°æ®æ„é€ ç­–ç•¥ã€çš„ ablationï¼Œæ¯”å¦‚ï¼šåªç”¨ commit seedã€åªç”¨åœºæ™¯æ¡ä»¶ç”Ÿæˆã€åªç”¨ä¸€èˆ¬ Self-Instructï¼Œè€Œä¸æ˜¯ä¸‰è€…ç»“åˆï¼›æˆ–è€…ä¸ OctoPack å¼ commit æ•°æ®ç›´æ¥è®­ç»ƒå¯¹æ¯”ï¼Œä¼šæ›´æ¸…æ™°åœ°å‘Šè¯‰è¯»è€…ã€Œå“ªä¸€æ­¥æœ€å€¼é’±ã€ã€‚\næ›´è´´è¿‘çœŸå®å·¥ç¨‹çš„ case study ç›®å‰çš„ä¾‹å­ä¸»è¦é›†ä¸­åœ¨ç›¸å¯¹ä¸­å°è§„æ¨¡çš„ç‰‡æ®µï¼Œå¦‚æœèƒ½é¢å¤–å±•ç¤ºä¸€äº›ã€Œå¤šå‡½æ•°ååŒã€ã€Œéœ€è¦ç†è§£æµ‹è¯•æ¡†æ¶/é…ç½®æ–‡ä»¶ã€çš„å¤æ‚ç¼–è¾‘æ¡ˆä¾‹ï¼Œå¹¶ç»™å‡ºå¤±è´¥æ¨¡å¼åˆ†æï¼Œå¯¹åç»­ç³»ç»Ÿè½åœ°ä¼šå¾ˆæœ‰æŒ‡å¯¼æ„ä¹‰ã€‚\n\n\nå…«ã€åœ¨å®é™…è®­ç»ƒæ ˆä¸­å¦‚ä½•è½åœ°ï¼Ÿ\nå¦‚æœè¦åœ¨ã€Œæˆ‘çš„å¤§è§„æ¨¡è®­ç»ƒæ ˆï¼ˆå¦‚åŸºäº Megatron / DeepSpeed / vLLM ç­‰ï¼‰ã€ä¸­å¼•å…¥ InstructCoder è¿™ç±»æ–¹æ³•ï¼Œå¤§è‡´éœ€è¦ä»ä»¥ä¸‹å‡ ä¸ªå±‚é¢è€ƒè™‘ï¼š\n\nDataLoader / æ•°æ®æ‰“åŒ…ä¸é¢„å¤„ç†\n\næŒ‰è®ºæ–‡æ ¼å¼ï¼ŒæŠŠæ ·æœ¬ç»Ÿä¸€ä¸ºï¼š \"&lt;instruction&gt;\\n\\n&lt;original code&gt;\" â†’ \"&lt;edited code&gt;\" è¿™æ ·çš„è¾“å…¥/è¾“å‡ºã€‚\néœ€è¦åšçš„å·¥ç¨‹å·¥ä½œï¼š\n\nè®¾è®¡ç»Ÿä¸€çš„æ¨¡æ¿ï¼ˆprompt formatï¼‰ï¼Œé¿å…ä¸åŒæ¥æºæ ·æœ¬é£æ ¼ä¸ä¸€è‡´ï¼›\né’ˆå¯¹é•¿ä»£ç ç‰‡æ®µï¼Œé…åˆå·²æœ‰çš„ pack/CP ç­–ç•¥ï¼ˆä¾‹å¦‚å¤šæ ·æœ¬æ‹¼æ¥ã€æœ€é•¿ä¼˜å…ˆã€pad é™åˆ¶ç­‰ï¼‰æé«˜ GPU åˆ©ç”¨ç‡ï¼›\nåœ¨é¢„å¤„ç†é˜¶æ®µå°±è®°å½•ã€Œç¼–è¾‘æ¯”ä¾‹ã€ã€Œè¯­è¨€ã€ã€Œåœºæ™¯æ ‡ç­¾ã€ç­‰å…ƒä¿¡æ¯ï¼Œæ–¹ä¾¿åç»­åš curriculum æˆ–é‡‡æ ·åŠ æƒã€‚\n\n\nå¹¶è¡Œè°ƒåº¦ï¼ˆDP / TP / PPï¼‰ä¸ä¸Šä¸‹æ–‡é•¿åº¦é…ç½®\n\nä»£ç ç¼–è¾‘ä»»åŠ¡å¾€å¾€æœ‰è¾ƒé•¿ä¸Šä¸‹æ–‡ï¼ˆåŸå§‹ä»£ç  + æ³¨é‡Š + æŒ‡ä»¤ï¼‰ï¼Œéœ€è¦ç»“åˆæ¨¡å‹ä¸Šä¸‹æ–‡é•¿åº¦å’Œæ˜¾å­˜é¢„ç®—ï¼Œåˆç†è®¾ç½® global batch / micro batchï¼š\n\nå¦‚æœå·²æœ‰çš„é¢„è®­ç»ƒ/å¯¹è¯æŒ‡ä»¤å¾®è°ƒç®¡çº¿å·²ç»æ”¯æŒé•¿ä¸Šä¸‹æ–‡ï¼Œå¯ä»¥ç›´æ¥å¤ç”¨å¯¹åº”çš„ PP/TP é…ç½®ï¼›\næ³¨æ„æ˜¾å­˜å³°å€¼ï¼šä»£ç ç‰‡æ®µé€šå¸¸ç»“æ„å¯†é›†ã€token åŒ–åé•¿åº¦ä¼šæ¯”è¾ƒå¯è§‚ï¼Œå¯èƒ½éœ€è¦é€‚å½“å‡å° batch æˆ–å¯ç”¨ activation checkpointã€‚\n\n\nå¼ é‡/ä¸Šä¸‹æ–‡å¹¶è¡Œç­–ç•¥\n\nå¯¹å·²æœ‰ TP/CP ç­–ç•¥ï¼Œä¸€èˆ¬ä¸éœ€è¦ä¸ºä»£ç ç¼–è¾‘ä¸“é—¨æ”¹ kernelï¼›\næ›´éœ€è¦æ³¨æ„çš„æ˜¯ï¼š\n\nä»£ç  token åˆ†å¸ƒä¸è‡ªç„¶è¯­è¨€ä¸åŒï¼ŒBPE merge åå®¹æ˜“å‡ºç°é•¿ identifierï¼Œéœ€è¦ç¡®è®¤åˆ†è¯å™¨æ˜¯å¦é€‚é…ï¼›\nåœ¨å¤šæ¨¡å‹å®¶æ—å…±å­˜çš„è®­ç»ƒå¹³å°ä¸Šï¼ˆå¦‚åŒæ—¶è®­ç»ƒå¯¹è¯æ¨¡å‹å’Œä»£ç æ¨¡å‹ï¼‰ï¼Œè¦ç¡®ä¿ code-specific çš„ tokenizer ä¸ vocab ä¸è¢«æ··ç”¨ã€‚\n\n\nkernel æˆ–ç®—å­å®ç°\n\næœ¬æ–‡é‡‡ç”¨çš„æ˜¯æ ‡å‡† Decoder-only Transformer + LoRAï¼Œå› æ­¤ä¸éœ€è¦æ–°çš„ç®—å­ï¼›\nå¦‚æœä½ çš„æ ˆé‡Œå·²ç»æœ‰ fused attentionã€fused MLP ç­‰é«˜æ€§èƒ½ kernelï¼Œä»£ç ç¼–è¾‘è®­ç»ƒå¯ä»¥ç›´æ¥å¤ç”¨ï¼›\nçœŸæ­£éœ€è¦å…³æ³¨çš„æ˜¯ï¼š\n\nLoRA/adapter çš„å®ç°æ˜¯å¦ä¸è¿™äº› fused kernel å…¼å®¹ï¼›\nå¯¹äº flash-attention ä¸€ç±»ç®—å­ï¼Œè¦ä¿è¯åœ¨é•¿ä»£ç ä¸Šä¸‹æ–‡ä¸‹ç¨³å®šã€ä¸ä¼šå› ä¸ºä¸è§„åˆ™åˆ†å¸ƒè§¦å‘æ…¢è·¯å¾„ã€‚\n\n\né€šä¿¡ä¸é›†ä½“æ“ä½œ\n\nåœ¨ DP/TP/PP å¤šç»´å¹¶è¡Œä¸‹ï¼Œä»£ç ç¼–è¾‘è®­ç»ƒå’Œæ™®é€š pretrain/sft åŸºæœ¬ä¸€è‡´ï¼š\n\nDPï¼šæ ‡å‡† all-reduce gradï¼›\nTPï¼šæ³¨æ„é•¿åºåˆ—ä¸‹ all-gather / reduce-scatter çš„å¸¦å®½å ç”¨ï¼›\nPPï¼šä¿è¯ stage ä¹‹é—´çš„ micro-batch è¶³å¤Ÿå¤§ï¼Œå¦åˆ™æµæ°´çº¿ç©ºæ³¡ä¼šè¢«é•¿ä¸Šä¸‹æ–‡æ”¾å¤§ã€‚\n\nä»å·¥ç¨‹å®è·µçœ‹ï¼Œæœ€å¯èƒ½çš„å‘ä¸åœ¨é€šä¿¡é€»è¾‘ï¼Œè€Œåœ¨äºä¸å‡åŒ€çš„åºåˆ—åˆ†å¸ƒï¼šè‹¥è®¸å¤š batch ä¸­åŒ…å«ã€Œæé•¿ä»£ç ç‰‡æ®µã€ï¼Œä¼šåœ¨æŸä¸€é˜¶æ®µé€ æˆè´Ÿè½½å³°å€¼ï¼Œå»ºè®®é¢„å¤„ç†æ—¶åšé•¿åº¦åˆ†å±‚ã€‚\n\né…ç½®æœç´¢ / è‡ªåŠ¨è°ƒå‚\n\néœ€è¦è°ƒä¼˜çš„å…³é”®å‚æ•°åŒ…æ‹¬ï¼š\n\nLoRA rankã€å­¦ä¹ ç‡ã€å¾®è°ƒæ­¥æ•°ï¼ˆå¤šå¤§ç¨‹åº¦ä¸Šã€Œä¸“é—¨åŒ–ã€æˆ code editorï¼‰ï¼›\nè®­ç»ƒæ•°æ®æ··åˆæ¯”ä¾‹ï¼šInstructCoder vs å…¶ä»–æŒ‡ä»¤æ•°æ®ï¼ˆé€šç”¨å¯¹è¯ã€ä»£ç ç”Ÿæˆç­‰ï¼‰ï¼›\né‡‡æ ·ç­–ç•¥ï¼šæ˜¯å¦å¯¹å°ç¼–è¾‘æ¯”ä¾‹æ ·æœ¬åŠ æƒï¼Œä»¥æŠ‘åˆ¶ã€Œç›´æ¥å¤åˆ¶è¾“å…¥ã€çš„æ·å¾„ã€‚\n\nå¯ä»¥åœ¨ç°æœ‰è¶…å‚æœç´¢æ¡†æ¶ä¸­ï¼ŒæŠŠã€ŒEditEval accuracyã€æˆ–å†…éƒ¨è‡ªå»ºçš„æ‰§è¡Œå¼è¯„æµ‹æŒ‡æ ‡ä½œä¸ºä¸»ç›®æ ‡ã€‚\n\nè°ƒè¯• / ç›‘æ§\n\nåœ¨è®­ç»ƒé˜¶æ®µï¼Œå»ºè®®é¢å¤–ç›‘æ§ï¼š\n\nEditEval / å†…éƒ¨ç¼–è¾‘è¯„æµ‹é›†ä¸Šçš„æ‰§è¡Œé€šè¿‡ç‡ï¼›\nä¸åŒç¼–è¾‘æ¯”ä¾‹åˆ†æ¡¶ä¸Šçš„å‡†ç¡®ç‡ï¼›\nå¯¹ç°æœ‰ä»£ç ç”Ÿæˆ benchmarkï¼ˆå¦‚ HumanEvalï¼‰çš„å½±å“ï¼Œé˜²æ­¢ä¸“ç²¾ç¼–è¾‘èƒ½åŠ›å¯¼è‡´ç”Ÿæˆèƒ½åŠ›é€€åŒ–ã€‚\n\nåœ¨çº¿/æ¨ç†æœåŠ¡ä¾§ï¼š\n\nè®°å½•ç”¨æˆ·çœŸå®ç¼–è¾‘ä»»åŠ¡çš„æˆåŠŸç‡ï¼ˆä¾‹å¦‚é›†æˆåˆ° CI çš„è‡ªåŠ¨æµ‹è¯•é€šè¿‡ç‡ï¼‰ï¼›\nç»Ÿè®¡ã€Œä¿ç•™åŸæ ·ã€ã€Œè¿‡åº¦æ”¹åŠ¨ã€ç­‰é”™è¯¯æ¨¡å¼ï¼Œä¸ºä¸‹ä¸€è½®æ•°æ®æ„é€ æä¾›åé¦ˆã€‚\n\n\n\n\nä¹ã€å€¼å¾—è¿›ä¸€æ­¥æ¢ç´¢çš„ç ”ç©¶æ–¹å‘\næ–¹å‘ä¸€ï¼šå¤šæ–‡ä»¶ã€å¤šæ¨¡å—ä»£ç ç¼–è¾‘\nç°å®å¼€å‘ä¸­ï¼Œå¾ˆå¤šç¼–è¾‘æ“ä½œéœ€è¦è·¨å¤šä¸ªæ–‡ä»¶è¿›è¡Œï¼ˆæ·»åŠ æ–°æ¨¡å—ã€æ›´æ–°æ¥å£å®šä¹‰ä¸æ‰€æœ‰è°ƒç”¨ç‚¹ç­‰ï¼‰ã€‚æœªæ¥å¯ä»¥æ‰©å±• InstructCoder ç±»æ•°æ®ï¼š\n\nè®©æŒ‡ä»¤æ˜ç¡®æè¿°è·¨æ–‡ä»¶é‡æ„ä»»åŠ¡ï¼›\nè¾“å…¥ä¸Šä¸‹æ–‡åŒ…å«å¤šæ–‡ä»¶ç‰‡æ®µæˆ–é¡¹ç›®ç»“æ„æ‘˜è¦ï¼›\nè¯„æµ‹åŸºå‡†æ‰©å±•ä¸ºå¤šæ¨¡å—æ„å»º + é›†æˆæµ‹è¯•ã€‚\n\næ–¹å‘äºŒï¼šå¤šè¯­è¨€ä¸å¼ºç±»å‹åœºæ™¯çš„ç¼–è¾‘\nå½“å‰ä¸»è¦é›†ä¸­åœ¨ Pythonï¼Œåç»­å¯ä»¥é¢å‘ C++/Rust/Java ç­‰å¼ºç±»å‹è¯­è¨€ï¼š\n\nç»“åˆç¼–è¯‘å™¨é”™è¯¯ä¿¡æ¯ã€ç±»å‹ç³»ç»Ÿçº¦æŸï¼Œæ„é€ æ›´å¤æ‚çš„ç¼–è¾‘æŒ‡ä»¤ï¼ˆä¾‹å¦‚ã€Œæ¶ˆé™¤æ‰€æœ‰æœªä½¿ç”¨æ¨¡æ¿å®ä¾‹ã€ã€Œä¿®æ­£ lifetime é”™è¯¯ã€ï¼‰ï¼›\nåˆ©ç”¨é™æ€åˆ†æå·¥å…·ç”Ÿæˆæ›´ç²¾ç¡®çš„ edit targetï¼Œå‡å°‘æœç´¢ç©ºé—´ã€‚\n\næ–¹å‘ä¸‰ï¼šæ˜¾å¼å»ºæ¨¡ã€Œç¼–è¾‘æ“ä½œã€è€Œéå®Œæ•´ä»£ç \nç›®å‰çš„åšæ³•æ˜¯ç›´æ¥ç”Ÿæˆæ–°çš„å®Œæ•´ä»£ç ç‰‡æ®µï¼Œæœªæ¥å¯ä»¥è€ƒè™‘ï¼š\n\næŠŠä»»åŠ¡å»ºæ¨¡ä¸ºã€Œç¼–è¾‘è„šæœ¬ã€ç”Ÿæˆï¼ˆinsert/delete/replace patchï¼‰ï¼Œåœ¨åå¤„ç†ä¸­åº”ç”¨åˆ°åŸå§‹ä»£ç ï¼›\nåœ¨è®­ç»ƒæ—¶çº¦æŸæ¨¡å‹å°½é‡å±€éƒ¨ä¿®æ”¹ï¼Œå‡å°‘ã€Œé‡å†™å…¨éƒ¨æ–‡ä»¶ã€é€ æˆçš„ diff å™ªå£°ï¼›\nåœ¨è¯„æµ‹ä¸­å¢åŠ å¯¹ patch å¤§å°ã€ä¿®æ”¹å®šä½ç²¾ç¡®åº¦çš„æŒ‡æ ‡ã€‚\n\næ–¹å‘å››ï¼šè®­ç»ƒé—­ç¯ä¸­å¼•å…¥æ‰§è¡Œåé¦ˆ\nå½“å‰æ‰§è¡Œæµ‹è¯•åªç”¨äºè¯„æµ‹ï¼Œæœªæ¥å¯ä»¥æ¢ç´¢ï¼š\n\nåœ¨è®­ç»ƒä¸­ä½¿ç”¨ RL from executionï¼Œè®©é€šè¿‡æµ‹è¯•çš„ç¼–è¾‘è·å¾—æ­£å¥–åŠ±ï¼›\næˆ–è€…åœ¨æ•°æ®åˆæˆé˜¶æ®µï¼Œç”¨æ‰§è¡Œæµ‹è¯•æ¥è¿‡æ»¤/åŠ æƒç”Ÿæˆæ ·æœ¬ï¼Œå½¢æˆæ›´å¼ºçš„ self-training é—­ç¯ã€‚\n\næ–¹å‘äº”ï¼šä¸ IDE / CI æµæ°´çº¿æ·±åº¦é›†æˆ\nä»å·¥ç¨‹è½åœ°è§’åº¦ï¼š\n\nå°†ç¼–è¾‘æ¨¡å‹ä¸ IDE æ’ä»¶ã€ä»£ç å®¡æŸ¥å·¥å…·ã€CI ç³»ç»Ÿè¿æ¥ï¼Œæ”¶é›†çœŸå®å¼€å‘è€…äº¤äº’æ•°æ®ï¼ˆç¼–è¾‘æˆåŠŸç‡ã€å›æ»šç‡ç­‰ï¼‰ï¼›\nåˆ©ç”¨è¿™äº›ã€Œäººç±»åé¦ˆã€è¿›ä¸€æ­¥æ„é€ é«˜ä»·å€¼çš„æŒ‡ä»¤/ç¼–è¾‘å¯¹ï¼ŒæŒç»­è¿­ä»£ä»£ç ç¼–è¾‘èƒ½åŠ›ã€‚\n\n\nåã€çŸ¥è¯†å›¾è°±æ€ç»´é“¾\nä»ä½ çš„ã€Œå¤§æ¨¡å‹è®­ç»ƒæ ˆã€è§†è§’ï¼Œè¿™ç¯‡è®ºæ–‡ä¸»è¦æ›´æ–°äº†ä»¥ä¸‹å‡ ä¸ªèŠ‚ç‚¹ï¼š\n\næ•°æ®ã€é¢„å¤„ç†ä¸æ‰“åŒ…ç­–ç•¥\n\nã€Œå¦‚ä½•ä» GitHub commits ä¸­æŠ½å–é«˜è´¨é‡ç¼–è¾‘æ ·æœ¬ã€ï¼Œå¹¶é€šè¿‡è‡ªæŒ‡ä»¤æ‰©å±•å½¢æˆå¤§è§„æ¨¡æŒ‡ä»¤æ•°æ®é›†ã€‚\nã€Œå¦‚ä½•è®¾è®¡æ‰§è¡Œå¼è¯„æµ‹åŸºå‡†ã€ï¼ŒæŠŠ code editing ä»æ–‡æœ¬ä»»åŠ¡æå‡ä¸ºã€Œå¸¦ç¨‹åºè¯­ä¹‰çš„ä»»åŠ¡ã€ã€‚\n\næ¨¡å‹ç»“æ„ä¸æ¶æ„è®¾è®¡\n\nä¸æ”¹åŠ¨åŸºç¡€ Transformer æ¶æ„ï¼Œé€šè¿‡ LoRA è¿™ç±» PEFT æŠ€æœ¯æ³¨å…¥ä»»åŠ¡ç‰¹å®šèƒ½åŠ›ï¼Œè¯´æ˜å¾ˆå¤šã€Œä¸“é—¨èƒ½åŠ›ã€ä¸ä¸€å®šéœ€è¦å¤§æ”¹æ¨¡å‹ã€‚\n\nå¹¶è¡Œä¸è°ƒåº¦\n\nè™½ç„¶è®ºæ–‡æœ¬èº«ä¸å¼ºè°ƒå¹¶è¡Œç»†èŠ‚ï¼Œä½†é•¿ä¸Šä¸‹æ–‡çš„ä»£ç ç¼–è¾‘è®­ç»ƒåœ¨å®é™…æ ˆä¸­ï¼Œä¼šç›´æ¥å½±å“ä½ å¯¹ TP/PP é…ç½®ã€batch å¤§å°å’Œæ¿€æ´»æ£€æŸ¥ç‚¹ç­–ç•¥çš„é€‰æ‹©ã€‚\n\nå†…å­˜ç®¡ç†ä¸æ˜¾å­˜ä¼˜åŒ–\n\nLoRA çš„é‡‡ç”¨æœ¬èº«å°±æ˜¯ä¸€ç§ã€Œå‚æ•°ä¸æ˜¾å­˜ç®¡ç†ã€ç­–ç•¥ï¼šåœ¨ 33B æ¨¡å‹ä¸Šç”¨å•å¡ A100 å®Œæˆå¾®è°ƒï¼Œä¸ºåœ¨èµ„æºå—é™ç¯å¢ƒä¸‹åšä¸“é¡¹èƒ½åŠ›è®­ç»ƒæä¾›äº†ä¾‹å­ã€‚(arXiv)\n\né€šä¿¡ä¸é›†ä½“æ“ä½œ\n\nä»ä»»åŠ¡å½¢æ€çœ‹ï¼Œä»£ç ç¼–è¾‘è®­ç»ƒä¸æ™®é€š SFT ä¸€è‡´ï¼Œä½†é•¿åºåˆ— + ä¸å‡åŒ€é•¿åº¦åˆ†å¸ƒä¼šå¯¹ all-reduce/all-gather ç­‰é€šä¿¡é˜¶æ®µé€ æˆæ–°çš„å‹åŠ›ï¼Œéœ€è¦åœ¨å®é™…ç³»ç»Ÿé‡Œåš profile å’Œè°ƒåº¦ç­–ç•¥ä¼˜åŒ–ã€‚\n\n\n10.1 ä¸ªäººæ”¶è·ä¸åæ€\nå¯¹å¤§æ¨¡å‹è®­ç»ƒä¸ç³»ç»Ÿè®¾è®¡è€Œè¨€ï¼Œè¿™ç¯‡è®ºæ–‡ç»™æˆ‘çš„æœ€å¤§å¯å‘æ˜¯ï¼šå¾ˆå¤šæˆ‘ä»¬ä»¥ä¸ºã€Œæ¨¡å‹ä¸è¡Œã€çš„åœºæ™¯ï¼Œå®é™…ä¸Šæ˜¯ã€Œæ•°æ®å’Œè¯„æµ‹æ²¡è·Ÿä¸Šã€ã€‚ä»…ä»…é€šè¿‡ä¸€ä¸ª carefully designed çš„æ‰§è¡Œå¼ benchmark + é’ˆå¯¹æ€§çš„æŒ‡ä»¤æ•°æ®ï¼Œå°±èƒ½æŠŠå¼€æºæ¨¡å‹çš„ç¼–è¾‘èƒ½åŠ›ä»ã€Œå‡ ä¹ä¸å¯ç”¨ã€æ¨åˆ°ã€Œæ¥è¿‘ ChatGPTã€ï¼Œè¿™è¯´æ˜ï¼š\n\nä¸€æ–¹é¢ï¼ŒåŸºç¡€æ¨¡å‹å·²ç»å…·å¤‡äº†ç›¸å½“å¤šçš„ä»£ç çŸ¥è¯†ä¸æ¨ç†èƒ½åŠ›ï¼›\nå¦ä¸€æ–¹é¢ï¼Œå¦‚æœä¸åœ¨ã€Œä»»åŠ¡å®šä¹‰ + è¯„æµ‹ + æ•°æ®æ„é€ ã€ä¸Šä¸‹åŠŸå¤«ï¼Œå¾ˆå®¹æ˜“ä½ä¼°æˆ–è¯¯ç”¨è¿™äº›èƒ½åŠ›ã€‚\n\nä»å®è·µè§’åº¦ï¼Œæˆ‘ä¼šè€ƒè™‘åœ¨è‡ªå·±çš„æ ˆé‡Œè¿ç§»ä¸¤ç±»ç†å¿µï¼š\n\nä¼˜å…ˆæ­å¥½æ‰§è¡Œå¼è¯„æµ‹é—­ç¯ï¼šåœ¨å¼•å…¥ä»»ä½•æ–°æ¨¡å‹/æ•°æ®ä¹‹å‰ï¼Œå…ˆæ˜ç¡®ã€Œè¿™ä¸ªä»»åŠ¡çš„å¯æ‰§è¡Œè¯„æµ‹æ˜¯ä»€ä¹ˆã€ï¼Œä¾‹å¦‚ä»£ç ç¼–è¾‘ä¸­çš„å•å…ƒæµ‹è¯•ã€ç«¯åˆ°ç«¯å›å½’æµ‹è¯•ï¼Œå†å›´ç»•è¿™ä¸ªè¯„æµ‹æ¥è®¾è®¡æ•°æ®å’Œè®­ç»ƒã€‚\nç”¨ LoRA/adapter åšèƒ½åŠ›ä¸“ç²¾å¾®è°ƒï¼šè€Œä¸æ˜¯ä¸€æ¬¡æ€§åšå·¨å¤§è§„æ¨¡ full finetuneã€‚è¿™æ ·å¯ä»¥åœ¨åŒä¸€å¥—åŸºç¡€æ¨¡å‹ä¸ŠæŒ‚è½½å¤šä¸ªã€Œèƒ½åŠ›å¤´ã€ï¼ˆä»£ç ç¼–è¾‘ã€é™æ€åˆ†æã€refactorã€review ç­‰ï¼‰ï¼ŒæŒ‰éœ€åŠ è½½ï¼Œä¾¿äºå·¥ç¨‹ç®¡ç†ã€‚\n\n\næ€»ä½“è¯„ä»·ï¼šInstructCoder æŠŠã€Œä»£ç ç¼–è¾‘ã€ä»ä¸€ä¸ªæ¨¡ç³Šçš„ä½¿ç”¨åœºæ™¯ï¼Œæ‹‰æˆäº†æœ‰æ˜ç¡®æ•°æ®æ„é€ æ–¹æ³•å’Œæ‰§è¡Œå¼è¯„æµ‹åŸºå‡†çš„ç³»ç»ŸåŒ–é—®é¢˜ï¼Œåœ¨å·¥ç¨‹è½åœ°ä¸Šæœ‰å¾ˆå¼ºçš„å‚è€ƒä»·å€¼ï¼›å¯¹äºå·²ç»æ‹¥æœ‰é€šç”¨ä»£ç  LLM çš„å›¢é˜Ÿï¼ŒæŒ‰ç…§æ–‡ä¸­çš„æ€è·¯æ„å»ºè‡ªå®¶ç¼–è¾‘æ•°æ®å’Œè¯„æµ‹é—­ç¯ï¼Œå¾ˆå¯èƒ½æ˜¯ä¸€ä¸ªæŠ•å…¥ç›¸å¯¹å¯æ§ã€ä½†å›æŠ¥æ˜æ˜¾çš„è·¯çº¿ã€‚\n\n","categories":["è®ºæ–‡é˜…è¯»"],"tags":["paper"]},{"title":"Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM","url":"/2025/11/23/paper/efficient_large_scale/","content":"\n\n\nä¸€ã€è®ºæ–‡é€Ÿè§ˆ\nè¿™ç¯‡ SCâ€™21 è®ºæ–‡èšç„¦çš„æ ¸å¿ƒé—®é¢˜æ˜¯ï¼šåœ¨ä¸Šåƒå— GPU çš„é›†ç¾¤ä¸Šï¼Œå¦‚ä½•é«˜æ•ˆè®­ç»ƒ 100Bï½1T çº§åˆ«çš„ Transformer è¯­è¨€æ¨¡å‹ï¼ŒåŒæ—¶æ—¢ä¸è¢«æ˜¾å­˜é™åˆ¶å¡æ­»ï¼Œåˆä¸è¿‡åº¦æµªè´¹ç®—åŠ›åœ¨é€šä¿¡å’Œæµæ°´ç©ºæ³¡ä¸Šã€‚(people.eecs.berkeley.edu)\nä½œè€…æå‡ºäº†ä¸€å¥—ç»„åˆå¼å¹¶è¡Œæ–¹æ¡ˆ PTD-Pï¼šåœ¨å•æœºå†…åšå¼ é‡å¹¶è¡Œï¼ˆTensor MPï¼‰ï¼Œè·¨æœºåšæµæ°´çº¿å¹¶è¡Œï¼ˆPipeline MPï¼‰ï¼Œæœ€å¤–å±‚å åŠ æ•°æ®å¹¶è¡Œï¼ˆDPï¼‰ï¼Œå¹¶é…å¥—æ–°çš„ interleaved 1F1B æµæ°´è°ƒåº¦ä»¥å‹ç¼© pipeline bubbleã€‚(people.eecs.berkeley.edu)\nåœ¨ä¸€å°å° DGX A100 ç»„æˆçš„é›†ç¾¤ä¸Šï¼Œè¿™å¥—æ–¹æ¡ˆæŠŠ 1T å‚æ•° GPT æ¨¡å‹çš„è®­ç»ƒè¿­ä»£åšåˆ°äº† 3072 å— GPU ä¸Šæ€»è®¡ 502 PFLOP/s çš„ååï¼Œå•å¡çº¦ 163 TFLOP/sï¼Œç›¸å½“äº A100 ç†è®ºå³°å€¼çš„çº¦ 52%ã€‚(people.eecs.berkeley.edu)\nè®ºæ–‡æœ€åç»™å‡ºäº†ä¸€äº›éå¸¸å·¥ç¨‹å‘çš„â€œé€‰å‹æŒ‡å—â€ï¼šTP/PP/DP æ¯”ä¾‹å¦‚ä½•æ­é…ã€micro-batch å¦‚ä½•é€‰ã€é€šä¿¡æ‹“æ‰‘å’Œå¹¶è¡Œç­–ç•¥å¦‚ä½•é€‚é…ï¼Œä¸ºä¹‹åçš„å¤§è§„æ¨¡ LLM è®­ç»ƒå®è·µåŸºæœ¬å®šäº†â€œæ•™ç§‘ä¹¦çº§â€çš„åŸºå‡†ã€‚(people.eecs.berkeley.edu)\näºŒã€è®ºæ–‡ç»“æ„\n\nå¼•è¨€ä¸é—®é¢˜èƒŒæ™¯ è¯´æ˜å¤§æ¨¡å‹è®­ç»ƒåœ¨æ˜¾å­˜å®¹é‡ä¸ç®—åŠ›éœ€æ±‚ä¸Šçš„çŸ›ç›¾ï¼Œå›é¡¾å·²æœ‰çš„ TP / PP / DP å·¥ä½œï¼ˆMegatronã€GPipeã€PipeDreamã€ZeRO ç­‰ï¼‰ï¼Œå¹¶ç‚¹å‡ºè¿™äº›æ–¹æ³•åœ¨â€œä¸Šåƒ GPU è§„æ¨¡â€æ—¶çš„æ ¹æœ¬ç“¶é¢ˆï¼Œé€‚åˆæƒ³å¿«é€ŸçŸ¥é“â€œä¸ºä»€ä¹ˆè¦æ PTD-Pâ€ çš„è¯»è€…å…ˆè¯»ã€‚(people.eecs.berkeley.edu)\nå¹¶è¡Œæ¨¡å¼ç»¼è¿°ä¸ PTD-P æ€»ä½“è®¾è®¡ ç³»ç»Ÿæ€§åœ°è®²è§£æ•°æ®å¹¶è¡Œã€æµæ°´å¹¶è¡Œã€å¼ é‡å¹¶è¡Œä¸‰ç§æ¨¡å¼çš„ä¼˜ç¼ºç‚¹ï¼Œå¹¶ç»™å‡ºä¸‰è€…ç»„åˆï¼ˆPTD-Pï¼‰çš„é«˜å±‚ç»“æ„ç¤ºæ„ä¸å®è·µç»éªŒï¼Œæ˜¯ç†è§£æ•´ä½“ç³»ç»Ÿæ¶æ„ä¸è¿›ç¨‹ç»„å¸ƒå±€çš„å…³é”®éƒ¨åˆ†ã€‚(people.eecs.berkeley.edu)\næµæ°´å¹¶è¡Œè°ƒåº¦ï¼šGPipeã€PipeDream-Flush ä¸ Interleaved 1F1B è¯¦ç»†åˆ†æä¸åŒ pipeline è°ƒåº¦çš„ bubble å¤§å°ã€æ¿€æ´»æ˜¾å­˜å ç”¨ä¸é€šä¿¡é‡ï¼Œå¹¶ç»™å‡º interleaved 1F1B çš„æ–°è°ƒåº¦åŠå®ƒåœ¨ååä¸Šçš„æ”¶ç›Šï¼Œæ˜¯æœ¬æ–‡ç†è®ºåˆ†æçš„æ ¸å¿ƒã€‚(people.eecs.berkeley.edu)\nå¼ é‡å¹¶è¡Œä¸é€šä¿¡ä¼˜åŒ– å›é¡¾ Megatron-LM çš„å¼ é‡å¹¶è¡Œæ‹†åˆ†æ–¹å¼ï¼Œè¯´æ˜åœ¨å¤šæœºå¤šå¡ç¯å¢ƒä¸‹å¦‚ä½•æŠŠ TP å±€é™åœ¨å•æœºå†…éƒ¨ï¼Œé…åˆ InfiniBand ç­‰è·¨èŠ‚ç‚¹é€šä¿¡ä¼˜åŒ–ï¼Œæ˜¯å®é™…æŠŠä»£ç æ”¹å¯¹çš„å·¥ç¨‹æŒ‡å—ã€‚(people.eecs.berkeley.edu)\nå®éªŒè¯„ä¼°ï¼šä» 1B åˆ° 1T çš„ç¼©æ”¾å®è¯ å±•ç¤ºä¸åŒ TP/PP/DP é…ç½®ä¸‹çš„ååä¸æ‰©å±•æ•ˆç‡ï¼Œå¯¹æ¯” ZeRO-3 ç­‰æ–¹æ¡ˆï¼Œä»¥åŠåœ¨ 175B / 530B / 1T æ¨¡å‹ä¸Šçš„æ€§èƒ½æ•°æ®ï¼Œæ˜¯æœ€å€¼å¾—å·¥ç¨‹äººå‘˜ç»†è¯»å¯¹æ ‡è‡ªå·±é›†ç¾¤çš„ä¸€èŠ‚ã€‚(people.eecs.berkeley.edu)\nç›¸å…³å·¥ä½œä¸å°ç»“ å°†æœ¬å·¥ä½œä¸ GPipeã€PipeDreamã€ZeRO ç­‰æ–¹æ³•å¯¹æ¯”ï¼Œå¼ºè°ƒè‡ªèº«çš„å®šä½ï¼ˆä¸¥æ ¼åŒæ­¥è¯­ä¹‰ + ä¸‰ç»´å¹¶è¡Œ + å·¥ç¨‹è½åœ°ï¼‰ï¼Œé€‚åˆä½œä¸ºå†™è‡ªå·±æ–¹æ¡ˆæ—¶çš„â€œRelated Work æ¨¡æ¿â€ã€‚(people.eecs.berkeley.edu)\n\n\næ ¸å¿ƒæ€æƒ³ï¼šé€šè¿‡åœ¨å•æœºå†…åšå¼ é‡å¹¶è¡Œã€è·¨æœºåšæµæ°´å¹¶è¡Œå¹¶å åŠ æ•°æ®å¹¶è¡Œçš„ PTD-P ä¸‰ç»´å¹¶è¡Œæ¶æ„ï¼Œå†é…åˆ interleaved 1F1B æµæ°´è°ƒåº¦å’Œé€šä¿¡ä¼˜åŒ–ï¼Œå¯ä»¥åœ¨ä¿æŒä¸¥æ ¼åŒæ­¥è¯­ä¹‰å’Œæœ‰é™æ˜¾å­˜å ç”¨çš„å‰æä¸‹ï¼ŒæŠŠ GPT ç±»è¯­è¨€æ¨¡å‹é«˜æ•ˆæ‰©å±•åˆ° 1T å‚æ•°å’Œä¸Šåƒ GPU è§„æ¨¡ã€‚(people.eecs.berkeley.edu)\n\n\nä¸‰ã€æ–¹æ³•ä¸ç³»ç»Ÿè®¾è®¡\næ•´ä½“æ€è·¯å¯ä»¥æ¦‚æ‹¬ä¸ºï¼šåœ¨ç»™å®šé›†ç¾¤æ‹“æ‰‘ï¼ˆDGX + NVLink + InfiniBandï¼‰çš„å‰æä¸‹ï¼Œç”¨æœ€é€‚åˆæ‹“æ‰‘çš„æ–¹å¼ç»„åˆ TP / PP / DPï¼Œå¹¶é€šè¿‡æ–°æµæ°´è°ƒåº¦æœ€å¤§åŒ–ç®—åŠ›åˆ©ç”¨ç‡ï¼ŒåŒæ—¶æŠŠè·¨èŠ‚ç‚¹é€šä¿¡å‹åŠ›å‹åˆ°æœ€ä½ã€‚(people.eecs.berkeley.edu)\nä½œè€…é‡ç‚¹è§£å†³äº†å‡ ä¸ªå­é—®é¢˜ï¼š\n\nå­é—®é¢˜ 1ï¼š å¦‚ä½•ç»„åˆ TP / PP / DPï¼Œåœ¨æœ‰é™æ˜¾å­˜ä¸‹æ”¯æ’‘ 1T çº§æ¨¡å‹ï¼Œåˆé¿å…åœ¨ä¸Šåƒ GPU æ—¶è¢«é€šä¿¡æ‹–å®ï¼Ÿ\nå­é—®é¢˜ 2ï¼š ä¼ ç»Ÿ GPipe/1F1B è°ƒåº¦çš„ pipeline bubble è¿‡å¤§ï¼Œå¦‚ä½•åœ¨ä¸æ”¾å¼ƒä¸¥æ ¼åŒæ­¥è¯­ä¹‰çš„å‰æä¸‹è¿›ä¸€æ­¥å‹ç¼© bubbleï¼Ÿ\nå­é—®é¢˜ 3ï¼š åœ¨ç°å®é›†ç¾¤æ‹“æ‰‘ä¸­ï¼ˆå¤šæœºå¤šå¡ã€NVLink + InfiniBandï¼‰ï¼Œå¦‚ä½•èªæ˜åœ°åˆ†é… TP/PP ç»´åº¦ï¼Œå‡å°‘â€œè·¨èŠ‚ç‚¹ all-reduceâ€è¿™ç§æ˜‚è´µé€šä¿¡ï¼Ÿ\nå­é—®é¢˜ 4ï¼š åœ¨å®é™…è®­ç»ƒä¸­ï¼Œå¦‚ä½•é€šè¿‡ micro-batch / global batch / activation recompute ç­‰è¶…å‚è°ƒèŠ‚ï¼Œè·å–æ›´é«˜çš„ååï¼Ÿ(people.eecs.berkeley.edu)\n\n3.1 æ ¸å¿ƒæ¨¡å—ä¸€è§ˆ\nä»¥ä¸‹æ¨¡å—åæ˜¯ç»“åˆè®ºæ–‡å†…å®¹ä¸ Megatron å®ç°çš„å·¥ç¨‹æ‹†è§£ï¼Œä¸æ˜¯åŸæ–‡çš„ section åç§°ï¼š\n\nPTD-P ä¸‰ç»´å¹¶è¡Œå¸ƒå±€æ¨¡å—ï¼šè´Ÿè´£æŠŠå…¨é›†ç¾¤åˆ’åˆ†ä¸ºæ•°æ®å¹¶è¡Œç»„ã€æµæ°´å¹¶è¡Œç»„å’Œå¼ é‡å¹¶è¡Œç»„ï¼Œå¹¶åœ¨ Megatron ä¸­æ˜ å°„ä¸ºä¸€ç³»åˆ—è¿›ç¨‹ç»„ï¼ˆdata / model / pipeline groupsï¼‰ï¼Œè§£å†³â€œç®—åŠ›å’Œæ˜¾å­˜å¦‚ä½•åœ¨ç»´åº¦ä¹‹é—´åˆ†é…â€çš„é—®é¢˜ã€‚(people.eecs.berkeley.edu)\nå¼ é‡å¹¶è¡Œ Transformer å±‚æ¨¡å—ï¼šæ²¿ç”¨ Megatron-LM çš„åˆ—å¹¶è¡Œ / è¡Œå¹¶è¡Œçº¿æ€§å±‚è®¾è®¡ï¼Œåœ¨å¤š GPU ä¸Šåˆ†ç‰‡ QKV / FFN æƒé‡ï¼Œå¹¶æ’å…¥å¿…è¦çš„ all-reduce / all-gather é€šä¿¡ï¼Œè§£å†³â€œå•å±‚æƒé‡è¿‡å¤§ï¼Œå•å¡æ”¾ä¸ä¸‹â€çš„é—®é¢˜ã€‚(people.eecs.berkeley.edu)\næµæ°´å¹¶è¡Œåˆ‡åˆ†ä¸è°ƒåº¦æ¨¡å—ï¼šæŠŠ N å±‚ Transformer å‡åŒ€åˆ‡åˆ†ä¸ºå¤šä¸ª pipeline stageï¼Œå¹¶å®ç° GPipeã€PipeDream-Flushï¼ˆ1F1Bï¼‰å’Œ interleaved 1F1B ä¸‰å¥—è°ƒåº¦é€»è¾‘ï¼Œè§£å†³â€œå¤šæœºè·¨å±‚ä¸²è¡Œå¯¼è‡´é—²ç½®â€çš„é—®é¢˜ã€‚(people.eecs.berkeley.edu)\næ•°æ®å¹¶è¡Œä¸æ¢¯åº¦èšåˆæ¨¡å—ï¼šåœ¨æ¯ä¸ª PT é…ç½®ä¸‹å†å¤åˆ¶è‹¥å¹²æ•°æ®å¹¶è¡Œå‰¯æœ¬ï¼Œé€šè¿‡é«˜æ•ˆçš„ data-parallel all-reduceï¼ˆå…¸å‹å°±æ˜¯ NCCL AllReduceï¼‰åŒæ­¥æ¢¯åº¦ï¼Œè§£å†³â€œå¤§ batch è®­ç»ƒç¨³å®šæ€§ä¸ååâ€çš„é—®é¢˜ã€‚(people.eecs.berkeley.edu)\næ˜¾å­˜ä¸é€šä¿¡ä¼˜åŒ–æ¨¡å—ï¼šåˆ©ç”¨æ··åˆç²¾åº¦ã€æ¿€æ´»é‡è®¡ç®—ã€é€šä¿¡ overlap å’Œæ‹“æ‰‘æ„ŸçŸ¥æ˜ å°„ï¼Œä¿è¯ï¼š1ï¼‰ç»å¤§éƒ¨åˆ† kernel å¤„äº compute-bound çŠ¶æ€ï¼›2ï¼‰æ•°æ®å¹¶è¡Œ / æµæ°´å¹¶è¡Œé€šä¿¡å°½é‡åœ¨è®¡ç®—ä¹‹ä¸‹â€œåŸ‹æ‰â€ã€‚(people.eecs.berkeley.edu)\nå¹¶è¡Œé…ç½®ä¸ç»éªŒå‡†åˆ™æ¨¡å—ï¼šè®ºæ–‡æœ€åæ€»ç»“çš„â€œç»éªŒå…¬å¼â€å’Œ heuristicsï¼Œç”¨æ¥æŒ‡å¯¼å¦‚ä½•é€‰æ‹© TP/PP/DP å› å­ã€micro-batch å¤§å°ç­‰ï¼Œå®é™…å°±æ˜¯ä¸€å¥—â€œäººè‚‰ auto-parallel tunerâ€ã€‚(people.eecs.berkeley.edu)\n\n3.2 æ•°æ®æµä¸æ§åˆ¶æµ\nä»å·¥ç¨‹è§†è§’çœ‹ï¼Œä¸€æ¬¡è®­ç»ƒè¿­ä»£å¯ä»¥åˆ†è§£ä¸ºå¦‚ä¸‹æ­¥éª¤ï¼ˆå¯ä»¥ç›´æ¥æ®æ­¤ç”»æ—¶åºå›¾æˆ– Mermaid æµç¨‹å›¾ï¼‰ï¼š\n\næ•°æ®é¢„å¤„ç†ä¸åˆ†ç‰‡\n\næ–‡æœ¬æ•°æ®ç¦»çº¿åˆ†è¯ã€chunk åŒ–ä¸ºå›ºå®šé•¿åº¦åºåˆ—ï¼ˆä¾‹å¦‚ GPT é£æ ¼çš„ packed datasetï¼‰ã€‚\nè®­ç»ƒå‰é€šè¿‡ index mapping æŠŠå…¨å±€æ ·æœ¬ç´¢å¼•æŒ‰æ•°æ®å¹¶è¡Œ rank å‡åŒ€åˆ‡åˆ†ï¼Œå½¢æˆæ¯ä¸ª DP rank çš„æœ¬åœ° shardã€‚(people.eecs.berkeley.edu)\n\nDataLoader + DistributedSampler\n\nå„ DP rank ä½¿ç”¨åˆ†å¸ƒå¼ Sampler è¿­ä»£è‡ªå·±çš„ shardï¼Œå¾—åˆ°ä¸€ä¸ª global batchã€‚\nglobal batch è¢«è¿›ä¸€æ­¥æ‹†åˆ†ä¸º \\(m\\) ä¸ª micro-batchï¼Œç”¨äºæµæ°´å¹¶è¡Œçš„ç®¡çº¿å¡«å……ã€‚\n\nä¸‰ç»´å¹¶è¡Œè¾“å…¥æ˜ å°„\n\nå¯¹äºæŸä¸ª DP rank å†…çš„ä¸€ä¸ª micro-batchï¼š\n\næ²¿æµæ°´çº¿ç»´åº¦ï¼ˆPPï¼‰æŠŠ micro-batch äº¤ç»™ç¬¬ä¸€ä¸ª stageã€‚\næ²¿å¼ é‡å¹¶è¡Œç»´åº¦ï¼ˆTPï¼‰ï¼Œæ¯ä¸ªå¼ é‡åˆ†ç‰‡åªæ¥æ”¶è‡ªå·±é‚£ä¸€ä»½è¾“å…¥å¼ é‡ï¼ˆä¾‹å¦‚åˆ—å¹¶è¡Œçº¿æ€§å±‚æ¯å¡æ‹¿åˆ°è¾“å…¥çš„å…¨éƒ¨ï¼Œä½†æƒé‡åªæ˜¯åˆ—åˆ†ç‰‡ï¼‰ã€‚(people.eecs.berkeley.edu)\n\n\nå‰å‘ä¼ æ’­ï¼ˆinterleaved 1F1B è°ƒåº¦ï¼‰\n\nè¿›å…¥ warmup åŒºæ®µï¼šä¸åŒ stage æ‰§è¡Œä¸åŒæ•°ç›®çš„ forwardï¼Œä»¥å¡«æ»¡æ•´æ¡ pipelineã€‚\nè¿›å…¥ steady åŒºæ®µï¼šæ¯ä¸ª stage æŒ‰â€œ1 ä¸ª forward + 1 ä¸ª backwardâ€çš„ 1F1B pattern å·¥ä½œï¼Œä½†è¿™é‡Œçš„â€œ1 ä¸ª stageâ€å·²ç»è¢«æ‹†æˆå¤šä¸ª model chunkï¼Œå½¢æˆ interleaved æ—¶é—´è¡¨ã€‚(people.eecs.berkeley.edu)\nåœ¨ TP ç»´åº¦å†…éƒ¨ï¼Œå‰å‘ä¸­çš„çº¿æ€§ / attention å±‚ä¼šæ’å…¥ all-reduce / all-gatherï¼Œé€šå¸¸é™åˆ¶åœ¨å•æœº NVLink å†…ã€‚\n\nåå‘ä¼ æ’­ä¸æ¢¯åº¦åŒæ­¥\n\næ¯ä¸ª micro-batch åœ¨ç®¡çº¿å°¾éƒ¨å®Œæˆ loss è®¡ç®—ï¼ŒæŠŠæ¢¯åº¦å‘å‰ä¸€ç«™ä¸€ç«™ä¼ å›å»ã€‚\næ¯ä¸ª TP åˆ†ç‰‡åœ¨æœ¬æœºå†…å®Œæˆå¼ é‡å¹¶è¡Œç›¸å…³çš„ all-reduce åï¼Œå¾—åˆ°å±€éƒ¨ shard æ¢¯åº¦ã€‚\nDP ç»´åº¦å¯¹æ‰€æœ‰ replica çš„å‚æ•°æ¢¯åº¦åšä¸€æ¬¡ data-parallel all-reduceï¼Œä¿è¯æ‰€æœ‰å‰¯æœ¬æƒé‡ä¸€è‡´ã€‚(people.eecs.berkeley.edu)\n\nå‚æ•°æ›´æ–°ä¸ç®¡çº¿ flush\n\nå½“æœ¬ batch çš„æ‰€æœ‰ micro-batch éƒ½å®Œæˆ forward+backward åï¼Œåœ¨ pipeline flush ä½ç½®ç»Ÿä¸€åšä¸€æ¬¡ optimizer stepï¼ˆä¾‹å¦‚ AdamWï¼‰ï¼Œä»¥ä¿æŒä¸¥æ ¼çš„åŒæ­¥è¯­ä¹‰ã€‚\nç”±äº interleaved 1F1B å‡å°‘äº† bubbleï¼Œflush å‘ç”Ÿå¾—æ›´æ—©ï¼Œæ•´ä½“ idle æ—¶é—´ä¸‹é™ã€‚(people.eecs.berkeley.edu)\n\nç»Ÿè®¡ä¸ç›‘æ§\n\nåœ¨è®­ç»ƒå¾ªç¯ä¸­æŒç»­ç»Ÿè®¡ per-GPU FLOPsã€é€šä¿¡å¸¦å®½ä½¿ç”¨ã€æ¿€æ´»æ˜¾å­˜ã€stage åˆ©ç”¨ç‡ç­‰æŒ‡æ ‡ï¼Œç”¨äºåç»­è°ƒå‚ä¸æ•…éšœæ’æŸ¥ã€‚(people.eecs.berkeley.edu)\n\n\n3.3 å…³é”®å‡è®¾ä¸é€‚ç”¨èŒƒå›´\n\nå‡è®¾ï¼šé›†ç¾¤å…·å¤‡é«˜å¸¦å®½ã€ä½å»¶è¿Ÿçš„ GPU é—´äº’è¿\n\nè®ºæ–‡å®éªŒåŸºäº NVLink/NVSwitchï¼ˆå•æœºï¼‰+ é«˜é€Ÿ InfiniBandï¼ˆè·¨æœºï¼‰ï¼Œæ•°æ®å¹¶è¡Œå’Œæµæ°´çº¿é€šä¿¡ä½¿ç”¨äº†æ¥è¿‘ TB/s çº§åˆ«çš„æœ‰æ•ˆå¸¦å®½ã€‚(people.eecs.berkeley.edu)\nè‹¥æ¢æˆæ™®é€šä»¥å¤ªç½‘æˆ–è€æ—§äº’è¿ï¼ŒTP/PP ä¹‹é—´çš„æœ€ä½³åˆ†é…ç‚¹ä¼šæ˜¾è‘—æ”¹å˜ï¼Œç”šè‡³å¯èƒ½éœ€è¦æ›´é‡çš„è®¡ç®—-é€šä¿¡ overlap æˆ–å‹ç¼©ï¼Œå¦åˆ™ååå¯èƒ½å¤§å¹…è·Œè½ã€‚\n\nå‡è®¾ï¼šæ¨¡å‹ç»“æ„ä¸»è¦æ˜¯å‡åŒ€å †å çš„ Transformer block\n\nPTD-P å’Œ interleaved åˆ‡åˆ†å‡å‡è®¾å„ä¸ª block è®¡ç®—é‡æ¥è¿‘ï¼Œå¯ä»¥ç®€å•â€œå‡åˆ†å±‚æ•°â€å®ç°è´Ÿè½½å‡è¡¡ã€‚(people.eecs.berkeley.edu)\nå¯¹äºå«æœ‰å¤§é‡å¼‚æ„æ¨¡å—ï¼ˆå¦‚è¶…å¤§ embeddingã€MoEã€decoder-only + å¤æ‚å¤´éƒ¨ï¼‰çš„æ¨¡å‹ï¼Œå¦‚æœä¸åšé¢å¤–çš„å±‚çº§é‡åˆ†é…ä¸ profileï¼Œå®¹æ˜“åœ¨æµæ°´çº¿æŸäº› stage å‡ºç°æ˜æ˜¾ç“¶é¢ˆã€‚\n\nå‡è®¾ï¼šé‡‡ç”¨æ··åˆç²¾åº¦ã€æ¿€æ´»é‡è®¡ç®—ç­‰æ˜¾å­˜ä¼˜åŒ–æ‰‹æ®µ\n\nè®ºæ–‡çš„ 1T æ¨¡å‹è®­ç»ƒé»˜è®¤ä½¿ç”¨ mixed precision å’Œ activations recomputeï¼Œå¦åˆ™æ˜¾å­˜å¾ˆéš¾æ”¯æ’‘å¤š micro-batch + å¤š stage çš„ç»„åˆã€‚(people.eecs.berkeley.edu)\nåœ¨åªç”¨ FP32 ä¸”ä¸å¼€é‡è®¡ç®—çš„ç¯å¢ƒä¸‹ï¼Œpipeline æ·±åº¦å’Œ micro-batch æ•°é‡å¿…é¡»æ˜¾è‘—æ”¶ç¼©ï¼Œbubble ç†è®ºåˆ†æä»æˆç«‹ï¼Œä½†å¯é€‰çš„å·¥ä½œç‚¹ä¼šå¤§å¹…å—é™ã€‚\n\nå‡è®¾ï¼šé‡‡ç”¨ä¸¥æ ¼åŒæ­¥çš„ä¼˜åŒ–å™¨è¯­ä¹‰\n\nPTD-P å§‹ç»ˆåœ¨ pipeline flush å¤„æ‰åšä¸€æ¬¡æƒé‡æ›´æ–°ï¼Œä¸ä½¿ç”¨å»¶è¿Ÿæˆ–å¼‚æ­¥æ›´æ–°ã€‚(people.eecs.berkeley.edu)\nå¦‚æœæ”¹ç”¨ PipeDream-2BW ç­‰å…è®¸ stale weights çš„æ–¹æ¡ˆï¼Œè™½ç„¶å¯ä»¥è¿›ä¸€æ­¥ç¼©çŸ­ bubbleï¼Œä½†ä¼šå¼•å…¥è®­ç»ƒç¨³å®šæ€§å’Œæ”¶æ•›è¡Œä¸ºçš„ä¸ç¡®å®šæ€§ï¼Œéœ€è¦é¢å¤–å®éªŒæ”¯æ’‘ã€‚(NVIDIA Developer)\n\n\n3.4 æ•°å­¦å…¬å¼ä¸ç®—æ³•è§£è¯»\nè®ºæ–‡çš„æ–¹æ³•éƒ¨åˆ†åŒ…å«äº†ä¸€äº›å…³äº pipeline bubble ä¸ interleaved è°ƒåº¦ çš„å®šé‡åˆ†æï¼Œè¿™é‡Œé€‰ä¸¤ç»„å…³é”®å…¬å¼åšè§£è¯»ã€‚å…¬å¼çš„å½¢å¼å¿ å®äºåŸæ–‡ï¼Œä½†è®²è§£éƒ¨åˆ†æ˜¯ç­‰ä»·é‡å†™ã€‚(people.eecs.berkeley.edu)\n3.4.1 GPipe è°ƒåº¦çš„ pipeline bubble åˆ†æ\nåŸæ–‡ä¸­çš„å…¬å¼ï¼šç®¡çº¿ç©ºæ³¡å æ¯”\nåœ¨ GPipe é£æ ¼çš„ â€œall-forward-then-all-backwardâ€ è°ƒåº¦ä¸‹ï¼Œè®¾ï¼š\n\n\\(m\\)ï¼šä¸€ä¸ª batch å†…çš„ micro-batch æ•°é‡ã€‚\n\\(p\\)ï¼špipeline stage æ•°ï¼ˆä½¿ç”¨å¤šå°‘è®¾å¤‡åšæµæ°´å¹¶è¡Œï¼‰ã€‚\n\\(t_f\\)ï¼šå•ä¸ª micro-batch çš„å‰å‘æ—¶é—´ã€‚\n\\(t_b\\)ï¼šå•ä¸ª micro-batch çš„åå‘æ—¶é—´ã€‚\n\nåˆ™ï¼š\n\næ‰¹å¤„ç†çš„ç†æƒ³è®¡ç®—æ—¶é—´ä¸º $ t_{} = m (t_f + t_b) $\npipeline bubble çš„æ—¶é—´ä¸º $ t_{} = (p - 1)(t_f + t_b) $\nbubble å ç†æƒ³æ—¶é—´çš„æ¯”ä¾‹ä¸º \\[\n\\text{BubbleFrac} = \\frac{t_{\\text{pb}}}{t_{\\text{id}}}\n= \\frac{p-1}{m}.\n\\](people.eecs.berkeley.edu)\n\nå«ä¹‰ä¸ç›´è§‚ç†è§£\n\nè¿™ç»„å…¬å¼è§£å†³çš„é—®é¢˜ï¼šåœ¨ç»™å®š stage æ•° \\(p\\) å’Œ micro-batch æ•° \\(m\\) æ—¶ï¼Œpipeline èµ·åœé˜¶æ®µâ€œç™½ç™½ç©ºè½¬â€çš„æ—¶é—´å æ¯”æ˜¯å¤šå°‘ã€‚\nå…³é”®ç»“è®ºï¼šæƒ³è®© bubble å°ï¼Œå°±è¦è®© \\(m \\gg p\\)ï¼Œå³â€œmicro-batch æ•°è¿œå¤§äº pipeline æ·±åº¦â€ã€‚\n\nç›´è§‚ç‰ˆæ“ä½œæè¿°\n\nå…ˆæŠŠä¸€ä¸ªå¤§ batch æ‹†æˆå¾ˆå¤š micro-batchã€‚\npipeline çš„æœ€å‰å‡ ä¸ªæ—¶é—´æ­¥é‡Œï¼Œä¸‹æ¸¸ device ä¸€ç›´åœ¨ç­‰ä¸Šæ¸¸çš„ç¬¬ä¸€æ‰¹æ•°æ® â€”â€” è¿™å°±æ˜¯å‰åŠæ®µ bubbleã€‚\nç­‰æ‰€æœ‰ micro-batch éƒ½æµå®Œï¼Œæœ€åå‡ ä¸ªæ—¶é—´æ­¥é‡Œï¼Œä¸Šæ¸¸ device å·²ç»æ²¡æ´»å¹²ï¼Œä¸‹æ¸¸è¿˜åœ¨å¤„ç†å°¾å·´ â€”â€” è¿™æ˜¯ååŠæ®µ bubbleã€‚\næ€»ä½“æ¥è¯´ï¼Œbubble çš„é•¿åº¦å°±æ˜¯â€œä¸¤ç«¯å„ç©ºè½¬ \\((p-1)\\) æ­¥â€çš„æ—¶é—´ä¹‹å’Œï¼Œå¹³å‡åˆ°æ•´ä¸ª batch ä¸Šå°±æ˜¯ \\(\\frac{p-1}{m}\\)ã€‚\n\n3.4.2 Interleaved 1F1B è°ƒåº¦çš„ bubble æ”¹è¿›\nåŸæ–‡ä¸­çš„å…¬å¼ï¼šinterleaved ä¹‹åçš„ bubble å æ¯”\nåœ¨ interleaved 1F1B è°ƒåº¦ä¸­ï¼Œæ¯å— GPU ä¸åªè´Ÿè´£ä¸€æ®µè¿ç»­å±‚ï¼Œè€Œæ˜¯è¢«åˆ‡æˆ \\(v\\) ä¸ªåŒ…å«æ›´å°‘å±‚çš„â€œmodel chunksâ€ï¼Œæ¢å¥è¯è¯´ æ¯ä¸ª device ä¸Šæœ‰ \\(v\\) ä¸ª pipeline stageã€‚\nåœ¨è¿™æ ·çš„æƒ…å†µä¸‹ï¼Œè®ºæ–‡ç»™å‡ºçš„ç»“æœæ˜¯ï¼ˆè¿™é‡Œå½¢å¼ä¸Šç­‰ä»·äºåŸæ–‡çš„æ¨å¯¼ï¼‰ï¼š(people.eecs.berkeley.edu)\n\næ¯ä¸ª chunk çš„å‰å‘ / åå‘æ—¶é—´è¿‘ä¼¼å˜ä¸º \\(t_f / v\\)ã€\\(t_b / v\\)ã€‚\nbubble æ—¶é—´å˜ä¸ºï¼š \\[\nt^{\\text{int}}_{\\text{pb}} = \\frac{(p-1)(t_f + t_b)}{v}\n\\]\nå¯¹åº”çš„ bubble å æ¯”ä¸ºï¼š \\[\n\\text{BubbleFrac}^{\\text{int}}\n= \\frac{t^{\\text{int}}*{\\text{pb}}}{t*{\\text{id}}}\n= \\frac{1}{v} \\cdot \\frac{p-1}{m}.\n\\]\n\nå«ä¹‰ä¸ç›´è§‚ç†è§£\n\nç›¸å½“äºæŠŠåŸæ¥çš„â€œ\\(p\\) ä¸ª big-stage pipelineâ€ç»†åˆ†æˆâ€œ\\(p \\cdot v\\) ä¸ªå° stageâ€ï¼Œä½†è¿™äº›å° stage è¢«â€œæ‰“åŒ…åˆ†é…â€åˆ°åŒä¸€å— GPU ä¸Šé¡ºåºæ‰§è¡Œã€‚\næ—¶é—´è½´ä¸Šï¼Œpipe flush ä¼šæ›´æ—©åœ°å‘ç”Ÿï¼Œç›¸å½“äºâ€œç”¨æ›´å¯†é›†çš„è®¡ç®—å—å¡«è¡¥äº†åŸæ¥ä¸¤ç«¯çš„ç©ºæ´â€ï¼Œbubble è¢«ç¼©çŸ­äº†çº¦ \\(v\\) å€ã€‚\n\nä»£ä»·ä¸æƒè¡¡\n\nè¿™å¹¶ä¸æ˜¯å…è´¹çš„ï¼šç”±äºä¸€ä¸ª micro-batch è¦ç»è¿‡æ›´å¤š stageï¼Œstage ä¹‹é—´çš„æ¿€æ´»é€šä¿¡æ¬¡æ•°ä¹Ÿä¼šå¢åŠ  \\(v\\) å€ã€‚è®ºæ–‡æŒ‡å‡ºï¼Œå¯¹åº”çš„é€šä¿¡é‡ä¹Ÿçº¿æ€§æ”¾å¤§ï¼Œéœ€è¦ä¾é å¤šç½‘å¡ / æ‹“æ‰‘æ„ŸçŸ¥é€šä¿¡æŠŠä»£ä»·å‹ä¸‹å»ã€‚(people.eecs.berkeley.edu)\n\n3.4.3 è®­ç»ƒæ—¶é—´ä¼°ç®—å…¬å¼\nè®ºæ–‡ä¸å®˜æ–¹åšå®¢è¿›ä¸€æ­¥ç»™å‡ºä¸€ä¸ªâ€œä¼°ç®—æ€»è®­ç»ƒæ—¶é—´â€çš„ç®€å•å…¬å¼ï¼ˆå¯¹å¤§æ¨¡å‹å¸¸è§ï¼‰ï¼š(NVIDIA Developer)\nè®¾ï¼š\n\n\\(P\\)ï¼šæ¨¡å‹å‚æ•°é‡ï¼›\n\\(T\\)ï¼šè®­ç»ƒ token æ€»æ•°ï¼›\n\\(N\\)ï¼šGPU æ•°é‡ï¼›\n\\(X\\)ï¼šå•å¡å®é™…ååï¼ˆTFLOP/sï¼‰ï¼›\n\nåˆ™è®­ç»ƒæ—¶é—´çº¦ä¸ºï¼š \\[\n\\text{TrainTime(sec)} \\approx 8 \\cdot \\frac{T \\cdot P}{N \\cdot X}.\n\\]\nè¿™ä¸ª \\(8\\) æ˜¯æŠŠä¸€æ¬¡å‰å‘ + åå‘çš„ FLOPs ç³»æ•°æŠ˜åˆåçš„è¿‘ä¼¼å› å­ï¼ˆå¯¹ GPT ç±»æ¨¡å‹å¸¸è§ä¼°è®¡ï¼‰ã€‚åœ¨å·¥ç¨‹å®è·µé‡Œï¼Œè¿™ä¸ªå…¬å¼å¯ä»¥ç”¨æ¥åšâ€œé¢„ç®—çº§â€ä¼°ç®—ï¼šç»™å®šæ¨¡å‹è§„æ¨¡ã€token æ•°å’Œé›†ç¾¤é…ç½®ï¼Œå¤§è‡´åˆ¤æ–­è¦è®­å‡ å‘¨ã€‚\n\nä¸å¸¸è§è®­ç»ƒæ ˆçš„å¯¹åº”å…³ç³»\nå¦‚æœæŠŠä¸Šé¢çš„æ¨¡å—æ”¾è¿›â€œæˆ‘çš„è®­ç»ƒæ ˆï¼ˆå¦‚ Megatron / DeepSpeed / vLLM ç­‰ï¼‰â€é‡Œï¼Œå¤§è‡´å¯ä»¥å¯¹åº”åˆ°ï¼š\n\nDataLoader / æ•°æ®é¢„å¤„ç†å±‚ï¼šè´Ÿè´£ global batch æ‹†åˆ†ã€åˆ†å¸ƒå¼é‡‡æ ·ã€packed dataset æ„å»ºï¼Œå¯¹åº”è®ºæ–‡é‡Œçš„æ•°æ®åˆ†ç‰‡ä¸ micro-batch æ‹†åˆ†é€»è¾‘ã€‚\nå¹¶è¡Œè°ƒåº¦å±‚ï¼ˆlauncher + parallel engineï¼‰ï¼šè´Ÿè´£æ„å»º PTD-P çš„è¿›ç¨‹ç»„ã€å†³å®š TP/PP/DP å› å­å’Œ rank æ˜ å°„ï¼Œå®ç°åœ¨é›†ç¾¤ä¸Šçš„ 3D å¹¶è¡Œå¸ƒå±€ã€‚\næ¨¡å‹å®šä¹‰å±‚ï¼ˆnn.Module + sharded layersï¼‰ï¼šå°† Transformer å±‚æ”¹å†™ä¸ºå¼ é‡å¹¶è¡Œç‰ˆæœ¬ï¼ˆåˆ—å¹¶è¡Œ/è¡Œå¹¶è¡Œçº¿æ€§ã€åˆ†ç‰‡ attention ç­‰ï¼‰ã€‚\né€šä¿¡ backend å±‚ï¼ˆNCCL / RCCL / è‡ªç ”ï¼‰ï¼šå®ç°æ•°æ®å¹¶è¡Œ all-reduceã€å¼ é‡å¹¶è¡Œ all-reduce / all-gather ä»¥åŠæµæ°´çº¿ stage ä¹‹é—´çš„ point-to-point ä¼ è¾“ã€‚\nkernel / ç®—å­ä¼˜åŒ–å±‚ï¼šä¸ºå¤§çŸ©é˜µä¹˜ã€softmaxã€layernorm ç­‰æä¾›é«˜æ•ˆ kernelï¼Œå¹¶é…åˆ activation recomputeï¼Œè®©å¤§éƒ¨åˆ† step å¤„äº compute-boundã€‚\nç›‘æ§ä¸è‡ªåŠ¨è°ƒå‚å±‚ï¼šæ”¶é›† per-stage ååã€bubble å æ¯”ã€é€šä¿¡å¸¦å®½ç­‰æŒ‡æ ‡ï¼Œæ ¹æ®è®ºæ–‡ heuristics è‡ªåŠ¨æœç´¢åˆé€‚çš„ TP/PP/DP ä¸ micro-batchã€‚\n\n\nå››ã€å»ºæ¨¡æ–¹å¼ä¸è¯„ä¼°æŒ‡æ ‡\n4.1 é—®é¢˜æ˜¯å¦‚ä½•å½¢å¼åŒ–çš„ï¼Ÿ\nä»ç³»ç»Ÿè§’åº¦çœ‹ï¼Œä½œè€…å…³å¿ƒçš„æ ¸å¿ƒä¼˜åŒ–ç›®æ ‡æ˜¯ï¼š\n\nåœ¨ç»™å®šçš„ GPU æ•°é‡ã€äº’è¿æ‹“æ‰‘å’Œæ¨¡å‹å‚æ•°è§„æ¨¡ä¸‹ï¼Œæœ€å°åŒ–è®­ç»ƒæ—¶é—´ / æœ€å¤§åŒ–å®é™… FLOPs åˆ©ç”¨ç‡ï¼ŒåŒæ—¶æ»¡è¶³æ˜¾å­˜çº¦æŸå’Œä¸¥æ ¼åŒæ­¥è¯­ä¹‰ã€‚(people.eecs.berkeley.edu)\n\nå¯ä»¥ç”¨ä¸¤ä¸ªå±‚æ¬¡æ¥ç†è§£å»ºæ¨¡æ–¹å¼ï¼š\n\nç®—åŠ›å±‚é¢ï¼š\n\nå¯¹äº GPT ç±»æ¨¡å‹ï¼Œä¸€æ¬¡å‰å‘+åå‘çš„ FLOPs å¤§çº¦å’Œ â€œå‚æ•°é‡ Ã— åºåˆ—é•¿åº¦ Ã— batch å¤§å°â€ æˆæ­£æ¯”ã€‚\nè‹¥å•å¡ååä¸º \\(X\\) TFLOP/sï¼Œæ€» FLOPs ä¸º \\(8TP\\)ï¼ˆå‰é¢å…¬å¼ä¸­çš„è¿‘ä¼¼ï¼‰ï¼Œç›®æ ‡å°±æ˜¯è®©å®é™…æµæ°´çº¿è°ƒåº¦ + é€šä¿¡å¼€é”€ä¸‹çš„æœ‰æ•ˆ \\(X\\) å°½å¯èƒ½æ¥è¿‘ç¡¬ä»¶å³°å€¼ã€‚(NVIDIA Developer)\n\nå¹¶è¡Œç­–ç•¥å±‚é¢ï¼š\n\nç»™å®š TP/PP/DP ä¸‰ä¸ªå¹¶è¡Œåº¦ \\((t, p, d)\\)ï¼Œä»¥åŠ micro-batch æ•° \\(m\\)ï¼Œå¯ä»¥åˆ†æå¯¹åº”çš„ bubble æ¯”ä¾‹ã€æ¿€æ´»æ˜¾å­˜å ç”¨å’Œé€šä¿¡é‡ï¼Œå¹¶é€šè¿‡å®éªŒæµ‹é‡å®é™…ååã€‚\nè®ºæ–‡æ²¡æœ‰æ„é€ ä¸€ä¸ªå®Œæ•´çš„å½¢å¼åŒ–æœ€ä¼˜åŒ–æ¨¡å‹ï¼Œè€Œæ˜¯æä¾›ä¸€ç³»åˆ—ç»éªŒè§„åˆ™æ¥é€‰å– â€œè¿‘ä¼¼æœ€ä¼˜â€ çš„ \\((t, p, d, m)\\) ç»„åˆã€‚(people.eecs.berkeley.edu)\n\n\nä¸»è¦ç®€åŒ–åŒ…æ‹¬ï¼š\n\næŠŠå¤§éƒ¨åˆ† kernel çœ‹æˆ compute-boundï¼Œå¿½ç•¥ç»†ç²’åº¦ cache è¡Œä¸ºç­‰å¤æ‚å› ç´ ï¼›\næŠŠ pipeline è°ƒåº¦çš„ä»£ä»·æŠ½è±¡ä¸º bubble + é€šä¿¡ï¼Œä¸¤è€…ä»¥ç®€å•å‚æ•°ï¼ˆå¦‚ \\(p, v, m\\)ï¼‰æ¥åˆ»ç”»ï¼›\nå‡è®¾ç›¸åŒ stage å†…çš„å±‚è®¡ç®—é‡åŸºæœ¬å‡åŒ€ï¼Œå¯å¿½ç•¥ load imbalanceã€‚\n\n4.2 æ ¸å¿ƒè¯„ä¼°æŒ‡æ ‡\nè®ºæ–‡åœ¨ç³»ç»Ÿè¯„ä¼°ä¸­ä½¿ç”¨äº†ä»¥ä¸‹å‡ ä¸ªå…³é”®æŒ‡æ ‡ï¼ˆæˆ‘ç”¨å·¥ç¨‹è§†è§’åšäº†é‡æ–°ç»„ç»‡ï¼‰ï¼š\n\nå•å¡å®é™…ååï¼ˆTFLOP/sï¼‰ä¸å³°å€¼å æ¯”\n\nç»Ÿè®¡åŒ…å«è®¡ç®—å’Œé€šä¿¡åœ¨å†…çš„ end-to-end FLOPs åˆ©ç”¨ç‡ï¼Œä¾‹å¦‚ 1T æ¨¡å‹åœ¨ 3072 A100 ä¸Šè¾¾åˆ°äº† 163 TFLOP/s / GPU â‰ˆ 52% å³°å€¼ã€‚(people.eecs.berkeley.edu)\nè¿™æ˜¯ç›´æ¥è¡¡é‡â€œè¿™å¥—å¹¶è¡Œ+è°ƒåº¦æŠŠç¡¬ä»¶å‹æ¦¨å¾—æ€ä¹ˆæ ·â€çš„æ ¸å¿ƒæŒ‡æ ‡ã€‚\n\nèšåˆååï¼ˆPetaFLOP/sï¼‰ä¸å¼±æ‰©å±•æ•ˆç‡\n\néšç€ GPU æ•°ä»å‡ åæ‰©å±•åˆ°å‡ åƒï¼Œæµ‹é‡æ€» petaFLOP/s ä¸ç†æƒ³çº¿æ€§æ‰©å±•çš„åå·®ã€‚(NVIDIA Developer)\nç”¨äºåˆ¤æ–­è¿™å¥—æ–¹æ¡ˆåœ¨å¤§è§„æ¨¡é›†ç¾¤ä¸Šçš„å¯æ‰©å±•æ€§ï¼Œç›´æ¥å¯¹åº”â€œèƒ½ä¸èƒ½è®­ 1T ç”šè‡³æ›´å¤§æ¨¡å‹â€ã€‚\n\npipeline bubble å æ¯”\n\nä½¿ç”¨å‰é¢æ¨å¯¼çš„ \\(\\frac{p-1}{m}\\) ä¸ \\(\\frac{1}{v}\\frac{p-1}{m}\\) ç­‰å…¬å¼æ¥ä¼°ç®—ä¸åŒè°ƒåº¦ä¸‹çš„ç†è®º bubbleï¼Œå¹¶é€šè¿‡æ—¶åºå›¾ï¼ˆæ—¶é—´è½´ï¼‰éªŒè¯ã€‚(people.eecs.berkeley.edu)\nä¸æµæ°´æ·±åº¦ã€micro-batch æ•°å’Œ interleaved åº¦æ•°ç›´æ¥å¯¹åº”ï¼Œæ˜¯ç†è§£ä¸ºä»€ä¹ˆ interleaved 1F1B æœ‰æ”¶ç›Šçš„å…³é”®ã€‚\n\næ˜¾å­˜å ç”¨ï¼ˆå‚æ•°ã€æ¿€æ´»ã€ä¼˜åŒ–å™¨çŠ¶æ€ï¼‰\n\nå¯¹æ¯” GPipe vs 1F1B vs interleaved ç­‰ä¸åŒæµæ°´è°ƒåº¦ä¸‹çš„æ¿€æ´»æ˜¾å­˜å³°å€¼ï¼›åŒæ—¶ä¸ ZeRO-3 ç­‰â€œåˆ‡å‚æ•°+ä¼˜åŒ–å™¨â€çš„æ–¹æ¡ˆç›¸æ¯”ã€‚(people.eecs.berkeley.edu)\nå¸®åŠ©è¯»è€…ç†è§£â€œæ˜¾å­˜æ˜¯è¢«å‚æ•°åƒæ‰äº†è¿˜æ˜¯è¢«æ¿€æ´»åƒæ‰äº†â€ï¼Œå¯¹å®é™…å·¥ç¨‹é‡Œè°ƒ activation recomputeã€checkpoint éå¸¸æœ‰æŒ‡å¯¼æ„ä¹‰ã€‚\n\né€šä¿¡å¸¦å®½æ¶ˆè€—ï¼ˆpipeline / data parallel ä¸¤ç±»ï¼‰\n\nè®ºæ–‡ç»™å‡ºäº†è®­ç»ƒ 1T æ¨¡å‹æ—¶ pipeline é€šä¿¡å’Œ data-parallel é€šä¿¡çš„æœ‰æ•ˆ bisection å¸¦å®½ï¼ˆå¦‚æ•°ç™¾ GB/s vs æ•°å TB/s çº§åˆ«ï¼‰ï¼Œä»¥å±•ç¤ºé€šä¿¡å·²ç»æ˜¯ç¬¬ä¸€ç­‰å…¬æ°‘ã€‚(people.eecs.berkeley.edu)\nè¿™ä¸€æŒ‡æ ‡ä¸é›†ç¾¤ç½‘ç»œé…ç½®ï¼ˆç½‘å¡æ•°é‡ã€æ‹“æ‰‘ã€æ‹¥å¡æ§åˆ¶ï¼‰å¼ºç›¸å…³ï¼Œæ˜¯è¿ç§»åˆ°è‡ªå·±æœºæˆ¿æ—¶å¿…é¡»æ ¸å¯¹çš„æ•°å­—ã€‚\n\n\n\näº”ã€ä¸»è¦å®éªŒå‘ç°\n\nä¸‰ç»´å¹¶è¡Œï¼ˆPTD-Pï¼‰åœ¨å¤§è§„æ¨¡é›†ç¾¤ä¸Šå®ç°äº†æ¥è¿‘çº¿æ€§çš„æ‰©å±•ï¼šåœ¨ 3072 å— A100 ä¸Šï¼Œ1T å‚æ•° GPT æ¨¡å‹çš„æ€»ååè¾¾åˆ° 502 PFLOP/sï¼Œå•å¡çº¦ 163 TFLOP/sï¼Œæ˜¾ç¤ºåœ¨é«˜å¸¦å®½äº’è¿ä¸‹ TP+PP+DP çš„ç»„åˆå¯ä»¥å……åˆ†åƒæ»¡ç¡¬ä»¶ã€‚(people.eecs.berkeley.edu)\ninterleaved 1F1B è°ƒåº¦åœ¨å¤šç§é…ç½®ä¸‹å¸¦æ¥äº† 10% ä»¥ä¸Šçš„ååæå‡ï¼šåœ¨ä¿æŒæ˜¾å­˜å ç”¨æ¥è¿‘ä¸å˜çš„å‰æä¸‹ï¼Œé€šè¿‡æŠŠæ¯å— GPU åˆ‡æˆå¤šä¸ª model chunkï¼Œç¼©çŸ­äº† pipeline flush çš„æ—¶é—´ï¼Œä»è€Œå‡å°‘äº† idleã€‚(people.eecs.berkeley.edu)\nTP ä¸ PP çš„ç»„åˆæ–¹å¼å¯¹æ€§èƒ½å½±å“å·¨å¤§ï¼šè®ºæ–‡æ˜¾ç¤ºï¼Œä¸€äº›â€œçœ‹èµ·æ¥åˆç†â€çš„ TP/PP å› å­åœ¨ä¸Šåƒ GPU æ—¶ä¼šå¯¼è‡´æœ€å¤š 2Ã— çš„ååæŸå¤±ï¼Œä¸»è¦åŸå› æ˜¯è·¨èŠ‚ç‚¹çš„å¼ é‡å¹¶è¡Œ all-reduce æˆæœ¬è¿‡é«˜ã€‚å°† TP é™åˆ¶åœ¨å•æœºå†…ã€æŠŠè·¨æœºç»´åº¦ç•™ç»™ PP æ˜¯å®è·µä¸­éå¸¸å…³é”®çš„ç»éªŒã€‚(people.eecs.berkeley.edu)\nåˆé€‚çš„ micro-batch å¤§å°å¯ä»¥å†æŒ–å‡º 10%ï½15% çš„æ”¶ç›Šï¼šmicro-batch å¤ªå°ï¼Œkernel æ— æ³•è¢«å……åˆ†å¡«æ»¡ï¼›å¤ªå¤§åˆä¼šæ”¾å¤§ pipeline bubble æˆ–å‡»ç©¿æ˜¾å­˜ã€‚è®ºæ–‡çš„å®è¯è¡¨æ˜ï¼Œâ€œæœ€ä½³ micro-batchâ€ æ˜¯ä¸€ä¸ªå¼ºçƒˆä¾èµ–æ¨¡å‹è§„æ¨¡å’Œå¹¶è¡Œé…ç½®çš„è¶…å‚ã€‚(people.eecs.berkeley.edu)\nä¸ ZeRO-3 ç­‰çº¯ DP+å‚æ•°åˆ‡åˆ†æ–¹æ¡ˆç›¸æ¯”ï¼ŒPTD-P åœ¨ç™¾äº¿ï½åƒäº¿è§„æ¨¡ä¸Šæœ‰æ˜æ˜¾ä¼˜åŠ¿ï¼šåœ¨ 175B å’Œ 530B æ¨¡å‹ä¸Šï¼Œä¸ ZeRO-3 å¯¹æ¯”ï¼ŒPTD-P æ–¹æ¡ˆåœ¨ç›¸åŒè®¾å¤‡æ•°ä¸‹ååé«˜çº¦ 70%ï¼Œå…³é”®å·®å¼‚åœ¨äºå‡å°‘äº†è·¨èŠ‚ç‚¹å¤§è§„æ¨¡å‚æ•°åŒæ­¥ã€‚(people.eecs.berkeley.edu)\n\n5.1 å…³é”®å›¾è¡¨è§£è¯»\n\nä¸‹åˆ—å›¾è¡¨æè¿°åŸºäºè®ºæ–‡å’Œå®˜æ–¹åšå®¢ä¸­çš„å†…å®¹ï¼Œå…·ä½“æ•°å€¼ä»¥åŸæ–‡ä¸ºå‡†ã€‚\n\n\nå›¾ï¼šèšåˆåå vs GPU æ•°é‡ä¸æ¨¡å‹è§„æ¨¡\n\nç°è±¡ï¼šä»çº¦ 1.7B å‚æ•°æ¨¡å‹åœ¨ 32 GPUï¼Œä¸Šå‡åˆ° 1T æ¨¡å‹åœ¨ 3072 GPUï¼Œæ€»ååä»æ•° PFLOP/s æå‡åˆ° 502 PFLOP/sï¼Œæ•´ä½“æ‰©å±•æ•ˆç‡è¶…è¿‡ 100Ã—ã€‚(NVIDIA Developer)\næ”¯æ’‘çš„è§‚ç‚¹ï¼šè¯´æ˜ PTD-P æ¶æ„åœ¨ç°å®ç¡¬ä»¶ä¸ç½‘ç»œæ¡ä»¶ä¸‹å¯ä»¥ç¨³å½“æ‰©å±•åˆ°ä¸‡äº¿çº§æ¨¡å‹ï¼Œä¸ºåæ¥å„ç§ 500B / 1T æ¨¡å‹æä¾›äº†å¯è¡Œæ€§è¯æ˜ã€‚\n\nå›¾ï¼šGPipe vs 1F1B vs Interleaved 1F1B è°ƒåº¦æ—¶é—´çº¿\n\nç°è±¡ï¼š\n\nGPipeï¼šå…ˆæ‰§è¡Œæ‰€æœ‰ micro-batch çš„ forwardï¼Œå†æ‰§è¡Œæ‰€æœ‰ backwardï¼Œbubble å¤§ä¸”æ¿€æ´»æ˜¾å­˜å ç”¨é«˜ã€‚\n1F1Bï¼ˆPipeDream-Flushï¼‰ï¼šwarmup + steady äº¤æ›¿ F/Bï¼Œbubble ä¸ GPipe ç›¸åŒï¼Œä½†æ¿€æ´»æ˜¾å­˜å³°å€¼æ˜¾è‘—é™ä½ã€‚\ninterleaved 1F1Bï¼šæŠŠæ¯ä¸ª device ä¸Šçš„å±‚åˆ‡æˆå¤šä¸ª chunkï¼Œæ—¶é—´è½´ä¸Š flush ç‚¹æ˜æ˜¾æå‰ï¼Œbubble é•¿åº¦ç¼©çŸ­ã€‚(people.eecs.berkeley.edu)\n\næ”¯æ’‘çš„è§‚ç‚¹ï¼šè§£é‡Šäº†ä¸ºä»€ä¹ˆåœ¨ç›¸åŒæ˜¾å­˜é¢„ç®—ä¸‹ï¼Œinterleaved è°ƒåº¦å¯ä»¥é¢å¤–å†åƒæ‰ä¸€éƒ¨åˆ† bubbleï¼Œä»è€Œå¤šæ‹¿ä¸€æˆªååã€‚\n\nè¡¨ï¼šä¸åŒ TP/PP/DP é…ç½®ä¸‹çš„ååå¯¹æ¯”\n\nç°è±¡ï¼šä¾‹å¦‚åœ¨ 175B / 530B æ¨¡å‹ä¸Šï¼Œä½¿ç”¨æ›´é«˜çš„ TPï¼ˆè·¨èŠ‚ç‚¹ï¼‰ä¼šæ˜¾è‘—æ¶åŒ–ååï¼Œè€Œå¢åŠ  PP æ·±åº¦å¹¶é™åˆ¶ TP åœ¨å•æœºå†…åˆ™èƒ½æŒç»­é è¿‘çº¿æ€§æ‰©å±•ã€‚(people.eecs.berkeley.edu)\næ”¯æ’‘çš„è§‚ç‚¹ï¼šå®šé‡å±•ç¤ºäº†â€œTP å°½é‡å±€é™åœ¨å•æœºã€PP è´Ÿè´£è·¨æœºæ‰©å±•â€çš„å®è·µå‡†åˆ™ï¼Œåé©³äº†â€œTP è¶Šå¤§è¶Šå¥½â€çš„ç›´è§‰ã€‚\n\n\nç»“æœè§£è¯»ä¸è¾¹ç•Œ\næ€»ä½“æ¥çœ‹ï¼Œè¿™äº›å®éªŒéå¸¸æœ‰åŠ›åœ°æ”¯æ’‘äº†è®ºæ–‡çš„ä¸¤ä¸ªæ ¸å¿ƒç»“è®ºï¼š 1ï¼‰ä¸‰ç»´å¹¶è¡Œ + interleaved è°ƒåº¦åœ¨ç°å®å¤§é›†ç¾¤ä¸Šæ˜¯å¯è½åœ°ä¸”é«˜æ•ˆçš„ï¼› 2ï¼‰TP/PP/DP å’Œ micro-batch çš„ç»„åˆæœ‰ä¸€å¥—å¯å¤ç”¨çš„ç»éªŒè§„åˆ™ã€‚\nä½†ä¹Ÿæœ‰ä¸€äº›æ˜æ˜¾çš„è¾¹ç•Œä¸æ½œåœ¨æ··æ·†å› ç´ ï¼š\n\nå®éªŒä¸»è¦åŸºäº A100 + NVLink + é«˜é€Ÿ InfiniBand çš„â€œè±ªåé…ç½®â€ï¼Œåœ¨æ™®é€šä»¥å¤ªç½‘ç¯å¢ƒä¸‹çš„å¯è¿ç§»æ€§éœ€è¦é¢å¤–å®éªŒã€‚\nç›®æ ‡ä»»åŠ¡åå‘ GPT ç±»è‡ªå›å½’ LLMï¼Œå°šæœªç³»ç»Ÿè¦†ç›– MoEã€encoder-decoderã€å¤šæ¨¡æ€ç­‰æ¶æ„ã€‚\nå¯¹æ”¶æ•›è´¨é‡ä¸ç¨³å®šæ€§çš„åˆ†æç›¸å¯¹ç®€ç•¥ï¼ˆå°¤å…¶æ˜¯å¯¹äºæå¤§ batchã€æ¿€è¿› pipeline æ·±åº¦çš„è®¾ç½®ï¼‰ï¼Œåœ¨â€œåªçœ‹ throughput ä¸çœ‹ lossâ€çš„åœºæ™¯é‡Œå¯èƒ½ä¼šè¢«è¯¯ç”¨ã€‚\n\n\nå…­ã€ä¼˜ç‚¹ä¸å±€é™\näº®ç‚¹ï¼ˆStrengthsï¼‰\n\né—®é¢˜å®šä¹‰æ¸…æ™°ä¸”è´´è¿‘å·¥ä¸šå®è·µï¼šç›´æ¥ç„å‡†â€œå¦‚ä½•é«˜æ•ˆè®­ç»ƒ 1T æ¨¡å‹â€çš„ç³»ç»Ÿé—®é¢˜ï¼Œè€Œä¸æ˜¯æŠ½è±¡çš„ç†è®ºæ¨¡å‹ï¼Œéå¸¸å¥‘åˆå½“ä¸‹å¤§æ¨¡å‹è®­ç»ƒéœ€æ±‚ã€‚(arXiv)\næ–¹æ³•è®¾è®¡ç³»ç»Ÿä¸”ç»„åˆæ€§å¼ºï¼šé€šè¿‡ PTD-P æŠŠ TP / PP / DP æœ‰æœºåœ°æ‹¼åœ¨ä¸€èµ·ï¼Œå¹¶ç»™å‡º interleaved 1F1B è¿™æ ·å¯ç›´æ¥åœ¨ç°æœ‰æ¡†æ¶ä¸­å®ç°çš„è°ƒåº¦æ”¹è¿›ã€‚\nåˆ†æä¸å·¥ç¨‹ç»†èŠ‚å…¼é¡¾ï¼šæ—¢æœ‰ bubble å…¬å¼ã€é€šä¿¡é‡ç­‰ç†è®ºåˆ†æï¼Œåˆç»™å‡ºäº† network bandwidth ä½¿ç”¨ã€kernel bound/ memory bound åˆ¤å®šç­‰éå¸¸â€œå·¥ç¨‹å‘³â€çš„æŒ‡æ ‡ã€‚(people.eecs.berkeley.edu)\nå®éªŒè§„æ¨¡ä¸è¯´æœåŠ›ï¼šåœ¨ 3072 A100 ä¸Šè®­ç»ƒ 1T æ¨¡å‹çš„ç»“æœæœ¬èº«å°±å…·æœ‰å¾ˆå¼ºçš„â€œç¤ºèŒƒæ•ˆåº”â€ï¼Œä¹Ÿä¸ºåç»­å·¥ä½œæä¾›äº†å¯¹æ ‡åŸºçº¿ã€‚(people.eecs.berkeley.edu)\nå¼€æºå®ç°å¯ç›´æ¥å‚è€ƒï¼šåŸºäº Megatron-LM çš„å…¬å¼€ä»£ç è®©è¯»è€…å¯ä»¥ç›´æ¥å¯¹ç…§å®ç°ç»†èŠ‚ã€å¤ç°å®éªŒç”šè‡³æ‰©å±•è‡ªå·±çš„å¹¶è¡Œç­–ç•¥ã€‚(GitHub)\n\nå±€é™ï¼ˆLimitationsï¼‰\n\nä¾èµ–é«˜ç«¯ç¡¬ä»¶ä¸ç½‘ç»œç¯å¢ƒï¼šå‡ ä¹æ‰€æœ‰å…³é”®ç»“è®ºéƒ½æ˜¯åœ¨ NVLink + é«˜é€Ÿ InfiniBand çš„å‰æä¸‹ç»™å‡ºçš„ï¼Œå¯¹â€œæ™®é€šæœºæˆ¿é…ç½®â€çš„é€‚ç”¨æ€§éœ€è¦è°¨æ…è§£è¯»ã€‚\næ¨¡å‹ç±»å‹ç›¸å¯¹å•ä¸€ï¼šä¸»è¦èšç„¦ GPT ç±» dense Transformerï¼Œå¯¹ MoEã€sparse attentionã€encoder-decoder ç­‰ç»“æ„ç¼ºä¹ç³»ç»Ÿå®éªŒã€‚\nç¼ºå°‘è‡ªåŠ¨å¹¶è¡Œæœç´¢æœºåˆ¶ï¼šè™½ç„¶ç»™å‡ºäº† heuristicsï¼Œä½†å¹¶æ²¡æœ‰ç±»ä¼¼ FlexFlow / Alpa é‚£æ ·çš„è‡ªåŠ¨æ¢ç´¢æœºåˆ¶ï¼Œå®é™…ä½¿ç”¨ä»éœ€è¦å¤§é‡ç»éªŒå’Œäººå·¥è°ƒå‚ã€‚(people.eecs.berkeley.edu)\nè®­ç»ƒè´¨é‡åˆ†æä¸å¤Ÿæ·±å…¥ï¼šæ›´åé‡ç³»ç»ŸæŒ‡æ ‡ï¼ˆthroughputã€åˆ©ç”¨ç‡ç­‰ï¼‰ï¼Œå¯¹ä¸åŒå¹¶è¡Œç­–ç•¥ / batch é…ç½®ä¸‹æ”¶æ•›é€Ÿåº¦ä¸æœ€ç»ˆç²¾åº¦çš„å½±å“è®¨è®ºæœ‰é™ã€‚\nä¸ ZeRO / FSDP ç­‰å‚æ•°åˆ‡åˆ†æŠ€æœ¯çš„ç»„åˆç©ºé—´æœªå®Œå…¨å±•å¼€ï¼šåªç»™å‡ºäº†ä¸€äº›å¯¹æ¯”ç»“æœï¼Œä½†æ²¡æœ‰æ·±å…¥æ¢è®¨â€œPTD-P + ZeRO-likeâ€çš„å¯èƒ½ç»„åˆã€‚(people.eecs.berkeley.edu)\n\n\nä¸ƒã€ä¸šå†…ç›¸å…³å·¥ä½œå¯¹æ¯”\nè¿™é‡Œé€‰ä¸‰ç±»å…¸å‹å·¥ä½œåšæ¨ªå‘å¯¹æ¯”ï¼šMegatron-LMï¼ˆåŸå§‹å¼ é‡å¹¶è¡Œï¼‰ã€GPipeï¼ˆæµæ°´å¹¶è¡Œï¼‰å’Œ ZeRO ç³»åˆ—ï¼ˆæ•°æ®å¹¶è¡Œ + å‚æ•°åˆ‡åˆ†ï¼‰ã€‚\n\n\n\n\n\n\n\n\n\nå·¥ä½œ\né—®é¢˜èšç„¦\næ–¹æ³•è·¯çº¿\nä¸æœ¬æ–‡å…³ç³»ä¸è¯„ä»·\n\n\n\n\nMegatron-LM (2019) (arXiv)\nå•æœºå¤šå¡ã€æ˜¾å­˜ä¸è¶³æ—¶å¦‚ä½•é€šè¿‡ intra-layer å¼ é‡å¹¶è¡Œè®­ç»ƒ 10B çº§ Transformer\nä¸»è¦é€šè¿‡åˆ—å¹¶è¡Œ / è¡Œå¹¶è¡Œçº¿æ€§å±‚ + all-reduce/all-gatherï¼Œåœ¨ 8 GPU å†…å®ç°æ•°åäº¿å‚æ•°æ¨¡å‹\næœ¬æ–‡åœ¨æ­¤åŸºç¡€ä¸Šæ‰©å±•åˆ°â€œå¤šæœº+æ›´å¤š GPUâ€ï¼Œå¹¶é¦–æ¬¡ç³»ç»Ÿæ€§æ¢ç´¢ TP ä¸ PPã€DP çš„ç»„åˆï¼Œæ˜¯ä»â€œå•æœºå¼ é‡å¹¶è¡Œâ€åˆ°â€œä¸‰ç»´å¹¶è¡Œâ€çš„è‡ªç„¶æ¼”è¿›\n\n\nGPipe (2019) (fid3024.github.io)\nå¦‚ä½•é€šè¿‡æµæ°´å¹¶è¡Œè®­ç»ƒè¶…å¤§æ¨¡å‹å¹¶ä¿æŒåŒæ­¥è¯­ä¹‰\nå°†æ¨¡å‹åˆ‡ä¸ºå¤šä¸ª stageï¼Œé€šè¿‡ micro-batch æµæ°´ + activation recompute å®ç°é«˜æ•ˆ pipeline\næœ¬æ–‡ç»§æ‰¿ GPipe çš„åŒæ­¥è¯­ä¹‰ä¸ batch splitting æ€è·¯ï¼Œä½†åœ¨è°ƒåº¦ä¸Šæ”¹ç”¨ PipeDream-Flush / interleaved 1F1Bï¼Œä»¥é™ä½æ¿€æ´»æ˜¾å­˜å’Œ bubbleï¼Œæ˜¯æ›´å·¥ç¨‹åŒ–çš„â€œç¬¬äºŒä»£æµæ°´æ–¹æ¡ˆâ€\n\n\nZeRO / ZeRO-Offload / ZeRO-3 (arXiv)\né€šè¿‡å‚æ•° / æ¢¯åº¦ / ä¼˜åŒ–å™¨çŠ¶æ€åˆ‡åˆ† + offload åœ¨ DP æ¡†æ¶ä¸‹æ”¯æ’‘è¶…å¤§æ¨¡å‹\nåœ¨æ•°æ®å¹¶è¡Œç»´åº¦ä¸Šå¯¹å‚æ•°ä¸ä¼˜åŒ–å™¨è¿›è¡Œç»†ç²’åº¦åˆ†ç‰‡ï¼Œå¹¶å¯å°†éƒ¨åˆ†çŠ¶æ€ offload åˆ° CPU/NVMe\nZeRO ç³»åˆ—å¼ºè°ƒâ€œDP+å‚æ•°åˆ‡åˆ†â€è·¯çº¿ï¼Œæœ¬å·¥ä½œå±•ç¤ºäº†åœ¨ 175B/530B è§„æ¨¡ä¸Š PTD-P å¯¹ ZeRO-3 çš„æ€§èƒ½ä¼˜åŠ¿ï¼›ä¸¤è€…åœ¨ç†å¿µä¸Šæ˜¯äº’è¡¥çš„ï¼Œåç»­ä¹Ÿå¯ä»¥æ¢ç´¢ PTD-P ä¸ ZeRO/FSDP çš„ç»„åˆ\n\n\n\næ€»ä½“æ¥è¯´ï¼Œè¿™ç¯‡ SCâ€™21 è®ºæ–‡æ›´åƒæ˜¯â€œå¼ é‡å¹¶è¡Œ + æµæ°´å¹¶è¡Œ + æ•°æ®å¹¶è¡Œâ€è¿™æ¡è·¯çº¿çš„é˜¶æ®µæ€§é›†å¤§æˆè€…ï¼Œä¸ ZeRO/FSDP ç­‰â€œå‚æ•°åˆ‡åˆ†â€è·¯çº¿å±äºå¯äº’è¡¥ã€å¯å¯¹æ¯”çš„ä¸¤æ¡ä¸»çº¿ã€‚\n7.1 ä¸ªäººè§‚ç‚¹\nä» reviewer çš„è§†è§’çœ‹ï¼Œè¿™ç¯‡å·¥ä½œåœ¨ baseline é€‰æ‹©ä¸å®éªŒè®¾ç½®ä¸Šè¿˜æ˜¯æ¯”è¾ƒè°¨æ…çš„ï¼šå¯¹æ¯”äº† ZeRO-3 ç­‰å½“æ—¶ä¸»æµæ–¹æ¡ˆï¼Œä¹Ÿç»™å‡ºäº†è¾ƒå®Œæ•´çš„ç¼©æ”¾æ›²çº¿ã€‚ä½†å¦‚æœè¿›ä¸€æ­¥æŠ ç»†èŠ‚ï¼Œæˆ‘ä¼šå¸Œæœ›çœ‹åˆ°ï¼š\n\næ›´å¤šå…³äºâ€œåŒç­‰æ˜¾å­˜é¢„ç®—â€çš„å¯¹æ¯”ï¼Œä¾‹å¦‚åœ¨ç›¸åŒæ˜¾å­˜å³°å€¼è€Œéç›¸åŒè®¾å¤‡æ•°é‡ä¸‹ PTD-P vs ZeRO/FSDP çš„ååå·®å¼‚ï¼›\nå¯¹è®­ç»ƒç¨³å®šæ€§å’Œ sample efficiency çš„æ›´ç»†ç²’åº¦åˆ†æï¼Œå°¤å…¶æ˜¯æå¤§ batchã€ææ·± pipeline æ—¶æ˜¯å¦éœ€è¦é¢å¤–æŠ€å·§ï¼ˆLR scheduleã€optimizer scaling ç­‰ï¼‰ã€‚\n\nå¦‚æœç”±æˆ‘æ¥è®¾è®¡ä¸€ç‰ˆâ€œå‡çº§ç‰ˆâ€å®éªŒï¼Œæˆ‘å¯èƒ½ä¼šï¼š\n\nåŠ å…¥ä¸åŒç½‘ç»œæ‹“æ‰‘ï¼ˆä¾‹å¦‚åªç”¨ 100GbEã€RoCEï¼‰çš„å®éªŒï¼Œå¯¹ PTD-P çš„å¯è¿ç§»æ€§åšæ›´å…¨é¢çš„è¯„ä¼°ï¼›\nç³»ç»Ÿæ¢ç´¢ â€œPTD-P + å‚æ•°åˆ‡åˆ†ï¼ˆZeRO/FSDPï¼‰â€ çš„ç»„åˆç©ºé—´ï¼Œçœ‹æ˜¯å¦å­˜åœ¨æ›´ä¼˜çš„ Pareto å‰æ²¿ç‚¹ï¼›\nåœ¨åŒä¸€å¥—ä»£ç æ¡†æ¶ä¸‹å…¬å¼€ä¸€ç»„â€œæ ‡å‡†é…ç½®â€ï¼ˆYAML/JSONï¼‰ï¼Œæ–¹ä¾¿ç¤¾åŒºç›´æ¥å¯¹æ ‡å’Œå¤ç°ã€‚\n\n\nå…«ã€åœ¨å®é™…è®­ç»ƒæ ˆä¸­å¦‚ä½•è½åœ°ï¼Ÿ\nå¦‚æœä½ å·²ç»æœ‰ä¸€å¥—è‡ªå·±çš„å¤§è§„æ¨¡è®­ç»ƒæ ˆï¼ˆä¾‹å¦‚åŸºäº Megatron / DeepSpeed / vLLM ç­‰ï¼‰ï¼Œè¦å¼•å…¥æœ¬æ–‡æ–¹æ³•ï¼Œå¤§è‡´å¯ä»¥ä»ä»¥ä¸‹å‡ ä¸ªæ–¹é¢æ”¹é€ ï¼š\n\nDataLoader / æ•°æ®æ‰“åŒ…ä¸é¢„å¤„ç†\n\nç¡®ä¿æ•°æ®å¯ä»¥è¢«ç¨³å®šåœ°åˆ’åˆ†ä¸ºå¤§çš„ global batch å’Œè¶³å¤Ÿå¤šçš„ micro-batchï¼Œä»¥æ»¡è¶³ \\(m \\gg p\\) çš„æ¡ä»¶ã€‚\nå¯¹ packed dataset åšå¥½â€œæ ·æœ¬åˆ° micro-batchâ€çš„æ˜ å°„å’Œé‡å¤åº¦æ§åˆ¶ï¼Œé¿å… pipeline æ·±åº¦å¼•å…¥éšå¼çš„ data skewã€‚\n\nå¹¶è¡Œè°ƒåº¦ï¼ˆTP/PP/DP ç»„åˆï¼‰\n\nåœ¨ launcher ç«¯æ˜¾å¼å¼•å…¥ä¸‰ç»´å¹¶è¡Œé…ç½®ï¼štensor_parallel_size, pipeline_model_parallel_size, data_parallel_sizeã€‚\nrank æ˜ å°„ä¸Šï¼Œä¼˜å…ˆä¿è¯ï¼šTP ç»´åº¦å®Œå…¨è½åœ¨å•æœºå†…ï¼ŒPP ç»´åº¦è·¨æœºï¼ŒDP å†è·¨æ›´å¤§èŒƒå›´ï¼›å¿…è¦æ—¶æ ¹æ®ç‰©ç†æ‹“æ‰‘ç¼–å†™è‡ªå®šä¹‰ rank -&gt; (dp,tp,pp) æ˜ å°„å‡½æ•°ã€‚(people.eecs.berkeley.edu)\nå·¥ç¨‹é£é™©ï¼šæ˜ å°„é”™è¯¯ä¼šç›´æ¥å¯¼è‡´â€œè·¨èŠ‚ç‚¹å¤§ all-reduceâ€ï¼Œæ€§èƒ½å¤§è·³æ°´ã€‚\n\nå¼ é‡å¹¶è¡Œç­–ç•¥ä¸ç®—å­å®ç°\n\næŠŠæ ¸å¿ƒæ¨¡å—ï¼ˆQKV projectionã€FFNã€embeddingã€LM head ç­‰ï¼‰æ”¹å†™ä¸ºå¼ é‡å¹¶è¡Œç‰ˆæœ¬ï¼Œåœ¨ TP ç»´åº¦ä¸Šæ’å…¥å¿…è¦çš„ all-reduce / all-gatherã€‚\nå¯¹äºâ€œéå¯¹ç§°æ¨¡å—â€ï¼ˆä¾‹å¦‚è¶…å¤§è¯è¡¨ embeddingã€MoE expertsï¼‰ï¼Œéœ€è¦å•ç‹¬ç­–ç•¥ï¼ˆå¦‚ vocabulary parallel embeddingã€expert parallel ç­‰ï¼‰ã€‚\né£é™©ï¼šå‚æ•°åˆå§‹åŒ–ã€checkpoint load/save éƒ½å¿…é¡»éµå¾ªç›¸åŒåˆ†ç‰‡è§„åˆ™ï¼Œå¦åˆ™ææ˜“åœ¨æ¢å¤è®­ç»ƒæ—¶è¸©é›·ã€‚\n\næµæ°´å¹¶è¡Œè°ƒåº¦ä¸é€šä¿¡\n\nåœ¨ pipeline ç»´åº¦å¼•å…¥ stage åˆ’åˆ†é€»è¾‘ï¼ŒæŠŠæ¨¡å‹åˆ†ä¸º num_layers / pipeline_size å·¦å³çš„å‡åŒ€å—ï¼›å†åŸºäº interleaved æ–¹æ¡ˆè¿›ä¸€æ­¥æŠŠæ¯å—æ‹†æˆå¤šä¸ª chunkã€‚\nå®ç° 1F1B å’Œ interleaved 1F1B è°ƒåº¦å™¨ï¼Œç¡®ä¿ï¼š\n\nflush ç‚¹ä¸€è‡´ï¼›\nä¸åŒ stage çš„ weight ç‰ˆæœ¬åœ¨ä¸€ä¸ª batch å†…ä¿æŒä¸¥æ ¼åŒæ­¥ã€‚\n\né£é™©ï¼šä¸€æ—¦è°ƒåº¦å™¨å®ç°æœ‰ bugï¼ˆä¾‹å¦‚æŸäº› micro-batch çš„ F/B é¡ºåºé”™ä½ï¼‰ï¼Œéå¸¸éš¾ä»¥æ’æŸ¥ï¼Œä¸”è¡¨è±¡å¾€å¾€åªæ˜¯â€œloss ä¸ç¨³å®šâ€ã€‚(people.eecs.berkeley.edu)\n\né€šä¿¡ backend ä¸ overlap\n\nåœ¨ NCCL åç«¯æ˜¾å¼åŒºåˆ†å‡ ç±»é€šä¿¡ï¼šTP all-reduceã€DP all-reduceã€PP P2Pï¼ˆsend/recvï¼‰ï¼Œå¹¶ç»™æ¯ç±»åˆ†é…ç‹¬ç«‹çš„ stream ä¸ä¼˜å…ˆçº§ã€‚\nå°è¯•æŠŠ DP all-reduce æ”¾åœ¨ backward tail éƒ¨åˆ†ä¸éƒ¨åˆ†è®¡ç®—é‡å ï¼ŒæŠŠ PP P2P ä¸ä¸‹ä¸€ä¸ª micro-batch çš„ F/B é‡å ã€‚\né£é™©ï¼šstream ä¾èµ–ä¸äº‹ä»¶ï¼ˆeventï¼‰åŒæ­¥å…³ç³»å¤æ‚ï¼Œå®¹æ˜“åŸ‹ race condition æˆ–æ­»é”ã€‚\n\næ˜¾å­˜ç®¡ç†ä¸ activation recompute\n\næ ¹æ®è®ºæ–‡å»ºè®®ï¼Œåœ¨è¾ƒæ·± pipeline è®¾ç½®ä¸‹ä¼˜å…ˆå¼€å¯ activation recomputeï¼ŒæŠŠæ¿€æ´»æ˜¾å­˜å³°å€¼ä» \\(O(mL)\\) å‹ç¼©åˆ° \\(O(p)\\) çº§åˆ«ã€‚(fid3024.github.io)\nå¯¹ä¸åŒ moduleï¼ˆattention / FFN / embeddingï¼‰è®¾ç½®ä¸åŒçš„ recompute ç­–ç•¥ï¼Œé¿å…æŠŠæ‰€æœ‰å±‚éƒ½é‡ç®—åˆ°å¯¼è‡´ç®—åŠ›æµªè´¹ã€‚\né£é™©ï¼šæ˜¾å­˜ç¢ç‰‡å’Œ allocator è¡Œä¸ºåœ¨å¤§è§„æ¨¡å¹¶è¡Œä¸‹ä¼šæ”¾å¤§ï¼Œéœ€è¦ä»”ç»†è§‚æµ‹ allocated / reserved / active ç­‰æŒ‡æ ‡ã€‚\n\né…ç½®æœç´¢ / è‡ªåŠ¨è°ƒå‚\n\næŠŠè®ºæ–‡ä¸­çš„ heuristics å°è£…ä¸ºä¸€ä¸ªâ€œå¹¶è¡Œé…ç½®å»ºè®®å™¨â€ï¼šç»™å®šæ¨¡å‹è§„æ¨¡ã€ç›®æ ‡åºåˆ—é•¿åº¦ã€è®¾å¤‡æ•°é‡ï¼Œè¾“å‡ºå€™é€‰ (tp, pp, dp, microbatch) ç»„åˆã€‚\nåœ¨ä¸Šçº¿å‰å¯¹è‹¥å¹²å€™é€‰é…ç½®è·‘çŸ­ç¨‹ benchmarkï¼ˆå‡ ååˆ°å‡ ç™¾ stepï¼‰ï¼Œæ ¹æ®å®é™…ååã€é€šä¿¡å æ¯”ã€æ˜¾å­˜å³°å€¼é€‰æ‹©æœ€ç»ˆé…ç½®ã€‚\n\n\n\nä¹ã€å€¼å¾—è¿›ä¸€æ­¥æ¢ç´¢çš„ç ”ç©¶æ–¹å‘\n\nè‡ªåŠ¨åŒ–ä¸‰ç»´å¹¶è¡Œæœç´¢ä¸ä»£ä»·æ¨¡å‹\n\né—®é¢˜ï¼šç›®å‰ PTD-P çš„é…ç½®ä¸»è¦åŸºäºç»éªŒå’Œå°‘é‡è¯•éªŒï¼Œç¼ºå°‘ç³»ç»ŸåŒ–çš„è‡ªåŠ¨æœç´¢ã€‚\nä»·å€¼ï¼šæ„å»ºä¸€ä¸ªé’ˆå¯¹ TP/PP/DP + micro-batch çš„ä»£ä»·æ¨¡å‹ï¼Œå†ç»“åˆå›¾æœç´¢æˆ–å¼ºåŒ–å­¦ä¹ ï¼Œåœ¨ç»™å®šé›†ç¾¤æ‹“æ‰‘å’Œæ¨¡å‹ç»“æ„ä¸‹è‡ªåŠ¨ç»™å‡ºè¿‘ä¼¼æœ€ä¼˜é…ç½®ï¼Œå¯ä»¥æ˜¾è‘—é™ä½å·¥ç¨‹äººå‘˜çš„è¯•é”™æˆæœ¬ã€‚(Deepak Narayanan)\n\nä¸å‚æ•°åˆ‡åˆ† / FSDP çš„æ·±åº¦èåˆ\n\né—®é¢˜ï¼šå½“å‰ PTD-P å’Œ ZeRO/FSDP å¤šä»¥â€œè°æ›´å¿«â€æ¥å¯¹æ¯”ï¼Œç¼ºä¹å¯¹ä¸¤è€…äº’è¡¥æ€§çš„ç³»ç»Ÿæ¢ç´¢ã€‚\nä»·å€¼ï¼šæ¢ç´¢åœ¨ PTD-P å¤–åˆå ä¸€å±‚å‚æ•°åˆ‡åˆ†ï¼ˆä¾‹å¦‚å¯¹åµŒå…¥å±‚æˆ–ä¼˜åŒ–å™¨çŠ¶æ€åš FSDP/ZeROï¼‰çš„æ··åˆæ–¹æ¡ˆï¼Œæœ‰æœ›åœ¨ä¿æŒé«˜ååçš„åŒæ—¶è¿›ä¸€æ­¥é™ä½æ˜¾å­˜å³°å€¼ï¼Œä½¿å¾—æ›´å¤§æ¨¡å‹åœ¨æ›´å°é›†ç¾¤ä¸Šå¯è¡Œã€‚(DeepSpeed)\n\né¢å‘éå‡åŒ€æ¨¡å‹ç»“æ„çš„è´Ÿè½½å‡è¡¡æµæ°´å¹¶è¡Œ\n\né—®é¢˜ï¼šç°å®å¤§æ¨¡å‹è¶Šæ¥è¶Šâ€œéå‡åŒ€â€ï¼Œä¾‹å¦‚ embedding ç‰¹åˆ«å¤§ã€éƒ¨åˆ† block å¸¦ MoEã€decoder head ç‰¹åˆ«é‡ï¼Œç®€å•çš„â€œå‡åˆ†å±‚æ•°â€ä¸å†åˆç†ã€‚\nä»·å€¼ï¼šåœ¨ PTD-P æ¡†æ¶ä¸‹å¼•å…¥è‡ªåŠ¨ partitionï¼ˆå¦‚åŸºäº profile çš„å›¾åˆ’åˆ†ï¼‰ï¼Œå¯¹ pipeline stage åšè´Ÿè½½å‡è¡¡ï¼Œå¯ä»¥æ˜¾è‘—é™ä½å• stage æˆä¸ºç“¶é¢ˆçš„æ¦‚ç‡ã€‚(pacman.cs.tsinghua.edu.cn)\n\né’ˆå¯¹å¼±äº’è¿é›†ç¾¤çš„é²æ£’å¹¶è¡Œç­–ç•¥\n\né—®é¢˜ï¼šå¾ˆå¤šå®é™…é›†ç¾¤å¹¶æ²¡æœ‰ NVLink + å¤šè·¯ InfiniBand è¿™ç§é…ç½®ï¼Œå¦‚ä½•åœ¨ 100GbE æˆ–å•è·¯ IB ä¸Šè·å¾—æœ‰æ„ä¹‰çš„æ‰©å±•ä»ä¸æ¸…æ¥šã€‚\nä»·å€¼ï¼šç ”ç©¶åœ¨å¼±äº’è¿åœºæ™¯ä¸‹ï¼Œå¦‚ä½•è°ƒæ•´ TP/PP/DP çš„åˆ†é…ã€åŠ å…¥é€šä¿¡å‹ç¼©/ç¨€ç– all-reduceã€å»¶è¿Ÿæ›´æ–°ç­‰æ‰‹æ®µï¼Œä½¿ PTD-P èƒ½åœ¨â€œå¹³ä»·é›†ç¾¤â€ä¸Šä¾ç„¶å®ç”¨ã€‚\n\nç«¯åˆ°ç«¯è®­ç»ƒç¨³å®šæ€§ä¸å¤§ batch æ”¶æ•›æ€§ç ”ç©¶\n\né—®é¢˜ï¼špipeline æ·±åº¦ã€interleaved åº¦æ•°ã€micro-batch å¤§å°éƒ½ä¼šå½±å“æœ‰æ•ˆ batch å’Œæ¢¯åº¦å™ªå£°ï¼Œä½†ç›®å‰åˆ†ææœ‰é™ã€‚\nä»·å€¼ï¼šç³»ç»Ÿåœ°ç ”ç©¶ä¸åŒå¹¶è¡Œé…ç½®å¯¹ loss æ›²çº¿ã€æ³›åŒ–æ€§èƒ½çš„å½±å“ï¼Œå¯ä»¥æŒ‡å¯¼åœ¨ä¸ç‰ºç‰²æ”¶æ•›è´¨é‡çš„å‰æä¸‹æ›´æ¿€è¿›åœ°æ¨å¤§ batch å’Œæ¨é«˜ååã€‚\n\n\n\nåã€çŸ¥è¯†å›¾è°±æ€ç»´é“¾\nä»â€œè„‘å†…çŸ¥è¯†å›¾è°±â€çš„è§’åº¦ï¼Œè¿™ç¯‡è®ºæ–‡åœ¨å¤šä¸ªæ–¹å‘ä¸Šéƒ½èµ·åˆ°äº†â€œè¿æ¥èŠ‚ç‚¹â€çš„ä½œç”¨ï¼š\n\nå¹¶è¡Œä¸è°ƒåº¦\n\næä¾›äº†ä¸€ä¸ªç»å…¸çš„ä¸‰ç»´å¹¶è¡Œ PTD-P æ¨¡å¼ï¼ŒæŠŠ TP/PP/DP ä¸‰ç§æ€è·¯ç»Ÿä¸€åœ¨ä¸€ä¸ªæ¡†æ¶ä¸‹ã€‚(people.eecs.berkeley.edu)\né€šè¿‡ GPipe â†’ PipeDream-Flush â†’ interleaved 1F1B çš„æ¼”è¿›ï¼Œç»™å‡ºäº†å¦‚ä½•åœ¨ä¿æŒåŒæ­¥è¯­ä¹‰çš„å‰æä¸‹æé™å‹ç¼© pipeline bubble çš„ç»“æ„åŒ–æ–¹æ³•ã€‚(people.eecs.berkeley.edu)\n\nå†…å­˜ç®¡ç†ä¸æ˜¾å­˜ä¼˜åŒ–\n\nç”¨ activation recompute + æ·± pipeline æ§åˆ¶æ¿€æ´»æ˜¾å­˜ï¼ŒæŠŠå¤§éƒ¨åˆ†æ˜¾å­˜é¢„ç®—ç•™ç»™å‚æ•°å’Œ optimizerã€‚(fid3024.github.io)\nä¸ ZeRO/FSDP ç³»åˆ—å½¢æˆäº†â€œæ¿€æ´» vs å‚æ•°ä¼˜åŒ–â€çš„ä¸¤æ¡äº’è¡¥è·¯çº¿ã€‚(arXiv)\n\né€šä¿¡ä¸é›†ä½“æ“ä½œ\n\næ˜ç¡®åŒºåˆ†äº† TP all-reduce / DP all-reduce / PP P2P ä¸‰ç±»é€šä¿¡ï¼Œå¹¶å¼ºè°ƒæ‹“æ‰‘æ„ŸçŸ¥æ˜ å°„å¯¹æ€§èƒ½çš„é‡è¦æ€§ã€‚(people.eecs.berkeley.edu)\né€šè¿‡å¯¹ bisection bandwidth ä½¿ç”¨çš„åˆ†æï¼ŒæŠŠâ€œç½‘ç»œâ€ä»è¾…åŠ©å› ç´ æå‡ä¸ºä¸€ç­‰å…¬æ°‘ã€‚\n\nkernel ä¸ç®—å­ä¼˜åŒ–\n\nè™½ç„¶ä¸æ˜¯æœ¬æ–‡é‡ç‚¹ï¼Œä½†ä½œè€…å¼ºè°ƒä¸ºäº†è®©è®­ç»ƒ compute-boundï¼Œéœ€è¦é«˜æ•ˆå®ç° GEMMã€Attentionã€LayerNorm ç­‰æ ¸å¿ƒç®—å­ï¼Œè¿™ä¸åç»­å„ç§ FlashAttentionã€fused-kernel å·¥ä½œæœ‰å¤©ç„¶è¿æ¥ã€‚(people.eecs.berkeley.edu)\n\næ¨¡å‹ç»“æ„ä¸æ¶æ„è®¾è®¡\n\né»˜è®¤åœºæ™¯æ˜¯å¤šå±‚å‡åŒ€çš„ GPT Transformerï¼Œè¿™å¯¹åæ¥çš„äººåœ¨è®¾è®¡â€œå¤§æ¨¡å‹ç»“æ„â€æ—¶æä¾›äº†ä¸€ä¸ªâ€œå¯¹ pipeline å‹å¥½â€çš„å‚è€ƒèŒƒå¼ã€‚\nä¹Ÿä¸ºåç»­ MoE / encoder-decoder ç­‰éå‡åŒ€æ¶æ„å¦‚ä½•åµŒå…¥ PTD-P æä¾›äº†å‡ºå‘ç‚¹ã€‚\n\næ•°æ®ã€é¢„å¤„ç†ä¸æ‰“åŒ…ç­–ç•¥\n\nå¼ºè°ƒ large batch + å¤š micro-batch å¯¹æµæ°´å¹¶è¡Œçš„å¿…è¦æ€§ï¼Œé—´æ¥æ¨åŠ¨äº†å¤§å®¶åœ¨æ•°æ®ç®¡çº¿ä¸­æ›´æ—©åœ°åš packed datasetã€åˆ†å¸ƒå¼ sampler ç­‰å·¥ç¨‹ä¼˜åŒ–ã€‚\n\n\n10.1 ä¸ªäººæ”¶è·ä¸åæ€\nå¯¹æˆ‘ä¸ªäººè€Œè¨€ï¼Œè¿™ç¯‡è®ºæ–‡æœ€å¤§çš„å¯å‘æœ‰ä¸¤ç‚¹ï¼š\n\næŠŠâ€œå¹¶è¡Œç­–ç•¥â€å’Œâ€œé›†ç¾¤æ‹“æ‰‘â€è§†ä½œä¸€ä¸ªæ•´ä½“æ¥ä¼˜åŒ– å¾ˆå¤šæ—¶å€™æˆ‘ä»¬åœ¨è®¨è®º TP/PP/DP æ—¶ä¼šâ€œå…ˆè®¾å®šé€»è¾‘å¹¶è¡Œåº¦ï¼Œå†å»é€‚é…ç¡¬ä»¶â€ï¼Œè€Œè¿™ç¯‡å·¥ä½œåè¿‡æ¥ï¼šå®ƒå…ˆçœ‹æ¸…æ¥š A100 + NVSwitch + InfiniBand çš„ç‰©ç†ç»“æ„ï¼Œå†è®¾è®¡ PTD-P çš„ rank æ˜ å°„å’Œé€šä¿¡è°ƒåº¦ã€‚è¿™ç§â€œç¡¬ä»¶é©±åŠ¨çš„è½¯ä»¶è®¾è®¡â€æ€è·¯ï¼Œå¯¹ä»»ä½•åšå¤§è§„æ¨¡ç³»ç»Ÿçš„äººéƒ½å¾ˆå€¼å¾—å€Ÿé‰´ã€‚\nç³»ç»Ÿå·¥ä½œä¹Ÿå¯ä»¥åšå¾—éå¸¸â€œå·¥ç¨‹å¯å¤ç”¨â€ è®ºæ–‡ä¸ä»…ä»…ç»™å‡ºç»“æœï¼Œè¿˜ç»™äº†æ¸…æ™°çš„ç»éªŒå‡†åˆ™å’Œå…¬å¼€å®ç°ï¼ˆMegatron-LMï¼‰ã€‚è¿™ä½¿å¾—å®ƒä¸ä»…æ˜¯ä¸€ä¸ªç ”ç©¶æˆæœï¼Œä¹Ÿæ˜¯ä¸€ä¸ªå¯ä»¥ç›´æ¥ç…§æ¬åˆ°è‡ªå·±è®­ç»ƒæ ˆçš„â€œæ“ä½œæ‰‹å†Œâ€ã€‚å¯¹æˆ‘åç»­è®¾è®¡è‡ªå·±è®­ç»ƒç³»ç»Ÿï¼ˆæ— è®ºæ˜¯åŸºäº Megatronã€è¿˜æ˜¯æ›´è½»é‡çš„æ ˆï¼‰éƒ½æä¾›äº†ä¸€ä¸ªéå¸¸å¥½çš„æ¨¡æ¿ï¼šä»»ä½•è®¾è®¡ï¼Œéƒ½å°½é‡æ²‰æ·€ä¸ºå¯å¤ç”¨çš„ä»£ç ä¸ heuristicsã€‚\n\nåœ¨å®è·µå±‚é¢ï¼Œæˆ‘ä¼šè€ƒè™‘ï¼š\n\nåœ¨è‡ªå·±çš„è®­ç»ƒæ ˆä¸­ï¼ŒæŠŠ pipeline è°ƒåº¦æŠ½è±¡æˆä¸€ä¸ªå¯æ’æ‹”æ¨¡å—ï¼Œå°è¯•ä»æœ€åŸºç¡€çš„ 1F1B å‡çº§åˆ° interleaved 1F1Bï¼Œè§‚å¯Ÿå¯¹æ˜¾å­˜å’Œååçš„å…·ä½“å½±å“ï¼›\nç³»ç»Ÿæ•´ç†ä¸€å¥—é’ˆå¯¹è‡ªå·±é›†ç¾¤çš„ â€œTP/PP/DP + micro-batch æ¨èè¡¨â€ï¼Œå¹¶åŠ å…¥ç®€å•çš„ profile é©±åŠ¨æœºåˆ¶ï¼Œé€æ­¥å‘â€œè‡ªåŠ¨é…ç½®â€æ¼”è¿›ã€‚\n\n\næ€»ä½“è¯„ä»·ï¼šè¿™ç¯‡ SCâ€™21 è®ºæ–‡åœ¨â€œå¦‚ä½•æŠŠ GPT ç±»å¤§æ¨¡å‹å¯é åœ°è®­åˆ° 1T å‚æ•°â€è¿™ä¸ªé—®é¢˜ä¸Šç»™å‡ºäº†éå¸¸ç³»ç»Ÿä¸”å¯è½åœ°çš„ç­”æ¡ˆï¼Œæ˜¯ç†è§£å½“ä»Šä¸»æµä¸‰ç»´å¹¶è¡Œè®­ç»ƒæ ˆï¼ˆå°¤å…¶æ˜¯ Megatron ç³»ï¼‰çš„å¿…è¯»æ–‡çŒ®ï¼Œæ›´åå·¥ç¨‹ä¸ç³»ç»Ÿä¼˜åŒ–ï¼Œå¯¹åšå¤§è§„æ¨¡è®­ç»ƒåŸºç¡€è®¾æ–½çš„è¯»è€…å°¤å…¶æœ‰é•¿æœŸå‚è€ƒä»·å€¼ã€‚\n\n","categories":["è®ºæ–‡é˜…è¯»"],"tags":["paper"]},{"title":"pytorchä¸­çš„streamå’Œevent","url":"/2025/09/07/distribute/stream_event/","content":"\n\n\nä¸€å¥è¯æ€»è§ˆï¼šæµï¼ˆstreamï¼‰æ˜¯ GPU ä¸Šçš„â€œæœ‰åºæŒ‡ä»¤é˜Ÿåˆ—â€ï¼Œäº‹ä»¶ï¼ˆeventï¼‰æ˜¯æ’åœ¨æµæ—¶é—´çº¿ä¸Šçš„â€œæ …æ /æ—¶é—´æˆ³â€ã€‚æŠŠ event.record() æ”¾åœ¨ç”Ÿäº§æµä¸Šï¼Œå†åœ¨æ¶ˆè´¹æµé‡Œ wait_event()ï¼Œå°±èƒ½åšåˆ°è®¾å¤‡ä¾§çš„æ— é˜»å¡ä¾èµ–ç¼–æ’ã€‚(docs.pytorch.org)\n\n\n1. åŸºæœ¬æ¦‚å¿µ\n\nStreamï¼ˆæµï¼‰ï¼šåŒä¸€æ¡æµå†…æŒ‰æäº¤é¡ºåºï¼ˆFIFOï¼‰æ‰§è¡Œï¼›ä¸åŒæµå½¼æ­¤ç‹¬ç«‹ï¼Œå¯å¹¶è¡Œè¿è¡Œã€‚PyTorch çš„ torch.cuda.Stream å°±æ˜¯ CUDA æµçš„å°è£…ï¼Œå¹¶æä¾› record_event / wait_event / wait_stream / synchronize ç­‰æ–¹æ³•ã€‚(docs.pytorch.org)\nEventï¼ˆäº‹ä»¶ï¼‰ï¼šåŒæ­¥æ ‡è®°ã€‚å¯ç”¨äºæµ‹æ—¶ä¸è·¨æµåŒæ­¥ï¼šåœ¨ç”Ÿäº§æµ record()ï¼Œåœ¨æ¶ˆè´¹æµ wait()/wait_event()ã€‚äº‹ä»¶ä¹Ÿå¯ elapsed_time() è¯»å–GPU ç«¯çš„æ¯«ç§’è®¡æ—¶ã€‚(docs.pytorch.org)\né»˜è®¤æµè¯­ä¹‰ï¼š\n\nLegacy default stream ä¼šä¸å…¶å®ƒï¼ˆé˜»å¡å‹ï¼‰æµäº’ç›¸åŒæ­¥ï¼›\nPer-thread default streamï¼ˆPTDSï¼‰ ä¸ä¸å…¶ä»–æµåŒæ­¥ï¼Œè¡Œä¸ºæ›´åƒæ˜¾å¼åˆ›å»ºçš„æµã€‚ ä¸¤è€…å¯åœ¨ç¼–è¯‘/å®å±‚é¢é€‰æ‹©ï¼Œè¡Œä¸ºä¸åŒä¼šå½±å“æ˜¯å¦â€œè‡ªåŠ¨åŒæ­¥â€ã€‚(NVIDIA Docs)\n\n\n\n2. ä¸‰ç§â€œç­‰å¾…â€çš„ä½œç”¨åŸŸï¼ˆè¶Šå°è¶Šå¥½ï¼‰\n\nè®¾å¤‡çº§ï¼štorch.cuda.synchronize(device) â€”â€” ç­‰è¯¥è®¾å¤‡ä¸Šæ‰€æœ‰æµåˆ°å½“å‰ä¸ºæ­¢çš„å·¥ä½œå®Œæˆã€‚æœ€é‡ï¼Œä¸€èˆ¬å°‘ç”¨ã€‚ï¼ˆè¯­ä¹‰ç­‰åŒ cudaDeviceSynchronizeï¼‰(developer.download.nvidia.com)\nå•æµçº§ï¼šstream.synchronize() â€”â€” åªç­‰è¿™ä¸€æ¡æµå·²æäº¤çš„å·¥ä½œï¼Œç­‰åŒ cudaStreamSynchronizeã€‚(docs.pytorch.org)\näº‹ä»¶çº§ï¼ševent.synchronize() â€”â€” åªç­‰è¯¥äº‹ä»¶æ‰€æ•è·çš„å·¥ä½œï¼Œç­‰åŒ cudaEventSynchronizeã€‚ç²’åº¦æœ€ç»†ï¼Œæ¨èä¼˜å…ˆç”¨äº‹ä»¶æ¥è¡¨è¾¾ä¾èµ–ã€‚(docs.pytorch.org)\n\n\nå£è¯€ï¼šdevice &gt; stream &gt; eventï¼ˆç­‰å¾…èŒƒå›´ä»å¤§åˆ°å°ï¼‰ã€‚é€‰æœ€å°å¿…è¦èŒƒå›´ï¼Œä¿ç•™å¹¶è¡Œåº¦ã€‚(developer.download.nvidia.com)\n\n\n3. è·¨æµåŒæ­¥çš„ä¸‰ç§æ–¹å¼\n\näº‹ä»¶æ …æ ï¼ˆæ¨èï¼‰\n\nç”Ÿäº§æµï¼ševent.record()\næ¶ˆè´¹æµï¼šconsumer.wait_event(event)ï¼ˆæˆ– event.wait(consumer)ï¼‰ è¯¥è°ƒç”¨ç«‹å³è¿”å›ï¼Œåªæ˜¯æŠŠâ€œç­‰å¾… eâ€è¿™æ¡ä¾èµ–å†™è¿›äº†æ¶ˆè´¹æµçš„é˜Ÿåˆ—ï¼›åç»­æäº¤çš„å·¥ä½œéƒ½ä¼šåœ¨ e å®Œæˆåæ‰§è¡Œã€‚(docs.pytorch.org)\n\næµ-æµç­‰å¾…\n\nthis.wait_stream(that)ï¼šè®© this æµåç»­å·¥ä½œï¼Œç­‰å¾… that æµå½“å‰å·²æäº¤çš„å·¥ä½œå®Œæˆã€‚(docs.pytorch.org)\n\né»˜è®¤æµè¯­ä¹‰ï¼ˆå†å²å…¼å®¹ï¼‰\n\nè‹¥ä½¿ç”¨ legacy default streamï¼Œå®ƒä¼šä¸å…¶å®ƒé˜»å¡æµäº’ç›¸åŒæ­¥ï¼›PTDS åˆ™ä¸ä¼šã€‚æ–°ä»£ç ä¸å»ºè®®ä¾èµ–è¿™ç§â€œéšå¼åŒæ­¥â€ã€‚(NVIDIA Docs)\n\n\n\n4. å¼ é‡ç”Ÿå‘½å‘¨æœŸçš„å®‰å…¨ï¼ˆsafeï¼‰ç”¨æ³•\nè·¨æµå…±äº«åŒä¸€å—æ˜¾å­˜æ—¶ï¼Œé™¤äº†â€œå†™æ¸…æ¥šä¾èµ–â€ï¼ˆäº‹ä»¶/æµç­‰å¾…ï¼‰ï¼Œè¿˜åº”åœ¨ä½¿ç”¨è¯¥å¼ é‡çš„æµä¸Šè°ƒç”¨ï¼š\ntensor.record_stream(consumer_stream)\nè¿™ä¼šå‘Šè¯‰ CUDA ç¼“å­˜åˆ†é…å™¨ï¼šè¯¥å¼ é‡ä¹Ÿåœ¨ consumer_stream ä¸Šè¢«ç”¨è¿‡ï¼Œä»è€Œé¿å…åœ¨ç”Ÿäº§æµé‡Šæ”¾åè¢«è¿‡æ—©å¤ç”¨ï¼Œé€ æˆæ½œåœ¨è¯»å†™ç«æ€ã€‚å¦åˆ™éœ€è¦åœ¨é‡Šæ”¾å‰æŠŠä½¿ç”¨åŒæ­¥å›åˆ›å»ºæµã€‚(docs.pytorch.org)\n\n5. CPUâ†”GPU æ‹·è´ä¸ non_blocking / pinned memory\n\nåªæœ‰å½“é¡µé”å®šå†…å­˜ï¼ˆpinnedï¼‰å‚ä¸æ—¶ï¼Œå¾ˆå¤šæ‹·è´æ‰èƒ½çœŸæ­£å¼‚æ­¥åŒ–å¹¶ä¸è®¡ç®—é‡å ï¼›PyTorch æ•™ç¨‹å¯¹ pin_memory() ä¸ non_blocking=True çš„è¡Œä¸ºåšäº†ç³»ç»Ÿè¯´æ˜ã€‚(docs.pytorch.org)\nè¯»å– D2H ç»“æœå‰ï¼Œåº”ç­‰å¾…æ‹·è´å®Œæˆï¼ˆäº‹ä»¶æˆ–åŒæ­¥ï¼‰ï¼Œä¸è¦ç›´æ¥åœ¨ CPU ç«¯æ¶ˆè´¹å¼‚æ­¥ç»“æœã€‚(docs.pytorch.org)\n\næ¨èæ¨¡å¼ï¼ˆD2H æ‹·è´ä¸â€œå¡ä½â€æ•´æœºï¼Œåªåœ¨ç”¨åˆ°ç»“æœæ—¶å°èŒƒå›´ç­‰å¾…ï¼‰ï¼š\nimport torchx  = torch.randn(1_000_000, device=&quot;cuda&quot;)dst = torch.empty_like(x, device=&quot;cpu&quot;, pin_memory=True)  # pinned CPU buffercopy_stream = torch.cuda.Stream()copy_done   = torch.cuda.Event()with torch.cuda.stream(copy_stream):    dst.copy_(x, non_blocking=True)  # å¼‚æ­¥ D2H    copy_done.record()               # ä»…æ‹·è´å®Œæˆå¤„æ‰“ç‚¹# â€¦â€¦CPU å¯ä»¥å…ˆåšåˆ«çš„æ´»â€¦â€¦copy_done.synchronize()              # åªæœ‰åœ¨çœŸæ­£è¦ç”¨ dst æ—¶æ‰ç­‰è¿™ä¸€æ¬¡print(dst[:5])\n\nè¦ç‚¹ï¼špinned + ä¸“ç”¨æ‹·è´æµ + äº‹ä»¶ï¼›é¿å…ç”¨è®¾å¤‡çº§ torch.cuda.synchronize() ç²—æš´â€œåˆ¹è½¦â€ã€‚(docs.pytorch.org, developer.download.nvidia.com)\n\n\n6. å¯è¿è¡Œæœ€å°ç¤ºä¾‹\n6.1 è®¡ç®—æµ â†’ é€šä¿¡/åå¤„ç†æµï¼ˆäº‹ä»¶æ …æ ï¼‰\nimport torchdevice = &quot;cuda&quot;compute = torch.cuda.Stream()comm    = torch.cuda.Stream()done    = torch.cuda.Event()x = torch.randn(1_000_000, device=device)with torch.cuda.stream(compute):    y = x.relu()    done.record()           # è®°å½•â€œy å·²å°±ç»ªâ€comm.wait_event(done)       # è®© comm æµç­‰åˆ° y å°±ç»ªwith torch.cuda.stream(comm):    z = y * 2               # åœ¨ GPU ç«¯è‡ªåŠ¨ç­‰å¾…ï¼Œä¸é˜»å¡ CPUtorch.cuda.synchronize()    # ç¤ºä¾‹æ”¶å°¾ï¼šçœŸå®å·¥ç¨‹é‡Œå¯ç»§ç»­æäº¤åç»­å·¥ä½œ\næœºåˆ¶è¯´æ˜ï¼šwait_event æŠŠâ€œç­‰å¾… eâ€æ’å…¥åˆ°æ¶ˆè´¹æµé˜Ÿåˆ—ï¼Œåªæœ‰äº‹ä»¶è§¦å‘åï¼Œæ¶ˆè´¹æµåç»­ kernel æ‰ä¼šæ‰§è¡Œï¼›è¿™éƒ½æ˜¯è®¾å¤‡ä¾§å®Œæˆï¼ŒCPU ä¸è¢«é˜»å¡ã€‚(docs.pytorch.org)\n6.2 ä¸‰æµç¤ºä¾‹ï¼ˆS2 ä¸ S3 éƒ½ç­‰ S1ï¼‰\ns1, s2, s3 = torch.cuda.Stream(), torch.cuda.Stream(), torch.cuda.Stream()e = torch.cuda.Event()with torch.cuda.stream(s1):    a = torch.randn(1024, 1024, device=&quot;cuda&quot;) @ torch.randn(1024, 1024, device=&quot;cuda&quot;)    e.record()s2.wait_event(e)s3.wait_event(e)with torch.cuda.stream(s2):    b = a.relu_()with torch.cuda.stream(s3):    c = a.sum()\n\nåŒä¸€ä¸ªäº‹ä»¶å¯ä»¥è¢«å¤šæ¡æµç­‰å¾…ï¼Œé€‚åˆâ€œä¸€å¯¹å¤šâ€çš„ä¾èµ–ã€‚(docs.pytorch.org)\n\n6.3 GPU ç«¯ç²¾å‡†è®¡æ—¶ï¼ˆEvent elapsed_timeï¼‰\nimport torchs = torch.cuda.Stream()start = torch.cuda.Event(enable_timing=True)end   = torch.cuda.Event(enable_timing=True)x = torch.randn(4096, 4096, device=&quot;cuda&quot;)w = torch.randn(4096, 4096, device=&quot;cuda&quot;)# é¢„çƒ­for _ in range(2): (x @ w).sum().relu_()with torch.cuda.stream(s):    start.record()    y = (x @ w).relu_()    end.record()end.synchronize()print(f&quot;elapsed = &#123;start.elapsed_time(end):.3f&#125; ms&quot;)\n\nelapsed_time è¿”å› start.record ä¸ end.record ä¹‹é—´çš„ GPU æ¯«ç§’æ•°ï¼›end.synchronize() ç¡®ä¿æµ‹é‡é—­åŒºé—´å·²å®Œæˆã€‚(docs.pytorch.org)\n\n\n7. å¸¸è§å‘ä¸é€Ÿè®°\n\näº‹ä»¶ä½ç½®è¦å¯¹ï¼šrecord() åªè¦†ç›–å®ƒä¹‹å‰å·²å…¥é˜Ÿçš„å·¥ä½œï¼›ä¹‹åæ–°æäº¤çš„å·¥ä½œä¸åŒ…å«åœ¨æœ¬äº‹ä»¶å†…ã€‚ä½¿ç”¨æ—¶å°† record() æ”¾åœ¨ç”Ÿäº§ç»“æŸç‚¹ã€‚(docs.pytorch.org)\nwait_event/wait_stream å‡ä¸ºâ€œå†™ä¾èµ–ã€ç«‹å³è¿”å›â€ï¼šå®ƒä»¬ä¸ä¼šé˜»å¡ CPUï¼Œåªå½±å“åç»­æäº¤åˆ°è¯¥æµçš„å·¥ä½œã€‚(docs.pytorch.org)\né»˜è®¤æµé™·é˜±ï¼šLegacy ä¸ PTDS è¯­ä¹‰ä¸åŒã€‚æ··ç”¨æ—¶ï¼Œlegacy ä¼šä¸é˜»å¡æµäº’ç›¸ç­‰å¾…ï¼›PTDS ä¸ä¼šã€‚æ–°å·¥ç¨‹å»ºè®®æ˜¾å¼å»ºæµ + æ˜¾å¼åŒæ­¥ï¼Œé¿å…è¸©éšå¼åŒæ­¥ã€‚(NVIDIA Docs)\næµä¼˜å…ˆçº§ï¼šä½æ•°å­—=é«˜ä¼˜å…ˆçº§ï¼›åªæ˜¯â€œå€¾å‘â€ï¼Œä¸æŠ¢å å·²åœ¨è¿è¡Œçš„ kernelã€‚(NVIDIA Docs)\n\n\n8. æœ¯è¯­ä¸€é¡µçº¸\n\nStreamï¼šè®¾å¤‡ä¸Šç‹¬ç«‹çš„æœ‰åºæ‰§è¡Œé˜Ÿåˆ—ã€‚record_eventã€wait_eventã€wait_streamã€synchronizeã€‚(docs.pytorch.org)\nEventï¼šè®¾å¤‡ä¾§æ …æ /æ—¶é—´æˆ³ï¼›recordã€waitã€synchronizeã€elapsed_timeã€‚(docs.pytorch.org)\nå®‰å…¨è·¨æµï¼šå†™ä¾èµ– + tensor.record_stream(consumer)ï¼ˆæˆ–æ‰‹åŠ¨ç¡®ä¿é‡Šæ”¾å‰åŒæ­¥å›åˆ›å»ºæµï¼‰ã€‚(docs.pytorch.org)\né«˜æ•ˆ D2Hï¼špinned + ä¸“ç”¨æ‹·è´æµ + äº‹ä»¶ï¼›æŒ‰éœ€ç­‰å¾…ï¼Œé¿å…å…¨è®¾å¤‡åŒæ­¥ã€‚(docs.pytorch.org)\n\n\nå‚è€ƒèµ„æ–™ï¼ˆå¼ºçƒˆå»ºè®®ç»†è¯»åŸæ–‡ï¼‰\n\nPyTorchï¼štorch.cuda.Stream APIï¼ˆå« wait_event / wait_stream / synchronizeï¼‰ä¸æ–‡æ¡£æ³¨é‡Šã€‚(docs.pytorch.org)\nPyTorchï¼štorch.cuda.Event APIï¼ˆrecord / wait / synchronize / elapsed_timeï¼‰ã€‚(docs.pytorch.org)\nPyTorchï¼štensor.record_streamï¼ˆè·¨æµå†…å­˜ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼‰ã€‚(docs.pytorch.org)\nPyTorch æ•™ç¨‹ï¼špin_memory() ä¸ non_blocking ä½¿ç”¨ä¸æ³¨æ„äº‹é¡¹ã€‚(docs.pytorch.org)\nNVIDIA CUDA æ–‡æ¡£ï¼šé»˜è®¤æµï¼ˆLegacy vs PTDSï¼‰è¯­ä¹‰ä¸æµä¼˜å…ˆçº§è¯´æ˜ã€‚(NVIDIA Docs)\nNVIDIA åŸ¹è®­è®²ä¹‰ï¼šcudaDeviceSynchronize / cudaStreamSynchronize / cudaEvent* çš„åŒæ­¥å¯¹æ¯”ä¸ç¤ºä¾‹ã€‚(developer.download.nvidia.com)\n\n\n","categories":["åˆ†å¸ƒå¼åŸºç¡€"],"tags":["stream"]},{"title":"lumos:Efficient Performance Modeling and Estimation for Large-scale LLM Training","url":"/2025/08/17/paper/lumos/","content":"\n\n\nä¸€å¥è¯æ€»ç»“ï¼šLumos æ˜¯ä¸€ä¸ªåŸºäºè¿è¡Œæ—¶ trace çš„å»ºæ¨¡/æ¨¡æ‹Ÿå·¥å…·ï¼Œä» PyTorch Kineto ç­‰é‡‡é›†åˆ°çš„äº‹ä»¶ä¸­è‡ªåŠ¨æ¢å¤ç²¾ç»†çš„æ‰§è¡Œå›¾ï¼ˆå«ç®—-é€šé‡å ä¸è·¨æµä¾èµ–ï¼‰ï¼Œå¹¶æ”¯æŒåœ¨ä¸é‡æ–°è·‘æ¨¡å‹çš„æƒ…å†µä¸‹ï¼Œå¯¹ DP/PP/æ¨¡å‹ç»“æ„ åš â€œwhat-ifâ€ ä¿®æ”¹ä¸å¿«é€Ÿä¼°ç®—ï¼›åœ¨ 512Ã—H100 é›†ç¾¤ä¸Šå›æ”¾å¹³å‡è¯¯å·®çº¦ 3.3%ã€‚(arXiv)\n\n\n1. æ ¸å¿ƒè´¡çŒ®ä¸å®šä½\n\nç²¾ç»†æ‰§è¡Œå›¾ï¼šä»…ç”¨æ¡†æ¶å†…ç½®çš„ profilerï¼ˆå¦‚ PyTorch Kinetoï¼‰å³å¯ä» CPU/GPU äº‹ä»¶æ¢å¤å››ç±»å…³é”®ä¾èµ–ï¼ˆCPUâ†’GPUã€GPUâ†’CPUã€åŒæµé¡ºåºã€è·¨æµäº‹ä»¶ï¼‰ï¼Œç²¾å‡†è¡¨è¾¾ç®—-é€šé‡å ä¸åŒæ­¥å…³ç³»ã€‚(arXiv)\nå›¾ç¼–è¾‘ &amp; å¿«é€Ÿå¤–æ¨ï¼šåœ¨ä¸æ”¹åŠ¨æ¨¡å‹/ç³»ç»Ÿçš„å‰æä¸‹ï¼Œä»åŸå§‹ trace-graph å‡ºå‘ï¼Œå¯¹ æ•°æ®å¹¶è¡Œï¼ˆDPï¼‰ã€æµæ°´å¹¶è¡Œï¼ˆPPï¼‰ ä¸æ¨¡å‹å±‚æ•°/éšè—ç»´åº¦åšå›¾çº§æ”¹å†™ï¼Œå†ç”¨æ¨¡æ‹Ÿå™¨é‡æ”¾ä¸€æ•´ä¸ªè¿­ä»£ä¼°ç®—æ€§èƒ½ã€‚(arXiv)\né«˜ç²¾åº¦å›æ”¾ï¼šåœ¨ç”Ÿäº§é›†ç¾¤ æœ€å¤š 512Ã—H100ã€å¤šç§ GPT-3 å˜ä½“ã€ä¸åŒå¹¶è¡Œç­–ç•¥ä¸‹ï¼Œè¿­ä»£æ—¶é—´å›æ”¾å¹³å‡è¯¯å·® 3.3%ï¼Œå¹¶èƒ½å†ç°å®æµ‹çš„æ‰§è¡Œç»†åˆ†å æ¯”ã€‚(arXiv)\n\n\n2. Lumos å¦‚ä½•ä» trace æ„å»ºæ‰§è¡Œå›¾\n\näº‹ä»¶æ¥æºï¼šç›´æ¥ä½¿ç”¨ PyTorch/TensorFlow çš„å†…ç½® profilerï¼ˆå¦‚ Kinetoï¼‰ï¼Œæ— éœ€å¯¹æ¨¡å‹æˆ–æ¡†æ¶åšä¾µå…¥å¼æ”¹é€ ã€‚(arXiv)\nä¾èµ–å»ºæ¨¡ï¼ˆå››ç±»ï¼‰ï¼š\n\nCPUâ†’GPUï¼ˆlaunchï¼‰ï¼šç”¨ correlation ID ç»‘å®š CPU ç«¯çš„ cudaLaunchKernel/cudaMemsetAsync ä¸å¯¹åº”çš„ GPU kernelã€‚\nGPUâ†’CPUï¼ˆåŒæ­¥ï¼‰ï¼šcudaDeviceSync/cudaStreamSync ç­‰éœ€è¦ç­‰åˆ°ç›¸å…³ GPU kernel å®Œæˆã€‚\nåŒæµé¡ºåºï¼šåŒä¸€ CUDA stream å†…æ ¸ä¸¥æ ¼é¡ºåºã€‚\nè·¨æµäº‹ä»¶ï¼šcudaEventRecord ä¸ cudaStreamWaitEvent å½¢æˆâ€œè®°å½•â†’ç­‰å¾…â€çš„è·¨æµä¾èµ–ï¼Œè¡¨è¾¾ä¸åŒæµé—´çš„æœ‰åºæ€§ã€‚(arXiv)\n\n\n\n3. å›¾ç¼–è¾‘ï¼šæ”¯æŒå“ªäº› â€œwhat-ifâ€ æ”¹åŠ¨\n\næ•°æ®å¹¶è¡Œï¼ˆDPï¼‰ï¼šåªéœ€è°ƒæ•´é€šä¿¡ä»»åŠ¡ï¼ˆå¦‚æ¢¯åº¦è§„çº¦ç±»ï¼‰çš„æ‰§è¡Œæ—¶é—´ï¼›æœ¬åœ°è®¡ç®—ä¸å˜ã€‚(arXiv)\næµæ°´å¹¶è¡Œï¼ˆPPï¼‰ï¼š\n\nå…ˆæŒ‰æ‰€é€‰è°ƒåº¦ï¼ˆå¦‚ 1F1Bï¼‰æ›´æ–°å„å¾®æ‰¹çš„å‰åå‘é¡ºåºï¼›\nå°†åŸå›¾ä¸­ä»»åŠ¡æŒ‰å±‚èšç±»åé‡åˆ†é…åˆ°æ–° stageï¼›\nåœ¨ stage è¾¹ç•Œæ’å…¥/é‡è¿æ¿€æ´»ä¸æ¢¯åº¦çš„ send/recvï¼›\nä¿ç•™åŸ trace ä¸­çš„ä¾èµ–æ¨¡å¼ä»¥ä¿è¯å¯é‡æ”¾æ­£ç¡®æ€§ã€‚(arXiv)\n\næ¨¡å‹ç»“æ„ï¼š\n\néšè—ç»´åº¦å˜æ›´ï¼šé‡å†™ç›¸å…³ç®—å­/å†…æ ¸çš„è¾“å…¥å¼ é‡ç»´åº¦å¹¶é‡ä¼°æ—¶é•¿ï¼›\nå±‚æ•°å˜æ›´ï¼šå¤åˆ¶/åˆ å‡å±‚å—å¹¶é‡è¿ä¾èµ–ä¸é€šä¿¡ã€‚(arXiv)\n\næš‚ä¸æ”¯æŒï¼šä¿®æ”¹ Tensor Parallelismï¼ˆTPï¼‰ï¼ˆé€šå¸¸å—é™äºå•æœºä¸”é€šä¿¡é‡ï¼Œç•™ä½œæœªæ¥å·¥ä½œï¼‰ã€‚(arXiv)\n\n\n4. æ¨¡æ‹Ÿå™¨ï¼šäº‹ä»¶é©±åŠ¨æµç¨‹ï¼ˆè®ºæ–‡ç®—æ³• 1 çš„è¦ç‚¹ï¼‰\n\nç»´æŠ¤ä¸¤ä¸ªé›†åˆï¼š\n\nå›ºå®šä¾èµ–ï¼ˆåˆå§‹åŒ–é˜¶æ®µä¸€æ¬¡æ€§ç¡®å®šï¼Œå¦‚åŒçº¿ç¨‹/åŒæµé¡ºåºã€CPUâ†’GPU çš„ launch è¾¹ï¼‰ï¼›\nè¿è¡ŒæœŸä¾èµ–ï¼ˆä¾‹å¦‚ cudaStreamSync éœ€è¦ç­‰å¾…**è¯¥æµä¸Šâ€œæœ€åä¸€ä¸ª kernelâ€**å®Œæˆï¼Œè¿™ä¸ªâ€œæœ€åâ€è¦åœ¨è°ƒåº¦æ—¶æ‰èƒ½ç¡®å®šï¼‰ã€‚\n\nä¸»å¾ªç¯ï¼šä»å°±ç»ªé›†åˆå–ä»»åŠ¡ â†’ åˆ†é…åˆ°å…¶â€œå¤„ç†å™¨â€ï¼ˆCPU çº¿ç¨‹/CUDA streamï¼‰ä¸Šè¿è¡Œ â†’ æ›´æ–°å¤„ç†å™¨å¯ç”¨æ—¶é—´ä¸åç»§ä»»åŠ¡çš„æœ€æ—©å¯å¯åŠ¨æ—¶é—´ï¼›è‹¥ä»æœ‰è¿è¡ŒæœŸä¾èµ–æœªæ»¡è¶³åˆ™å»¶åã€‚(arXiv)\n\n\n5. è¯„æµ‹è®¾ç½®ä¸å…³é”®æ•°å­—\n\nè§„æ¨¡ä¸ç¯å¢ƒï¼šæœ€å¤š 512Ã—H100ï¼ˆ32 å°ä¸»æœºï¼‰ï¼ŒRoCE æ•°æ®ä¸­å¿ƒç½‘ç»œï¼ˆæ¯ä¸»æœº 8Ã—400Gbpsï¼‰ï¼ŒCUDA 12.4ï¼ŒPyTorch 2.5ï¼ŒTransformer Engine 0.12.0ï¼ŒLightning 1.9.4ã€‚(arXiv)\nå¯¹æ¯”åŸºçº¿ï¼šä¸ dPROï¼ˆtrace-driven å›æ”¾ç³»ç»Ÿï¼‰ç›¸æ¯”ï¼ŒLumos åœ¨å¤æ‚å¹¶è¡Œé…ç½®ä¸‹èƒ½æ›´å¥½æ•æ‰è·¨æµä¾èµ–ä¸ç®—-é€šé‡å ï¼Œæ˜¾è‘—é™ä½å›æ”¾è¯¯å·®ã€‚(arXiv)\nç»“æœï¼šå›æ”¾å¹³å‡è¯¯å·® ~3.3%ï¼›å¹¶å±•ç¤ºåœ¨ DP/PP/ç»“æ„å¤–æ¨æ—¶çš„ä¼°ç®—å‡†ç¡®æ€§ä¸æ‰§è¡Œç»†åˆ†ï¼ˆæš´éœ²è®¡ç®—/æš´éœ²é€šä¿¡/é‡å /å…¶ä»–ï¼‰ã€‚(arXiv)\n\n\n6. å·¥ç¨‹å®ç°ä¸ä½¿ç”¨é—¨æ§›\n\nå®ç°è§„æ¨¡ï¼šçº¦ 5,200 è¡Œ Pythonã€‚(arXiv)\næ¥å…¥æˆæœ¬ï¼šåœ¨è®­ç»ƒä»£ç é‡Œæ’å…¥ ~10 è¡Œ profiler hook é‡‡é›† Kineto traceï¼Œéšåèµ°è‡ªåŠ¨åŒ–æµç¨‹ï¼šå»ºå›¾ â†’ å›¾ç¼–è¾‘ â†’ æ¨¡æ‹Ÿä¼°ç®—ã€‚(arXiv)\n\n\n7. é€‚ç”¨/ä¸é€‚ç”¨åœºæ™¯\n\né€‚ç”¨ï¼š\n\néœ€è¦åœ¨çœŸå®æœºç¾¤å¤–å¿«é€Ÿæ¯”è¾ƒå¹¶è¡Œ/ç»“æ„é…ç½®ï¼ˆDP/PP/å±‚æ•°/éšè—ç»´ï¼‰å¹¶ä¼°ç®—æ”¶ç›Šï¼›\néœ€è¦é«˜ä¿çœŸå›æ”¾æ¥å®šä½ç®—-é€šé‡å ä¸è·¨æµåŒæ­¥å¤„çš„æ€§èƒ½ç“¶é¢ˆã€‚\n\nå½“å‰ä¸é€‚ç”¨/æ³¨æ„ï¼š\n\nä¿®æ”¹ TP çš„å¤–æ¨ï¼ˆè®ºæ–‡æš‚æœªæ”¯æŒï¼‰ï¼›\nè¿½æ±‚ FLOPsã€å†…å­˜ã€å¸¦å®½ã€èƒ½è€—ç­‰ç³»ç»Ÿçº§æŒ‡æ ‡ï¼ˆè®ºæ–‡ç§°ä¸ºåç»­è®¡åˆ’ï¼‰ï¼›\nä¼°ç®—å‡è®¾æ–°é…ç½®å¯æ­£å¸¸è¿è¡Œï¼ˆä¸è€ƒè™‘ OOM ç­‰å¤±æ•ˆæƒ…å½¢ï¼‰ã€‚(arXiv)\n\n\n\n8. ä¸æ—¢æœ‰å·¥ä½œçš„å…³ç³»ï¼ˆç¤ºä¾‹ï¼šdPROï¼‰\n\ndPRO åŒæ ·æ˜¯ trace-driven çš„æ€§èƒ½è¯Šæ–­/å›æ”¾ç³»ç»Ÿï¼Œä½†åœ¨å¤æ‚ LLM å¹¶è¡Œä¸‹ï¼Œè·¨æµä¾èµ–ä¸é‡å çš„ç²¾ç»†å»ºæ¨¡æ›´å›°éš¾ï¼Œå®¹æ˜“å¯¼è‡´è¿‡åº¦ä¹è§‚çš„å¹¶è¡Œé¢„æµ‹ï¼›Lumos åœ¨è¿™äº›æ–¹é¢åšäº†ç³»ç»Ÿå¢å¼ºå¹¶æ˜¾è‘—é™ä½è¯¯å·®ã€‚(arXiv)\n\n\n9. è®ºæ–‡ä¸ä¼šè®®ä¿¡æ¯ï¼ˆå¯å¼•ç”¨ï¼‰\n\nè®ºæ–‡ï¼ˆarXivï¼‰ï¼šâ€œLumos: Efficient Performance Modeling and Estimation for Large-scale LLM Trainingâ€ï¼ˆ2025-04-12 é¦–æ¬¡æäº¤ï¼‰ã€‚(arXiv)\nPDFï¼ˆä½œè€…ä¸»é¡µé•œåƒ/MLSys è®ºæ–‡ï¼‰ï¼šå¯ä¸‹è½½å…¨æ–‡ã€‚(mingyu-liang.github.io)\nMLSys 2025 æ¥æ”¶ä¸æ—¥ç¨‹é¡µé¢ï¼ˆå«æŠ¥å‘Š/å½•æ’­å…¥å£ï¼‰ã€‚(mlsys.org)\n\n\n10. ä»£ç ä¸å¼€æºçŠ¶æ€ï¼ˆæˆªè‡³ 2025-08-15ï¼‰\n\næœªè§å®˜æ–¹ä»£ç åº“é“¾æ¥ï¼ˆarXiv/MLSys é¡µé¢ä¸ä½œè€… PDF ä¸­å‡æœªæä¾›ï¼‰ï¼Œç¤¾åŒºé‡Œå­˜åœ¨åŒåä½†æ— å…³çš„ â€œLumosâ€ é¡¹ç›®ï¼ˆå¦‚ Agent/è§†é¢‘ç”Ÿæˆ/è§†è§‰ç­‰ï¼‰ï¼Œæ³¨æ„åŒºåˆ†ã€‚(arXiv, mlsys.org, GitHub)\n\n\n11. å¿«é€Ÿä¸Šæ‰‹ï¼ˆç¤ºæ„ï¼‰\n\né‡‡é›† Kineto trace â†’ æ„å»ºæ‰§è¡Œå›¾ â†’ åœ¨å›¾ä¸Šç¼–è¾‘ï¼ˆDP/PP/ç»“æ„ï¼‰â†’ æ¨¡æ‹Ÿå›æ”¾/ä¼°ç®—ã€‚ è®ºæ–‡æ­£æ–‡ç»™å‡ºäº†å…¸å‹çš„ PyTorch profiler ç”¨æ³•ç¤ºæ„ä¸å…¨æµç¨‹ç¤ºæ„å›¾ã€‚(arXiv)\n\n\n12. ä½ å¯èƒ½å…³å¿ƒçš„ç»†èŠ‚ï¼ˆç²¾ç‚¼ç‰ˆï¼‰\n\nä¸ºä»€ä¹ˆæ›´å‡†ï¼Ÿ\n\nç”¨ correlation ID ä¸²èµ· CPU launch ä¸ GPU kernelï¼›\næ˜¾å¼æ¢å¤ è·¨æµäº‹ä»¶ï¼ˆRecord/Waitï¼‰ä¸åŒæ­¥ï¼ˆStream/Device Syncï¼‰ï¼›\nåœ¨æ¨¡æ‹Ÿå™¨ä¸­å°†ä¾èµ–åˆ†ä¸ºå›ºå®šä¸è¿è¡ŒæœŸï¼Œç¡®ä¿åƒ â€œç­‰å¾…è¯¥æµæœ€åä¸€ä¸ª kernelâ€ è¿™ç±»è¯­ä¹‰è¢«æ­£ç¡®è¡¨è¾¾ã€‚(arXiv)\n\næ”¹ DP/PP æ€ä¹ˆç®—ï¼Ÿ\n\nDPï¼šåªé‡èµ‹é€šä¿¡ä»»åŠ¡æ—¶é•¿ï¼›\nPPï¼šæ›´æ–°è°ƒåº¦ï¼ˆå¦‚ 1F1Bï¼‰â†’ ä»»åŠ¡æŒ‰å±‚åˆ†ç»„å¹¶é‡åˆ† stage â†’ åœ¨è¾¹ç•Œæ’å…¥ send/recv â†’ ä¿æŒä¾èµ–é—­åˆã€‚(arXiv)\n\n\n\nå‚è€ƒæ–‡çŒ® / é“¾æ¥\n\nLumos è®ºæ–‡ï¼ˆarXiv é¡µé¢ä¸ PDFï¼‰ï¼š(arXiv)\nLumosï¼ˆMLSys 2025 ä¼šè®®é¡µé¢/æ—¥ç¨‹/å½•æ’­ï¼‰ï¼š(mlsys.org)\ndPROï¼ˆtrace-driven å›æ”¾åŸºçº¿è®ºæ–‡ï¼‰ï¼š(arXiv)\n\n\n\næ³¨ï¼šæœ¬æ–‡æ¡£åªæ‘˜å–å¯¹å·¥ç¨‹è½åœ°æœ€å…³é”®çš„äº‹å®ä¸æ–¹æ³•ï¼Œæ›´å¤šå›¾ä¾‹ï¼ˆå¦‚ PPÃ—TP å¾®æ‰¹è°ƒåº¦ç¤ºä¾‹ï¼‰ä¸å®Œæ•´ç®—æ³•ç»†èŠ‚è¯·å‚é˜…åŸè®ºæ–‡æ­£æ–‡ä¸é™„å›¾ã€‚(arXiv)\n\n\n","categories":["è®ºæ–‡é˜…è¯»"],"tags":["paper"]},{"title":"Reducing Activation Recomputation in Large Transformer Models","url":"/2025/11/23/paper/reducing_activation_recomputation/","content":"\n\nä¸€ã€è®ºæ–‡é€Ÿè§ˆ\nè¿™ç¯‡è®ºæ–‡å…³æ³¨çš„å¤§é—®é¢˜æ˜¯ï¼šåœ¨å¤§è§„æ¨¡ Transformer æ¨¡å‹è®­ç»ƒä¸­ï¼Œæ¿€æ´»ï¼ˆactivationsï¼‰å ç”¨çš„æ˜¾å­˜è¶Šæ¥è¶Šå¤¸å¼ ï¼Œä¸ºäº†çœæ˜¾å­˜æ™®éä½¿ç”¨â€œå…¨å±‚æ¿€æ´»é‡è®¡ç®—ï¼ˆå…¨ checkpointï¼‰â€ï¼Œä½†è¿™ä¼šå¸¦æ¥ 30%â€“40% çš„é¢å¤–ç®—åŠ›å¼€é”€ã€‚ ä½œè€…ä» Transformer ç»“æ„å‡ºå‘ï¼Œå»ºç«‹äº†ä¸€å¥—è¿‘ä¼¼ä½†éå¸¸å®ç”¨çš„â€œæ¿€æ´»å†…å­˜æ¨¡å‹â€ï¼Œç³»ç»Ÿåˆ†æäº†å¼ é‡å¹¶è¡Œï¼ˆTPï¼‰ã€åºåˆ—å¹¶è¡Œï¼ˆSPï¼‰ã€æµæ°´å¹¶è¡Œï¼ˆPPï¼‰å¯¹æ¿€æ´»å†…å­˜çš„å½±å“ï¼Œå¹¶æå‡ºä¸¤å¤§æŠ€æœ¯ï¼šå°†åºåˆ—å¹¶è¡Œä¸å¼ é‡å¹¶è¡Œèåˆï¼Œä»¥åŠå¯¹æ¿€æ´»è¿›è¡Œé€‰æ‹©æ€§é‡è®¡ç®—ã€‚ ç»¼åˆèµ·æ¥ï¼Œè¿™äº›æ–¹æ³•åœ¨ä¸å¢åŠ é€šä¿¡é‡çš„å‰æä¸‹ï¼Œå®ç°äº†æ¿€æ´»æ˜¾å­˜çº¦ 5Ã— çš„å‹ç¼©ï¼Œç›¸æ¯”â€œå…¨å±‚é‡ç®—â€åªä¿ç•™äº† ~2%â€“7% çš„è®¡ç®—å¼€é”€ï¼›åœ¨ 22Bâ€“1T è§„æ¨¡æ¨¡å‹ä¸Šï¼Œè¿­ä»£ throughput æå‡å¤§çº¦ 30%ï¼ŒGPU FLOPs åˆ©ç”¨ç‡èƒ½ç¨³å®šåœ¨ 50%+ã€‚\näºŒã€è®ºæ–‡ç»“æ„\n\nå¼•è¨€ä¸ç›¸å…³å·¥ä½œ ä»‹ç»å¤§æ¨¡å‹è®­ç»ƒä¸­çš„å†…å­˜ç“¶é¢ˆã€ç°æœ‰å¹¶è¡Œ/å†…å­˜ä¼˜åŒ–æŠ€æœ¯ï¼ˆTP/PPã€ZeROã€offloadã€å·²æœ‰ SP ç­‰ï¼‰ï¼Œå¹¶è¯´æ˜æœ¬æ–‡èšç„¦åœ¨â€œæ¨¡å‹å¹¶è¡Œ + æ¿€æ´»å†…å­˜â€è¿™ä¸ªç»´åº¦ã€‚é€‚åˆå¿«é€Ÿäº†è§£é—®é¢˜èƒŒæ™¯å’Œä¸å…¶å®ƒæ–¹æ¡ˆå…³ç³»æ—¶é˜…è¯»ã€‚\nTransformer ç»“æ„ä¸ç¬¦å·çº¦å®šï¼ˆSection 3ï¼‰ ç»Ÿä¸€å®šä¹‰ \\(s,b,h,a,L,t,p,v\\) ç­‰ç¬¦å·ï¼Œå¹¶æ‹†å¼€åˆ†æ self-attention ä¸ MLP å†…éƒ¨çš„æ¿€æ´»ç»“æ„ã€‚é€‚åˆåœ¨è‡ªå·±åšæ¨å¯¼ã€å¯¹æ¥ä»£ç å®ç°æ—¶é‡ç‚¹çœ‹ã€‚\næ¿€æ´»å†…å­˜å»ºæ¨¡ä¸å¹¶è¡Œç­–ç•¥ï¼ˆSection 4ï¼‰ å…ˆç»™å‡ºâ€œå•å±‚æ¿€æ´»å†…å­˜è¿‘ä¼¼å…¬å¼â€ï¼Œå†ä¾æ¬¡å åŠ ï¼šå¼ é‡å¹¶è¡Œï¼ˆTPï¼‰ã€TP+SPã€å†åˆ°æµæ°´å¹¶è¡Œï¼ˆPPï¼‰ï¼Œæ¨å¯¼å‡ºæ€»æ¿€æ´»å†…å­˜çš„é—­å¼è¡¨è¾¾ï¼Œæ˜¯å…¨æ–‡æœ€æ ¸å¿ƒçš„ç†è®ºéƒ¨åˆ†ã€‚\né€‰æ‹©æ€§æ¿€æ´»é‡è®¡ç®—ï¼ˆSection 5ï¼‰ å¯¹æ¯”â€œå…¨å±‚é‡ç®—â€å’Œâ€œåªé‡ç®— attention ä¸­ä¸€éƒ¨åˆ†ç®—å­â€çš„å·®å¼‚ï¼Œç»™å‡ºåœ¨ GPT-3 / MT-NLG è§„æ¨¡ä¸‹çš„å†…å­˜ä¸ FLOPs é‡çº§ï¼Œå¯¹å·¥ç¨‹ä¸Šâ€œè¯¥ checkpoint å“ªäº› opâ€ç»™å‡ºæ˜ç¡®æŒ‡å¼•ã€‚\nå®éªŒè¯„ä¼°ï¼ˆSection 6ï¼‰ é€šè¿‡å•å±‚ micro benchmark + ç«¯åˆ°ç«¯è®­ç»ƒï¼ˆ22B/175B/530B/1Tï¼‰éªŒè¯æ¨¡å‹ä¸å®éªŒçš„ä¸€è‡´æ€§ï¼ŒæŠ¥å‘Šæ˜¾å­˜å ç”¨ã€æ¯å±‚æ—¶å»¶ã€è¿­ä»£æ—¶é—´ã€MFU/HFU ç­‰æŒ‡æ ‡ï¼Œæ˜¯åˆ¤æ–­â€œå€¼ä¸å€¼çš„ä¸Šå·¥ç¨‹å®ç°â€çš„å…³é”®ã€‚\næ€»ç»“ä¸æœªæ¥å·¥ä½œï¼ˆSection 7 + Appendixï¼‰ å°ç»“ä¸¤å¤§æŠ€æœ¯ï¼ˆTP+SP + selective recomputeï¼‰çš„è´¡çŒ®ï¼Œå¹¶è®¨è®º pipeline é¦–æ®µæ˜¾å­˜ç¢ç‰‡ã€è‡ªåŠ¨åŒ–æœç´¢ checkpoint ç­–ç•¥ç­‰æœªæ¥æ–¹å‘ã€‚\n\n\næ ¸å¿ƒæ€æƒ³ï¼šé’ˆå¯¹å¤§è§„æ¨¡ Transformerï¼Œå…ˆç”¨è§£ææ¨¡å‹ç²¾ç¡®åˆ»ç”»æ¿€æ´»å†…å­˜ï¼Œå†é€šè¿‡â€œå¼ é‡å¹¶è¡Œ + åºåˆ—å¹¶è¡Œâ€çš„ç»„åˆå°†æ¿€æ´»å‡åŒ€åˆ†æ‘Šåˆ°å„è®¾å¤‡ï¼Œå¹¶åªå¯¹ FLOPs ä¾¿å®œä½†å†…å­˜å·¨å¤§çš„å­ç®—å­åšé€‰æ‹©æ€§é‡è®¡ç®—ï¼Œåœ¨å‡ ä¹ä¸å¢åŠ é€šä¿¡ã€æå°ç®—åŠ›å¼€é”€çš„å‰æä¸‹ï¼Œå®ç°çº¦ 5Ã— çš„æ¿€æ´»æ˜¾å­˜å‹ç¼©ä¸ 30% å·¦å³çš„ååæå‡ã€‚\n\n\nä¸‰ã€æ–¹æ³•ä¸ç³»ç»Ÿè®¾è®¡\nä»å·¥ç¨‹è§†è§’çœ‹ï¼Œæœ¬æ–‡è¦è§£å†³çš„æ˜¯ï¼š\n\nâ€œå¦‚ä½•åœ¨ä¸å´©æ‰è®­ç»ƒååçš„å‰æä¸‹ï¼ŒæŠŠæ¿€æ´»æ˜¾å­˜å‹åˆ°èƒ½è·‘ trillion-scale æ¨¡å‹çš„æ°´å¹³ï¼Ÿâ€\n\næ•´ä½“æ€è·¯æ˜¯â€œä¸¤æ­¥èµ°â€ï¼š\n\nå»ºæ¨¡ï¼šæŠŠ Transformer æ¯ä¸€å±‚ã€æ¯ä¸€å—ï¼ˆattention / MLP / LayerNorm / Dropoutï¼‰çš„æ¿€æ´»å†…å­˜ç”¨å…¬å¼æ•°æ¸…æ¥šï¼Œé¡ºå¸¦æŠŠ TP / SP / PP çš„å½±å“éƒ½ä»£å…¥è¿›å»ã€‚\nä¼˜åŒ–ï¼š\n\nåœ¨ç»“æ„å±‚é¢ï¼šè®¾è®¡ä¸€ç§ TP + SP ç»„åˆçš„å¹¶è¡Œæ–¹å¼ï¼Œé€šè¿‡ \\(g / \\bar g\\) æ“ä½œæŠŠé TP åŒºåŸŸæŒ‰åºåˆ—åˆ‡ç‰‡ï¼Œé¿å… LayerNorm/Dropout è¿™ç±»æ¿€æ´»åœ¨ TP ç»„å†…é‡å¤å­˜å‚¨ã€‚\nåœ¨ç®—å­å±‚é¢ï¼šåªå¯¹ attention ä¸­â€œå¤§æ¿€æ´»ã€ä½ FLOPsâ€é‚£ä¸€éƒ¨åˆ†åš é€‰æ‹©æ€§é‡è®¡ç®—ï¼Œå…¶å®ƒåœ°æ–¹ç…§å¸¸ç¼“å­˜ï¼Œä»è€Œåœ¨â€œæ˜¾å­˜â€å’Œâ€œé‡ç®—å¼€é”€â€ä¹‹é—´å–å¾—æ›´ä¼˜æŠ˜ä¸­ã€‚\n\n\nå¯ä»¥æ‹†æˆå‡ ä¸ªå…·ä½“å­é—®é¢˜ï¼š\n\nå­é—®é¢˜ 1ï¼š å¦‚ä½•ç”¨ä¸€ä¸ªç®€æ´çš„å…¬å¼åˆ»ç”»â€œå•å±‚ Transformer çš„æ¿€æ´»å†…å­˜â€ï¼Œå¹¶èƒ½å¹³æ»‘ä»£å…¥ TP/SP/PP ç­‰å¹¶è¡Œå‚æ•°ï¼Ÿ\nå­é—®é¢˜ 2ï¼š å¦‚ä½•æŠŠåºåˆ—å¹¶è¡Œå’Œå¼ é‡å¹¶è¡Œæ‰åœ¨ä¸€èµ·ï¼Œåœ¨ä¸å¢åŠ é€šä¿¡å¸¦å®½çš„å‰æä¸‹ï¼ŒæŠŠä¹‹å‰ TP é‡Œâ€œæ²¡æ³•åˆ‡â€çš„é‚£ä¸€éƒ¨åˆ†æ¿€æ´»æŒ‰åºåˆ—åˆ†ç‰‡ï¼Ÿ\nå­é—®é¢˜ 3ï¼š åœ¨ä¸€å±‚å†…éƒ¨ï¼Œå“ªäº›æ¿€æ´»é€‚åˆ checkpointï¼ˆé‡ç®—ï¼‰ï¼Œå“ªäº›åº”è¯¥ç›´æ¥å­˜ï¼Ÿæ€æ ·åœ¨ QKV/softmax/attention over V è¿™äº›å­ç®—å­ä¹‹é—´åˆ‡åˆ†ï¼Ÿ\nå­é—®é¢˜ 4ï¼š å½“å†å åŠ æµæ°´å¹¶è¡Œæ—¶ï¼Œç¬¬ä¸€ stage éœ€è¦å­˜å¤šå°‘ micro-batch çš„æ¿€æ´»ï¼Œä»¥åŠå¦‚ä½•åœ¨å®è·µä¸­æ§åˆ¶ recompute çš„å¼€é”€ä¸å¤±æ§ï¼Ÿ\n\n3.1 æ ¸å¿ƒæ¨¡å—ä¸€è§ˆ\næŒ‰è®ºæ–‡æ€è·¯ï¼ŒæŠŠæ–¹æ³•æ‹†æˆå‡ ä¸ªâ€œå·¥ç¨‹æ¨¡å—â€ä¼šæ›´æ¸…æ™°ï¼š\n\næ¿€æ´»å†…å­˜è¿‘ä¼¼æ¨¡å‹ï¼šç»™å‡ºæ— å¹¶è¡Œæ—¶çš„â€œå•å±‚æ¿€æ´»å†…å­˜å…¬å¼â€ï¼ŒæŠŠ attention / MLP / LayerNorm / Dropout å„è‡ªçš„è´¡çŒ®æ‹†å¼€ï¼Œå¹¶æ˜ç¡®å“ªäº›å¯ä»¥å¿½ç•¥ï¼ˆå° bufferï¼‰ã€‚\nå¼ é‡å¹¶è¡Œï¼ˆTensor Parallel, TPï¼‰åŸºçº¿ï¼šå‡è®¾ TP åªåˆ‡ attention / MLP å†…éƒ¨çš„å¤§ GEMMï¼ŒæŠŠæ¿€æ´»åœ¨è¿™äº› op å†…éƒ¨å‡åŒ€åˆ†æ‘Šåˆ° \\(t\\) ä¸ªè®¾å¤‡ï¼Œä½† LayerNorm / Dropout ç­‰é TP åŒºåŸŸä»æ˜¯æ¯å¡ä¸€ä»½ã€‚\nåºåˆ—å¹¶è¡Œï¼ˆSequence Parallel, SPï¼‰+ è½¬æ¢ç®—å­ \\(g/\\bar g\\)ï¼šåœ¨é TP åŒºåŸŸæ²¿åºåˆ—ç»´ \\(s\\) åˆ‡åˆ†ï¼Œè®¾è®¡ \\(g\\)ï¼ˆall-gatherï¼‰å’Œ \\(\\bar g\\)ï¼ˆreduce-scatterï¼‰æ¥åœ¨â€œåºåˆ—åˆ‡åˆ†åŸŸâ€å’Œâ€œå¼ é‡åˆ‡åˆ†åŸŸâ€ä¹‹é—´æ— ç¼è½¬æ¢ã€‚\né€‰æ‹©æ€§æ¿€æ´»é‡è®¡ç®—ï¼ˆSelective Activation Recomputationï¼‰ï¼šåªé‡ç®— attention ä¸­åœ¨ \\(QK^\\top\\)ã€softmaxã€softmax dropoutã€attention over V åŒºåŸŸçš„æ¿€æ´»ï¼Œå®ƒä»¬å†…å­˜å·¨å¤§ä½†æ¯å…ƒç´  FLOPs ä¸å¤šï¼›å…¶ä½™éƒ¨åˆ†ç…§å¸¸ç¼“å­˜ã€‚\nä¸æµæ°´å¹¶è¡Œçš„ç»“åˆï¼ˆ1F1B / interleaved 1F1Bï¼‰ï¼šåˆ†æåœ¨ç»å…¸ 1F1B è°ƒåº¦ä¸‹ï¼Œé¦–ä¸ªæµæ°´ stage æ°¸è¿œéœ€è¦åŒæ—¶ hold \\(L\\) å±‚æ¿€æ´»ï¼›åœ¨æ­¤åŸºç¡€ä¸Šç»™å‡ºæ€»æ¿€æ´»å†…å­˜å…¬å¼ï¼Œå¹¶è®¨è®º interleaved pipeline æ—¶çš„ä¿®æ­£å› å­ã€‚\n\n3.2 æ•°æ®æµä¸æ§åˆ¶æµ\nç”¨â€œä»è¾“å…¥åˆ° lossï¼Œå†åˆ°åå‘â€çš„è§†è§’ï¼Œå¯ä»¥æŠŠæ•°æ®æµ/æ§åˆ¶æµä¸²æˆå¦‚ä¸‹æ­¥éª¤ï¼ˆåªå…³æ³¨å•ä¸ª stackï¼‰ï¼š\n\nè¾“å…¥åµŒå…¥å±‚\n\nè¯è¡¨ embeddingï¼šæŸ¥è¡¨å¾—åˆ°å½¢çŠ¶ä¸º \\((s, b, h)\\) çš„ token è¡¨ç¤ºã€‚\nåŠ ä¸Šå¯å­¦ä¹ çš„ä½ç½®ç¼–ç ï¼ˆåŒå½¢çŠ¶ï¼‰ï¼Œå¾—åˆ° \\(X^{(0)}\\) ä½œä¸ºç¬¬ 1 å±‚è¾“å…¥ã€‚\nåœ¨å¯ç”¨ SP æ—¶ï¼Œè¿™ä¸€å±‚çš„ Dropout mask ä¹Ÿå¯ä»¥æŒ‰åºåˆ—åˆ‡åˆ†å­˜å‚¨ã€‚\n\nç¬¬ \\(\\ell\\) ä¸ª Transformer å±‚çš„å‰å‘ï¼ˆæ— å¹¶è¡Œè§†è§’ï¼‰\n\nLayerNormï¼š\\(Y = \\text{LN}(X)\\)ï¼Œè¾“å‡ºä»ä¸º \\((s,b,h)\\)ï¼Œéœ€è¦ç¼“å­˜è¾“å…¥ \\(X\\) ä½œä¸ºæ¿€æ´»ã€‚\nSelf-Attentionï¼š\n\nQKV æŠ•å½±ï¼šä» \\(Y\\) ç»è¿‡ä¸‰æ¬¡çº¿æ€§å±‚å¾—åˆ° \\(Q,K,V\\)ï¼Œå°ºå¯¸ $ (s,b,h)$ æˆ– \\((s,b,h/a)\\)ã€‚\n\\(QK^\\top\\)ï¼šè®¡ç®—æ³¨æ„åŠ› logitsï¼Œå°ºå¯¸å¤§çº¦ä¸º \\((a,s,s,b)\\)ã€‚\nsoftmax + dropoutï¼šå¾—åˆ°æ³¨æ„åŠ›æƒé‡ï¼Œå†æ–½åŠ  dropoutã€‚\nattention over Vï¼šç”¨æ³¨æ„åŠ›æƒé‡åŠ æƒ Vï¼Œå¾—åˆ° \\((s,b,h)\\) çš„è¾“å‡ºã€‚\nè¾“å‡ºçº¿æ€§ï¼šå†æŠ•å½±å› \\((s,b,h)\\)ã€‚è¿™äº›æ­¥éª¤äº§ç”Ÿå¤§é‡ä¸­é—´æ¿€æ´»ã€‚\n\næ®‹å·® + LayerNormï¼šæŠŠ attention è¾“å‡ºåŠ å›è¾“å…¥ï¼Œåšç¬¬äºŒæ¬¡ LNã€‚\nMLPï¼š\n\nçº¿æ€§ \\(h \\to 4h\\)ï¼Œäº§ç”Ÿ \\((s,b,4h)\\)ã€‚\nGeLU éçº¿æ€§ï¼Œéœ€è¦ç¼“å­˜è¾“å…¥ã€‚\nçº¿æ€§ \\(4h \\to h\\)ï¼Œå†åŠ  Dropoutã€‚\næ®‹å·®åŠ å›ã€‚\n\n\nTP + SP ä¸‹çš„å‰å‘æ§åˆ¶æµï¼ˆä»¥ MLP ä¸ºä¾‹ï¼‰\n\nåœ¨ LayerNorm å‰ï¼Œè¾“å…¥ \\(X\\) å·²æŒ‰åºåˆ—ç»´åˆ‡åˆ†ï¼š\\([X^{s}_1, X^{s}_2, \\dots, X^{s}_t]\\)ã€‚\nLayerNorm åœ¨å„ rank æœ¬åœ°åšï¼Œè¾“å‡º \\([Y^{s}_1,\\dots,Y^{s}_t]\\)ï¼Œæ­¤æ—¶ä»æŒ‰åºåˆ—åˆ‡åˆ†ã€‚\nä¸ºé€å…¥ MLP ä¸­çš„ GEMMï¼Œéœ€è¦å®Œæ•´åºåˆ—ï¼šè°ƒç”¨ \\(g\\) åš all-gather æŠŠ \\(Y\\) åœ¨æ¯ä¸ª TP rank ä¸Šæ‹¼æˆå®Œæ•´çš„ \\((s,b,h)\\)ã€‚\nçº¿æ€§ + GeLU + çº¿æ€§å†…éƒ¨æ²¿éšè—ç»´åˆ‡åˆ†ï¼ˆæ ‡å‡† TPï¼‰ï¼Œæ¯å¡åªå¤„ç† \\(h/t\\) æˆ– \\(4h/t\\) çš„ sliceã€‚\nMLP è¾“å‡º \\(W_1, W_2, \\dots, W_t\\) éœ€è¦å…ˆæ±‚å’Œå†æŒ‰åºåˆ—åˆ‡åˆ†ç»™ä¸‹æ¸¸ Dropoutï¼Œäºæ˜¯ç”¨ \\(\\bar g\\) å®ç°â€œæ±‚å’Œ + æŒ‰åºåˆ— RSâ€çš„ reduce-scatterã€‚\nDropoutã€æ®‹å·®åœ¨åºåˆ—åˆ‡åˆ†åŸŸä¸­æœ¬åœ°å®Œæˆã€‚\n\né€‰æ‹©æ€§é‡è®¡ç®—çš„æ§åˆ¶æµï¼ˆä»¥ attention ä¸ºä¸»ï¼‰\n\næ­£å¸¸å‰å‘æ—¶ï¼Œåªä¿ç•™ï¼š\n\nè¾“å…¥ LN å‰åçš„å¼ é‡ï¼›\nMLP è¾“å…¥/è¾“å‡ºï¼›\nä»¥åŠ attention ä¸­â€œå®½åº¦å°šæœªæ”¾å¤§â€çš„éƒ¨åˆ†ã€‚\n\nå¯¹äº \\(QK^\\top\\)ã€softmaxã€softmax dropoutã€attention over V ç­‰åŒºåŸŸï¼š\n\nä¸ç¼“å­˜ä¸­é—´æ¿€æ´»ï¼Œåªåœ¨åå‘éœ€è¦æ—¶é‡è·‘ä¸€æ¬¡å‰å‘å­å›¾ã€‚\n\nåå‘æ—¶ï¼Œæ¡†æ¶çš„ checkpoint é©±åŠ¨ï¼š\n\nå…ˆé‡ç®—è¢«æ ‡è®°çš„å­å›¾ï¼Œå†åŸºäºé‡ç®—æ¿€æ´»åšåå‘ã€‚\nå…¶å®ƒæœª checkpoint çš„éƒ¨åˆ†ç›´æ¥ç”¨ç¼“å­˜æ¿€æ´»åå‘ã€‚\n\n\næµæ°´å¹¶è¡Œä¸‹çš„æ—¶åºå…³ç³»\n\né‡‡ç”¨ 1F1B è°ƒåº¦ï¼Œé¦–ä¸ª stage å¿…é¡»åŒæ—¶ hold å¤šä¸ª micro-batch çš„æ¿€æ´»ï¼Œä»¥å¡«æ»¡æµæ°´ã€‚\nå¯¹é¦–ä¸ª stage æ¥è¯´ï¼Œæœ‰æ•ˆâ€œå±‚æ•°â€æ˜¯ \\(L\\)ï¼Œå³ä½¿å®ƒå®é™…åªåŒ…å« \\(L/p\\) ä¸ªç‰©ç†å±‚ã€‚\nselective recompute å…è®¸ä¼˜å…ˆå¯¹æœ€å å†…å­˜çš„éƒ¨åˆ†é‡ç®—ï¼Œrest full-cacheï¼Œä»è€Œåœ¨æ˜¾å­˜å’Œé‡ç®—å¼€é”€é—´æŒ‰å®é™…å¡å®¹é‡åšæŠ˜ä¸­ã€‚\n\n\n3.3 å…³é”®å‡è®¾ä¸é€‚ç”¨èŒƒå›´\nè®ºæ–‡ä¸­çš„æ¨å¯¼å’Œç»“è®ºåŸºäºè‹¥å¹²é‡è¦å‡è®¾ï¼Œåœ¨å®è·µä¸­éœ€è¦æ„è¯†åˆ°å®ƒä»¬çš„è¾¹ç•Œï¼š\n\nåªè€ƒè™‘ä¸»å¹² Transformer å—ï¼Œå¿½ç•¥â€œå° bufferâ€\n\nå‡è®¾ï¼šLayerNorm çš„å‡å€¼/æ–¹å·®ï¼ˆ\\(2sb\\)ï¼‰å’Œ bias ç­‰ \\(O(h)\\) çº§åˆ« buffer å¯ä»¥å¿½ç•¥ï¼Œä»…å…³æ³¨ \\(O(sbh)\\) çš„æ¿€æ´»ã€‚\nå¯èƒ½å¤±æ•ˆçš„åœºæ™¯ï¼šæçŸ­åºåˆ—ã€å° hidden size æˆ–å¤§é‡é¢å¤–è¾…åŠ©åˆ†æ”¯ï¼ˆä¾‹å¦‚å¤šä»»åŠ¡å¤´ï¼‰æ—¶ï¼Œè¿™äº›â€œå° bufferâ€å æ¯”ä¸Šå‡ï¼Œç†è®ºæ¨¡å‹ä¸å®é™…æ˜¾å­˜å¯èƒ½æœ‰æ•°ä¸ªç™¾åˆ†ç‚¹åå·®ã€‚\n\nç»Ÿä¸€ä½¿ç”¨ 16-bit æ¿€æ´»ï¼ˆæ¯å…ƒç´  2 bytesï¼‰ï¼Œdropout mask 1 byte\n\nå‡è®¾ï¼šæ‰€æœ‰æ¿€æ´»éƒ½ä»¥ FP16/BF16 å­˜å‚¨ï¼Œåªæœ‰ logits ç­‰å°‘é‡å¼ é‡ä½¿ç”¨ FP32ã€‚\né£é™©ï¼šå¦‚æœä½ çš„æ ˆä¸­ä»å¤§é‡ä¿ç•™ FP32 æ¿€æ´»ï¼ˆæ¯”å¦‚ç¨³å®šæ€§åŸå› ï¼‰ã€æˆ–è€…æœ‰è‡ªå®šä¹‰ kernel ä½¿ç”¨æ›´å®½çš„ä¸­é—´æ ¼å¼ï¼Œå®é™…æ˜¾å­˜ä¼šé«˜äºæ¨¡å‹é¢„æµ‹ã€‚\n\nå±‚ç»“æ„é«˜åº¦åŒè´¨ï¼Œå¿½ç•¥ embedding / output å±‚è´¡çŒ®\n\nå‡è®¾ï¼šæ‰€æœ‰ Transformer å—çš„ç»“æ„ç›¸åŒï¼Œembedding å’Œæœ€åä¸€å±‚ FC / loss çš„é¢å¤–æ¿€æ´»å¯ä»¥è¿‘ä¼¼å¿½ç•¥ã€‚\nä¾‹å¤–ï¼šåœ¨éå¸¸æµ…çš„ç½‘ç»œï¼ˆå° \\(L\\)ï¼‰æˆ– embedding/output æå¤§ï¼ˆè¶…å¤§ vocabï¼‰æ—¶ï¼Œè¿™ä¸€è¿‘ä¼¼ä¼šå˜å·®ï¼Œéœ€è¦æ‰‹å·¥åŠ ä¸Šé¢å¤–é¡¹ã€‚\n\né‡‡ç”¨ 1F1B æˆ– interleaved 1F1B æµæ°´è°ƒåº¦ï¼Œé¦– stage ä¸ºç“¶é¢ˆ\n\nå‡è®¾ï¼šæµæ°´è°ƒåº¦ä¸º 1F1B æˆ–æ–‡ä¸­çš„ interleaved å˜ä½“ï¼Œå¹¶é€šè¿‡å¢å¤§ micro-batch æ•°é‡æŠŠæµæ°´â€œå‹æ»¡â€ï¼Œä½¿é¦–ä¸ª stage çš„æ¿€æ´»æ˜¾å­˜æˆä¸ºç³»ç»Ÿç“¶é¢ˆã€‚\nåœ¨éå…¸å‹è°ƒåº¦ï¼ˆå¤§é‡ pipeline bubbleã€å¼‚æ„ stageã€åŠ¨æ€åˆ†é…ï¼‰æˆ–å¼º offload åœºæ™¯ï¼Œè¿™ä¸ªå‡è®¾å¯èƒ½ä¸æˆç«‹ï¼Œéœ€è¦é‡æ–°è®¡ç®—æ¯ä¸ª stage çš„å³°å€¼ã€‚\n\nattention å¤´æ•° \\(a\\)ã€åºåˆ—é•¿åº¦ \\(s\\) è¶³å¤Ÿå¤§ï¼Œä½¿ \\(5as/h \\gg 34\\)\n\nå‡è®¾ï¼šåœ¨ GPT-3ã€MT-NLG è¿™ç§è§„æ¨¡ä¸‹ï¼Œattention ååŠæ®µæ¿€æ´»ï¼ˆ\\(QK^\\top\\)ã€softmax ç­‰ï¼‰å äº†ç»å¤§å¤šæ•°æ˜¾å­˜ã€‚\nå½“ \\(s\\) å¾ˆçŸ­ã€\\(a\\) å¾ˆå°‘ã€\\(h\\) å¾ˆå¤§æ—¶ï¼Œ\\(5as/h\\) ä¸å†æ˜¾è‘—å¤§äº 34ï¼Œè¿™æ—¶ selective recompute çš„æ”¶ç›Šä¼šä¸‹é™ã€‚\n\n\n3.4 æ•°å­¦å…¬å¼ä¸ç®—æ³•è§£è¯»\nè¿™ä¸€å°èŠ‚æŒ‘å‡ºè®ºæ–‡ä¸­å‡ ä¸ªå…³é”®å…¬å¼ï¼Œåˆ†åˆ«ä»â€œåŸæ–‡å½¢å¼ â†’ å«ä¹‰ â†’ ç›´è§‚æ“ä½œâ€ä¸‰ä¸ªå±‚æ¬¡æ¥ç†è§£ã€‚\n3.4.1 å•å±‚æ¿€æ´»å†…å­˜ï¼ˆæ— æ¨¡å‹å¹¶è¡Œï¼‰\nåŸæ–‡ä¸­çš„å…¬å¼ï¼ˆå¼ (1)ï¼‰ï¼š\n\\[\nM_{\\text{act, layer}} = sbh \\left( 34 + 5a \\frac{s}{h} \\right)\n\\]\n\nåœ¨è§£å†³ä»€ä¹ˆé—®é¢˜ï¼Ÿ è¿™æ˜¯â€œä¸€ä¸ª Transformer å±‚åœ¨å‰å‘ä¸­éœ€è¦ç¼“å­˜å¤šå°‘æ¿€æ´»â€çš„è¿‘ä¼¼å…¬å¼ï¼Œç”¨æ¥ä¼°ç®—åœ¨ä¸ä½¿ç”¨ä»»ä½• TP/SP/PP æ—¶ï¼Œæ¯å±‚æ¿€æ´»å ç”¨çš„æ˜¾å­˜ã€‚\nç¬¦å·å«ä¹‰ï¼š\n\n\\(s\\)ï¼šåºåˆ—é•¿åº¦ï¼ˆsequence lengthï¼‰\n\\(b\\)ï¼šmicro-batch å¤§å°\n\\(h\\)ï¼šhidden ç»´åº¦\n\\(a\\)ï¼šattention å¤´æ•°\n\\(M_{\\text{act, layer}}\\)ï¼šè¿™ä¸€å±‚çš„æ€»æ¿€æ´»å†…å­˜ï¼ˆå•ä½æ˜¯ bytesï¼Œå› ä¸ºæ¯å…ƒç´ å·²ç»ä¹˜ä¸Šäº† 2 bytesï¼‰\n\nå¦‚ä½•å¾—åˆ° 34 å’Œ \\(5a s/h\\)ï¼Ÿï¼ˆç›´è§‚ç‰ˆï¼‰\n\næŠŠä¸€ä¸ªå±‚æ‹†æˆï¼šä¸¤æ¬¡ LayerNormã€ä¸€ä¸ª attention å—ã€ä¸€ä¸ª MLP å—ã€‚\nç²—ç•¥ç»Ÿè®¡æ¯éƒ¨åˆ†éœ€è¦ç¼“å­˜çš„å¼ é‡æ•°é‡å’Œå¤§å°ï¼š\n\nattention å—çº¦è´¡çŒ® \\(11sbh + 5as^2b\\)ï¼›\nMLP çº¦è´¡çŒ® \\(19sbh\\)ï¼›\nä¸¤ä¸ª LayerNorm åˆè®¡è´¡çŒ® \\(4sbh\\)ã€‚\n\nåˆèµ·æ¥å°±æ˜¯ \\((11 + 19 + 4) s b h = 34sbh\\)ï¼Œå†æŠŠ \\(5as^2b\\) å†™æˆ \\(sbh \\cdot 5a s/h\\)ï¼Œå¾—åˆ°ä¸Šå¼ã€‚\n\nç­‰ä»·é‡å†™ï¼ˆä»…ä¸ºç›´è§‚ï¼‰ï¼š\n\n\\[\nM_{\\text{act, layer}}\n= s b h \\cdot 34 ;+; 5 a s^2 b\n\\]\nå¯ä»¥ç›´æ¥çœ‹æˆâ€œä¸åºåˆ—é•¿åº¦çº¿æ€§ç›¸å…³çš„ä¸»å¹²éƒ¨åˆ† + ä¸ \\(s^2\\) ç›¸å…³çš„ attention å¤æ‚éƒ¨åˆ†â€ã€‚\n\nç›´è§‚æ“ä½œæè¿°ï¼š å¦‚æœä½ ç»™å®š \\((s, b, h, a)\\)ï¼Œé‚£ä¹ˆï¼š\n\nå…ˆç®—å‡ºâ€œæ¯å±‚ä¸»å¹²æ¿€æ´»â€çš„å¤§å°ï¼š\\(34sbh\\)ï¼›\nå†ç®—å‡ºâ€œattention æ­£æ–¹å½¢çŸ©é˜µç›¸å…³â€çš„å¤§å°ï¼š\\(5as^2b\\)ï¼›\näºŒè€…ç›¸åŠ å°±æ˜¯è¿™ä¸€å±‚éœ€è¦ç¼“å­˜çš„æ¿€æ´»å­—èŠ‚æ•°ã€‚\n\n\n3.4.2 å¼ é‡å¹¶è¡Œä¸‹çš„å•å±‚æ¿€æ´»ï¼ˆTPï¼‰\nåŸæ–‡ä¸­çš„å…¬å¼ï¼ˆå¼ (2)ï¼‰ï¼š\n\\[\nM_{\\text{act, layer}}^{\\text{TP}}\n= sbh \\left(\n10 + \\frac{24}{t} + 5a \\frac{s}{ht}\n\\right)\n\\]\n\nå«ä¹‰ï¼š åœ¨ \\(t\\) è·¯å¼ é‡å¹¶è¡Œï¼ˆTPï¼‰ä¸‹ï¼Œåªæœ‰ attention å’Œ MLP å†…éƒ¨â€œåˆ‡å¾—åŠ¨â€çš„é‚£éƒ¨åˆ†æ¿€æ´»æŒ‰ \\(1/t\\) åˆ†æ‘Šåˆ°äº†å„å¡ï¼Œè€Œ LayerNorm å’Œè‹¥å¹² Dropout åŒºåŸŸä»ç„¶åœ¨æ¯å¡å®Œæ•´ä¿ç•™ï¼Œå¯¼è‡´å¸¸æ•°ä» 34 å˜æˆäº† \\(10 + 24/t\\)ï¼Œè€Œ attention ä¸­çš„ \\(5as^2b\\) é¡¹å˜æˆäº† \\(5as^2b/t\\)ã€‚\nç›´è§‚ç†è§£ï¼š\n\nâ€œ10â€ï¼šæœªåˆ‡åˆ†ã€åœ¨æ¯å¼ å¡ä¸Šé‡å¤å­˜åœ¨çš„ LayerNorm + Dropout ç­‰æ¿€æ´»ã€‚\n\\(24/t\\)ï¼šTP åçœŸæ­£è¢«å‡åˆ†çš„éƒ¨åˆ†ï¼ˆå¤§ GEMM ç›¸å…³ï¼‰ã€‚\n\\(5a s/(ht)\\)ï¼šattention ä¸­ \\(s^2\\) çº§åˆ«çš„æ¿€æ´»åœ¨ \\(t\\) å¡ä¸Šå¹³å‡åˆ†æ‘Šã€‚\n\nç›´è§‚æ“ä½œæè¿°ï¼š\n\nå…ˆåƒå¼ (1) é‚£æ ·ç®—ä¸€éâ€œæ€»çš„ä¸»å¹²æ¿€æ´»â€ä¸ â€œattention æ¿€æ´»â€ï¼›\nå†æŠŠèƒ½åˆ‡çš„éƒ¨åˆ†é™¤ä»¥ \\(t\\)ï¼Œä¸èƒ½åˆ‡çš„éƒ¨åˆ†ä¿æŒä¸å˜ï¼›\næŠŠå®ƒä»¬åˆèµ·æ¥ï¼Œå°±å¾—åˆ°äº†ä¸Šå¼ã€‚\n\n\n3.4.3 å¼ é‡ + åºåˆ—å¹¶è¡Œï¼ˆTP+SPï¼‰\nåŸæ–‡ä¸­çš„å…¬å¼ï¼ˆå¼ (4)ï¼‰ï¼š\n\\[\n\\begin{aligned}\nM_{\\text{act, layer}}^{\\text{TP+SP}}\n&amp;= sbh \\left(\n\\frac{10}{t} + \\frac{24}{t} + 5a \\frac{s}{ht}\n\\right) \\\n&amp;= \\frac{sbh}{t}\\left(\n34 + 5a \\frac{s}{h}\n\\right)\n\\end{aligned}\n\\]\n\nå«ä¹‰ï¼š æŠŠä¹‹å‰ TP ä¸‹ä»ç„¶é‡å¤çš„ 10\\(sbh\\) è¿™å—ï¼Œé€šè¿‡æ²¿åºåˆ—ç»´çš„ SP å†åˆ‡ä¸€åˆ€ï¼Œæœ€ç»ˆæ•´å±‚æ¿€æ´»ï¼ˆåŒ…æ‹¬ attention çš„é‚£ä¸€å—ï¼‰éƒ½è¢«å‡åŒ€åœ°åˆ†æ‘Šåˆ°äº† \\(t\\) ä¸ª TP rank ä¸Šâ€”â€”ç›´è§‚å°±æ˜¯â€œæ¿€æ´»å†…å­˜æ•´ä½“é™¤ä»¥ \\(t\\)â€ã€‚\nå…³é”®ç‚¹ï¼š\n\nä¾é  \\(g\\)ï¼ˆall-gatherï¼‰å’Œ \\(\\bar g\\)ï¼ˆreduce-scatterï¼‰è¿™å¯¹â€œè½¬æ¢ç®—å­â€æŠŠ LayerNorm / Dropout åŒºåŸŸä»åºåˆ—åˆ‡åˆ†åŸŸåˆ‡å›å¼ é‡åˆ‡åˆ†åŸŸå†åˆ‡å›å»ã€‚\né€šä¿¡å¸¦å®½ä¸å˜ï¼šå› ä¸ºåŸæ¥çš„ ring all-reduce æœ¬èº«å°±æ˜¯ reduce-scatter + all-gather çš„ç»„åˆã€‚\n\nç›´è§‚æ“ä½œæè¿°ï¼š\n\nå…ˆæŒ‰å¼ (1) ç®—å‡ºæ— å¹¶è¡Œæ—¶ \\(M_{\\text{act, layer}}\\)ï¼›\nå†ç®€å•é™¤ä»¥ \\(t\\)ï¼Œå°±å¾—åˆ° TP+SP ä¸‹æ¯å¡éœ€è¦çš„æ¿€æ´»å†…å­˜ã€‚\n\n\n3.4.4 åŠ ä¸Šæµæ°´å¹¶è¡Œåçš„æ€»æ¿€æ´»å†…å­˜\nåŸæ–‡ä¸­çš„å…¬å¼ï¼ˆå¼ (5)ï¼‰ï¼š\n\\[\nM_{\\text{total}}^{\\text{acts}} =\n\\frac{s b h L}{t}\\left(\n34 + 5 a \\frac{s}{h}\n\\right)\n\\]\n\nå«ä¹‰ï¼š åœ¨ 1F1B æµæ°´è°ƒåº¦ä¸‹ï¼Œé¦–ä¸ª pipeline stage å°½ç®¡åªè´Ÿè´£ \\(L/p\\) ä¸ªç‰©ç†å±‚ï¼Œä½†å› ä¸ºè¦åŒæ—¶â€œåœ¨é£â€\\(p\\) ä¸ª micro-batchï¼Œæœ€ç»ˆ peak æ¿€æ´»é‡ç­‰ä»·äºâ€œ\\(L\\) å±‚éƒ½å‹åœ¨è¿™ä¸€å¡ä¸Šâ€ã€‚å› æ­¤æ€»æ¿€æ´»å†…å­˜ç­‰äºâ€œå•å±‚æ¿€æ´» Ã— \\(L\\) å±‚ / \\(t\\)â€ã€‚\nç›´è§‚æ“ä½œï¼š\n\nç”¨å¼ (4) ç®—å‡ºå•å±‚ TP+SP ä¸‹çš„æ¿€æ´»ï¼š\\(\\frac{s b h}{t}(34 + 5 a s/h)\\)ï¼›\nä¹˜ä¸Šéœ€è¦åŒæ—¶é©»ç•™çš„â€œç­‰æ•ˆå±‚æ•°â€â€”â€”åœ¨ç»å…¸ 1F1B ä¸­å°±æ˜¯ \\(L\\)ï¼›\nå¾—åˆ°ä¸Šå¼ã€‚\n\n\n\nå¦‚æœé‡‡ç”¨ interleaved pipelineï¼Œè®ºæ–‡æŒ‡å‡ºéœ€è¦å†ä¹˜ä¸Šä¸€ä¸ª \\((1 + \\frac{p-1}{pm})\\) çš„ä¿®æ­£å› å­ï¼Œè¿™é‡Œä¸å±•å¼€ã€‚\n\n3.4.5 å…¨å±‚é‡ç®— vs é€‰æ‹©æ€§é‡ç®—\n\nå…¨å±‚æ¿€æ´»é‡ç®—çš„å†…å­˜ï¼ˆç®€å•æƒ…å½¢ï¼‰\nåŸæ–‡ä¸­çš„ç»“è®ºï¼š\n\\[M_{\\text{full-recompute}} \\approx 2 s b h L\\]\n\nå«ä¹‰ï¼šå¦‚æœä½ åª checkpoint æ¯å±‚è¾“å…¥/è¾“å‡ºï¼ˆå‡è®¾æ¯å±‚åªä¸€ç»„ï¼‰ï¼Œå¿½ç•¥å…¶å®ƒæ¿€æ´»ï¼Œé‚£ä¹ˆæ¯å±‚åªéœ€è¦å­˜ä¸¤ä»½ \\((s,b,h)\\)ï¼Œæ€»å…±å°±æ˜¯ \\(2sbhL\\)ã€‚\né—®é¢˜ï¼šæ˜¾å­˜æ˜¯ä¸‹æ¥äº†ï¼Œä½†æ¯æ¬¡åå‘è¦å¤šè·‘ä¸€ä¸ªå®Œæ•´å‰å‘ï¼ŒFLOPs å¢åŠ çº¦ 33%â€“40%ï¼Œåœ¨å¤§æ¨¡å‹ä¸Šéå¸¸è‚‰ç–¼ã€‚\n\né€‰æ‹©æ€§æ¿€æ´»é‡ç®—ï¼ˆé‡ç‚¹ï¼‰\nåŸæ–‡ä¸­çš„å…¬å¼ï¼ˆå¼ (6)ï¼‰ï¼š\n\\[\nM_{\\text{selective}} =\n\\frac{34 s b h L}{t}\n\\]\n\nå«ä¹‰ï¼šåœ¨ TP+SP çš„åŸºç¡€ä¸Šï¼Œåªå¯¹ attention ä¸­â€œå¤§æ¿€æ´»ã€ä½ FLOPsâ€çš„é‚£å‡ å—åšé‡ç®—ï¼ŒæŠŠ \\(5 a s^2 b\\) é‚£ä¸€å¨æ¿€æ´»å®Œå…¨ä»æ˜¾å­˜ä¸­ç§»é™¤ï¼Œåªå‰©ä¸‹ä¸»å¹²çš„ \\(34sbh\\)ï¼Œç„¶åå†é™¤ä»¥ \\(t\\)ã€‚\nç›´è§‚ï¼š\n\næ— å¹¶è¡Œ + æ— é‡ç®—ï¼š\\(L \\times sbh(34 + 5as/h)\\)ï¼›\nTP+SP + æ— é‡ç®—ï¼šå†é™¤ä»¥ \\(t\\)ï¼›\nTP+SP + é€‰æ‹©æ€§é‡ç®—ï¼šå†æŠŠ \\(5as/h\\) é‚£å—æ•´ä¸ªç æ‰ï¼Œå¯¹åº”å°±å˜æˆå¼ (6)ã€‚\n\nä»¥ GPT-3 / MT-NLG ä¸ºä¾‹ï¼š å¯¹äº GPT-3 (\\(a=96,s=2048,h=12288\\))ï¼Œæœ‰ \\(5 a s/h \\approx 80\\)ï¼› å¯¹äº MT-NLG (\\(a=128,s=2048,h=20480\\))ï¼Œæœ‰ \\(5 a s/h \\approx 64\\)ã€‚ ç›¸æ¯”ä¸»å¹²å¸¸æ•° 34ï¼Œè¿™è¯´æ˜ç»å¤§å¤šæ•°æ¿€æ´»å…¶å®æ¥è‡ªé‚£ä¸€å°æ’® attention å­ç®—å­ï¼Œç æ‰å®ƒä»¬èƒ½çœæ‰ 60%â€“70% çš„æ¿€æ´»ï¼Œè€Œç›¸åº”é‡ç®— FLOPs ä»…å¢åŠ  1.6%â€“2.7%ã€‚\n\n\n\nä¸å¸¸è§è®­ç»ƒæ ˆçš„å¯¹åº”å…³ç³»\nä»â€œæˆ‘çš„å¤§è§„æ¨¡è®­ç»ƒæ ˆï¼ˆå¦‚ Megatron / DeepSpeed / vLLM ç­‰ï¼‰â€è§†è§’ï¼Œå¯ä»¥è¿™ä¹ˆç†è§£è¿™äº›æ¨¡å—å¯¹åº”åˆ°å“ªå‡ å±‚ï¼š\n\næ¿€æ´»å†…å­˜æ¨¡å‹ â†’ é…ç½®æœç´¢/è‡ªåŠ¨è°ƒå‚å±‚\n\nç”¨ä¸Šé¢çš„å…¬å¼å¿«é€Ÿé¢„ä¼°åœ¨ç»™å®š \\((s,b,h,a,L,t,p)\\) ä¸‹çš„æ¿€æ´»å³°å€¼ï¼Œå¸®åŠ©é€‰æ‹© TP/SP/PP ç»„åˆå’Œ micro-batch å¤§å°ã€‚\n\nTP+SP ç»„åˆå¹¶è¡Œ â†’ æ¨¡å‹å¹¶è¡Œç­–ç•¥å±‚\n\nå¯¹åº”æ¡†æ¶é‡Œâ€œå¼ é‡å¹¶è¡Œ + åºåˆ—å¹¶è¡Œâ€çš„ç»´åº¦é…ç½®ï¼Œä¾‹å¦‚ tensor_model_parallel_sizeã€sequence_parallel_sizeï¼Œä»¥åŠç›¸å…³ shard è§„åˆ™ã€‚\n\n\\(g/\\bar g\\) ç®—å­ â†’ é€šä¿¡ backend + kernel å±‚\n\nå®é™…è½åœ°å°±æ˜¯æŠŠåŸæ¥çš„ all_reduce æ›¿æ¢æˆé…å¯¹çš„ all_gather + reduce_scatterï¼Œå¸¸å¸¸ä¸ GEMM kernel èåˆåœ¨ä¸€èµ·ä»¥å‡å°‘ä¸­é—´ç¼“å†²æ‹·è´ã€‚\n\né€‰æ‹©æ€§æ¿€æ´»é‡ç®— â†’ Checkpoint ç­–ç•¥/è‡ªåŠ¨é‡ç®—å±‚\n\nå¯¹åº”æ¡†æ¶é‡Œçš„ activation_checkpoint_methodã€checkpoint_attention ä¹‹ç±»çš„å¼€å…³ï¼Œä»¥åŠåœ¨ Python å›¾é‡ŒåŒ…ä¸€å±‚ checkpoint(function, *args)ã€‚\n\nPipeline åˆ†æ â†’ å¹¶è¡Œè°ƒåº¦ä¸ä½œä¸šç¼–æ’å±‚\n\nå†³å®šæ¯ä¸ª stage æ”¾å¤šå°‘å±‚ã€micro-batch æ•°é‡ã€æ˜¯å¦ä½¿ç”¨ interleaved pipelineï¼Œå¹¶ç¡®ä¿é¦– stage çš„æ˜¾å­˜å³°å€¼æ»¡è¶³å¡å®¹é‡ã€‚\n\n\n\nå››ã€å»ºæ¨¡æ–¹å¼ä¸è¯„ä¼°æŒ‡æ ‡\n4.1 é—®é¢˜æ˜¯å¦‚ä½•å½¢å¼åŒ–çš„ï¼Ÿ\næ ¸å¿ƒä¼˜åŒ–ç›®æ ‡å¯ä»¥ç®€å•æ¦‚æ‹¬ä¸ºï¼š\n\nåœ¨ç»™å®šè®¾å¤‡æ˜¾å­˜çº¦æŸä¸å¹¶è¡Œé…ç½®ï¼ˆTP/SP/PPï¼‰çš„æ¡ä»¶ä¸‹ï¼Œ æœ€å°åŒ–æ¿€æ´»å†…å­˜å³°å€¼ä¸é‡ç®—å¸¦æ¥çš„é¢å¤– FLOPs å¼€é”€ä¹‹å’Œã€‚\n\nè®ºæ–‡æ²¡æœ‰å†™æˆä¸¥æ ¼çš„ä¼˜åŒ–é—®é¢˜ï¼Œä½†é€šè¿‡å…¬å¼åŸºæœ¬éšå¼å®Œæˆäº†å»ºæ¨¡ï¼š\n\næ¿€æ´»å†…å­˜æ¨¡å‹ï¼š\n\næ— å¹¶è¡Œæ—¶å•å±‚æ¿€æ´»ï¼š \\(M_{\\text{act, layer}} = sbh(34 + 5 a s/h)\\)ã€‚\nTP+SP+PP åé¦– stage æ€»æ¿€æ´»ï¼š \\(M_{\\text{total}} = \\dfrac{s b h L}{t} (34 + 5 a s/h)\\)ã€‚\nselective recompute åï¼š \\(M_{\\text{selective}} = \\dfrac{34 s b h L}{t}\\)ã€‚\n\nFLOPs æ¨¡å‹ï¼š\nè¡¨ 2 ä¸­ç»™å‡ºäº†ä¸åŒé…ç½®ä¸‹æ¯å±‚ FLOPsï¼Œä¾‹å¦‚æ— å¹¶è¡Œæ—¶ï¼š\n$$ _{} =================================\n72 s b h^2 (1 + ) $$\nå…¶å®ƒé…ç½®åˆ™åœ¨æ­¤åŸºç¡€ä¸Šé™¤ä»¥ \\(t\\)ï¼Œæˆ–å¢åŠ éƒ¨åˆ†é‡ç®—ç›¸å…³é¡¹ï¼ˆæ¯”å¦‚ selective recompute ä¸‹çš„ \\(1 + \\frac{2s}{9h}\\) ç­‰ï¼‰ã€‚\nç®€åŒ–ä¸çº¦æŸï¼š\n\nå‡è®¾æ‰€æœ‰å±‚åŒæ„ï¼Œå¿½ç•¥ embedding/output ç­‰å°å¤´ï¼›\nåªè€ƒè™‘å• precisionï¼ˆ16-bitï¼‰æ¿€æ´»ï¼›\nåªåˆ†æ FP ç®—åŠ›ï¼Œæš‚ä¸å¼•å…¥é€šä¿¡æ—¶å»¶æ¨¡å‹ï¼ˆé€šä¿¡é€šè¿‡â€œbytes communicatedâ€å•ç‹¬æŠ¥å‘Šï¼‰ã€‚\n\n\næ•´ä¸ªå»ºæ¨¡çš„æ€è·¯æ˜¯ï¼šå…ˆç”¨è§£æå¼é”å®šâ€œç†è®ºä¸Šæœ€ä¼˜çš„å†…å­˜åˆ†æ‘Šæ–¹å¼â€ï¼Œå†åœ¨è¿™ä¸ªç©ºé—´å†…è®¨è®ºä¸åŒ checkpoint ç­–ç•¥çš„ä»£ä»·ã€‚\n4.2 æ ¸å¿ƒè¯„ä¼°æŒ‡æ ‡\nè®ºæ–‡é‡Œçš„æŒ‡æ ‡éå¸¸å·¥ç¨‹å‘ï¼ŒåŸºæœ¬å¯ä»¥ç›´æ¥æ˜ å°„åˆ°ä½ çš„ç›‘æ§é¢æ¿ä¸Šï¼š\n\næ¿€æ´»å†…å­˜ï¼ˆActivations Memoryï¼‰\n\nå«ä¹‰ï¼šå•å±‚æˆ–æ•´ä¸ªæ¨¡å‹åœ¨å‰å‘/åå‘æ—¶ä¸ºæ¿€æ´»åˆ†é…çš„æ˜¾å­˜å³°å€¼ï¼ˆé€šå¸¸ä»¥ GB æˆ–å å¡æ€»æ˜¾å­˜çš„ç™¾åˆ†æ¯”è¡¨ç¤ºï¼‰ã€‚\nå¯¹åº”å…³ç³»ï¼šç›´æ¥å†³å®šâ€œèƒ½ä¸èƒ½åœ¨ä¸€å¼ å¡ä¸Šè·‘ä¸‹è¿™ä¸ªé…ç½®â€ï¼Œä¹Ÿæ˜¯æ˜¯å¦éœ€è¦å†æ‰“å¼€é‡ç®—çš„ç¬¬ä¸€åˆ¤æ–­ä¾æ®ã€‚\n\næ¯å±‚å‰å‘/åå‘æ—¶å»¶ï¼ˆForward / Backward Time per Layerï¼‰\n\nå«ä¹‰ï¼šå›ºå®šæ¨¡å‹ &amp; batch è®¾ç½®ä¸‹ï¼Œå•å±‚ forward + backward çš„ wall-clock æ—¶é—´ï¼ˆmsï¼‰ï¼Œæ–‡ä¸­ç”¨å•å±‚ 22B æ¨¡å‹æ¥åš micro benchmarkã€‚\nå¯¹åº”å…³ç³»ï¼šç”¨æ¥æ‹†åˆ†â€œé‡ç®—å¤šè€—äº†å¤šå°‘æ—¶é—´â€ã€â€œSP/TP å¯¹ LayerNorm/Dropout åŠ é€Ÿäº†å¤šå°‘â€ã€‚\n\né‡ç®—å¼€é”€ï¼ˆRecompute Overheadï¼‰\n\nå«ä¹‰ï¼šåœ¨â€œæ— é‡ç®— baselineâ€çš„å‰æä¸‹ï¼Œé‡ç®—ä¹‹å forward+backward æ€»æ—¶å»¶çš„ç›¸å¯¹æå‡ï¼Œæ¯”å¦‚ full recompute çš„ +39% vs selective+SP çš„ +4%ã€‚\nå¯¹åº”å…³ç³»ï¼šå¸®åŠ©åˆ¤æ–­â€œå¤šçœçš„æ˜¾å­˜æ˜¯å¦å€¼è¿™ç‚¹æ—¶é—´â€ï¼Œå¯¹äºæ•´æœºè®­ç»ƒååå°¤ä¸ºå…³é”®ã€‚\n\nç«¯åˆ°ç«¯è¿­ä»£æ—¶é—´ï¼ˆIteration Time / Throughputï¼‰\n\nå«ä¹‰ï¼šä¸€æ¬¡å®Œæ•´è¿­ä»£ï¼ˆforward+backward+ä¼˜åŒ–å™¨æ›´æ–°ï¼‰æ‰€éœ€æ—¶é—´ï¼Œè®ºæ–‡ä¸­æŠ¥å‘Šçš„æ˜¯ 22B/175B/530B/1T æ¨¡å‹çš„è¿­ä»£æ—¶é—´ä¸å¯¹åº” throughput æå‡ï¼ˆçº¦ 29%â€“32%ï¼‰ã€‚\nå¯¹åº”å…³ç³»ï¼šè¿™æ˜¯æœ€è´´è¿‘â€œè®­ç»ƒæ€»æ—¶é•¿â€çš„æŒ‡æ ‡ï¼Œä¹Ÿæœ€å®¹æ˜“æ˜ å°„åˆ°é¢„ç®—ä¸Šã€‚\n\næ¨¡å‹ FLOPs åˆ©ç”¨ç‡ï¼ˆMFUï¼‰ä¸ç¡¬ä»¶ FLOPs åˆ©ç”¨ç‡ï¼ˆHFUï¼‰\n\nå«ä¹‰ï¼š\n\nMFUï¼šæ¨¡å‹ç†è®º FLOPs / å³°å€¼ç®—åŠ›ï¼›\nHFUï¼šå®é™…æ‰§è¡Œ FLOPsï¼ˆåŒ…æ‹¬é‡ç®—ï¼‰/ å³°å€¼ç®—åŠ›ã€‚\n\nå¯¹åº”å…³ç³»ï¼šè¯´æ˜åœ¨åº”ç”¨ selective recompute åï¼Œè™½ç„¶å®é™… FLOPs ç¨æœ‰å¢åŠ ï¼Œä½†æ€»ä½“ç®—åŠ›åˆ©ç”¨ç‡ä»ç„¶å¯ä»¥ç»´æŒç”šè‡³ç•¥å‡ï¼Œæ¯”å¦‚ 1T æ¨¡å‹çš„ MFU/HFU åœ¨ 56% å·¦å³ã€‚\n\né€šä¿¡é‡ï¼ˆBytes Communicatedï¼‰\n\nå«ä¹‰ï¼šæ¯å±‚åœ¨ä¸åŒé…ç½®ä¸‹çš„æ€»é€šä¿¡å­—èŠ‚æ•°ï¼Œè¡¨ 2 ä¸­ä»¥ bytes å½¢å¼ç»™å‡ºã€‚\nå¯¹åº”å…³ç³»ï¼šå¯¹æ¯”â€œTP vs TP+SP vs full/partial recomputeâ€æ˜¯å¦å¼•å…¥é¢å¤– all-gather / reduce-scatterï¼Œå¸®åŠ©åˆ¤æ–­åœ¨ä¸åŒç½‘ç»œæ‹“æ‰‘ï¼ˆå•æœº NVLinkã€å¤šæœº IBï¼‰ä¸‹æ˜¯å¦ä¼šè¢«é€šä¿¡ç“¶é¢ˆå¡ä½ã€‚\n\n\n\näº”ã€ä¸»è¦å®éªŒå‘ç°\nç”¨å‡ æ¡ç»“è®ºæŠŠæ•´ç¯‡å®éªŒçš„è¦ç‚¹ä¸²ä¸€ä¸‹ï¼š\n\nTP+SP / selective recompute å•ç‹¬ä½¿ç”¨æ—¶ï¼Œå„è‡ªéƒ½èƒ½å°†æ¿€æ´»æ˜¾å­˜å‹åˆ° TP åŸºçº¿çš„çº¦ä¸€åŠï¼š ä»…åŠ  sequence parallelismï¼Œå°±èƒ½æŠŠæ¿€æ´»é™åˆ°åŸæ¥çš„ ~50%ï¼›ä»…åŠ  selective recomputeï¼ŒåŒæ ·çº¦åŠï¼›ä¸¤è€…å åŠ å¯è¾¾åˆ°çº¦ 5Ã— çš„å‹ç¼©ï¼Œä½¿å¾— 175B / 530B / 1T é…ç½®åœ¨ 80GB å¡ä¸Šå˜å¾—å¯è¡Œã€‚\né€‰æ‹©æ€§é‡ç®—æå¤§é™ä½äº†é‡ç®—å¼€é”€ï¼š åœ¨ 22B å•å±‚å®éªŒä¸­ï¼š\n\nå…¨å±‚é‡ç®—ï¼šforward+backward æ€»æ—¶å»¶å¢åŠ  39%ï¼›\nselective é‡ç®—ï¼šå¢åŠ  7%ï¼›\nselective + SPï¼šä»…å¢åŠ  4%ã€‚\n\nå¯¹å¤§æ¨¡å‹è¶Šå‹å¥½ï¼Œæ¨¡å‹è¶Šå¤§æ”¶ç›Šè¶Šé«˜ï¼š å¯¹ 530B å’Œ 1T æ¨¡å‹ï¼Œfull recompute çš„é‡ç®— overhead çº¦ 36%ï¼Œè€Œ selective+SP çš„ overhead ä»… 2%ã€‚\nç«¯åˆ°ç«¯ååæå‡çº¦ 30%ï¼š åœ¨ 4 ç»„æ¨¡å‹ï¼ˆ22B/175B/530B/1Tï¼‰ä¸Šï¼Œä¸â€œfull recompute + æ—  SPâ€ç›¸æ¯”ï¼Œæœ¬æ–‡æ–¹æ¡ˆçš„è¿­ä»£æ—¶é—´ç¼©çŸ­ 29%â€“32%ï¼Œå¯¹åº” throughput åŒæ¯”ä¾‹æå‡ã€‚\nFLOPs åˆ©ç”¨ç‡ç¨³æ­¥æå‡ï¼š éšæ¨¡å‹è§„æ¨¡å˜å¤§ï¼ŒMFU / HFU ä» 40%+ æå‡åˆ° 56% å·¦å³ï¼Œè¯´æ˜æ¿€æ´»å†…å­˜ä¼˜åŒ–å¸¦æ¥çš„â€œæ›´å¤§ batchã€æ›´å¥½å¹¶è¡Œé…ç½®â€å¯¹æ•´ä½“ç¡¬ä»¶åˆ©ç”¨ç‡æ”¶ç›Šæ˜¾è‘—ã€‚\n\n5.1 å…³é”®å›¾è¡¨è§£è¯»\n\nå›¾ 7ï¼šä¸åŒæ–¹æ¡ˆçš„æ¿€æ´»å†…å­˜å æ¯”ï¼ˆç›¸å¯¹äº TP baselineï¼‰\n\nç°è±¡ï¼šéšç€æ¨¡å‹è§„æ¨¡å¢å¤§ï¼Œsequence parallelism ä¸ selective recompute å•ç‹¬ä½¿ç”¨æ—¶éƒ½èƒ½å°†æ¿€æ´»å‹åˆ°çº¦ 50%ï¼›åˆç”¨åèƒ½é™åˆ°ä¸åˆ° 20%ï¼Œè€Œ full recompute åœ¨ 10% å·¦å³ã€‚\næ”¯æ’‘ä¸»å¼ ï¼šè¯´æ˜åœ¨â€œåªä»˜å‡º 2%â€“7% é‡ç®—å¼€é”€â€çš„å‰æä¸‹ï¼ŒTP+SP+selective å·²ç»éå¸¸æ¥è¿‘ full recompute çš„å†…å­˜æ•ˆç‡ï¼Œä½†å°‘äº†å¤§é‡æ— è°“çš„ç®—åŠ›å¼€é”€ï¼Œæ˜¯å®è·µä¸­æ›´å¹³è¡¡çš„æ–¹æ¡ˆã€‚\n\nå›¾ 8ï¼šæ¯å±‚ forward / backward / recompute æ—¶é—´æ‹†åˆ†\n\nç°è±¡ï¼š\n\nbaseline æ— é‡ç®—æ—¶ï¼Œbackward æ—¶é—´è¿œå¤§äº forwardï¼›\nfull recompute ç»™ backward é¡¶ä¸Šå»ä¸€å¤§å—ï¼›\nselective+SP çš„â€œé‡ç®—æ¡â€éå¸¸ç»†ï¼Œå¯¹æ•´ä½“å½±å“æå°ã€‚\n\næ”¯æ’‘ä¸»å¼ ï¼šè¯æ˜ selective é‡ç®—ç¡®å®åªæŠŠé‡ç®—é›†ä¸­åœ¨ FLOPs ç¨å¤šçš„é‚£ä¸€å°å—ï¼Œä¸”é€šè¿‡é‡å é€šä¿¡/è®¡ç®—æŠŠ overhead å‹å¾—å¾ˆä½ã€‚\n\nè¡¨ 5ï¼šç«¯åˆ°ç«¯è¿­ä»£æ—¶é—´ä¸ FLOPs åˆ©ç”¨ç‡\n\nç°è±¡ï¼šæ‰€æœ‰è§„æ¨¡æ¨¡å‹çš„ iteration time éƒ½ä» â€œfull recomputeâ€ é…ç½®ä¸­å‡æ‰äº† ~30%ï¼›åŒæ—¶ MFU/HFU éšè§„æ¨¡å¢å¤§è€Œå‡é«˜ï¼Œ1T æ¨¡å‹å¯åˆ° 56%+ã€‚\næ”¯æ’‘ä¸»å¼ ï¼šè¯´æ˜æœ¬æ–‡ä¸ä»…ä»…æ˜¯â€œæŠŠæ˜¾å­˜å‡‘å¤Ÿå°±å®Œäº‹â€ï¼Œè€Œæ˜¯åœ¨å®é™…è®­ç»ƒååå’Œç¡¬ä»¶åˆ©ç”¨ç‡ä¸Šéƒ½è¯æ˜äº†å·¥ç¨‹ä»·å€¼ã€‚\n\n\nç»“æœè§£è¯»ä¸è¾¹ç•Œ\næ€»ä½“æ¥çœ‹ï¼Œå®éªŒéå¸¸æœ‰è¯´æœåŠ›ï¼šå…¬å¼æ¨å¯¼å’Œå®æµ‹æ•°æ®é«˜åº¦åŒ¹é…ï¼Œä»å•å±‚ micro benchmark åˆ°ä¸Šç™¾å±‚ã€ä¸Šä¸‡å¡çš„ç«¯åˆ°ç«¯å®éªŒï¼Œéƒ½å±•ç¤ºäº† TP+SP+selective çš„ç¨³å®šä¼˜åŠ¿ã€‚\nä½†ä¹Ÿå­˜åœ¨ä¸€äº›æœªå®Œå…¨è¦†ç›–çš„ç»´åº¦ï¼Œä¾‹å¦‚ï¼š\n\nå¹¶æœªç³»ç»Ÿè¯„ä¼° æ›´å¤æ‚çš„é‡å¤ç»“æ„ï¼ˆMoEã€å¸¦å¤šè·¯åˆ†æ”¯çš„ encoder-decoderï¼‰ä¸­ selective recompute çš„æ”¶ç›Šä¸å¼€é”€ï¼›\nå¯¹ æ¢¯åº¦ checkpoint æœç´¢ç®—æ³•ï¼ˆå¦‚ CVPR 2021 çš„ Optimal Checkpoint Searchï¼‰åªåœ¨ç›¸å…³å·¥ä½œä¸­æåŠï¼Œæœªåšç›´æ¥å¯¹æ¯”ï¼›\nå®éªŒä¸»è¦é›†ä¸­åœ¨å•ä¸€ç¡¬ä»¶å¹³å°ä¸ç½‘ç»œæ‹“æ‰‘ï¼Œå¯¹ä½å¸¦å®½å¤šæœºç¯å¢ƒä¸‹â€œall-gather / reduce-scatter æ•°é‡å¢åŠ æ˜¯å¦æˆä¸ºç“¶é¢ˆâ€ç¼ºä¹ç³»ç»Ÿè¯„ä»·ã€‚\n\n\nå…­ã€ä¼˜ç‚¹ä¸å±€é™\näº®ç‚¹ï¼ˆStrengthsï¼‰\n\né—®é¢˜åˆ»ç”»éå¸¸ç²¾å‡†ï¼šä»â€œæ¿€æ´»å†…å­˜â€è€Œä¸æ˜¯â€œæ€»æ˜¾å­˜â€åˆ‡å…¥ï¼Œå°† attention / MLP / LN / Dropout çš„æ¿€æ´»å æ¯”æ‹†å¾—éå¸¸ç»†ï¼Œæœ‰åˆ©äºå·¥ç¨‹ä¸Šé’ˆå¯¹æ€§ä¼˜åŒ–ã€‚\nè§£ææ¨¡å‹ç®€å•ä½†å¨åŠ›å¤§ï¼šå‡ ä¸ªçŸ­å…¬å¼å°±è§£é‡Šäº† TP / SP / PP çš„å†…å­˜è¡Œä¸ºï¼Œå¹¶è‡ªç„¶ç»™å‡ºâ€œæ¿€æ´»å‡åŒ€åˆ†æ‘Šåˆ° TP ç»„â€çš„æœ€ä¼˜å½¢å¼ï¼Œä¸ºåç»­å·¥ä½œæä¾›äº†ç»Ÿä¸€çš„åº¦é‡å°ºã€‚\nTP+SP è®¾è®¡ä¼˜é›…ï¼šé€šè¿‡ \\(g/\\bar g\\) å°† all-reduce æ‹†æˆ all-gather + reduce-scatterï¼Œä¸æ”¹å˜é€šä¿¡å¸¦å®½ï¼Œä»…æ”¹å˜é€šä¿¡ç®—å­çš„å½¢æ€ï¼Œå°±è§£å†³äº†é TP åŒºåŸŸçš„æ¿€æ´»é‡å¤é—®é¢˜ã€‚\né€‰æ‹©æ€§é‡ç®—éå¸¸å·¥ç¨‹å‹å¥½ï¼šåªéœ€è¦åœ¨ attention å†…éƒ¨åŠ å‡ å¤„ checkpoint æ ‡è®°ï¼Œæ—¢å‡å°‘å¤§é‡æ¿€æ´»ï¼Œåˆé¿å…åƒâ€œå…¨å±‚é‡ç®—â€é‚£æ ·åŠ¨è¾„ +30% FLOPsã€‚\nå®éªŒè¦†ç›–åˆ° trillion-scaleï¼šåœ¨ 22Bâ€“1T å››ä¸ªé‡çº§æ¨¡å‹ä¸Šå®Œæ•´è¯„ä¼°ï¼ŒåŒ…å«å•å±‚æ—¶å»¶ã€æ•´æ¨¡å‹è¿­ä»£æ—¶é—´ã€MFU/HFUï¼Œéå¸¸è´´è¿‘å®é™…å¤§æ¨¡å‹è®­ç»ƒåœºæ™¯ã€‚\nä¸ç°æœ‰å¹¶è¡Œæ ˆé«˜åº¦å…¼å®¹ï¼šTP+SP+PP çš„ç»„åˆå¯ä»¥è‡ªç„¶åµŒå…¥åˆ°ä¸»æµ 3D å¹¶è¡Œæ¡†æ¶ä¸­ï¼Œä¸ä¸ ZeRO/FSDP ç­‰å‚æ•°/ä¼˜åŒ–å™¨åˆ‡åˆ†æŠ€æœ¯å†²çªã€‚(arXiv)\n\nå±€é™ï¼ˆLimitationsï¼‰\n\nç»“æ„å‡è®¾è¾ƒå¼ºï¼šåªé’ˆå¯¹æ ‡å‡†å• stack Transformerï¼Œä¸”é»˜è®¤å±‚ç»“æ„é«˜åº¦ä¸€è‡´ï¼Œå¯¹ MoEã€encoder-decoderã€å¤šä»»åŠ¡å¤´ç­‰å¤æ‚æ‹“æ‰‘çš„é€‚é…å¹¶æœªæ·±å…¥è®¨è®ºã€‚\nå®Œå…¨æ‰‹å·¥çš„ checkpoint ç­–ç•¥ï¼šå½“å‰ selective recompute æ–¹æ¡ˆåŸºäºäººå·¥åˆ†æï¼Œå¹¶æœªåˆ©ç”¨å›¾æœç´¢/è‡ªåŠ¨è°ƒåº¦ç®—æ³•å»è¿›ä¸€æ­¥é€¼è¿‘ç†è®ºæœ€ä¼˜ã€‚\nç¼ºå°‘å¯¹æ¿€æ´»ç¢ç‰‡åŒ–é—®é¢˜çš„å®šé‡åˆ†æï¼šè™½ç„¶ç»“è®ºéƒ¨åˆ†æåˆ°ç¢ç‰‡å’Œé¦– stage å†…å­˜ä¸å‡æ˜¯æœªæ¥å·¥ä½œæ–¹å‘ï¼Œä½†æ­£æ–‡æœªç»™å‡ºç³»ç»Ÿæµ‹é‡æˆ–æ¨¡å‹ã€‚\né€šä¿¡æ€§èƒ½å‡è®¾åç†æƒ³ï¼šå°† all-reduce = reduce-scatter + all-gather è§†ä½œâ€œé€šä¿¡å¸¦å®½ä¸å˜â€ï¼Œåœ¨è·¨æœºã€éå…¨è¿æ¥æ‹“æ‰‘ä¸‹å¯èƒ½ä¸å®Œå…¨æˆç«‹ã€‚\nä¸å…¶å®ƒå†…å­˜ä¼˜åŒ–æŠ€æœ¯çš„ç»„åˆåˆ†ææœ‰é™ï¼šä¾‹å¦‚ä¸ ZeRO/FSDPã€offloadã€FlashAttention ç­‰ç»„åˆåçš„æ•´ä½“æ”¶ç›Šï¼Œç›®å‰ä»éœ€è¯»è€…è‡ªè¡Œæ¢ç´¢ã€‚(arXiv)\n\n\nä¸ƒã€ä¸šå†…ç›¸å…³å·¥ä½œå¯¹æ¯”\nä¸‹é¢é€‰ 3 ç±»ä»£è¡¨æ€§å·¥ä½œï¼Œä¸æœ¬æ–‡åšä¸€ä¸ªå·¥ç¨‹è§†è§’ä¸‹çš„å¯¹æ¯”ï¼š\n\n\n\n\n\n\n\n\n\nå·¥ä½œ\né—®é¢˜å®šä¹‰\næ–¹æ³•è·¯çº¿\nè´¡çŒ®ä¸å®ç”¨ä»·å€¼ï¼ˆä¸»è§‚ï¼‰\n\n\n\n\næœ¬æ–‡ï¼šå‡å°‘æ¿€æ´»é‡è®¡ç®—\nå¤§è§„æ¨¡ Transformer è®­ç»ƒä¸­ï¼Œæ¿€æ´»æ˜¾å­˜æˆä¸ºä¸»è¦ç“¶é¢ˆï¼Œfull recompute å¸¦æ¥å·¨å¤§ç®—åŠ›å¼€é”€ã€‚\nç²¾ç¡®å»ºæ¨¡æ¿€æ´»å†…å­˜ï¼Œç»“åˆ TP + SP å‡åˆ†æ¿€æ´»ï¼Œå¹¶åœ¨å±‚å†…å¯¹å­ç®—å­åš selective recomputeã€‚\nåœ¨ä¸æ”¹æ¨¡å‹ç»“æ„çš„å‰æä¸‹ï¼Œæ˜¾å­˜å‹ç¼© 5Ã—ï¼Œååæå‡ ~30%ï¼Œå¯¹äºå·²æœ‰ 3D å¹¶è¡Œæ ˆå‡ ä¹æ˜¯â€œå¿…é€‰é¡¹â€ã€‚\n\n\nZeRO / FSDP ç³»åˆ—(arXiv)\nèšç„¦ å‚æ•°+ä¼˜åŒ–å™¨çŠ¶æ€ çš„å†…å­˜å†—ä½™ï¼Œä½¿æ¨¡å‹è§„æ¨¡éšè®¾å¤‡æ•°çº¿æ€§æ‰©å±•ã€‚\né€šè¿‡åˆ‡åˆ† optimizer stateã€gradientã€parameterï¼Œå°†æ•°æ®å¹¶è¡Œä¸­çš„å†—ä½™å…¨éƒ¨æ‰“æ•£ï¼Œé…åˆ offloadã€‚\nå¤§å¹…å‡å°â€œæ¨¡å‹çŠ¶æ€â€å ç”¨ï¼Œé€‚åˆåœ¨ DP ç»´åº¦æ‰©å±•ï¼Œå’Œæœ¬æ–‡åœ¨ç»´åº¦ä¸Šé«˜åº¦äº’è¡¥ã€‚\n\n\nGSPMD / é€šç”¨ SPMD å¹¶è¡Œ(arXiv)\næä¾›ä¸€ç§ç»Ÿä¸€çš„å›¾çº§ SPMD å¹¶è¡ŒæŠ½è±¡ï¼Œæ”¯æŒ TP/PP/DP/æ··åˆã€‚\nå°†å¹¶è¡Œè§†ä½œå¯¹ tensor shape çš„â€œsharding specâ€ï¼Œç”±ç¼–è¯‘å™¨è‡ªåŠ¨å®Œæˆè°ƒåº¦ä¸é€šä¿¡æ’å…¥ã€‚\nåœ¨ç¼–è¯‘å±‚é¢å¯¹å„ç§å¹¶è¡Œå½¢å¼è¿›è¡Œç»Ÿä¸€æè¿°ï¼Œé€‚åˆä½œä¸º TP+SP+selective è¿™ç±»ä¼˜åŒ–çš„â€œè½½ä½“â€ã€‚\n\n\nSequence Parallelism from System Perspectiveï¼ˆSP ç³»åˆ—å·¥ä½œï¼‰(ResearchGate)\né¢å‘è¶…é•¿åºåˆ—è®­ç»ƒï¼Œå…³æ³¨ æ²¿åºåˆ—ç»´åˆ‡åˆ† activations/å‚æ•° çš„ç³»ç»Ÿè®¾è®¡ã€‚\næå‡ºå¤šç§ SP å˜ä½“ï¼ˆring attention ç­‰ï¼‰ï¼Œé€šè¿‡åœ¨ attention å†…åŠ å…¥ç‰¹æ®Šé€šä¿¡æ¨¡å¼å‡å°‘ \\(s^2\\) å­˜å‚¨å’Œè®¡ç®—ã€‚\nå¯¹é•¿ä¸Šä¸‹æ–‡æ¨¡å‹æä¸ºé‡è¦ï¼Œä¸æœ¬æ–‡çš„ SP æ€è·¯ç±»ä¼¼ä½†æ›´å…³æ³¨â€œé•¿åºåˆ—ä¸‹ attention çš„è®¡ç®— patternâ€ã€‚\n\n\n\næ•´ä½“è€Œè¨€ï¼Œæœ¬æ–‡å¯ä»¥çœ‹ä½œæ˜¯ â€œTP-centric 3D å¹¶è¡Œæ ˆä¸­é’ˆå¯¹æ¿€æ´»çš„ä¸€å—è¡¥å®Œâ€ï¼š\n\nåœ¨å‚æ•°/ä¼˜åŒ–å™¨ç»´åº¦ï¼Œå®ƒè‡ªç„¶å¯ä»¥ä¸ ZeRO/FSDP ååŒï¼›\nåœ¨ç¼–è¯‘/å›¾è°ƒåº¦ç»´åº¦ï¼Œå¯ä»¥è¢« GSPMD ç­‰ SPMD æ¡†æ¶å®ç°ä¸ºä¸€å¥— sharding è§„åˆ™ä¸é€šä¿¡é‡å†™ï¼›\nåœ¨é•¿åºåˆ—åœºæ™¯ä¸‹ï¼Œå¯ä¸æ›´æ¿€è¿›çš„ SP / context parallel / ring attention ç­‰æ–¹æ¡ˆäº’è¡¥ã€‚\n\n7.1 ä¸ªäººè§‚ç‚¹\nä»â€œå¦‚ä½•å†™ä¸€ç¯‡ç³»ç»Ÿè®ºæ–‡â€çš„è§’åº¦çœ‹ï¼Œè¿™ç¯‡æ–‡ç« çš„è®ºè¯è·¯çº¿éå¸¸æ¸…æ™°ï¼š\n\nå…ˆç”¨è§£ææ¨¡å‹è§£é‡Šæ¸…æ¥š â€œä¸ºä»€ä¹ˆéœ€è¦ TP+SP + selectiveâ€ï¼Œä»¥åŠå®ƒåœ¨å…¬å¼ä¸Šçš„æœ€ä¼˜æ€§ï¼›\nå†ç”¨å¤šç»„å®éªŒéªŒè¯â€œæ¨¡å‹å’Œç°å®åŸºæœ¬ä¸€è‡´â€ï¼Œå¹¶è´¯ç©¿ä¸åŒæ¨¡å‹è§„æ¨¡ï¼Œé¿å…åªåœ¨å•ä¸€è§„æ¨¡åš cherry-pickã€‚\n\nå¦‚æœè¦æŒ‘åˆºï¼Œæˆ‘è§‰å¾—å¯ä»¥åŠ å¼ºçš„éƒ¨åˆ†æœ‰ï¼š\n\nbaseline æ›´ä¸°å¯Œï¼šç›®å‰é‡ç®—éƒ¨åˆ†ä¸»è¦å¯¹æ¯”çš„æ˜¯â€œfull recompute vs selectiveâ€ï¼Œå¦‚æœèƒ½å†åŠ ä¸Šâ€œä¸€äº›è‡ªåŠ¨ checkpoint æœç´¢ç®—æ³•â€ï¼ˆä¾‹å¦‚ Feng &amp; Huang 2021ï¼‰æˆ–ç°æœ‰æ¡†æ¶ä¸­çš„é»˜è®¤ç­–ç•¥ï¼Œå¯¹å·¥ç¨‹é€‰å‹ä¼šæ›´æœ‰å‚è€ƒæ„ä¹‰ã€‚\nä¸å…¶å®ƒå†…å­˜ä¼˜åŒ–çš„ç»„åˆå®éªŒï¼šä¾‹å¦‚å°† TP+SP+selective ä¸ ZeRO/FSDP/FlashAttention/å‚æ•° offload ä¸€èµ·æ”¾å…¥åŒä¸€å¼ å¯¹æ¯”è¡¨ä¸­ï¼Œè¯´æ˜ä¸åŒç»´åº¦ä¸Šçš„å¯å åŠ æ€§ã€‚\nå¯¹ç¢ç‰‡å’Œè°ƒåº¦çš„æ›´ç³»ç»Ÿåˆ†æï¼šå¦‚èƒ½åœ¨é™„å½•ä¸­è¡¥å…… pipeline é¦– stage çš„å†…å­˜ç¢ç‰‡åˆ†å¸ƒã€ä¸åŒ micro-batch æ•°é‡å¯¹ç¢ç‰‡çš„å½±å“ï¼Œä¼šæ›´åˆ©äºå·¥ç¨‹è½åœ°æ—¶åšäºŒæ¬¡æƒè¡¡ã€‚\n\n\nå…«ã€åœ¨å®é™…è®­ç»ƒæ ˆä¸­å¦‚ä½•è½åœ°ï¼Ÿ\nå‡è®¾ä½ å·²ç»æœ‰ä¸€å¥—â€œ3D å¹¶è¡Œ + æ¿€æ´» checkpointâ€ çš„è®­ç»ƒæ ˆï¼ˆæ¯”å¦‚æŸç§ Megatron/DeepSpeed é£æ ¼ï¼‰ï¼Œè¦å¼•å…¥æœ¬æ–‡æ–¹æ³•ï¼Œå¤§è‡´å¯ä»¥ä»ä»¥ä¸‹å‡ ä¸ªå±‚é¢åŠ¨æ‰‹ï¼š\n\nå¹¶è¡Œè°ƒåº¦ï¼ˆTP / SP / PP ç»„åˆï¼‰\n\nåœ¨ç°æœ‰ TP é…ç½®ä¸Šï¼Œæ–°å¢ sequence parallel ç»´åº¦ï¼Œä¾‹å¦‚å¢åŠ  sequence_parallel_sizeï¼Œå¹¶ä¸º LN/Dropout/embedding/output ç­‰é TP åŒºåŸŸæŒ‡å®šâ€œæŒ‰åºåˆ—åˆ‡åˆ†â€çš„ layoutã€‚\nåœ¨ pipeline åˆ‡åˆ†æ—¶ï¼Œæ˜¾å¼è€ƒè™‘â€œé¦– stage éœ€è¦ hold \\(L\\) å±‚æ¿€æ´»â€çš„äº‹å®ï¼Œç”¨ä¸Šé¢çš„å…¬å¼è¯„ä¼°ä¸åŒ pipeline_model_parallel_size ä¸‹çš„ peak æ˜¾å­˜ã€‚\nå¯¹å¤šæœºåœºæ™¯ï¼Œç¡®è®¤ SP çš„é€šä¿¡ç»„ï¼ˆé€šå¸¸å’Œ TP ç»„ä¸€è‡´ï¼‰ï¼Œé¿å…è·¨èŠ‚ç‚¹é¢‘ç¹åš all-gather / reduce-scatterã€‚\n\nkernel / ç®—å­å®ç°\n\nä¸º LN/Dropout/write-back ç­‰ç®—å­å¢åŠ  SP awarenessï¼šè¾“å…¥å¼ é‡åœ¨åºåˆ—ç»´ä¸Šæ˜¯ shard çš„ï¼Œç®—å­åº”èƒ½åœ¨å±€éƒ¨ shard ä¸Šå·¥ä½œã€‚\nå°†åŸæœ¬åœ¨ TP å†…éƒ¨ä½¿ç”¨çš„ all_reduce æ”¹å†™æˆæˆå¯¹çš„ all_gather + reduce_scatterï¼Œå¹¶å°½å¯èƒ½ä¸ GEMM kernel èåˆï¼Œå‡å°‘ä¸­é—´ bufferã€‚\nåœ¨ attention ä¸­ï¼Œå¯¹ \\(QK^\\top\\)ã€softmaxã€dropoutã€attention over V é‚£ä¸€æ®µå­å›¾å¢åŠ â€œä¾¿äºé‡ç®—â€çš„è¾¹ç•Œï¼Œæ¯”å¦‚ä½¿ç”¨æ¡†æ¶å†…çš„ checkpoint åŒ…ä¸€å±‚ã€‚\n\næ¿€æ´» checkpoint / é‡ç®—ç­–ç•¥\n\næä¾›ä¸€ä¸ªç»†ç²’åº¦çš„é‡ç®—é…ç½®æ¥å£ï¼Œå…è®¸ç”¨æˆ·å•ç‹¬æ§åˆ¶ï¼š\n\næ˜¯å¦å¯¹ attention å†…éƒ¨åš selective checkpointï¼›\næ˜¯å¦å¯¹ MLP æˆ–æ•´å±‚åšé¢å¤– checkpointï¼ˆåœ¨æ›´ç´§å¼ æ˜¾å­˜ä¸‹ï¼‰ã€‚\n\nå°†è®ºæ–‡é‡Œçš„â€œGPU çº§ FLOPs overhead ä¼°ç®—å…¬å¼â€å›ºåŒ–ä¸ºå·¥å…·å‡½æ•°ï¼Œè®©ç”¨æˆ·åœ¨é…ç½®æ–‡ä»¶ä¸­çœ‹åˆ°â€œé¢„ä¼°é‡ç®— overhead ä¸æ¿€æ´»èŠ‚çœæ¯”ä¾‹â€ï¼Œä»¥å¸®åŠ©é€‰è¾¹ç•Œã€‚\n\né€šä¿¡ä¸é›†ä½“æ“ä½œ backend\n\nåœ¨é€šä¿¡å±‚é¢å¤–æ”¯æŒâ€œåŸºäºå½¢çŠ¶ä¸ layout çš„ all-reduce â†” AG+RS é‡å†™â€ï¼Œå¿…è¦æ—¶å¯¹ all_gather å’Œ reduce_scatter åšä¸“é—¨è°ƒä¼˜ï¼ˆpipeline overlapã€ç»„å†…æ‹“æ‰‘ awareness ç­‰ï¼‰ã€‚\nä¸º SP/TP çš„é€šä¿¡ group æä¾›ç»Ÿä¸€ç®¡ç†ï¼Œé¿å…å‡ºç°â€œä¸€ä¸ª rank åŒæ—¶éš¶å±å¤ªå¤š group å¯¼è‡´ NCCL resource ç´§å¼ â€çš„é—®é¢˜ã€‚\n\nDataLoader / é¢„å¤„ç†ä¸æ‰“åŒ…ç­–ç•¥\n\nè™½ç„¶æœ¬æ–‡ä¸ç›´æ¥æ”¹å˜ DataLoaderï¼Œä½†åœ¨å®è·µä¸­é€šå¸¸ä¼šåˆ©ç”¨â€œèŠ‚çœä¸‹æ¥çš„æ¿€æ´»æ˜¾å­˜â€å»å¢åŠ  micro-batch æˆ– global batchï¼Œæ­¤æ—¶éœ€è¦æ£€æŸ¥ï¼š\n\næ•°æ®æ‰“åŒ…æ˜¯å¦æ”¯æŒæ›´å¤§ batchï¼ˆå°¤å…¶æ˜¯å¤šä»»åŠ¡æ··åˆæ•°æ®é›†ï¼‰ï¼›\né•¿åºåˆ—è®­ç»ƒæ—¶ï¼Œæ˜¯å¦ä¸ SP / context parallel ç­‰ç­–ç•¥å†²çªã€‚\n\n\né…ç½®æœç´¢ / è‡ªåŠ¨è°ƒå‚\n\nå°†æ¿€æ´»å†…å­˜æ¨¡å‹ä¸ FLOPs æ¨¡å‹åšæˆä¸€ä¸ªå°å·¥å…·ï¼ˆç”šè‡³å¯ä»¥å†™æˆ Python è„šæœ¬ï¼‰ï¼Œåœ¨ç»™å®šç¡¬ä»¶è§„æ ¼å’Œæ¨¡å‹é…ç½®çš„æƒ…å†µä¸‹ï¼Œè‡ªåŠ¨æœç´¢å¯è¡Œçš„ (TP, SP, PP, micro-batch) ç»„åˆã€‚\nå¯¹äºè‡ªåŠ¨åŒ–çš„ launcherï¼Œå¯ä»¥åœ¨æäº¤å‰ç›´æ¥ç»™å‡ºâ€œé¢„ä¼° peak æ˜¾å­˜ã€é‡ç®—å¼€é”€ã€MFU ä¸Šé™â€ç­‰ä¿¡æ¯ã€‚\n\nç›‘æ§ä¸è°ƒè¯•\n\nåœ¨æ¡†æ¶ä¸­å¢åŠ  per-layer / per-stage çš„ æ¿€æ´»å†…å­˜è¿½è¸ªï¼ˆé€šè¿‡ forward/backward hooksï¼‰ï¼ŒéªŒè¯æ˜¯å¦ç¬¦åˆè®ºæ–‡å…¬å¼çš„é¢„ä¼°ã€‚\nç›‘æ§â€œé‡ç®—åŒºâ€çš„æ—¶é—´å æ¯”ï¼Œç¡®è®¤ selective é‡ç®—çš„ overhead æ˜¯å¦æ¥è¿‘è®ºæ–‡ä¸­çš„ 2%â€“7%ï¼Œè‹¥è¿œé«˜äºæ­¤éœ€è¦æ£€æŸ¥é€šä¿¡ overlap æ˜¯å¦ç”Ÿæ•ˆã€‚\n\n\næ€»çš„æ¥è¯´ï¼Œå¼•å…¥æœ¬æ–‡æ–¹æ³•çš„å·¥ç¨‹å·¥ä½œé‡ä¸»è¦é›†ä¸­åœ¨ ç®—å­ layout æ”¹å†™ + é€šä¿¡æ¨¡å¼é‡å†™ + checkpoint ç­–ç•¥ç»†åŒ–ï¼Œå¯¹ä¸Šå±‚æ¨¡å‹ä»£ç ä¾µå…¥è¾ƒå°ã€‚\n\nä¹ã€å€¼å¾—è¿›ä¸€æ­¥æ¢ç´¢çš„ç ”ç©¶æ–¹å‘\n\nè‡ªåŠ¨åŒ–æ¿€æ´»é‡ç®—ç­–ç•¥æœç´¢\n\né—®é¢˜ï¼šç›®å‰ selective recompute ä»åŸºäºæ‰‹å·¥åˆ’åˆ†ï¼›å¯¹äºæ›´å¤æ‚çš„ç½‘ç»œç»“æ„ï¼Œäººè‚‰é€‰æ‹© checkpoint è¾¹ç•Œæ—¢è´¹æ—¶åˆå¯èƒ½ sub-optimalã€‚\nä»·å€¼ï¼šç»“åˆå·²æœ‰çš„â€œæœ€ä¼˜ checkpoint æœç´¢â€ç®—æ³•ï¼ˆå¦‚ CVPR 2021 Feng &amp; Huangï¼‰ä¸æœ¬æ–‡çš„æ¿€æ´»å†…å­˜æ¨¡å‹ï¼Œæœ‰æœ›è‡ªåŠ¨ç»™å‡ºåœ¨ä¸åŒæ˜¾å­˜é¢„ç®—ä¸‹çš„æœ€ä½³é‡ç®—ç­–ç•¥ã€‚\n\nä¸ ZeRO / FSDP / offload çš„ç»Ÿä¸€å»ºæ¨¡\n\né—®é¢˜ï¼šå½“å‰å®è·µå¾€å¾€åŒæ—¶å¯ç”¨å‚æ•°/æ¢¯åº¦/ä¼˜åŒ–å™¨çš„åˆ‡åˆ†ä¸ offloadï¼Œä»¥åŠæ¿€æ´»å±‚é¢çš„ TP+SP+selectiveï¼Œç¼ºä¹ç»Ÿä¸€çš„æˆæœ¬æ¨¡å‹ã€‚\nä»·å€¼ï¼šæ„å»ºä¸€ä¸ªç»Ÿä¸€çš„â€œæ˜¾å­˜+FLOPs+é€šä¿¡ä¸‰å…ƒæ¨¡å‹â€ï¼Œè‡ªåŠ¨åœ¨â€œåŠ å¤§ DPã€åŠ å¤§ TP/SPã€åŠ å¤§å°é‡ç®—â€ä¹‹é—´å¹³è¡¡ï¼ŒæŒ‡å¯¼ trillion-scale è®­ç»ƒæ ˆè®¾è®¡ã€‚\n\né¢å‘é•¿ä¸Šä¸‹æ–‡çš„åºåˆ—å¹¶è¡Œä¸é‡ç®—ååŒ\n\né—®é¢˜ï¼šéšç€ 128K+ ä¸Šä¸‹æ–‡æ¨¡å‹æ™®åŠï¼Œå„ç±» sequence/context parallelï¼ˆring attentionã€Ulysses ç­‰ï¼‰å°† attention å˜å¾—æ›´åŠ å¤æ‚ã€‚(ResearchGate)\nä»·å€¼ï¼šåœ¨è¿™äº› SP å˜ä½“ä¸­å¼•å…¥ selective recomputeï¼Œåˆ†æåœ¨ \\(s\\gg h\\) æƒ…å†µä¸‹é‡ç®—å¼€é”€çš„ç²¾ç¡®è¡Œä¸ºï¼Œå¯èƒ½ä¼šç»™é•¿ä¸Šä¸‹æ–‡æ¨¡å‹å¸¦æ¥æ–°çš„å¯è¡Œé…ç½®ã€‚\n\né’ˆå¯¹ MoE ä¸ç¨€ç–ç»“æ„çš„æ¿€æ´»å†…å­˜ä¼˜åŒ–\n\né—®é¢˜ï¼šMoE å°†è®¡ç®—ç¨€ç–åŒ–ï¼Œä½†æ¿€æ´»å†…å­˜ä»å¯èƒ½è¾ƒé«˜ï¼Œä¸”è·¯ç”±/é—¨æ§å¸¦æ¥æ–°çš„é€šä¿¡ä¸å­˜å‚¨æ¨¡å¼ã€‚\nä»·å€¼ï¼šæ‰©å±•æœ¬æ–‡çš„æ¿€æ´»æ¨¡å‹åˆ°â€œç¨€ç–æ¿€æ´»â€åœºæ™¯ï¼Œå®šä¹‰ per-expert çš„æ¿€æ´»ä¸é‡ç®—ç­–ç•¥ï¼Œæœ‰åŠ©äºåœ¨ä¿æŒç¨€ç–è®¡ç®—ä¼˜åŠ¿çš„åŒæ—¶è¿›ä¸€æ­¥å‹ç¼©æ˜¾å­˜ã€‚\n\npipeline é¦– stage å†…å­˜ç¢ç‰‡ä¸åŠ¨æ€è°ƒåº¦\n\né—®é¢˜ï¼šè®ºæ–‡æåˆ° pipeline é¦– stage çš„æ˜¾å­˜ä¸å‡ä¸ç¢ç‰‡åŒ–æ˜¯æœªæ¥æ–¹å‘ä¹‹ä¸€ï¼Œä½†å°šæ— ç³»ç»Ÿæ–¹æ¡ˆã€‚\nä»·å€¼ï¼šç»“åˆ allocator è¡Œä¸ºï¼ˆå¦‚ buddy / caching allocatorï¼‰ä¸ dynamic micro-batchingï¼Œæ¢ç´¢åœ¨ä¸æ”¹æ¨¡å‹ç»“æ„çš„å‰æä¸‹ï¼Œé€šè¿‡è°ƒåº¦ä¸åˆ†é…ç­–ç•¥è¿›ä¸€æ­¥é™ä½é¦– stage å³°å€¼ã€‚\n\n\n\nåã€çŸ¥è¯†å›¾è°±æ€ç»´é“¾\nä»â€œå¤§æ¨¡å‹ç³»ç»Ÿâ€çš„çŸ¥è¯†å›¾è°±æ¥çœ‹ï¼Œè¿™ç¯‡è®ºæ–‡æ¶‰åŠçš„è¿æ¥ç‚¹å¤§è‡´å¦‚ä¸‹ï¼š\n\nå¹¶è¡Œä¸è°ƒåº¦\n\næä¾›äº†ä¸€ä¸ªæŠŠ TP+SP+PP ä¸€èµ·æ”¾è¿›æ¿€æ´»å†…å­˜å…¬å¼çš„æ¡†æ¶ï¼Œè®©â€œå¦‚ä½•é€‰ TP/SP/PP ç»„åˆâ€ä»æ‹è„‘è¢‹å˜æˆå¯è®¡ç®—çš„é—®é¢˜ã€‚\næŠŠ 1F1B / interleaved pipeline çš„æ˜¾å­˜å³°å€¼ç‰¹æ€§ç”¨ç®€æ´å…¬å¼åˆ»ç”»å‡ºæ¥ï¼Œä¸ºä¹‹åçš„æµæ°´è°ƒåº¦è®ºæ–‡ï¼ˆå¦‚å¤šç§ 1F1B å˜ä½“ï¼‰æä¾›äº†å¯¹æ¯”åŸºçº¿ã€‚(ACL Anthology)\n\nå†…å­˜ç®¡ç†ä¸æ˜¾å­˜ä¼˜åŒ–\n\næŠŠæ¿€æ´»å†…å­˜æ‹†è§£æˆâ€œä¸»å¹²ï¼ˆ\\(34sbh\\)ï¼‰+ attention æ–¹é˜µï¼ˆ\\(5as^2b\\)ï¼‰â€ï¼Œè®©äººä¸€çœ¼çœ‹å‡ºä¼˜åŒ–ç©ºé—´åœ¨å“ªé‡Œã€‚\nselective recompute å±•ç¤ºäº†â€œé€šè¿‡ç²¾ç»†å®šä½ FLOPs ä¾¿å®œåŒºâ€æ¥æ¢æ˜¾å­˜ï¼Œæ˜¯ä¸€ç±»å€¼å¾—åœ¨å…¶ä»–ç»“æ„ä¸Šé‡å¤ä½¿ç”¨çš„æ¨¡å¼ã€‚\n\né€šä¿¡ä¸é›†ä½“æ“ä½œ\n\næ˜¾å¼åˆ©ç”¨â€œall-reduce = RS + AGâ€è¿™ä¸€äº‹å®ï¼Œé€šè¿‡ \\(g/\\bar g\\) æ”¹å†™é€šä¿¡å›¾ï¼Œå®ç°æ¿€æ´»åˆ‡åˆ†è€Œä¸å¢åŠ æ€»é€šä¿¡é‡ã€‚\nå¯¹æ¯”äº†ä¸åŒæ–¹æ¡ˆä¸‹ per-layer é€šä¿¡ bytesï¼Œä¸ºä¹‹åçš„é€šä¿¡ä¼˜åŒ–å·¥ä½œæä¾›äº†ä¸€ä¸ªå¯å‚è€ƒçš„ baselineã€‚\n\nkernel ä¸ç®—å­ä¼˜åŒ–\n\nå¼ºè°ƒåœ¨ LN / Dropout / embedding / output ç­‰ç®—å­ä¸­ä¹Ÿåš SPï¼Œè®©è¿™äº›â€œçœ‹ä¼¼ç®€å•â€çš„ç®—å­çœŸæ­£äº«å—åˆ°å¹¶è¡Œå¸¦æ¥çš„å†…å­˜ä¸é€Ÿåº¦æ”¶ç›Šã€‚\né¼“åŠ±æŠŠé€šä¿¡ç®—å­å’Œ GEMM èåˆï¼Œä»è€Œå‡å°‘ä¸­é—´ buffer ä¸ kernel launch overheadã€‚\n\næ¨¡å‹ç»“æ„ä¸æ¶æ„è®¾è®¡\n\nè™½ç„¶æ¨¡å‹ç»“æ„æœ¬èº«æœªä¿®æ”¹ï¼Œä½†æ¿€æ´»å†…å­˜åˆ†æå¯ä»¥ç›´æ¥ç”¨æ¥è¯„ä¼°â€œåŠ å®½/åŠ æ·±/åŠ å¤´æ•°/åŠ åºåˆ—é•¿åº¦â€å¯¹æ˜¾å­˜çš„å½±å“ï¼Œä¸ºè®¾è®¡æ–°æ¶æ„æä¾›é‡åŒ–ä¾æ®ã€‚\nå¯¹ GPT-3/MT-NLG çš„å…·ä½“å‚æ•°åšäº†ä»£å…¥ï¼Œä¸ä»…å‘Šè¯‰ä½ â€œå…¬å¼é•¿å•¥æ ·â€ï¼Œè¿˜å‘Šè¯‰ä½ â€œåœ¨çœŸå®é…ç½®ä¸‹æ•°å€¼æ˜¯å¤šå¤§â€ã€‚\n\næ•°æ®ã€é¢„å¤„ç†ä¸æ‰“åŒ…ç­–ç•¥\n\nä»ä¾§é¢è¯´æ˜äº†â€œèŠ‚çœæ¿€æ´»æ˜¾å­˜ä¹‹åå¯ä»¥åšä»€ä¹ˆâ€ï¼šå¯ä»¥æ¢æˆæ›´å¤§ micro-batchã€æ›´é•¿åºåˆ—æˆ–æ›´å¤š global batchï¼Œå¯¹ DataLoader ä¸æ•°æ®æ‰“åŒ…ç­–ç•¥æå‡ºäº†æ–°çš„éœ€æ±‚ã€‚\n\n\n10.1 ä¸ªäººæ”¶è·ä¸åæ€\nå¯¹æˆ‘ä¸ªäººæ¥è¯´ï¼Œè¿™ç¯‡è®ºæ–‡æœ€å¤§çš„å¯å‘åœ¨äºâ€”â€”å¾ˆå¤šçœ‹ä¼¼â€œç»éªŒä¸»ä¹‰â€çš„å¹¶è¡Œ/é‡ç®—æŠ€å·§ï¼Œå…¶å®å¯ä»¥è¢«ä¸€ä¸ªéå¸¸ç®€æ´çš„è§£ææ¨¡å‹ç»Ÿä¸€æè¿°ã€‚ä¸€æ—¦æŠŠæ¿€æ´»å†…å­˜æ‹†æˆ \\(34sbh\\) å’Œ \\(5as^2b\\) ä¸¤å—ï¼Œå¾ˆå¤šé€‰æ‹©å°±å˜å¾—æ˜¾è€Œæ˜“è§ï¼šTP+SP åº”è¯¥æ€ä¹ˆåˆ‡ã€attention ä¸­å“ªä¸€éƒ¨åˆ†å€¼å¾— checkpointã€pipeline stage æ€ä¹ˆåˆ†å±‚ç­‰ï¼Œéƒ½å¯ä»¥ä»å…¬å¼é‡Œç›´æ¥è¯»å‡ºæ¥ã€‚\nå¦ä¸€ä¸ªæ”¶è·æ˜¯å¯¹ â€œå±€éƒ¨é‡ç®—â€è¿™ä¸€æ¨¡å¼çš„å†è®¤è¯†ï¼šä»¥å‰æåˆ° gradient checkpointï¼Œå¤šæ•°äººåªæƒ³åˆ°â€œæŒ‰å±‚ checkpointâ€ï¼›æœ¬æ–‡å±•ç¤ºäº†â€œæŒ‰å±‚å†…å­ç®—å­ checkpointâ€å¯ä»¥æ›´ç²¾ç»†åœ°è°ƒèŠ‚æ˜¾å­˜/ç®—åŠ›çš„ trade-offï¼Œè€Œä¸”å®ç°æˆæœ¬å¹¶æ²¡æœ‰æƒ³è±¡ä¸­é‚£ä¹ˆé«˜â€”â€”åªè¦ä½ æ„¿æ„åœ¨ç®—å­å›¾ä¸Šå¤šç”»å‡ æ¡è¾¹ç•Œã€‚\nä»å®è·µè§’åº¦ï¼Œæˆ‘è®¤ä¸ºå€¼å¾—ç«‹åˆ»å°è¯•è¿ç§»åˆ°è‡ªå·±è®­ç»ƒæ ˆé‡Œçš„ç‚¹ä¸»è¦æœ‰ä¸¤ä¸ªï¼š\n\nç¬¬ä¸€æ˜¯ åœ¨ç°æœ‰ TP æ ˆä¸Šè¡¥é½ SPï¼Œè‡³å°‘è¦è®© LN/Dropout/embedding/output è¿™äº›æ¿€æ´»ä¹Ÿèƒ½æŒ‰åºåˆ— shardï¼›\nç¬¬äºŒæ˜¯åœ¨ attention å†…éƒ¨å®ç°ç±»ä¼¼çš„ selective recomputeï¼ŒæŠŠ \\(QK^\\top\\)ã€softmaxã€attention over V é‚£å—æŠ½æˆä¸€ä¸ª checkpoint å­å›¾ï¼Œå¹¶é…åˆé€šä¿¡/è®¡ç®— overlap åšäº›å¾®è°ƒã€‚\n\n\næ€»ä½“è¯„ä»·ï¼šè¿™ç¯‡å·¥ä½œåœ¨ä¸æ”¹å˜æ¨¡å‹ç»“æ„ã€ä¸è¿‡åº¦ä¾µå…¥è®­ç»ƒæ ˆçš„å‰æä¸‹ï¼Œç”¨ä¸€å¥—ç®€æ´çš„ç†è®ºå’Œä¸€ç»„æ‰å®çš„å¤§è§„æ¨¡å®éªŒï¼Œç»™å‡ºäº†ä¸€ä¸ªå‡ ä¹â€œé»˜è®¤åº”å½“å¯ç”¨â€çš„æ¿€æ´»å†…å­˜ä¼˜åŒ–æ–¹æ¡ˆã€‚å¯¹äºå·²ç»è¿è¡Œ 3D å¹¶è¡Œå¤§æ¨¡å‹è®­ç»ƒçš„å›¢é˜Ÿï¼Œå®ƒæ›´åå·¥ç¨‹å®è·µï¼›è€Œå¯¹äºæ­£åœ¨æ­å»ºè®¾å¤‡/å¹¶è¡Œæ ˆçš„äººï¼Œåˆ™æä¾›äº†ä¸€ä¸ªéå¸¸æ¸…æ™°çš„â€œå¹¶è¡Œ+é‡ç®—è”åˆè®¾è®¡â€å‚è€ƒèŒƒå¼ã€‚\n\n","categories":["è®ºæ–‡é˜…è¯»"],"tags":["paper"]},{"title":"Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism","url":"/2025/11/22/paper/megatron_lm/","content":"\n\nåŸæ–‡ï¼šMegatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism Â· arXiv\n\nä¸€ã€è®ºæ–‡é€Ÿè§ˆ\nMegatron-LMè®ºæ–‡æå‡ºäº†ä¸€ç§åœ¨ç°æœ‰æ·±åº¦å­¦ä¹ æ¡†æ¶ä¸‹è®­ç»ƒè¶…å¤§è§„æ¨¡Transformerè¯­è¨€æ¨¡å‹çš„å®ç”¨æ–¹æ³•ã€‚ä½œè€…é€šè¿‡å±‚å†…æ¨¡å‹å¹¶è¡Œï¼ˆIntra-layer Model Parallelismï¼‰å°†å•ä¸ªTransformerå±‚çš„è®¡ç®—æ‹†åˆ†åˆ°å¤šä¸ªGPUä¸Šæ‰§è¡Œï¼Œä»¥çªç ´å•GPUå†…å­˜é™åˆ¶ã€‚è¿™ä¸€æ–¹æ³•ä»…éœ€åœ¨æ ‡å‡†PyTorchå®ç°ä¸­æ’å…¥å°‘é‡é€šä¿¡æ“ä½œï¼Œæ— éœ€å®šåˆ¶ç¼–è¯‘å™¨æˆ–åº•å±‚åº“ä¿®æ”¹ï¼Œä¾¿å®ç°äº†å¯¹æ•°åäº¿å‚æ•°æ¨¡å‹çš„é«˜æ•ˆè®­ç»ƒã€‚è®ºæ–‡ä»¥GPT-2å’ŒBERTä¸¤ç±»æ¨¡å‹ä¸ºä¾‹ï¼ŒæˆåŠŸåœ¨512å¼ GPUä¸Šè®­ç»ƒäº†çº¦83äº¿å‚æ•°çš„GPT-2æ¨¡å‹å’Œ39äº¿å‚æ•°çš„BERTæ¨¡å‹ï¼Œè¾¾åˆ°äº†å½“æ—¶æœ€å…ˆè¿›çš„æ€§èƒ½å’Œæ•ˆæœã€‚\nåœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œå·¥ç¨‹å®è·µæ˜¯æ ¸å¿ƒï¼šé€šè¿‡å·§å¦™åˆ©ç”¨å¼ é‡å¹¶è¡ŒæŠ€æœ¯ï¼ŒMegatron-LMå……åˆ†å‘æŒ¥äº†GPUé›†ç¾¤ç®—åŠ›ã€‚åœ¨ä¸ç‰ºç‰²è®¡ç®—ç²¾åº¦å’Œæ¨¡å‹æ”¶æ•›çš„å‰æä¸‹ï¼Œä½œè€…å®ç°äº†æ¥è¿‘çº¿æ€§çš„åŠ é€Ÿæ¯”å’Œé«˜è¾¾15.1 PetaFLOPsçš„æŒç»­è®¡ç®—ååã€‚æ›´é‡è¦çš„æ˜¯ï¼Œè®ºæ–‡å±•ç¤ºäº†æ¨¡å‹è§„æ¨¡ä¸æ€§èƒ½çš„è‰¯æ€§å…³ç³»ï¼šéšç€å‚æ•°å¢å¤šï¼Œè¯­è¨€æ¨¡å‹çš„å›°æƒ‘åº¦ï¼ˆperplexityï¼‰æ˜¾è‘—ä¸‹é™ï¼Œä¸‹æ¸¸ä»»åŠ¡å‡†ç¡®ç‡ç¨³æ­¥æå‡ã€‚æ­¤å¤–ï¼Œä½œè€…è¿˜å‘ç°å¯¹äºBERTè¿™ç±»åŒå‘Transformeræ¨¡å‹ï¼Œéœ€è¦å¯¹Layer Normalizationå±‚çš„æ’å…¥ä½ç½®è¿›è¡Œè°ƒæ•´ï¼Œä»¥ç¡®ä¿å¤§æ¨¡å‹è®­ç»ƒè¿‡ç¨‹çš„ç¨³å®šå’Œç²¾åº¦æå‡ã€‚\näºŒã€è®ºæ–‡ç»“æ„\nè®ºæ–‡é¦–å…ˆä»‹ç»äº†ç ”ç©¶èƒŒæ™¯å’ŒæŒ‘æˆ˜ï¼ŒåŒ…æ‹¬å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒçš„è¶‹åŠ¿ä»¥åŠè®­ç»ƒæ­¤ç±»æ¨¡å‹é¢ä¸´çš„å†…å­˜ç“¶é¢ˆï¼ˆç¬¬2èŠ‚ï¼‰ã€‚æ¥ä¸‹æ¥ï¼Œåœ¨æ–¹æ³•éƒ¨åˆ†ï¼ˆç¬¬3èŠ‚ï¼‰ï¼Œä½œè€…è¯¦ç»†æè¿°äº†Transformeræ¶æ„ä¸­çš„æ¨¡å‹å¹¶è¡Œå®ç°æ–¹æ¡ˆï¼Œè§£é‡Šå¦‚ä½•åœ¨ä¸æ”¹å˜æ¨¡å‹åŸºæœ¬ç»“æ„çš„æƒ…å†µä¸‹ï¼Œå°†æ¯ä¸€å±‚çš„è®¡ç®—åˆ†æ‘Šåˆ°å¤šä¸ªè®¾å¤‡ï¼Œå¹¶å®šä¹‰äº†ç›¸åº”çš„é€šä¿¡åŸè¯­ï¼ˆå¦‚All-Reduceï¼‰çš„ä½¿ç”¨ç­–ç•¥ã€‚ç„¶åï¼Œè®ºæ–‡è¿›å…¥å®éªŒè®¾ç½®å’Œç»“æœåˆ†æï¼ˆç¬¬4~5èŠ‚ï¼‰ï¼šä½œè€…ç»™å‡ºäº†æ¨¡å‹ä¸è®­ç»ƒé…ç½®ã€è¯„ä¼°æŒ‡æ ‡ï¼Œå¹¶é€šè¿‡ä¸€ç³»åˆ—å®éªŒå±•ç¤ºäº†æ‰€ææ–¹æ³•çš„æ‰©å±•æ€§å’Œæœ‰æ•ˆæ€§ã€‚å…¶ä¸­ï¼Œç¬¬5èŠ‚åˆ†åˆ«æŠ¥å‘Šäº†é’ˆå¯¹GPT-2ï¼ˆå•å‘è¯­è¨€æ¨¡å‹ï¼‰å’ŒBERTï¼ˆåŒå‘è¯­è¨€æ¨¡å‹ï¼‰çš„é¢„è®­ç»ƒç»“æœï¼Œä»¥åŠåœ¨WikiText103ã€LAMBADAã€RACEç­‰åŸºå‡†ä¸Šçš„æ€§èƒ½å¯¹æ¯”ã€‚æœ€åï¼Œç¬¬6èŠ‚æ€»ç»“äº†ä¸»è¦ç»“è®ºå¹¶è®¨è®ºäº†æœªæ¥å·¥ä½œã€‚\n\næ ¸å¿ƒæ€æƒ³ï¼šé€šè¿‡åœ¨Transformerå±‚å†…å¼•å…¥ç®€æ´é«˜æ•ˆçš„æ¨¡å‹å¹¶è¡Œå’Œé€šä¿¡æœºåˆ¶ï¼ŒMegatron-LMå®ç°äº†è¶…å¤§æ¨¡å‹çš„åˆ†å¸ƒå¼è®­ç»ƒï¼Œåœ¨ç°æœ‰è½¯ç¡¬ä»¶æ ˆä¸Šè¾¾æˆäº†å‰æ‰€æœªæœ‰çš„æ¨¡å‹è§„æ¨¡ä¸æ€§èƒ½æå‡ã€‚\n\nä¸‰ã€æ–¹æ³•ä¸ç³»ç»Ÿè®¾è®¡\næœ¬æ–‡æ–¹æ³•çš„æ ¸å¿ƒæ˜¯åœ¨ä¸æ”¹å˜æ¨¡å‹æ•´ä½“ç»“æ„çš„å‰æä¸‹ï¼Œå°†å•ä¸ªTransformerå±‚çš„è®¡ç®—åˆ’åˆ†åˆ°å¤šä¸ªGPUä¸Šå¹¶è¡Œæ‰§è¡Œã€‚å›´ç»•è¿™ä¸€ç›®æ ‡ï¼Œä½œè€…è§£å†³äº†è‹¥å¹²å­é—®é¢˜ï¼š\n\nå¦‚ä½•å¯¹Transformerçš„å…³é”®ç»„æˆï¼ˆè‡ªæ³¨æ„åŠ›å’Œå‰é¦ˆç½‘ç»œï¼‰è¿›è¡Œåˆ’åˆ†ï¼Œä»¥æœ€å°åŒ–è·¨GPUé€šä¿¡ï¼Ÿ\n\nå¦‚ä½•åœ¨PyTorchä¸­ç”¨å°‘é‡åŸç”Ÿæ“ä½œå®ç°ä¸Šè¿°å¹¶è¡Œè®¡ç®—ï¼Œå¹¶ç¡®ä¿è‡ªåŠ¨æ±‚å¯¼æ­£ç¡®å·¥ä½œï¼Ÿ\n\nå¦‚ä½•ä¸æ•°æ®å¹¶è¡Œã€æµæ°´å¹¶è¡Œç­‰å…¶ä»–å¹¶è¡ŒèŒƒå¼å…¼å®¹ï¼Œå……åˆ†åˆ©ç”¨å¤§å‹é›†ç¾¤çš„è®¡ç®—èƒ½åŠ›ï¼Ÿ\n\nå¦‚ä½•åœ¨ä¿æŒæ¨¡å‹ç²¾åº¦å’Œç¨³å®šæ€§çš„åŒæ—¶ï¼Œå®ç°è®¡ç®—ä¸é€šä¿¡çš„é«˜æ•ˆé‡å ï¼Ÿ\n\n3.1 æ ¸å¿ƒæ¨¡å—ä¸€è§ˆ\n\nå¼ é‡å¹¶è¡ŒTransformerå±‚ï¼šå°†Transformerå±‚å†…éƒ¨çš„å¤§çŸ©é˜µä¹˜æ³•æ‹†åˆ†åˆ°å¤šGPUæ‰§è¡Œã€‚ä¾‹å¦‚ï¼Œå°†è‡ªæ³¨æ„åŠ›å’Œå‰é¦ˆå±‚ä¸­çš„æƒé‡çŸ©é˜µæŒ‰åˆ—æˆ–è¡Œåˆ†å—ï¼Œæ¯ä¸ªGPUè´Ÿè´£ä¸€éƒ¨åˆ†è®¡ç®—ã€‚æ­¤æ¨¡å—çš„ä½œç”¨æ˜¯åœ¨ä¿è¯è®¡ç®—æ­£ç¡®æ€§çš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½å•GPUæ˜¾å­˜å ç”¨ï¼Œå­é—®é¢˜æ¶‰åŠå¦‚ä½•åˆ’åˆ†æƒé‡åŠé‡ç»„è¾“å‡ºã€‚\né€šä¿¡æ“ä½œæ¨¡å—ï¼šæä¾›å¿…è¦çš„GPUé—´é€šä¿¡åŸè¯­ï¼Œå¦‚All-Reduceï¼ˆå…¨å½’çº¦æ±‚å’Œï¼‰å’ŒAll-Gatherï¼ˆå…¨æ±‡é›†ï¼‰ã€‚è¿™äº›é€šä¿¡åœ¨å‰å‘æˆ–åå‘è¿‡ç¨‹ä¸­æ’å…¥ï¼Œç”¨äºæ±‡æ€»è·¨GPUçš„éƒ¨åˆ†ç»“æœæˆ–æ¢¯åº¦ã€‚æ¨¡å—ä½œç”¨æ˜¯åœ¨å¹¶è¡Œè®¡ç®—çš„å„å­éƒ¨åˆ†ä¹‹é—´ä¼ é€’ä¿¡æ¯ï¼Œå¯¹åº”çš„å­é—®é¢˜æ˜¯å¦‚ä½•å°†é€šä¿¡å¼€é”€é™åˆ°æœ€ä½å¹¶é¿å…é˜»å¡è®­ç»ƒæµç¨‹ã€‚\nå¹¶è¡Œè°ƒåº¦æ§åˆ¶ï¼šè´Ÿè´£åè°ƒå¤šGPUçš„æ‰§è¡Œé¡ºåºå’ŒåŒæ­¥ï¼ŒåŒ…æ‹¬åˆ’åˆ†æ•°æ®å¹¶è¡Œç»„ä¸æ¨¡å‹å¹¶è¡Œç»„ã€åœ¨ä¸åŒå¹¶è¡Œç»´åº¦é—´åˆ†é…è®¡ç®—ä»»åŠ¡ç­‰ã€‚å…¶ä½œç”¨æ˜¯ä¿éšœå„GPUæŒ‰è®¡åˆ’ååŒå·¥ä½œï¼Œå­é—®é¢˜åŒ…æ‹¬å¦‚ä½•è®¾è®¡åŒæ­¥ç‚¹ä»¥åŠé¿å…æ­»é”ã€‚\næ··åˆç²¾åº¦ä¸å†…å­˜ä¼˜åŒ–ï¼šåœ¨ä¿è¯è®­ç»ƒç¨³å®šçš„æƒ…å†µä¸‹ä½¿ç”¨åŠç²¾åº¦æµ®ç‚¹ï¼ˆFP16/BF16ï¼‰å’Œæ¢¯åº¦æ£€æŸ¥ç‚¹ç­‰æŠ€æœ¯æ¥è¿›ä¸€æ­¥é™ä½æ˜¾å­˜å ç”¨ã€æé«˜è¿ç®—æ•ˆç‡ã€‚è¯¥æ¨¡å—è¾…åŠ©å¤§è§„æ¨¡å¹¶è¡Œè®­ç»ƒé¡ºåˆ©è¿›è¡Œï¼Œæ¶‰åŠçš„å­é—®é¢˜æ˜¯å¦‚ä½•åœ¨å‡å°å†…å­˜çš„åŒæ—¶ä¸å¼•å…¥æ•°å€¼ä¸ç¨³å®šã€‚\n\n3.2 æ•°æ®æµä¸æ§åˆ¶æµ\næ•´ä¸ªæ¨¡å‹å¹¶è¡Œè®­ç»ƒæµç¨‹å¯ä»¥åˆ†ä¸ºä»¥ä¸‹ä¸»è¦æ­¥éª¤ï¼š\n\næ•°æ®åˆ†å‘ï¼šè®­ç»ƒå¼€å§‹æ—¶ï¼Œæ•°æ®åŠ è½½å™¨å°†æ¯ä¸ªmini-batchåˆ’åˆ†ç»™å„ä¸ªæ•°æ®å¹¶è¡Œç»„ï¼›åœ¨åŒä¸€æ•°æ®å¹¶è¡Œç»„å†…ï¼Œå±äºæ¨¡å‹å¹¶è¡Œç»„çš„å¤šä¸ªGPUæ¥æ”¶ç›¸åŒçš„è¾“å…¥å­æ‰¹ã€‚è¿™ä¿è¯äº†å¹¶è¡ŒGPUåœ¨å¤„ç†åŒä¸€ç»„æ ·æœ¬æ—¶æ‰€éœ€çš„ä¸€è‡´è¾“å…¥ã€‚\nå‰å‘ä¼ æ’­ï¼ˆæ¨¡å‹å¹¶è¡Œéƒ¨åˆ†ï¼‰ï¼šå¯¹äºTransformerçš„æ¯ä¸€å±‚ï¼Œæ‰§è¡Œä»¥ä¸‹å­æ­¥éª¤ï¼š\n\næ¯ä¸ªGPUæŒæœ‰è¯¥å±‚æƒé‡çš„ä¸€éƒ¨åˆ†ï¼ˆä¾‹å¦‚ï¼Œå°†æƒé‡çŸ©é˜µæ²¿åˆ—åˆ’åˆ†ä¸º\\(P\\)å—ï¼Œåˆ†é…ç»™\\(P\\)ä¸ªGPUï¼‰ã€‚å„GPUåŸºäºå®Œæ•´çš„è¾“å…¥æ¿€æ´»\\(X\\)ï¼Œå„è‡ªè®¡ç®—éƒ¨åˆ†çº¿æ€§å˜æ¢ï¼š\\(Y_i = X \\times A_i\\)ï¼ˆå…¶ä¸­\\(A_i\\)è¡¨ç¤ºGPU \\(i\\)ä¸Šçš„æƒé‡å­çŸ©é˜µï¼‰ã€‚å¯¹\\(Y_i\\)åº”ç”¨éçº¿æ€§æ¿€æ´»ï¼ˆå¦‚GeLUï¼‰å¾—åˆ°éƒ¨åˆ†è¾“å‡ºã€‚\nå°†ä¸Šè¿°éƒ¨åˆ†è¾“å‡º\\(Y_i\\)åœ¨GPUé—´è¿›è¡Œé€šä¿¡ç»„åˆã€‚å…·ä½“è€Œè¨€ï¼Œå¯¹å‰é¦ˆå±‚ç¬¬äºŒéƒ¨åˆ†çš„è®¡ç®—ï¼Œå„GPUè®¡ç®—è‡ªå·±çš„éƒ¨åˆ†è¾“å‡º\\(Z_i = Y_i \\times B_i\\)ï¼ˆè¿™é‡Œ\\(B_i\\)æ˜¯è¯¥GPUæŒæœ‰çš„ç¬¬äºŒä¸ªæƒé‡å­çŸ©é˜µï¼‰ã€‚éšåæ‰§è¡Œä¸€æ¬¡All-Reduceé€šä¿¡ï¼šå„GPUå°†\\(Z_i\\)ç›¸åŠ å¹¶åŒæ­¥å¾—åˆ°å®Œæ•´è¾“å‡º\\(Z = \\sum_{i=1}^{P} Z_i\\)ï¼Œå†è¿›å…¥åç»­å±‚ã€‚å¯¹äºè‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œé‡‡ç”¨ç±»ä¼¼ç­–ç•¥ï¼šå„GPUåˆ†åˆ«è®¡ç®—ä¸€éƒ¨åˆ†æ³¨æ„åŠ›å¤´çš„è¾“å‡ºï¼Œæœ€åé€šè¿‡é€šä¿¡æ•´åˆå¾—åˆ°å®Œæ•´çš„å¤šå¤´æ³¨æ„åŠ›ç»“æœã€‚\nï¼ˆå¯é€‰ï¼‰æ‰§è¡Œå…¶ä»–å¿…è¦æ“ä½œï¼ˆå¦‚Dropoutã€æ®‹å·®è¿æ¥å’ŒLayerNormï¼‰ï¼Œè¿™äº›æ“ä½œå¤§å¤šä¸éœ€è¦è·¨GPUé€šä¿¡æˆ–è€…é€šä¿¡å¼€é”€å¾ˆå°ã€‚è‡³æ­¤å®Œæˆå½“å‰å±‚çš„å‰å‘è®¡ç®—ï¼Œå†å°†ç»“æœä¼ é€’ç»™ä¸‹ä¸€å±‚é‡å¤ä¸Šè¿°è¿‡ç¨‹ã€‚\n\næŸå¤±è®¡ç®—ï¼šæ¨¡å‹æœ€åä¸€å±‚è¾“å‡ºç»è¿‡å¿…è¦çš„æ‹¼æ¥æˆ–èšåˆåï¼Œç”¨äºè®¡ç®—è¯­è¨€æ¨¡å‹çš„è®­ç»ƒç›®æ ‡ï¼ˆä¾‹å¦‚ï¼ŒGPT-2çš„è‡ªå›å½’ä¸‹ä¸€ä¸ªè¯é¢„æµ‹çš„äº¤å‰ç†µæŸå¤±æˆ–BERTçš„æ©ç è¯­è¨€æ¨¡å‹æŸå¤±ï¼‰ã€‚æŸå¤±æ ‡é‡åœ¨æ•°æ®å¹¶è¡Œç»´åº¦ä¸Šè¿›ä¸€æ­¥åšä¸€æ¬¡All-Reduceï¼Œä»¥ç¡®ä¿å„GPUä½¿ç”¨å…¨å±€ä¸€è‡´çš„æŸå¤±å€¼è¿›è¡Œæ¢¯åº¦è®¡ç®—ã€‚\nåå‘ä¼ æ’­ï¼šæŒ‰ç…§å±‚é¡ºåºåå‘ä¼ æ’­æ¢¯åº¦ã€‚åœ¨æ¯ä¸ªå¹¶è¡Œå±‚åä¼ æ—¶æ‰§è¡Œä¸å‰å‘å¯¹å¶çš„é€šä¿¡ï¼š\n\nå¯¹äºå‰å‘ä¸­é€šè¿‡All-Reduceèšåˆçš„è¾“å‡ºï¼Œåœ¨åå‘ä¸­å„GPUä¼šæ”¶åˆ°ç›¸åŒçš„æ¢¯åº¦\\(\\partial Z\\)ï¼Œå› æ­¤ä¸éœ€è¦å†é€šä¿¡ï¼ˆç›¸å½“äºå‰å‘é€šä¿¡çš„â€œä¼´éšâ€æ“ä½œåœ¨åå‘æ˜¯æ’ç­‰ä¼ é€’ï¼‰ã€‚\nå¯¹äºå‰å‘ä¸­æœªé€šä¿¡è€Œå¤åˆ¶å­˜åœ¨çš„è¾“å…¥ï¼ˆä¾‹å¦‚æ¯ä¸ªGPUéƒ½ç”¨åˆ°äº†å®Œæ•´çš„\\(X\\)ï¼‰ï¼Œåå‘æ¢¯åº¦éœ€è¦æ±‡æ€»ï¼šå„GPUæ ¹æ®æœ¬åœ°è®¡ç®—å¾—åˆ°\\(\\partial X_i\\)åï¼Œæ‰§è¡Œä¸€æ¬¡All-Reduceå°†æ¢¯åº¦æ±‚å’Œ\\(\\partial X = \\sum_{i=1}^{P} \\partial X_i\\)ï¼Œå†ä¼ å›ä¸Šä¸€å±‚ã€‚è¿™å¯¹åº”äºå‰å‘å¤åˆ¶æ“ä½œçš„åå‘é€šä¿¡ã€‚\nå„GPUè®¡ç®—è‡ªå·±æŒæœ‰æƒé‡çš„æ¢¯åº¦\\(\\partial A_i, \\partial B_i\\)ï¼Œè¿™äº›æ¢¯åº¦ä¼šåœ¨æ¨¡å‹å¹¶è¡Œç»„å†…ä¿æŒåˆ†å¸ƒçŠ¶æ€ï¼ˆæ¯ä¸ªGPUåªæ›´æ–°è‡ªå·±é‚£éƒ¨åˆ†æƒé‡ï¼‰ã€‚åœ¨æ•°æ®å¹¶è¡Œç»„èŒƒå›´ï¼Œåˆ™éœ€å¯¹æ¢¯åº¦åšAll-Reduceä»¥èšåˆæ¥è‡ªä¸åŒæ•°æ®åˆ†ç‰‡çš„æ›´æ–°ã€‚\n\nå‚æ•°æ›´æ–°ï¼šåœ¨ä¼˜åŒ–å™¨é˜¶æ®µï¼Œå„GPUä½¿ç”¨èšåˆåçš„å…¨å±€æ¢¯åº¦æ›´æ–°å¯¹åº”çš„æƒé‡å­çŸ©é˜µå‚æ•°ã€‚ç”±äºä½¿ç”¨äº†å¦‚Adamä¹‹ç±»çš„ä¼˜åŒ–å™¨ï¼Œæ¯ä¸ªGPUä¹Ÿç»´æŠ¤å¹¶æ›´æ–°ä¸å…¶å‚æ•°å¯¹åº”çš„ä¼˜åŒ–å™¨çŠ¶æ€ï¼ˆå¦‚ä¸€é˜¶ã€äºŒé˜¶åŠ¨é‡ï¼‰ï¼Œä¿è¯å„è‡ªå‚æ•°çš„æ›´æ–°åŒæ­¥ä¸€è‡´ã€‚\nè¿­ä»£ä¸åŒæ­¥ï¼šä¸€ä¸ªè®­ç»ƒiterationå®Œæˆåï¼Œè¿›å…¥ä¸‹ä¸€æ‰¹æ•°æ®é‡å¤ä¸Šè¿°è¿‡ç¨‹ã€‚è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå„GPUé€šè¿‡åŒæ­¥é€šè®¯ä¿è¯åœ¨å…³é”®ç‚¹ï¼ˆå¦‚All-Reduceï¼‰ä¸Šä¸€è‡´ï¼Œé¿å…å‡ºç°è®¡ç®—ç«æ€ã€‚åŒæ—¶åˆ©ç”¨æµæ°´çº¿å¹¶è¡Œï¼ˆå¦‚æœ‰ï¼‰å¯ä»¥åœ¨ç­‰å¾…é€šä¿¡æ—¶å¼€å§‹ä¸‹ä¸€å±‚çš„è®¡ç®—ï¼Œä»¥æé«˜è®¡ç®—é€šä¿¡é‡å åº¦ã€‚\n\né€šè¿‡ä¸Šè¿°æ•°æ®æµä¸æ§åˆ¶æµè®¾è®¡ï¼ŒMegatron-LMå®ç°äº†åœ¨å¤šGPUé—´é«˜å¹¶è¡Œåº¦ä¸”åè°ƒä¸€è‡´çš„è®­ç»ƒè¿‡ç¨‹ã€‚åœ¨å…¸å‹å®ç°ä¸­ï¼Œæ¯å¼ GPUè¿›ç¨‹ä¸¥æ ¼æŒ‰ç…§æ—¢å®šé¡ºåºæ‰§è¡Œï¼Œæ—¢å‘æŒ¥GPUå¹¶è¡Œç®—åŠ›åˆå°†é€šä¿¡å¼€é”€é™è‡³å¿…è¦çš„æœ€å°ã€‚\n3.3 å…³é”®å‡è®¾ä¸é€‚ç”¨èŒƒå›´\nè®­ç»ƒæ¡†æ¶åœ¨è®¾è®¡æ—¶åšå‡ºäº†ä¸€äº›é»˜è®¤å‡è®¾ï¼Œè¿™äº›å‡è®¾ç•Œå®šäº†æ–¹æ³•é€‚ç”¨çš„èŒƒå›´ï¼Œä¹ŸæŒ‡æ˜åœ¨ä½•ç§æƒ…å†µä¸‹æ•ˆæœå¯èƒ½ä¸ä½³ï¼š\n\né«˜å¸¦å®½ä½å»¶è¿Ÿçš„é€šä¿¡ç½‘ç»œï¼šå‡è®¾GPUä¹‹é—´æ‹¥æœ‰é«˜é€Ÿäº’è”ï¼ˆå¦‚NVLinkæˆ–InfiniBandï¼‰ï¼Œä»¥æ”¯æ’‘é¢‘ç¹çš„All-Reduceæ“ä½œã€‚å¦‚æœé€šä¿¡ç½‘ç»œè¾ƒæ…¢æˆ–è€…èŠ‚ç‚¹é—´å»¶è¿Ÿè¿‡é«˜ï¼Œæ¨¡å‹å¹¶è¡Œçš„åŒæ­¥å¼€é”€å°†æ˜¾è‘—å¢é•¿ï¼Œæ•´ä½“åŠ é€Ÿæ¯”ä¼šé™ä½ç”šè‡³å¤±å»ä¼˜åŠ¿ã€‚\næ¨¡å‹ç»“æ„æ˜“äºåˆ†å—ï¼šæ–¹æ³•å‡è®¾Transformerå±‚ç­‰ç»“æ„å¯ä»¥æŒ‰ç»´åº¦è§„åˆ™åˆ’åˆ†ï¼ˆä¾‹å¦‚å°†çŸ©é˜µå‡åŒ€åˆ‡åˆ†ï¼‰ã€‚å¦‚æœæ¨¡å‹ä¸­å­˜åœ¨éš¾ä»¥åˆ‡åˆ†çš„ç®—å­æˆ–å¼ºè€¦åˆçš„è·¨é€šé“è¿ç®—ï¼ˆå¦‚æŸäº›è‡ªå®šä¹‰å±‚æˆ–åŠ¨æ€è®¡ç®—å›¾ï¼‰ï¼Œæ¨¡å‹å¹¶è¡Œéš¾ä»¥ç›´æ¥åº”ç”¨ï¼Œéœ€ä¿®æ”¹æ¨¡å‹ç»“æ„æˆ–æ”¾å¼ƒå¹¶è¡Œï¼Œå¦åˆ™ä¼šå¯¼è‡´ä¸æ­£ç¡®æˆ–æ•ˆç‡ä½ä¸‹ã€‚\nè¶³å¤Ÿå¤§çš„batchå’Œè®¡ç®—è´Ÿè½½ï¼šä¸ºæ‘Šè–„é€šä¿¡æˆæœ¬ï¼Œé»˜è®¤è®­ç»ƒä½¿ç”¨è¾ƒå¤§çš„mini-batchå’Œé•¿åºåˆ—ã€‚è‹¥åœºæ™¯ä¸­batchå°ºå¯¸å—é™æˆ–æ¨¡å‹è§„æ¨¡ä¸å¤Ÿå¤§ï¼Œé€šä¿¡å¼€é”€ç›¸å¯¹è®¡ç®—å¯èƒ½å æ¯”è¿‡é«˜ï¼Œä½¿å¹¶è¡Œæ”¶æ•ˆç”šå¾®ã€‚è¿™ç§æƒ…å†µä¸‹ï¼Œç®€å•çš„æ•°æ®å¹¶è¡Œå¯èƒ½æ›´é«˜æ•ˆã€‚\nGPUèµ„æºè§„æ¨¡åŒ¹é…æ¨¡å‹å¤§å°ï¼šå‡å®šæœ‰å……è¶³çš„GPUæ¥åˆ†æ‹…æ¨¡å‹ï¼ˆä¾‹å¦‚83äº¿å‚æ•°æ¨¡å‹éœ€è¦8è·¯æ¨¡å‹å¹¶è¡Œä»¥ä¸Šï¼‰ã€‚å¦‚æœGPUæ•°é‡ä¸è¶³ä»¥åˆ‡åˆ†æ¨¡å‹è‡³å„è‡ªå†…å­˜å®¹é‡å¯å®¹çº³ï¼Œä»ç„¶ä¼šå‡ºç°å†…å­˜ä¸è¶³çš„é—®é¢˜ã€‚æ­¤å¤–ï¼Œæ–¹æ³•æš‚æœªè€ƒè™‘å¼‚æ„å†…å­˜ï¼ˆå¦‚CPUå†…å­˜ã€NVMeï¼‰çš„è°ƒåº¦åˆ©ç”¨ã€‚\nä¸€è‡´çš„è®¡ç®—ç¯å¢ƒï¼šè¦æ±‚å‚ä¸è®­ç»ƒçš„æ‰€æœ‰GPUç®—åŠ›å‡è¡¡ã€ç¯å¢ƒä¸€è‡´ã€‚è‹¥éƒ¨åˆ†è®¾å¤‡æ€§èƒ½ä¸ä¸€æˆ–å‡ºç°ä¸­æ–­ï¼ŒåŒæ­¥è®­ç»ƒä¼šæ‹–æ…¢è‡³æœ€æ…¢èŠ‚ç‚¹ã€‚è¿™æ„å‘³ç€åœ¨ä¸å…·å¤‡æ•…éšœå®¹é”™æœºåˆ¶æ—¶ï¼Œé›†ç¾¤ä¸­ä»»ä¸€èŠ‚ç‚¹çš„å¤±è´¥éƒ½ä¼šä¸­æ–­æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ã€‚\n\nä¸Šè¿°å‡è®¾ç¡®ä¿äº†Megatron-LMæ–¹æ³•åœ¨å¤§å‹GPUé›†ç¾¤ã€æ ‡å‡†Transformeræ¨¡å‹åœºæ™¯ä¸‹è¡¨ç°è‰¯å¥½ã€‚å½“è¿™äº›æ¡ä»¶ä¸æ»¡è¶³æ—¶ï¼Œéœ€å¯¹è®­ç»ƒé…ç½®è¿›è¡Œè°ƒæ•´ï¼ˆä¾‹å¦‚å‡å°‘å¹¶è¡Œåº¦ã€é‡‡ç”¨æ¿€æ´»é‡è®¡ç®—æˆ–ZeROä¼˜åŒ–ç­‰ï¼‰æ¥å¼¥è¡¥æˆ–é€‚é…ï¼Œå¦åˆ™è®­ç»ƒæ•ˆç‡å’Œæ•ˆæœå¯èƒ½å—å½±å“ã€‚\n3.4 æ•°å­¦å…¬å¼ä¸ç®—æ³•è§£è¯»\nç”±äºæœ¬æ–‡åé‡ç³»ç»Ÿå®ç°ï¼Œè®ºæ–‡ä¸­å¹¶æœªå¤§é‡ä½¿ç”¨å¤æ‚å…¬å¼æ¨å¯¼ï¼Œä½†å…¶ä¸­å…³é”®è¿‡ç¨‹å¯ç”¨ç®€æ˜çš„æ•°å­¦è¡¨ç¤ºæè¿°å…¶æ­£ç¡®æ€§å’Œé«˜æ•ˆæ€§ã€‚ä¾‹å¦‚ï¼Œå¯¹äºTransformerå‰é¦ˆå±‚ï¼ˆä¸¤ä¸ªçº¿æ€§å±‚çš„ç»„åˆï¼‰åœ¨ä¸¤è·¯æ¨¡å‹å¹¶è¡Œ(\\(P=2\\))ä¸‹çš„åˆ’åˆ†ï¼Œå¯ä»¥è¡¨ç¤ºå¦‚ä¸‹ï¼š\n\nåˆ’åˆ†è®¡ç®—ï¼šè®¾è¾“å…¥å¼ é‡ä¸º\\(X \\in \\mathbb{R}^{B\\times H}\\)ï¼ˆæ‰¹å¤§å°\\(B\\)ï¼Œéšå±‚ç»´åº¦\\(H\\)ï¼‰ï¼Œç¬¬ä¸€å±‚æƒé‡\\(A \\in \\mathbb{R}^{H\\times I}\\)ï¼Œç¬¬äºŒå±‚æƒé‡\\(B \\in \\mathbb{R}^{I\\times H}\\)ï¼Œå…¶ä¸­\\(I\\)ä¸ºå‰é¦ˆå±‚éšç»´åº¦ã€‚å°†\\(A\\)æŒ‰åˆ—å‡åˆ†ä¸ºä¸¤éƒ¨åˆ†\\([A_1,\\ A_2]\\)ï¼Œå°†\\(B\\)æŒ‰è¡Œå‡åˆ†ä¸ºä¸¤éƒ¨åˆ†\\(\\begin{pmatrix}B_1;\\\\ B_2\\end{pmatrix}\\)ï¼ˆè¿™æ ·\\(A_1, A_2 \\in \\mathbb{R}^{H\\times (I/2)}\\)ï¼Œ \\(B_1, B_2 \\in \\mathbb{R}^{(I/2)\\times H}\\)ï¼‰ã€‚\nå±€éƒ¨å‰å‘ï¼šGPUâ‚å’ŒGPUâ‚‚åˆ†åˆ«è®¡ç®—ï¼š\\(Y_1 = \\mathrm{GeLU}(X A_1)\\)ï¼Œ\\(Y_2 = \\mathrm{GeLU}(X A_2)\\)ã€‚ç”±äºå¯¹éçº¿æ€§\\(\\mathrm{GeLU}(Â·)\\)çš„åˆ’åˆ†è¾“å‡ºäº’ä¸ä¾èµ–ï¼Œè¿™ä¸€æ­¥ä¸éœ€è¦é€šä¿¡ã€‚\nå±€éƒ¨åˆå¹¶ï¼šæ¥ç€ï¼Œå„GPUç»§ç»­è®¡ç®—ç¬¬äºŒå±‚å±€éƒ¨è¾“å‡ºï¼š\\(Z_1 = Y_1 B_1\\), \\(Z_2 = Y_2 B_2\\)ã€‚æ­¤æ—¶æ¯ä¸ª\\(Z_i\\)éƒ½æ˜¯æœ€ç»ˆè¾“å‡º\\(Z\\)çš„ä¸€éƒ¨åˆ†è´¡çŒ®ã€‚å®Œæ•´è¾“å‡ºå¯è¡¨ç¤ºä¸º\\(Z = Z_1 + Z_2 = X (A_1 B_1 + A_2 B_2)\\)ã€‚ä¸ºäº†å¾—åˆ°\\(Z\\)ï¼Œç³»ç»Ÿæ‰§è¡Œä¸€æ¬¡All-Reduceå°†\\(Z_1, Z_2\\)åœ¨ä¸¤GPUé—´æ±‚å’ŒåŒæ­¥ï¼Œä½¿æ¯ä¸ªGPUéƒ½è·å¾—å®Œæ•´çš„\\(Z\\)ç”¨äºåç»­è®¡ç®—ã€‚\næ¢¯åº¦å›ä¼ ï¼šåœ¨åå‘ä¼ æ’­ä¸­ï¼Œè®¾æœ€ç»ˆè¾“å‡ºçš„æ¢¯åº¦ä¸º\\(\\partial Z\\)ï¼ˆå„GPUåœ¨All-Reduceåæ‹¥æœ‰ç›¸åŒçš„\\(\\partial Z\\)ï¼‰ã€‚åˆ™æ¯ä¸ªGPUå¯ä»¥å±€éƒ¨è®¡ç®—è‡ªå·±çš„æ¢¯åº¦åˆ†é‡ï¼š\\(\\partial Y_1 = \\partial Z B_1^T\\), \\(\\partial Y_2 = \\partial Z B_2^T\\)ï¼Œä»¥åŠ\\(\\partial X_1 = \\partial Y_1 A_1^T\\), \\(\\partial X_2 = \\partial Y_2 A_2^T\\)ï¼Œè¿˜æœ‰å±€éƒ¨æƒé‡æ¢¯åº¦\\(\\partial B_1 = Y_1^T \\partial Z\\), \\(\\partial B_2 = Y_2^T \\partial Z\\)ï¼Œ\\(\\partial A_1 = X^T (\\partial Y_1)\\), \\(\\partial A_2 = X^T (\\partial Y_2)\\)ã€‚\n\nå¯¹äº\\(\\partial Z\\)ï¼Œå‰å‘å·²é€šè¿‡All-Reduceå¾—åˆ°å®Œæ•´\\(Z\\)ï¼Œåå‘ä¸éœ€é€šä¿¡ï¼Œå„GPUç›´æ¥ä½¿ç”¨\\(\\partial Z\\)è®¡ç®—å³å¯ï¼ˆå³æ¢¯åº¦åœ¨è¿™ä¸€å±‚çš„å‰å‘é€šä¿¡å¯¹åº”åå‘æ’ç­‰ï¼‰ã€‚\nå¯¹äº\\(\\partial X\\)ï¼Œç”±äºå‰å‘æ—¶\\(X\\)çš„è®¡ç®—è¢«å„GPUå¤ç”¨ï¼Œåå‘éœ€å°†å„GPUç®—å¾—çš„\\(\\partial X_i\\)æ±‚å’Œã€‚é€šè¿‡ä¸€æ¬¡All-Reduceï¼Œå¾—åˆ°\\(\\partial X = \\partial X_1 + \\partial X_2\\)å¹¶å°†ç»“æœå¹¿æ’­è‡³ä¸¤GPUï¼ˆè¿™å¯¹åº”å‰å‘å¤åˆ¶çš„åå‘é€šä¿¡æ­¥éª¤ï¼‰ã€‚\næƒé‡æ¢¯åº¦\\(\\partial A_i, \\partial B_i\\)å¤©ç„¶æ˜¯åˆ†å¸ƒå¼çš„ï¼Œå„GPUå„è‡ªè´Ÿè´£è‡ªå·±åˆ†å—çš„æ›´æ–°ï¼›ä¸åŒæ•°æ®å¹¶è¡Œå®ä¾‹çš„æƒé‡æ¢¯åº¦ç¨åè¿˜éœ€è·¨èŠ‚ç‚¹æ±‚å’Œå¹³å‡ï¼Œä½†åœ¨æ¨¡å‹å¹¶è¡Œç»„å†…éƒ¨ä¸éœ€è¦é¢å¤–åŒæ­¥ã€‚\n\n\nä¸Šè¿°è¿‡ç¨‹ä½“ç°äº†ä½œè€…å¼•å…¥çš„ä¸¤ä¸ªå…³é”®é€šä¿¡ç®—å­\\(f\\)å’Œ\\(g\\)çš„ä½œç”¨:\n\nè¿ç®—\\(g\\)åœ¨å‰å‘æ˜¯All-Reduceï¼ˆå¦‚å°†\\(Z_i\\)æ±‚å’Œå¾—åˆ°\\(Z\\)ï¼‰ï¼Œåœ¨åå‘åˆ™æ˜¯æ’ç­‰ä¼ é€’æ¢¯åº¦ï¼›\nè¿ç®—\\(f\\)åœ¨å‰å‘æ˜¯æ’ç­‰ï¼ˆå¦‚å°†\\(X\\)å¤åˆ¶ä½¿ç”¨ï¼‰ï¼Œåœ¨åå‘åˆ™æ˜¯All-Reduceï¼ˆæ±‡æ€»\\(\\partial X\\)ï¼‰ã€‚\n\né€šè¿‡è¿™å¯¹å…±è½­ç®—å­\\(f/g\\)ï¼Œä½œè€…ä»…ç”¨å¯¥å¯¥æ•°è¡Œä»£ç å®ç°äº†æ¨¡å‹å¹¶è¡Œæ‰€éœ€çš„åŒæ­¥ã€‚æ•´ä½“è€Œè¨€ï¼Œè™½ç„¶è®ºæ–‡å…¬å¼ä¸å¤šï¼Œä½†ç®—æ³•æœ¬èº«åŸºäºä»¥ä¸Šç®€å•æ­£ç¡®çš„çº¿æ€§ä»£æ•°å…³ç³»ï¼Œç¡®ä¿å¹¶è¡Œè®¡ç®—å®Œå…¨ç­‰ä»·äºåŸå§‹å…¨æ¨¡å‹è®¡ç®—ã€‚æ­¤å¤–ï¼Œè®­ç»ƒæ—¶è¿˜æ­é…äº†æ ‡å‡†çš„äº¤å‰ç†µæŸå¤±\\(\\mathcal{L}(\\theta) = -\\frac{1}{N}\\sum_{i=1}^{N}\\log P_\\theta(w_i \\mid \\text{context}_i)\\)æ¥å½¢å¼åŒ–è¯­è¨€æ¨¡å‹ç›®æ ‡ï¼Œå…¶ä¸­\\(P_\\theta\\)æ˜¯æ¨¡å‹å¯¹è¯\\(w_i\\)çš„é¢„æµ‹æ¦‚ç‡ã€‚æ¨¡å‹é€šè¿‡æœ€å°åŒ–æ­¤æŸå¤±è®­ç»ƒï¼ŒåŒæ—¶ä»¥å›°æƒ‘åº¦ï¼ˆPerplexityï¼‰\\(\\mathrm{PPL} = \\exp(\\mathcal{L})\\)è¡¡é‡æ¨¡å‹å¯¹è¯­è¨€çš„æ‹Ÿåˆç¨‹åº¦ã€‚\nä¸å¸¸è§è®­ç»ƒæ ˆçš„å¯¹åº”å…³ç³»ï¼šä¸Šè¿°Megatron-LMçš„å®ç°ä¸å…¸å‹æ·±åº¦å­¦ä¹ è®­ç»ƒæ ˆå„ç»„ä»¶ä¸€ä¸€å¯¹åº”ï¼š\n\næ•°æ®åŠ è½½ï¼šåˆ©ç”¨å¸¸è§„çš„æ•°æ®è¯»å–ç®¡é“ï¼Œç»“åˆDistributedSamplerç­‰æœºåˆ¶ï¼Œåœ¨æ•°æ®å¹¶è¡Œç»´åº¦ä¸Šåˆ’åˆ†æ•°æ®é›†ã€‚å¯¹äºæ¨¡å‹å¹¶è¡Œç»„å†…çš„GPUï¼Œç¡®ä¿å®ƒä»¬æ”¶åˆ°ç›¸åŒçš„æ ·æœ¬æ‰¹ï¼ˆä¾‹å¦‚é€šè¿‡å›ºå®šéšæœºç§å­æˆ–å¹¿æ’­æ•°æ®ï¼‰æ¥å…±åŒè®¡ç®—ä¸€ä¸ªå­æ‰¹æ¬¡ã€‚è¿™ä¸æ ‡å‡†DataLoaderæµç¨‹å…¼å®¹ï¼Œåªæ˜¯éœ€è¦è€ƒè™‘ç»„å†…æ•°æ®ä¸€è‡´æ€§ã€‚\nå¹¶è¡Œè°ƒåº¦ï¼šé€šè¿‡PyTorchåˆ†å¸ƒå¼é€šä¿¡ç»„ç­‰æ‰‹æ®µï¼Œå°†GPUåˆ’åˆ†ä¸ºå¤šå±‚æ¬¡å¹¶è¡Œç»„ï¼ˆå¦‚æ¯8å—GPUä¸ºä¸€ç»„è¿›è¡Œå¼ é‡æ¨¡å‹å¹¶è¡ŒTPï¼Œå¤šç»„ä¹‹é—´å†åšæ•°æ®å¹¶è¡ŒDPï¼‰ã€‚æ¡†æ¶åˆ©ç”¨PyTorch DDPï¼ˆDistributed Data Parallelï¼‰å’Œè‡ªå®šä¹‰çš„å¹¶è¡Œåº“åè°ƒå„ç»´åº¦ä¸Šçš„åŒæ­¥ã€‚Megatron-LMçš„æ–¹æ³•ä¹Ÿå¯ä¸æµæ°´å¹¶è¡Œ(PP)ç»“åˆä½¿ç”¨ï¼Œå°†æ¨¡å‹å±‚æ‹†åˆ†åˆ°ä¸åŒè®¾å¤‡ä»¥è·å¾—è¿›ä¸€æ­¥æ‰©å±•ã€‚æ­¤å¤–ï¼Œæ–°è¿‘å‡ºç°çš„ä¸Šä¸‹æ–‡å¹¶è¡Œ(CP)ï¼ˆåœ¨åºåˆ—é•¿åº¦ç»´åº¦è¿›è¡Œå¹¶è¡Œï¼‰ä¹Ÿå±äºå¯é€‰æ–¹æ¡ˆï¼Œå°½ç®¡åŸè®ºæ–‡æœªæ¶‰åŠï¼Œä½†æ¦‚å¿µä¸Šå¯ä¸TP/PPäº’è¡¥ï¼Œç”¨äºå¤„ç†è¶…é•¿åºåˆ—ã€‚æ€»ä½“æ¥è¯´ï¼Œå¹¶è¡Œè°ƒåº¦ç”±é«˜å±‚è„šæœ¬æˆ–Launcherè´Ÿè´£ï¼Œæ— éœ€äººå·¥å¹²é¢„æ¯æ­¥é€šä¿¡ï¼Œè®­ç»ƒè¿‡ç¨‹äº•ç„¶æœ‰åºåœ°åœ¨å„è®¾å¤‡ä¸Šå¹¶è¡Œå±•å¼€ã€‚\nå†…æ ¸ç®—å­ï¼šæ¨¡å‹çš„å¤§éƒ¨åˆ†è®¡ç®—ä»é€šè¿‡æ ‡å‡†æ·±åº¦å­¦ä¹ ç®—å­ï¼ˆçŸ©é˜µä¹˜ã€LayerNormã€æ¿€æ´»å‡½æ•°ç­‰ï¼‰å®ç°ã€‚Megatron-LMå……åˆ†åˆ©ç”¨äº†NVIDIA GPUä¸Šçš„cuBLASå’ŒNCCLåº“ï¼Œä¿è¯çŸ©é˜µä¹˜æ³•ã€All-Reduceç­‰å…³é”®è·¯å¾„é«˜åº¦ä¼˜åŒ–ã€‚æ•´ä¸ªå®ç°æœªå¼•å…¥æ–°çš„åº•å±‚å†…æ ¸ï¼Œä»…åœ¨Pythonå±‚å°†å·²æœ‰ç®—å­ç»„åˆä»¥å®ç°æ¨¡å‹å¹¶è¡Œã€‚ç„¶è€Œï¼Œå·¥ç¨‹ä¸Šå›¢é˜Ÿä¹Ÿæ•´åˆäº†ä¸€äº›Kernelä¼˜åŒ–ï¼ˆå¦‚èåˆQKVçº¿æ€§å˜æ¢ã€èåˆDropout+Biasç­‰ï¼‰æ¥å‡å°‘æ¡†æ¶å¼€é”€ï¼Œæé«˜å•æ­¥æ‰§è¡Œæ•ˆç‡ã€‚è¿™å¯¹åº”è®­ç»ƒæ ˆä¸­å¯¹ç®—å­çš„é«˜æ•ˆå®ç°éƒ¨åˆ†ï¼Œä¸å¸¸è§æ¡†æ¶ï¼ˆPyTorchã€DeepSpeedç­‰ï¼‰çš„ä¼˜åŒ–æ€è·¯ä¸€è‡´ã€‚\né€šä¿¡åç«¯ï¼šä½¿ç”¨NCCLç­‰é«˜æ€§èƒ½é€šä¿¡åº“å®ç°All-Reduceã€All-Gatherç­‰æ“ä½œï¼Œç¡®ä¿åœ¨å¤šGPUå¤šèŠ‚ç‚¹ç¯å¢ƒä¸‹é€šä¿¡é«˜æ•ˆå¯é ã€‚NCCLè´Ÿè´£åº•å±‚ä¼ è¾“ï¼Œåˆ©ç”¨ç¯å½¢ç®—æ³•ç­‰åœ¨GPUé—´ä¼ è¾“å¼ é‡ï¼Œå¹¶è‡ªåŠ¨ä½¿ç”¨NVLinkæˆ–InfiniBandç­‰äº’è”åŠ é€Ÿã€‚Megatron-LMçš„é€šä¿¡éœ€æ±‚ä¸å…¸å‹Collectiveé€šä¿¡åœºæ™¯åŒ¹é…ï¼Œå¦‚åŒæ­¥SGDä¸­çš„æ¢¯åº¦All-Reduceï¼Œåªæ˜¯è¿™é‡Œåœ¨æ¨¡å‹å†…éƒ¨æ›´é¢‘ç¹ã€‚ç”±äºé‡‡ç”¨æˆç†Ÿåç«¯ï¼Œå¼€å‘è€…ä¸éœ€å…³å¿ƒé€šä¿¡ç»†èŠ‚ï¼Œä½†éœ€è¦æ­£ç¡®è®¾ç½®ç¯å¢ƒï¼ˆå¦‚MPIå¯åŠ¨ã€GPUæ‹“æ‰‘ï¼‰ä»¥å‘æŒ¥å¸¦å®½æ½œåŠ›ã€‚\nè®­ç»ƒè¿‡ç¨‹é›†æˆï¼šä¸Šè¿°å„æ¨¡å—èå…¥è®­ç»ƒä¸»å¾ªç¯ï¼Œä¸å¸¸è§è®­ç»ƒæ ˆä¸­çš„DataLoaderã€Optimizerã€Schedulerå…±åŒæ„æˆå®Œæ•´æµç¨‹ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒMegatron-LMä¸ä¸»æµè®­ç»ƒæ¡†æ¶ï¼ˆä¾‹å¦‚NVIDIAçš„Megatron-LMä»£ç åº“ã€Microsoft DeepSpeedç­‰ï¼‰è‰¯å¥½ç»“åˆï¼Œè¿™äº›æ¡†æ¶æä¾›äº†é…ç½®æ¥å£æ¥æ‰“å¼€å¼ é‡å¹¶è¡Œã€æµæ°´å¹¶è¡Œç­‰ç‰¹æ€§ï¼Œä½¿å¾—å®é™…è½åœ°æ—¶åªéœ€åœ¨é…ç½®æ–‡ä»¶ä¸­æŒ‡å®šå¹¶è¡Œç¨‹åº¦å³å¯ï¼Œå¤§å¤§é™ä½äº†å·¥ç¨‹å®æ–½éš¾åº¦ã€‚\n\né€šè¿‡ä¸Šè¿°å¯¹åº”å…³ç³»å¯ä»¥çœ‹å‡ºï¼ŒMegatron-LMçš„æ–¹æ³•è¢«è®¾è®¡ä¸ºå¯ç§»æ¤ã€å¯ç»„åˆçš„ï¼Œå¼€å‘è€…æ— éœ€é‡æ„æ•´ä¸ªè®­ç»ƒæ ˆï¼Œåªéœ€åœ¨å¸¸è§„çš„è®­ç»ƒæµç¨‹ä¸­å¼€å¯ç›¸åº”å¹¶è¡Œç­–ç•¥ï¼Œä¾¿èƒ½åœ¨ç°æœ‰ç¡¬ä»¶ä¸Šè®­ç»ƒè¶…å¤§è§„æ¨¡æ¨¡å‹ã€‚\nå››ã€å»ºæ¨¡æ–¹å¼ä¸è¯„ä¼°æŒ‡æ ‡\n4.1 é—®é¢˜æ˜¯å¦‚ä½•å½¢å¼åŒ–çš„ï¼Ÿ\nä½œè€…å°†è¶…å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹è®­ç»ƒé—®é¢˜å½¢å¼åŒ–ä¸ºç»å…¸çš„æ— ç›‘ç£è¯­è¨€å»ºæ¨¡ä»»åŠ¡ã€‚å¯¹äºGPT-2è¿™ç±»è‡ªå›å½’è¯­è¨€æ¨¡å‹ï¼Œç›®æ ‡æ˜¯åœ¨ç»™å®šå‰æ–‡çš„æ¡ä»¶ä¸‹æœ€å¤§åŒ–ä¸‹ä¸€ä¸ªå•è¯å‡ºç°çš„æ¦‚ç‡ï¼›å¯¹äºBERTè¿™ç±»åŒå‘æ¨¡å‹ï¼Œåˆ™é€šè¿‡æ©ç è¯­è¨€æ¨¡å‹é¢„æµ‹è¢«é®è”½çš„å•è¯ã€‚åŒæ—¶ï¼ŒBERTçš„é¢„è®­ç»ƒè¿˜åŒ…å«ä¸‹ä¸€å¥é¢„æµ‹ç­‰ä»»åŠ¡ã€‚ä½†æ€»ä½“è€Œè¨€ï¼Œè®­ç»ƒå¯å½’ç»“ä¸ºåœ¨å¤§è§„æ¨¡è¯­æ–™ä¸Šæœ€å°åŒ–é¢„æµ‹è¯¯å·®çš„é—®é¢˜ã€‚\nå½¢å¼åŒ–æ¥è¯´ï¼Œç»™å®šè®­ç»ƒè¯­æ–™åºåˆ—\\(\\{w_1, w_2, ..., w_N\\}\\)ï¼Œæ¨¡å‹éœ€å­¦ä¹ å‚æ•°\\(\\theta\\)ä»¥æœ€å¤§åŒ–åºåˆ—æ¦‚ç‡\\(P_\\theta(w_1, ..., w_N)\\)ã€‚è¿™é€šå¸¸è½¬åŒ–ä¸ºæœ€å°åŒ–äº¤å‰ç†µæŸå¤±ï¼š \\[L(\\theta) = -\\frac{1}{N}\\sum_{t=1}^{N} \\log P_\\theta(w_t \\mid w_{&lt;t})\\] å¯¹äºGPT-2ï¼Œ\\(P_\\theta(w_t \\mid w_{&lt;t})\\)æ˜¯åŸºäºå…ˆå‰æ‰€æœ‰è¯é¢„æµ‹ä¸‹ä¸€è¯çš„æ¦‚ç‡ï¼›å¯¹äºBERTï¼Œè®­ç»ƒæ—¶å¯¹éšæœºé®è”½çš„è¯\\(w_k\\)é¢„æµ‹å…¶åŸè¯ã€‚è¯¥æŸå¤±è¡¡é‡æ¨¡å‹å¯¹è®­ç»ƒåˆ†å¸ƒçš„æ‹Ÿåˆç¨‹åº¦ï¼Œè¶Šå°è¡¨ç¤ºæ¨¡å‹å¯¹ä¸Šä¸‹æ–‡çš„é¢„æµ‹è¶Šå‡†ç¡®ã€‚ä¸ºä¾¿äºè§£é‡Šè®­ç»ƒéš¾åº¦ï¼Œè®ºæ–‡è¿˜ä½¿ç”¨å›°æƒ‘åº¦ï¼ˆPerplexity, PPLï¼‰æŒ‡æ ‡ï¼Œå°†å¹³å‡æŸå¤±æŒ‡æ•°åŒ–ï¼š\\(\\mathrm{PPL} = \\exp(L)\\)ï¼Œå®ƒè¡¨ç¤ºæ¨¡å‹åœ¨ä¸ç¡®å®šåº¦ä¸Šçš„ç­‰æ•ˆè¯æ±‡è¡¨è§„æ¨¡ï¼Œå›°æƒ‘åº¦è¶Šä½æ„å‘³ç€è¯­è¨€æ¨¡å‹è¶Šå¥½ã€‚\nåœ¨æ¨¡å‹å¹¶è¡Œçš„èƒŒæ™¯ä¸‹ï¼Œä½œè€…æ²¡æœ‰å¯¹ç›®æ ‡å‡½æ•°è¿›è¡Œä¿®æ”¹ï¼Œæ¨¡å‹å¹¶è¡Œä»…æ”¹å˜äº†è®¡ç®—åˆ†å¸ƒæ–¹å¼ï¼Œä¸å½±å“ä¸Šè¿°å½¢å¼åŒ–å®šä¹‰ã€‚å› æ­¤ï¼Œé—®é¢˜ä»ç„¶æ˜¯é€šè¿‡æ¢¯åº¦ä¸‹é™æ±‚è§£\\(\\min_\\theta L(\\theta)\\)ã€‚ä¸åŒçš„æ˜¯ï¼Œä»–ä»¬æ„å»ºäº†ä¸€ä¸ªå¯æ‰©å±•çš„è®¡ç®—ç»“æ„ä½¿è¿™ä¸ªä¼˜åŒ–è¿‡ç¨‹åœ¨æ•°ç™¾GPUä¸Šå¹¶è¡Œå®Œæˆã€‚æ¢è¨€ä¹‹ï¼Œå½¢å¼åŒ–çš„ç›®æ ‡ä¿æŒä¸å˜ï¼Œå˜åŒ–çš„æ˜¯å®ç°è¿™ä¸€ç›®æ ‡çš„è®¡ç®—ç­–ç•¥ã€‚\n4.2 æ ¸å¿ƒè¯„ä¼°æŒ‡æ ‡\nä¸ºè¯„ä¼°æ–¹æ³•æ•ˆæœï¼Œè®ºæ–‡é‡‡ç”¨äº†å¤šæ–¹é¢çš„æŒ‡æ ‡ï¼ŒåŒ…æ‹¬æ¨¡å‹æ€§èƒ½å’Œç³»ç»Ÿæ•ˆç‡ï¼š\n\nå›°æƒ‘åº¦ (Perplexity)ï¼šè¯­è¨€æ¨¡å‹å¸¸ç”¨æŒ‡æ ‡ï¼Œå®šä¹‰ä¸ºæµ‹è¯•é›†ä¸Š\\(2^{\\text{äº¤å‰ç†µ}}\\)ã€‚å›°æƒ‘åº¦åæ˜ æ¨¡å‹é¢„æµ‹ä¸‹ä¸€ä¸ªè¯çš„ä¸ç¡®å®šæ€§ï¼Œå€¼è¶Šä½è¡¨ç¤ºæ¨¡å‹é¢„æµ‹è¶Šå‡†ç¡®ã€‚ä½œè€…æŠ¥å‘Šäº†WikiText-103æ•°æ®é›†çš„å›°æƒ‘åº¦ï¼Œç”¨äºè¡¡é‡ä¸åŒå‚æ•°è§„æ¨¡GPT-2æ¨¡å‹çš„è¯­è¨€å»ºæ¨¡èƒ½åŠ›ã€‚\nå‡†ç¡®ç‡ (Accuracy)ï¼šé’ˆå¯¹ä¸‹æ¸¸ä»»åŠ¡çš„è¯„ä»·æŒ‡æ ‡ã€‚ä¾‹å¦‚LAMBADAæ•°æ®é›†çš„å®Œå½¢å¡«ç©ºä»»åŠ¡é‡‡ç”¨å®Œå¥é¢„æµ‹å‡†ç¡®ç‡ï¼ŒRACEé˜…è¯»ç†è§£ä»»åŠ¡é‡‡ç”¨é€‰æ‹©é¢˜å‡†ç¡®ç‡ã€‚è¿™äº›æŒ‡æ ‡è¡¡é‡æ¨¡å‹åœ¨ç‰¹å®šNLPä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼Œæ•°å€¼è¶Šé«˜è¶Šå¥½ã€‚è®ºæ–‡ä¸­ç‰¹åˆ«å…³æ³¨LAMBADAçš„å•è¯é¢„æµ‹å‡†ç¡®ç‡å’ŒRACEè€ƒè¯•é¢˜çš„å‡†ç¡®ç‡æå‡ã€‚\nä¸‹æ¸¸ä»»åŠ¡ç»¼åˆæŒ‡æ ‡ï¼šå¯¹äºBERTæ¨¡å‹ï¼Œä½œè€…è¯„ä¼°äº†åœ¨GLUEåŸºå‡†ä¸Šçš„å¤šé¡¹ä»»åŠ¡ï¼ˆMNLIã€QQPç­‰ï¼‰çš„å‡†ç¡®ç‡å’Œåœ¨SQuADé—®ç­”ä¸Šçš„F1/Exact Matchç­‰ã€‚è¿™äº›æŒ‡æ ‡ç»¼åˆä½“ç°å¤§æ¨¡å‹åœ¨è¿ç§»å­¦ä¹ åœºæ™¯çš„æ•ˆæœã€‚è®ºæ–‡å°†ä¸åŒè§„æ¨¡BERTæ¨¡å‹åœ¨è¿™äº›ä»»åŠ¡ä¸Šçš„åˆ†æ•°è¿›è¡Œå¯¹æ¯”ï¼Œè¯æ˜æ¨¡å‹è§„æ¨¡æå‡å¸¦æ¥çš„æ€§èƒ½å¢é•¿ã€‚\nè®¡ç®—ååé‡ï¼šä»¥æ¯ç§’å¤„ç†çš„æµ®ç‚¹è¿ç®—æ•°æ¥è¡¡é‡è®­ç»ƒæ•ˆç‡ã€‚ä½œè€…æŠ¥å‘Šäº†åœ¨512 GPUä¸Šè¾¾åˆ°çš„15.1 PetaFLOPsæŒç»­æ€§èƒ½ï¼Œä»¥åŠå•GPUçš„39 TeraFLOPsä¸ºåŸºå‡†ã€‚è¿™ä¸€æŒ‡æ ‡å±•ç¤ºå¹¶è¡Œä¼˜åŒ–çš„ç¡¬ä»¶æ•ˆç‡ï¼Œæ¥è¿‘ç†è®ºå³°å€¼çš„æ¯”ä¾‹è¶Šé«˜è¡¨ç¤ºå¹¶è¡Œæ–¹æ³•è¶Šé«˜æ•ˆã€‚è®ºæ–‡ä¸­æåˆ°è¾¾åˆ°å•å¡å³°å€¼30%ï¼ˆé‡‡ç”¨FP16è®­ç»ƒï¼‰ï¼Œå¤šå¡æ‰©å±•æ•ˆç‡çº¦76%ã€‚\næ‰©å±•æ•ˆç‡ (Scaling Efficiency)ï¼šå®šä¹‰ä¸ºå®é™…åŠ é€Ÿæ¯”ä¸ç†æƒ³çº¿æ€§åŠ é€Ÿæ¯”çš„æ¯”å€¼ã€‚ä¾‹å¦‚512å¡è¾¾åˆ°76%æ„å‘³ç€å®é™…é€Ÿåº¦çº¦ä¸ºçº¿æ€§512å€åŠ é€Ÿçš„0.76å€ã€‚ä½œè€…é€šè¿‡å¼±æ‰©å±•ï¼ˆå¢åŠ GPUåŒæ—¶å¢å¤§æ¨¡å‹å‚æ•°ï¼‰å’Œå¼ºæ‰©å±•ï¼ˆå›ºå®šæ¨¡å‹è§„æ¨¡å¢åŠ GPUï¼‰å®éªŒè¯„ä¼°äº†è¯¥å€¼ã€‚é«˜æ‰©å±•æ•ˆç‡è¡¨æ˜å¹¶è¡Œç®—æ³•åœ¨å¢åŠ è®¡ç®—èµ„æºæ—¶èƒ½æœ‰æ•ˆåˆ©ç”¨è€Œéæµªè´¹ç®—åŠ›ã€‚\nè®­ç»ƒç¨³å®šæ€§ï¼šè¿™ä¸æ˜¯æ˜ç¡®çš„æ•°å€¼æŒ‡æ ‡ï¼Œä½†é€šè¿‡lossæ›²çº¿å’Œå¹³ç¨³è®­ç»ƒè¿‡ç¨‹æ¥è¡¡é‡ã€‚ç‰¹åˆ«æ˜¯BERTæ¨¡å‹åœ¨ä¸åŒLayerNormæ”¾ç½®æ–¹å¼ä¸‹çš„å¤§æ¨¡å‹è®­ç»ƒæ˜¯å¦å‘æ•£ï¼Œè¢«ä½œä¸ºæ¯”è¾ƒå†…å®¹ã€‚è®ºæ–‡é€šè¿‡æ›²çº¿å›¾å±•ç¤ºäº†åŸå§‹æ¶æ„ä¸‹å¤§æ¨¡å‹è®­ç»ƒçš„ä¸ç¨³å®šï¼Œä»¥åŠè°ƒæ•´æ¶æ„åçš„ç¨³å®šä¸‹é™ï¼Œä»è€Œä¾§é¢åæ˜ äº†è®­ç»ƒç¨³å®šæ€§æ”¹è¿›ã€‚\n\nç»¼ä¸Šï¼Œè¿™äº›æŒ‡æ ‡æ¶µç›–æ¨¡å‹æ•ˆæœï¼ˆå›°æƒ‘åº¦ã€å‡†ç¡®ç‡ï¼‰å’Œç³»ç»Ÿæ•ˆç‡ï¼ˆFLOPsã€æ‰©å±•æ¯”ï¼‰ä¸¤ä¸ªæ–¹é¢ã€‚é€šè¿‡åŒæ—¶å…³æ³¨NLPä»»åŠ¡è¡¨ç°å’Œèµ„æºåˆ©ç”¨ç‡ï¼Œä½œè€…å…¨é¢è¯„ä¼°äº†Megatron-LMçš„ä¼˜è¶Šæ€§ã€‚\näº”ã€ä¸»è¦å®éªŒå‘ç°\n\næ¨¡å‹å¹¶è¡Œæœ‰æ•ˆæå‡äº†å¯è®­ç»ƒæ¨¡å‹è§„æ¨¡ä¸æ€§èƒ½ï¼šä½œè€…æˆåŠŸè®­ç»ƒäº†å‚æ•°é‡é«˜è¾¾8.3äº¿ï¼ˆGPT-2ï¼‰å’Œ3.9äº¿ï¼ˆBERTï¼‰çš„è¶…å¤§æ¨¡å‹:ï¼ˆæ³¨ï¼šåŸæ–‡å•ä½ä¸º billionï¼Œå³10äº¿ï¼Œè¿™é‡Œç®€åŒ–æè¿°ï¼‰ï¼Œæ˜¾è‘—è¶…å‡ºå½“æ—¶å¹¿æ³›ä½¿ç”¨çš„æ¨¡å‹è§„æ¨¡ï¼ˆä¾‹å¦‚BERT-Largeçš„3.36äº¿ï¼‰ã€‚éšç€è§„æ¨¡æ‰©å¤§ï¼Œæ¨¡å‹åœ¨è¯­è¨€å»ºæ¨¡å’Œä¸‹æ¸¸ä»»åŠ¡ä¸Šçš„è¡¨ç°å•è°ƒæå‡ã€‚è¿™éªŒè¯äº†â€œå¤§æ¨¡å‹å¸¦æ¥æ›´å¥½æ•ˆæœâ€çš„è¶‹åŠ¿ï¼Œå¹¶è¯æ˜äº†åªè¦é…å¥—çš„å¹¶è¡Œè®­ç»ƒå¾—å½“ï¼Œæå‡å‚æ•°è§„æ¨¡ä¾ç„¶èƒ½å¸¦æ¥æ”¶ç›Šã€‚\næé«˜çš„ç¡¬ä»¶ååä¸å¯æ‰©å±•æ€§ï¼šåœ¨512 GPUçš„GPUé›†ç¾¤ä¸Šï¼ŒMegatron-LMå®ç°äº†15.1 PFLOPsçš„æŒç»­è®­ç»ƒååï¼Œè¾¾åˆ°å•å¡æ€§èƒ½çš„76%æ‰©å±•æ•ˆç‡ã€‚è€ƒè™‘åˆ°é€šä¿¡å’ŒåŒæ­¥å¼€é”€ï¼Œè¿™ä¸€æ•ˆç‡éå¸¸æ¥è¿‘çº¿æ€§æ‰©å±•çš„ç†æƒ³å€¼ï¼Œè¯´æ˜ä½œè€…çš„æ–¹æ³•å……åˆ†åˆ©ç”¨äº†é›†ç¾¤è®¡ç®—èƒ½åŠ›ã€‚å¼±æ‰©å±•å®éªŒæ˜¾ç¤ºï¼Œæ¨¡å‹å‚æ•°ä¸GPUæ•°é‡åŒæ¯”å¢é•¿æ—¶ï¼ŒåååŸºæœ¬éšGPUçº¿æ€§å¢åŠ ï¼›å¼ºæ‰©å±•å®éªŒä¹Ÿå±•ç¤ºäº†è‰¯å¥½çš„åŠ é€Ÿæ¯”ã€‚è¿™æ„å‘³ç€é€šè¿‡æœ¬æ–¹æ³•ï¼Œå¢åŠ ç®—åŠ›å‡ ä¹å¯ä»¥ç›´æ¥ç”¨äºè®­ç»ƒæ›´å¤§æ¨¡å‹æˆ–åŠ é€Ÿè®­ç»ƒè¿‡ç¨‹ï¼Œå¹¶è¡Œæ”¶ç›Šæ¥è¿‘ç†æƒ³ã€‚\nSOTAæ°´å¹³çš„ä»»åŠ¡æ•ˆæœï¼šè®­ç»ƒå¾—åˆ°çš„8.3B GPT-2æ¨¡å‹åœ¨WikiText103æ•°æ®é›†ä¸Šè¾¾åˆ°10.8çš„å›°æƒ‘åº¦ï¼ˆæ­¤å‰æœ€ä½³ä¸º15.8ï¼‰ï¼Œåœ¨LAMBADAå®Œå½¢å¡«ç©ºæµ‹è¯•ä¸­å‡†ç¡®ç‡66.5%ï¼ˆæ­¤å‰æœ€ä½³63.2%ï¼‰ã€‚åŒæ ·ï¼Œ3.9Bçš„Megatron-BERTåœ¨RACEé˜…è¯»ç†è§£ä»»åŠ¡ä¸Šè¾¾åˆ°90.9%å‡†ç¡®ç‡ï¼ˆè¶…è¿‡æ­¤å‰SOTAçš„89.4%ï¼‰ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œé€šè¿‡å¢åŠ æ¨¡å‹å®¹é‡å’Œä½¿ç”¨æ›´é•¿æ—¶é—´é¢„è®­ç»ƒï¼Œè¯­è¨€æ¨¡å‹å¯ä»¥å¤§å¹…æå‡å¯¹æ–‡æœ¬çš„ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ï¼Œåˆ·æ–°å¤šä¸ªåŸºå‡†ä»»åŠ¡çš„è®°å½•ã€‚\næ¶æ„å¾®è°ƒå¯¹å¤§æ¨¡å‹è‡³å…³é‡è¦ï¼šå®éªŒä¸­ä¸€ä¸ªçªå‡ºçš„å‘ç°æ˜¯ï¼ŒLayerNormçš„ä½ç½®ä¼šå½±å“BERTå¤§å‹æ¨¡å‹çš„è®­ç»ƒå¯è¡Œæ€§ã€‚åŸå§‹BERTæ¶æ„åœ¨æ®‹å·®è¿æ¥ä¹‹åä½¿ç”¨LayerNormï¼ˆPost-LNï¼‰ï¼Œä½œè€…å‘ç°å½“å‚æ•°æ‰©å±•åˆ°æ•°äº¿è§„æ¨¡æ—¶è®­ç»ƒå‡ºç°ä¸ç¨³å®šç”šè‡³æ€§èƒ½é€€åŒ–ã€‚é€šè¿‡æ”¹ç”¨Pre-LNæ¶æ„ï¼ˆåœ¨æ¯ä¸ªå­å±‚è®¡ç®—å‰åº”ç”¨LayerNormï¼‰ï¼Œæ¨¡å‹è®­ç»ƒå˜å¾—ç¨³å®šï¼Œå¹¶éšç€è§„æ¨¡å¢åŠ å‡†ç¡®ç‡æŒç»­æå‡ã€‚è¿™ä¸€ç°è±¡å¼ºè°ƒäº†åœ¨æ”¾å¤§æ¨¡å‹å°ºå¯¸æ—¶ï¼Œè®­ç»ƒç¨³å®šæ€§å¯èƒ½æˆä¸ºç“¶é¢ˆï¼Œéœ€è¦é€šè¿‡æ¶æ„è°ƒæ•´ï¼ˆæˆ–ä¼˜åŒ–å™¨è¶…å‚è°ƒæ•´ï¼‰æ¥è§£å†³ã€‚\nå·¥ç¨‹å®ç°å¼€æ”¾ä¸”å¯å¤ç”¨ï¼šä½œè€…å°†å®Œæ•´çš„è®­ç»ƒä»£ç å’Œæµæ°´çº¿å®ç°å¼€æºåœ¨NVIDIA/Megatron-LMä»“åº“ã€‚è¿™æ„å‘³ç€ç ”ç©¶ç¤¾åŒºå’Œå·¥ä¸šç•Œå¯ä»¥ç›´æ¥ä½¿ç”¨è¿™ä¸€æˆæœæ¥è®­ç»ƒè‡ªå·±çš„å¤§æ¨¡å‹ã€‚è¿™åœ¨å½“æ—¶å…·æœ‰é‡è¦æ„ä¹‰ï¼šä¸ä»…è¯æ˜äº†æ–¹æ³•çš„å¯è¡Œæ€§ï¼Œä¹Ÿé™ä½äº†æŠ€æœ¯ä¼ æ’­é—¨æ§›ã€‚è®¸å¤šåç»­å·¥ä½œï¼ˆä¾‹å¦‚å¾®è½¯çš„Turing-NLG 170äº¿å‚æ•°æ¨¡å‹ï¼‰éƒ½å»ºç«‹åœ¨Megatron-LMçš„æ–¹æ³•ä¹‹ä¸Šï¼Œä½“ç°äº†è¯¥å·¥ä½œçš„å½±å“åŠ›å’Œå®ç”¨ä»·å€¼ã€‚\n\n5.1 å…³é”®å›¾è¡¨è§£è¯»\nå®éªŒéƒ¨åˆ†åŒ…å«å¤šå¹…å›¾è¡¨ï¼Œå½¢è±¡åœ°æ”¯æŒäº†ä¸Šè¿°å‘ç°ï¼š\n\næ‰©å±•æ•ˆç‡æ›²çº¿ï¼šè®ºæ–‡çš„Figure 1å±•ç¤ºäº†ä¸åŒå¹¶è¡Œé…ç½®ä¸‹çš„è®¡ç®—æ•ˆç‡å¯¹æ¯”ã€‚å…¶ä¸­æ¨¡å‹å¹¶è¡Œï¼ˆå¼ é‡å¹¶è¡Œï¼‰éšGPUæ•°é‡å¢é•¿çš„åååŸºæœ¬æ¥è¿‘ç†æƒ³ç›´çº¿ï¼Œè€Œä»…æ•°æ®å¹¶è¡Œåœ¨é«˜GPUæ•°æ—¶æ•ˆç‡å¼€å§‹ä¸‹é™ã€‚å›¾ä¸­æ ‡æ³¨çš„76%æ‰©å±•æ•ˆç‡è¯æ˜äº†8è·¯æ¨¡å‹å¹¶è¡Œåœ¨512å¡ä¸Šä»ä¿æŒé«˜æ•ˆã€‚è¿™ä¸€å›¾è¡¨ç›´è§‚è¯æ˜äº†Megatron-LMæ–¹æ¡ˆçš„é«˜å¯æ‰©å±•æ€§ï¼Œæ”¯æŒç¬¬ä¸€æ¡ä¸»è¦å‘ç°ã€‚\néªŒè¯å›°æƒ‘åº¦éšè¿­ä»£æ”¶æ•›å›¾ï¼šFigure 6ç»˜åˆ¶äº†ä¸åŒè§„æ¨¡GPT-2æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„å›°æƒ‘åº¦éšè®­ç»ƒè¿›ç¨‹ï¼ˆè¿­ä»£æ•°ï¼‰çš„ä¸‹é™è¶‹åŠ¿ã€‚ä»å›¾ä¸­å¯ä»¥çœ‹åˆ°ï¼Œè¾ƒå¤§çš„æ¨¡å‹ä¸ä»…æœ€ç»ˆå›°æƒ‘åº¦æ›´ä½ï¼ˆä¾‹å¦‚8.3Bæ¨¡å‹æœ€ç»ˆéªŒè¯PPLçº¦9.27ï¼Œå°æ¨¡å‹æ˜æ˜¾æ›´é«˜ï¼‰ï¼Œè€Œä¸”æ”¶æ•›æ›´å¿«ï¼ˆåœ¨ç›¸åŒè¿­ä»£å†…å¤§æ¨¡å‹è¾¾åˆ°æ›´ä½PPLï¼‰ã€‚è¿™è¯´æ˜å¢åŠ æ¨¡å‹å®¹é‡å¸¦æ¥çš„æ”¶ç›Šæ˜¯åŒé‡çš„ï¼šæ€§èƒ½æå‡å’Œæ”¶æ•›åŠ é€Ÿï¼Œæ”¯æŒäº†â€œå¤§æ¨¡å‹æ›´æœ‰æ•ˆâ€çš„è®ºæ–­ã€‚\nBERTæ¶æ„å¯¹æ¯”è®­ç»ƒæ›²çº¿ï¼šFigure 7æ¯”è¾ƒäº†åŸå§‹BERTæ¶æ„å’Œè°ƒæ•´LayerNormåæ¶æ„åœ¨è®­ç»ƒå¤§æ¨¡å‹æ—¶çš„lossæ›²çº¿ã€‚æ›²çº¿(a)ï¼ˆåŸå§‹ï¼‰å‡ºç°éœ‡è¡ç”šè‡³æ— æ³•é™ä½ï¼Œè€Œæ›²çº¿(b)ï¼ˆè°ƒæ•´åï¼‰å¹³æ»‘æ”¶æ•›åˆ°æ›´ä½lossã€‚è¿™å¼ å›¾å½¢è±¡åœ°æ”¯æ’‘äº†ç¬¬å››æ¡å‘ç°ï¼šæ­£ç¡®çš„LayerNormä½ç½®æ¶ˆé™¤äº†è®­ç»ƒä¸ç¨³å®šï¼Œä½¿å¾—3.9Bå‚æ•°BERTæˆåŠŸæ”¶æ•›å¹¶å–å¾—æ›´é«˜ç²¾åº¦ã€‚å®ƒæé†’æˆ‘ä»¬åœ¨å¤§æ¨¡å‹è®­ç»ƒä¸­ï¼Œå°çš„æ¶æ„æ”¹åŠ¨ä¼šå¸¦æ¥å·¨å¤§å½±å“ã€‚\nä¸‹æ¸¸ä»»åŠ¡ç»“æœè¡¨æ ¼ï¼šè®ºæ–‡çš„Table 3å’ŒTable 5æ±‡æ€»äº†æ¨¡å‹åœ¨WikiText103ã€LAMBADAç­‰æ— ç›‘ç£ä»»åŠ¡ä»¥åŠRACEã€MNLIç­‰ä¸‹æ¸¸ä»»åŠ¡çš„å…·ä½“æ•°å€¼ã€‚ä¾‹å¦‚Table 3æ¸…æ™°åˆ—å‡ºäº†355Mã€2.5Bã€8.3Bå„æ¨¡å‹çš„WikiTextå›°æƒ‘åº¦å’ŒLAMBADAå‡†ç¡®ç‡ï¼Œä»¥åŠè¿‡å»SOTAå¯¹æ¯”ã€‚è¿™äº›è¡¨æ ¼æ•°æ®ä¸€ç›®äº†ç„¶åœ°è¯æ˜äº†æ¨¡å‹è§„æ¨¡æå‡å¸¦æ¥çš„æ€§èƒ½å¢ç›Šå’ŒSOTAè¶…è¶Šï¼Œä¸ºç¬¬äºŒå’Œç¬¬ä¸‰æ¡å‘ç°æä¾›äº†å®šé‡ä¾æ®ã€‚\n\né€šè¿‡ä»¥ä¸Šå…³é”®å›¾è¡¨ï¼Œè¯»è€…å¯ä»¥ç›´è§‚ç†è§£Megatron-LMæ–¹æ³•çš„æ•ˆæœï¼šè®¡ç®—æ•ˆç‡é«˜ã€æ¨¡å‹è¡¨ç°ä¼˜å¼‚ä¸”æ¶æ„è°ƒæ•´å‘æŒ¥å…³é”®ä½œç”¨ã€‚æ¯ä¸ªå›¾è¡¨å’Œè¡¨æ ¼éƒ½å¯¹åº”åœ°æ”¯æ’‘äº†å‰æ–‡çš„å®éªŒç»“è®ºã€‚\nç»“æœè§£è¯»ä¸è¾¹ç•Œï¼šæ€»ä½“è€Œè¨€ï¼ŒMegatron-LMçš„å®éªŒç»“æœå±•ç°äº†ä»¤äººä¿¡æœçš„æ€§èƒ½æå‡å’Œæ‰©å±•èƒ½åŠ›ï¼Œè¯æ˜åªè¦è®­ç»ƒèµ„æºå……è¶³ï¼Œå¤§è§„æ¨¡æ¨¡å‹çš„æ½œåŠ›å¯ä»¥è¢«å……åˆ†æŒ–æ˜ã€‚è¿™ä¸€ç»“è®ºå¯¹NLPé¢†åŸŸå½±å“æ·±è¿œâ€”â€”å®ƒä¸ºæ­¤åå‡ºç°çš„æ›´å¤§æ¨¡å‹ï¼ˆå¦‚GPT-3ç­‰ï¼‰å¥ å®šäº†æ–¹æ³•åŸºç¡€ï¼Œè¡¨æ˜é‡‡ç”¨æ¨¡å‹å¹¶è¡Œç­‰æŠ€æœ¯èƒ½å¤Ÿæœ‰æ•ˆåœ°è®­ç»ƒç™¾äº¿çº§å‚æ•°æ¨¡å‹ã€‚ç„¶è€Œï¼Œä¹Ÿéœ€è¦ç†æ€§çœ‹å¾…è¿™äº›ç»“æœçš„é€‚ç”¨èŒƒå›´å’Œå±€é™ï¼š\n\né¦–å…ˆï¼Œæˆæœ¬ä¸èƒ½è€—è¾¹ç•Œï¼šè¾¾åˆ°è®ºæ–‡ä¸­çš„SOTAç»“æœä¾èµ–æ•°ç™¾GPUæ—¥ä»¥ç»§å¤œçš„è®¡ç®—ï¼ˆè®ºæ–‡æåŠ8.3Bæ¨¡å‹å•è½®epochè®­ç»ƒéœ€çº¦ä¸¤å¤©ã€‚è¿™ç§è§„æ¨¡çš„è®¡ç®—ä»£ä»·ä½¿å¾—å¤§æ¨¡å‹è®­ç»ƒä¸»è¦å±€é™äºé¡¶å°–å®éªŒå®¤å’Œå…¬å¸ã€‚æ¢è¨€ä¹‹ï¼Œæ–¹æ³•è™½ç„¶è¯æ˜å¯è¡Œï¼Œä½†åœ¨èµ„æºå—é™ç¯å¢ƒä¸‹éš¾ä»¥å¤ç°ï¼Œæˆæœ¬å’Œèƒ½è€—æ˜¯ç°å®è¾¹ç•Œä¹‹ä¸€ã€‚\næ¨¡å‹è§„æ¨¡çš„æ”¶ç›Šé€’å‡ï¼šå°½ç®¡è®ºæ–‡ä¸­æ€§èƒ½éšè§„æ¨¡å¢é•¿è€Œæå‡ï¼Œä½†å¹¶æœªç³»ç»Ÿæ¢è®¨å¢é•¿åˆ°æ›´é«˜å‚æ•°é‡æ—¶æ˜¯å¦å­˜åœ¨æ‹ç‚¹æˆ–ç“¶é¢ˆã€‚åç»­ç ”ç©¶æå‡ºäº†Scaling Lawï¼ˆæ‰©å±•è§„å¾‹ï¼‰ï¼ŒæŒ‡å‡ºæ€§èƒ½æå‡å¯¹æ•°é€’å‡ã€‚Megatron-LMçš„ç»“æœä¸»è¦è¦†ç›–åˆ°8Bé‡çº§ï¼Œå¯¹äºç™¾äº¿ç”šæˆ–åƒäº¿å‚æ•°æ˜¯å¦çº¿æ€§é€‚ç”¨ï¼Œä»å­˜åœ¨ä¸ç¡®å®šæ€§ï¼ˆå¾…æ ¸å®ï¼‰ã€‚\né€šç”¨æ€§ä¸å…¶å®ƒå› ç´ ï¼šè®ºæ–‡é›†ä¸­åœ¨Transformerè¯­è¨€æ¨¡å‹ï¼Œå¯¹å…¶å®ƒæ¶æ„ï¼ˆCNNã€RNNï¼‰æˆ–å…¶å®ƒä»»åŠ¡çš„å¯æ¨å¹¿æ€§æœªåšå®éªŒã€‚ä¾‹å¦‚è§†è§‰æ¨¡å‹çš„å¤§è§„æ¨¡è®­ç»ƒæ˜¯å¦ä¹Ÿèƒ½ç›´æ¥å¥—ç”¨ç±»ä¼¼æ–¹æ³•å°šå¾…éªŒè¯ã€‚æ­¤å¤–ï¼Œè®ºæ–‡å…³æ³¨è§„æ¨¡å’Œå¹¶è¡Œï¼Œæœ¬èº«å¹¶æœªè¯¦ç»†è®¨è®ºä¼˜åŒ–ç®—æ³•ã€æ­£åˆ™åŒ–ç­‰å¯¹æœ€ç»ˆæ€§èƒ½çš„å½±å“ï¼Œè¿™äº›åœ¨æ›´å¤§è§„æ¨¡è®­ç»ƒæ—¶å¯èƒ½å˜å¾—æ˜¾è‘—ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œç»“æœçš„ä¼˜ç§€éƒ¨åˆ†å½’å› äºæ›´å¤§æ¨¡å‹å®¹é‡ï¼Œä½†ä¼˜åŒ–ç»†èŠ‚æˆ–è®­ç»ƒæ•°æ®ç­‰å› ç´ å¯¹ç»“æœçš„è´¡çŒ®æ²¡æœ‰åˆ†åˆ«é‡åŒ–ã€‚\nè¯„æµ‹ç»´åº¦æœ‰é™ï¼šä½œè€…ä¸»è¦ä»¥æ ‡å‡†åŸºå‡†ä»»åŠ¡è¡¡é‡æ¨¡å‹ï¼Œä¾§é‡äºå‡†ç¡®ç‡å’Œå›°æƒ‘åº¦ç­‰æŒ‡æ ‡ã€‚è€Œå¯¹äºå¤§æ¨¡å‹æ½œåœ¨çš„å…¶å®ƒè¯„æµ‹ç»´åº¦ï¼ˆå¦‚æ³›åŒ–èƒ½åŠ›ã€åè§å’Œå…¬å¹³æ€§ã€é²æ£’æ€§ç­‰ï¼‰ï¼Œè®ºæ–‡æ²¡æœ‰æ¶‰çŒã€‚è¿™äº›æ„æˆäº†ç»“æœè§£è¯»çš„è¾¹ç•Œï¼šæ€§èƒ½å“è¶Šä¸ç­‰äºå®Œç¾ï¼Œå¤§æ¨¡å‹åœ¨å®ç”¨ä¸­è¿˜éœ€è¦è€ƒè™‘æ›´å¤šå…¨é¢çš„æŒ‡æ ‡ã€‚\n\næ€»ä¹‹ï¼ŒMegatron-LMçš„å®éªŒæˆæœåœ¨å¤§æ¨¡å‹è®­ç»ƒé¢†åŸŸæ ‘ç«‹äº†æ ‡æ†ï¼Œä½†åŒæ—¶ä¹Ÿæç¤ºæˆ‘ä»¬æ³¨æ„èƒŒåçš„ä»£ä»·å’Œæœªè§£å†³çš„é—®é¢˜ã€‚åœ¨ç»§ç»­è¿½æ±‚æ›´å¤§æ›´å¼ºæ¨¡å‹çš„é“è·¯ä¸Šï¼Œè¿™äº›è¾¹ç•Œæ¡ä»¶å°†æ˜¯éœ€è¦å…‹æœçš„æŒ‘æˆ˜ã€‚\nå…­ã€ä¼˜ç‚¹ä¸å±€é™\nStrengths â€“ äº®ç‚¹ï¼š\n\nå¤§å¹…æå‡å¯è®­ç»ƒæ¨¡å‹è§„æ¨¡ï¼šMegatron-LMæ–¹æ¡ˆæ˜¾è‘—çªç ´å•æœºæ˜¾å­˜é™åˆ¶ï¼Œä½¿å¾—å½“æ—¶æ¨¡å‹å‚æ•°è§„æ¨¡ä»æ•°äº¿æå‡åˆ°æ•°åäº¿çº§åˆ«æˆä¸ºå¯èƒ½ã€‚è¿™ç§èƒ½åŠ›ç›´æ¥æ¨åŠ¨äº†æ›´é«˜æ€§èƒ½çš„è¯­è¨€æ¨¡å‹å‡ºç°ï¼Œä¸ºä¹‹åçš„è¶…å¤§è§„æ¨¡æ¨¡å‹ï¼ˆå¦‚GPT-3ç­‰ï¼‰é“ºå¹³é“è·¯ã€‚\nå·¥ç¨‹å®ç°ç®€å•é«˜æ•ˆï¼šæ–¹æ³•ä¸ä¾èµ–ç‰¹æ®Šç¼–è¯‘å™¨æˆ–æ¡†æ¶æ”¹åŠ¨ï¼Œä»…é€šè¿‡æ’å…¥All-Reduceç­‰é€šä¿¡æ“ä½œå®ç°ã€‚å€ŸåŠ©PyTorchå·²æœ‰æœºåˆ¶ï¼Œå°±èƒ½è¾¾åˆ°æ¥è¿‘ç†æƒ³çš„æ‰©å±•æ•ˆç‡ã€‚è¿™æ„å‘³ç€ç°æœ‰ä»£ç åº“æ˜“äºé›†æˆï¼Œé™ä½äº†å¹¶è¡Œè®­ç»ƒçš„å®ç°å¤æ‚åº¦ï¼Œå…·æœ‰å¾ˆé«˜çš„å·¥ç¨‹å®ç”¨ä»·å€¼ã€‚\nSOTAæ€§èƒ½è¯æ˜æœ‰æ•ˆæ€§ï¼šè®ºæ–‡ä¸ä»…åœ¨ç†è®ºä¸Šæå‡ºæ–¹æ³•ï¼Œè¿˜é€šè¿‡å®é™…è®­ç»ƒéªŒè¯äº†å¤§æ¨¡å‹å¸¦æ¥çš„æ€§èƒ½æå‡ï¼ŒåŒ…æ‹¬åˆ·æ–°å¤šé¡¹NLPä»»åŠ¡çš„SOTAã€‚è¿™ä¸ºâ€œå¤§æ¨¡å‹æ›´å¥½â€æä¾›äº†ç›´æ¥è¯æ®ï¼Œå¢å¼ºäº†å­¦ç•Œä¸šç•Œå¯¹æŠ•å…¥èµ„æºè®­ç»ƒæ›´å¤§æ¨¡å‹çš„ä¿¡å¿ƒã€‚\nçµæ´»å…¼å®¹å…¶ä»–å¹¶è¡Œç­–ç•¥ï¼šä½œè€…å¼ºè°ƒå…¶å¼ é‡æ¨¡å‹å¹¶è¡Œä¸æ•°æ®å¹¶è¡Œå’Œæµæ°´çº¿å¹¶è¡Œæ˜¯æ­£äº¤ä¸”å¯ç»“åˆçš„ã€‚è¿™ä¸€ç‰¹æ€§è®©æ–¹æ³•å¯åº”ç”¨äºå„ç§é›†ç¾¤è§„æ¨¡å’Œå†…å­˜éœ€æ±‚ä¸‹ï¼Œé€šè¿‡å¤šé‡å¹¶è¡Œçš„ç»„åˆè¿›ä¸€æ­¥æ‰©å±•ã€‚ä¾‹å¦‚8è·¯æ¨¡å‹å¹¶è¡Œé…åˆ64è·¯æ•°æ®å¹¶è¡Œçš„æ··åˆæ–¹æ¡ˆåœ¨è®ºæ–‡ä¸­è·å¾—æˆåŠŸã€‚\næ¶æ„æ´å¯Ÿä¸æ”¹è¿›ï¼šå·¥ä½œä¸­å‘ç°çš„LayerNormè°ƒæ•´å¯¹BERTæ€§èƒ½çš„å½±å“ï¼Œæ˜¯ä¸€ä¸ªå®è´µçš„ç»éªŒæ•™è®­ã€‚è¿™å±•ç¤ºäº†ä½œè€…å¯¹æ¨¡å‹è®­ç»ƒåŠ¨æ€çš„æ·±å…¥æ´å¯Ÿï¼Œå¹¶æä¾›äº†æ”¹è¿›å¤§æ¨¡å‹ç¨³å®šæ€§çš„ä¸€ä¸ªé€šç”¨æŠ€å·§ï¼ˆåæ¥è¢«å¹¿æ³›é‡‡ç”¨ä¸ºPre-LN Transformeræ¶æ„ï¼‰ã€‚\nå¼€æºä¸å½±å“ï¼šä½œè€…å¼€æºäº†Megatron-LMè®­ç»ƒä»£ç å’Œé…ç½®ï¼Œä¸ºç¤¾åŒºæä¾›äº†ç›´æ¥ä½¿ç”¨å¤§è§„æ¨¡è®­ç»ƒæ–¹æ¡ˆçš„æœºä¼šã€‚è¿™æå¤§åœ°åŠ é€Ÿäº†ç›¸å…³ç ”ç©¶çš„å‘å±•ã€‚éšåè®¸å¤šå¤§å‹æ¨¡å‹è®­ç»ƒï¼ˆMicrosoft Turing-NLG, EleutherAI GPTç­‰ï¼‰éƒ½å€Ÿé‰´æˆ–ç›´æ¥ä½¿ç”¨äº†Megatron-LMçš„å®ç°ï¼Œå……åˆ†ä½“ç°äº†æœ¬å·¥ä½œçš„å½±å“åŠ›ã€‚\n\nLimitations â€“ å±€é™ï¼š\n\nèµ„æºè¦æ±‚æé«˜ï¼šè¯¥æ–¹æ³•éœ€è¦å¤§é‡GPUååŒè®­ç»ƒæ‰èƒ½å‘æŒ¥ä¼˜åŠ¿ã€‚è®ºæ–‡å®éªŒç”¨åˆ°512å—V100 GPUï¼Œè¿™ç§è§„æ¨¡çš„èµ„æºæä¸ºæ˜‚è´µä¸”æ™®é€šå›¢é˜Ÿéš¾ä»¥è·å¾—ã€‚å³ä½¿æ–¹æ³•æœ¬èº«é«˜æ•ˆï¼Œä½†ç®—åŠ›å’Œå†…å­˜é—¨æ§›ä¾ç„¶é™åˆ¶äº†å®ƒçš„æ™®åŠé¢ï¼Œè¿™å±äºæ— æ³•å¿½è§†çš„ç°å®å±€é™ã€‚\né€šä¿¡ç“¶é¢ˆä»å­˜åœ¨ï¼šå°½ç®¡å·²å°†é€šä¿¡å‹ç¼©åˆ°æ¯å±‚ä»…2æ¬¡All-Reduceï¼Œä½†å¯¹äºæ›´å¤§è§„æ¨¡å¹¶è¡Œï¼ˆå¦‚æˆåƒä¸Šä¸‡GPUï¼‰ï¼Œé€šä¿¡å¼€é”€å¯èƒ½å¢é•¿å¹¶æˆä¸ºç“¶é¢ˆã€‚ç½‘ç»œæ‹“æ‰‘ä¸ä½³æˆ–å¸¦å®½ä¸è¶³æ—¶æ•ˆç‡ä¼šæ€¥å‰§ä¸‹é™ã€‚å› æ­¤è¯¥æ–¹æ³•åœ¨è¶…å¤§è§„æ¨¡é›†ç¾¤ä¸‹çš„æ•ˆç‡å¯ä¼¸ç¼©æ€§éœ€è¦è¿›ä¸€æ­¥éªŒè¯ï¼Œé€šä¿¡å»¶å±•æ€§æ˜¯æ½œåœ¨çš„çŸ­æ¿ã€‚\nä¾èµ–ç‰¹å®šæ¨¡å‹ç»“æ„ï¼šæ–¹æ¡ˆåˆ©ç”¨Transformerå±‚çš„å‡åŒ€ç»“æ„å’Œç‹¬ç«‹æ€§å®ç°å¹¶è¡Œï¼Œå¯¹Transformerä»¥å¤–çš„æ¨¡å‹ï¼ˆå¦‚RNNã€CNNï¼‰å¹¶ä¸ä¸€å®šç›´æ¥é€‚ç”¨ã€‚è‹¥æ¨¡å‹å±‚ä¹‹é—´å­˜åœ¨ä¾èµ–é¡ºåºæˆ–å…¨å±€æ“ä½œï¼Œåˆ™æ— æ³•å¥—ç”¨ç®€å•çš„å¼ é‡å¹¶è¡Œåˆ’åˆ†ã€‚æ­¤å¤–ï¼Œå¯¹äºæŸäº›éœ€è¦è·¨å±‚é€šä¿¡çš„ç½‘ç»œï¼Œæ–¹æ³•éœ€è°ƒæ•´æˆ–æ— æ³•ä½¿ç”¨ã€‚\nå†…å­˜ç“¶é¢ˆè½¬ç§»ï¼šæ¨¡å‹å¹¶è¡Œé™ä½äº†æ¯ä¸ªGPUçš„æ¨¡å‹å‚æ•°å†…å­˜ï¼Œä½†å¹¶æœªè§£å†³ä¼˜åŒ–å™¨çŠ¶æ€å’Œæ¿€æ´»çš„å†…å­˜æ¶ˆè€—ã€‚ä»¥Adamä¼˜åŒ–ä¸ºä¾‹ï¼Œä»éœ€è¦ä¸ºæ¯ä¸ªå‚æ•°ç»´æŠ¤é¢å¤–2å€çš„çŠ¶æ€ã€‚è¿™äº›åœ¨å¤§æ¨¡å‹ä¸‹å æ®å¤§é‡å†…å­˜ã€‚è™½ç„¶å¯ä»¥å€ŸåŠ©æ¢¯åº¦æ£€æŸ¥ç‚¹ç­‰ç¼“è§£æ¿€æ´»å†…å­˜ï¼Œä½†ä¼˜åŒ–å™¨çŠ¶æ€å’Œæ¢¯åº¦çš„å†…å­˜é—®é¢˜åœ¨è®ºæ–‡ä¸­æœªè§£å†³ï¼Œåç»­ZeROç­‰æŠ€æœ¯æ­£æ˜¯ä¸ºæ­¤æå‡ºã€‚\nè®­ç»ƒç¨³å®šæ€§å…¶ä»–é—®é¢˜ï¼šé™¤äº†LayerNormä½ç½®è°ƒæ•´ï¼Œè¶…å¤§æ¨¡å‹è®­ç»ƒå¯èƒ½é¢ä¸´å…¶ä»–æ•°å€¼ç¨³å®šæŒ‘æˆ˜ï¼Œå¦‚æ¢¯åº¦çˆ†ç‚¸/æ¶ˆå¤±ã€å­¦ä¹ ç‡è§„åˆ’ç­‰ã€‚è®ºæ–‡ä»…æ¢è®¨äº†LayerNormä¸€ç§å› ç´ ã€‚å¯¹äºä¸åŒæ¨¡å‹å’Œæ›´é•¿è®­ç»ƒè¿‡ç¨‹ï¼Œè¿˜å¯èƒ½å‡ºç°æœªé¢„è§çš„ä¸ç¨³å®šï¼Œéœ€è¦é¢å¤–è°ƒä¼˜ã€‚æ–¹æ³•æœ¬èº«æ²¡æœ‰æä¾›å…³äºè¿™äº›æ–¹é¢çš„ä¿è¯ã€‚\nè¯„ä¼°èŒƒå›´æœ‰é™ï¼šä½œè€…ä¸»è¦å…³æ³¨æ¨¡å‹ç²¾åº¦å’Œé€Ÿåº¦ï¼Œå¯¹æ¨¡å‹äº§ç”Ÿçš„å…¶ä»–å½±å“å¦‚æ³›åŒ–ã€é²æ£’æ€§ã€åè§ç­‰æœªåšè®¨è®ºã€‚å¤§æ¨¡å‹å¾€å¾€å¸¦æ¥å‚æ•°å¤šã€è¡¨è¾¾èƒ½åŠ›å¼ºçš„åŒæ—¶ï¼Œä¹Ÿå¯èƒ½è®°å¿†è®­ç»ƒæ•°æ®æˆ–æ”¾å¤§åè§ã€‚Megatron-LMè®­ç»ƒå‡ºçš„æ¨¡å‹åœ¨è¿™äº›æ–¹é¢çš„è¡Œä¸ºæ²¡æœ‰åœ¨è®ºæ–‡ä¸­æ¢è®¨ï¼Œè¿™å±äºæ–¹æ³•åœ¨å®é™…åº”ç”¨ä¸­çš„å±€é™å’Œé£é™©ã€‚\n\nä¸ƒã€ä¸šå†…ç›¸å…³å·¥ä½œå¯¹æ¯”\nå¤§è§„æ¨¡æ¨¡å‹è®­ç»ƒæ˜¯è¿‘å¹´AIç ”ç©¶çš„çƒ­ç‚¹ï¼ŒMegatron-LMä¸å…¶ä»–ä¸€äº›å¹¶è¡ŒåŒ–æˆ–æ¨¡å‹å‹ç¼©æ€è·¯æœ‰æ‰€åŒºåˆ«å’Œå…³è”ã€‚ä¸‹é¢é€‰å–å‡ é¡¹åŒæœŸæˆ–ç›¸å…³å·¥ä½œè¿›è¡Œå¯¹æ¯”ï¼š\n\nGPipe (2018) â€“ æµæ°´çº¿å¹¶è¡Œï¼šGoogleæå‡ºçš„GPipeå°†æ¨¡å‹ä¸åŒå±‚åˆ‡åˆ†åˆ°ä¸²è¡Œçš„è®¾å¤‡ä¸Šï¼Œé‡‡ç”¨å¾®æ‰¹æ¬¡æµæ°´çº¿æ–¹å¼æ¥å¹¶è¡Œè®­ç»ƒã€‚å…¶é—®é¢˜å®šä¹‰åŒä¸ºçªç ´å•å¡å†…å­˜é™åˆ¶ï¼Œä½†æ–¹æ³•è·¯çº¿ä¸åŒï¼šGPipeä¸»æ‰“è·¨å±‚å¹¶è¡Œï¼Œå°†æ¨¡å‹åˆ†æ®µè€ŒMegatron-LMä¸»æ‰“å±‚å†…å¹¶è¡Œï¼Œåœ¨æ¯å±‚å†…éƒ¨åˆ‡åˆ†çŸ©é˜µã€‚GPipeéœ€è¦å°†æ¨¡å‹é‡æ„ä¸ºpipelineå¹¶ç®¡ç†â€œbubbleâ€å»¶è¿Ÿï¼Œè€ŒMegatron-LMåªéœ€åœ¨å±‚å†…æ’å…¥é€šä¿¡ã€‚ä¸¤è€…å¯ç»„åˆï¼ˆæ­£å¦‚Megatronä½œè€…æ‰€è¨€æ¨¡å‹å¹¶è¡Œä¸æµæ°´çº¿å¹¶è¡Œæ­£äº¤ï¼‰ï¼ŒGPipeä¾§é‡å‡å°‘å³°å€¼å†…å­˜ï¼ŒMegatronè¿½æ±‚å……åˆ†åˆ©ç”¨ç®—åŠ›ã€‚ä¸»è§‚è¯„ä»·æ¥çœ‹ï¼ŒGPipeå®ç°å¤æ‚åº¦è¾ƒé«˜ï¼Œéœ€è¦ç‰¹æ®Šæ¡†æ¶æ”¯æŒï¼ˆå¦‚TensorFlow XLAï¼‰ï¼Œè®­ç»ƒæ—¶éœ€è¦å‡è¡¡å„åˆ†æ®µè®¡ç®—è´Ÿè½½ï¼Œå¦åˆ™ä¼šæœ‰æµæ°´ç­‰å¾…ã€‚è€ŒMegatron-LMå®ç°æ›´ç®€æ´ç›´æ¥ï¼Œåœ¨PyTorché‡Œå‡ ä¹å³æ’å³ç”¨ã€‚ä½†GPipeå¯¹é€šä¿¡çš„éœ€æ±‚è¾ƒä½ï¼ˆæ¯é˜¶æ®µä»…éœ€ä¼ é€’æ¿€æ´»ç»™ä¸‹æ¸¸ï¼‰ï¼Œåœ¨è¶…é•¿åºåˆ—æˆ–ææ·±ç½‘ç»œæ—¶å¯èƒ½æ›´é«˜æ•ˆã€‚æ€»ä½“è€Œè¨€ï¼ŒäºŒè€…å„æ“…æ‰€é•¿ï¼Œå¯ç»“åˆç”¨äºæ›´å¤§æ¨¡å‹ï¼šä¸šç•Œå®è·µå¸¸å°†Megatronçš„å¼ é‡å¹¶è¡Œä¸GPipeçš„åˆ†å±‚å¹¶è¡Œä¸€åŒä½¿ç”¨ï¼Œå®ç°2Då¹¶è¡Œæ‰©å±•ã€‚\nMesh-TensorFlow (2018) â€“ å¼ é‡åˆ’åˆ†æ¡†æ¶ï¼šShazeerç­‰æå‡ºçš„Mesh-TensorFlowæä¾›äº†ä¸€ç§åœ¨ä»»æ„åˆ†å¸ƒå¼è®¾å¤‡ç½‘æ ¼ï¼ˆmeshï¼‰ä¸Šåˆ’åˆ†å¼ é‡çš„æ–¹æ³•ã€‚å®ƒçš„é—®é¢˜å®šä¹‰ä¹Ÿæ˜¯åœ¨ä¸åŒè®¾å¤‡é—´åˆ’åˆ†æ¨¡å‹å¼ é‡ï¼Œæ–¹æ³•ä¸Šé€šè¿‡åœ¨TensorFlowä¸­å£°æ˜å¼ é‡çš„åˆ†å¸ƒç»´åº¦ï¼Œç”±XLAç¼–è¯‘å™¨è‡ªåŠ¨ç”Ÿæˆå¹¶è¡Œæ‰§è¡Œè®¡åˆ’ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒMegatron-LMæ˜¯æ‰‹å·¥åœ¨PyTorchä¸­æ’å…¥é€šä¿¡å®ç°å¹¶è¡Œï¼ŒMesh-TFåˆ™é«˜åº¦ä¾èµ–ç¼–è¯‘å™¨ä¼˜åŒ–ã€‚Mesh-TFçš„å¯ç»„åˆæ€§å¼ºï¼Œå¯ä»¥æ”¯æŒå¤šç§å¹¶è¡Œæ¨¡å¼æ··åˆï¼Œä½†éœ€è¦ä½¿ç”¨å…¶DSLé‡æ–°å®šä¹‰æ¨¡å‹ï¼Œå®šåˆ¶æˆæœ¬é«˜ã€‚Megatron-LMæ³¨é‡æ˜“ç”¨ï¼Œåœ¨PyTorchåŸç”Ÿæ¨¡å‹ä¸Šç¨åŠ ä¿®æ”¹å³å¯ã€‚ä¸»è§‚è¯„ä»·ï¼ŒMesh-TFä½œä¸ºé€šç”¨æ¡†æ¶çµæ´»å¼ºå¤§ï¼Œæ”¯æŒä¾‹å¦‚TPUä¸Šçš„å¹¶è¡Œå¹¶æ›¾ç”¨äºè°·æ­Œçš„T5ç­‰æ¨¡å‹è®­ç»ƒï¼›ä½†è°ƒè¯•å’Œå®ç°éš¾åº¦è¾ƒå¤§ï¼Œæ¨¡å‹å¼€å‘è€…éœ€è¦ç†è§£å¹¶è¡Œå¸ƒå±€æ¦‚å¿µã€‚è€ŒMegatron-LMèƒœåœ¨å®ç”¨æ•ˆç‡ï¼Œé’ˆå¯¹Transformerè¿™ç§è§„åˆ™æ¨¡å‹ç»™å‡ºäº†ç°æˆä¼˜åŒ–æ–¹æ¡ˆã€‚Mesh-TFä¾é XLAï¼ŒæŸç§ç¨‹åº¦ä¸Šé¢„ç¤ºäº†æœªæ¥æ·±åº¦å­¦ä¹ ç¼–è¯‘å™¨çš„æ–¹å‘ï¼›Megatron-LMåˆ™åœ¨å½“æ—¶ç¡¬ä»¶è½¯ä»¶æ¡ä»¶ä¸‹åŠæ—¶æä¾›äº†å¯è½åœ°çš„æ–¹æ¡ˆã€‚\nDeepSpeed ZeRO (2020) â€“ ä¼˜åŒ–å™¨çŠ¶æ€å¹¶è¡Œï¼šå¾®è½¯æå‡ºçš„ZeROä¼˜åŒ–å™¨å±äºæ•°æ®å¹¶è¡Œå†…å­˜ä¼˜åŒ–èŒƒç•´ã€‚å®ƒä¸Megatron-LMé—®é¢˜å®šä¹‰çš„å…±åŒç‚¹åœ¨äºéƒ½è§£å†³GPUæ˜¾å­˜ä¸è¶³é™åˆ¶å¤§æ¨¡å‹è®­ç»ƒï¼Œä½†è·¯çº¿æˆªç„¶ä¸åŒï¼šZeROé€šè¿‡åˆ’åˆ†ä¼˜åŒ–å™¨çŠ¶æ€å’Œæ¢¯åº¦æ¥é™ä½æ¯å¼ å¡çš„å†…å­˜å ç”¨ï¼Œä¸æ”¹å˜æ¨¡å‹æœ¬èº«çš„å¹¶è¡Œè®¡ç®—é¡ºåºã€‚ç®€è¨€ä¹‹ï¼ŒZeROä»æ˜¯æ•°æ®å¹¶è¡Œè®­ç»ƒï¼Œåªæ˜¯åœ¨æ¯æ­¥åå°†å„å¡çš„æ¢¯åº¦å’Œä¼˜åŒ–å™¨ç´¯ç§¯ä¿¡æ¯åˆ†æ‘Šå­˜å‚¨ã€‚è¿™æ ·æ¯å¼ å¡åªéœ€ç»´æŠ¤å…¨å±€1/æµ·é‡çš„æ•°æ®å‰¯æœ¬ï¼Œä»è€Œæ”¯æŒæ›´å¤§æ¨¡å‹ã€‚ZeROä¸Megatronå…·å¤‡å¾ˆå¼ºçš„å¯ç»„åˆæ€§ï¼šäº‹å®ä¸Šè®¸å¤šè®­ç»ƒæ ˆåŒæ—¶é‡‡ç”¨Megatronçš„æ¨¡å‹å¹¶è¡Œå’ŒZeROçš„ä¼˜åŒ–å™¨ç¢ç‰‡åŒ–ï¼Œä½¿å¾—æ¨¡å‹å‚æ•°ã€æ¢¯åº¦ã€ä¼˜åŒ–å™¨éƒ½å¾—åˆ°å……åˆ†å¹¶è¡Œã€‚ä¸»è§‚ä¸Šçœ‹ï¼ŒZeROå¯¹ç°æœ‰è®­ç»ƒä»£ç æ”¹åŠ¨è¾ƒå°‘ï¼ˆåˆ©ç”¨DeepSpeedåº“å°è£…å®ç°ï¼‰ï¼Œä½†å®ƒéœ€è¦é¢‘ç¹é€šä¿¡åŒæ­¥ç¢ç‰‡åŒ–çš„æ¢¯åº¦ï¼Œé€šä¿¡é‡éšå‚æ•°å¢é•¿çº¿æ€§ä¸Šå‡ï¼Œå¯¹ç½‘ç»œä¾èµ–å¤§ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒMegatronåœ¨é™ä½é€šä¿¡é¢‘æ¬¡æ–¹é¢åšäº†ä¼˜åŒ–ï¼ˆæ¯å±‚2æ¬¡All-Reduceå›ºå®šï¼‰ã€‚ä¸¤è€…çš„æ€æƒ³å¯ä»¥ç»“åˆï¼šMegatronè§£å†³è®¡ç®—å’Œå‰å‘å†…å­˜ï¼ŒZeROè§£å†³æ¢¯åº¦å’Œä¼˜åŒ–å™¨å†…å­˜ï¼Œå…±åŒçªç ´å¤šæ–¹é¢ç“¶é¢ˆã€‚æœªæ¥ä¸Šç™¾äº¿å‚æ•°æ¨¡å‹è®­ç»ƒä¸­ï¼Œæ··åˆå¼ é‡å¹¶è¡Œ+ZeROå·²æˆä¸ºäº‹å®æ ‡å‡†é…ç½®ã€‚\nALBERT (2019) â€“ å‚æ•°å…±äº«å‹ç¼©ï¼šLanç­‰æå‡ºçš„ALBERTé’ˆå¯¹BERTæ¨¡å‹è§„æ¨¡ç“¶é¢ˆï¼Œé‡‡ç”¨è·¨å±‚å‚æ•°å…±äº«å’Œå‘é‡åˆ†è§£åµŒå…¥ç­‰æ–¹æ³•å‡å°‘å‚æ•°æ€»é‡ï¼Œä»¥æå‡æ¨¡å‹è®­ç»ƒå¯è¡Œæ€§ã€‚å®ƒè§£å†³çš„æ˜¯ç±»ä¼¼é—®é¢˜ï¼ˆBERTè¶…è¿‡BERT-Largeåæ•ˆæœä¸‹é™å’Œèµ„æºä¸è¶³ï¼‰ï¼Œä½†æ–¹æ³•ä¸æ˜¯å¹¶è¡Œè®­ç»ƒï¼Œè€Œæ˜¯æ”¹å˜æ¨¡å‹ç»“æ„ä½¿å‚æ•°æ›´å°‘ã€æ›´é«˜æ•ˆã€‚ä¾‹å¦‚å°†æ¯å±‚Transformeræƒé‡å…±äº«ï¼Œä»è€Œå¤§å¹…å‡å°‘å‚æ•°é‡ã€‚Megatron-LMå’ŒALBERTå¯ä»¥è¯´å–å¾„ç›¸åï¼šä¸€ä¸ªæ˜¯é€šè¿‡å¢åŠ ç¡¬ä»¶èµ„æºå¹¶è¡Œä»¥å®¹çº³æ›´å¤šå‚æ•°ï¼Œä¸€ä¸ªæ˜¯é€šè¿‡ä¼˜åŒ–ç½‘ç»œè®¾è®¡åœ¨åŒæ ·èµ„æºä¸‹å‡å°‘å‚æ•°ã€‚è¿™ä¸¤ç§å¯ä¸€å®šç¨‹åº¦ç»„åˆï¼ˆæ¯”å¦‚ä½¿ç”¨æ¨¡å‹å¹¶è¡Œè®­ç»ƒALBERTä¹Ÿå¯è¿›ä¸€æ­¥æé«˜æ•ˆç‡ï¼‰ï¼Œä½†å› ä¸ºALBERTå‡å°‘å‚æ•°ä¹Ÿæ„å‘³ç€å®¹é‡ä¸‹é™ï¼Œåæ¥çš„å®è·µè¯æ˜ä¸å…±äº«å‚æ•°çš„å¤§æ¨¡å‹å¾€å¾€æ•ˆæœæ›´å¥½ã€‚å› æ­¤Megatronçš„æ–¹æ³•æ›´åå‘â€œç”¨ç¡¬ä»¶ brute force å®ç°æ•ˆæœæå‡â€ï¼Œè€ŒALBERTå±äºâ€œå·§å¦™è®¾è®¡æ¨¡å‹å‹ç¼©â€ã€‚ä¸»è§‚è¯„ä»·ï¼ŒALBERTå¯¹å­¦æœ¯ç ”ç©¶æœ‰æ„ä¹‰ï¼Œå¯å‘äº†å‚æ•°é«˜æ•ˆåˆ©ç”¨çš„æ€è·¯ï¼Œä½†åœ¨çœŸæ­£è¿½æ±‚SOTAæ—¶è¿˜æ˜¯æ›´å¤§çš„éå…±äº«æ¨¡å‹èƒœå‡ºã€‚Megatron-LMä»£è¡¨çš„è·¯çº¿è·¯å¾„åœ¨åæ¥å±…ä¸Šï¼Œè¯æ˜äº†åªè¦èƒ½è®­ç»ƒï¼Œå¤§æ¨¡å‹çš„æ•ˆæœç»ˆå°†ä¼˜äºå°æ¨¡å‹+å‚æ•°å…±äº«ã€‚\n\n7.1 ä¸ªäººè§‚ç‚¹\nç»¼è§‚è¿™äº›å·¥ä½œï¼ŒMegatron-LMä»¥å…¶å®ç”¨æ€§å’Œé«˜æ•ˆæ€§èƒ½è„±é¢–è€Œå‡ºã€‚ä½œä¸ºè¯»è€…ï¼Œæˆ‘è®¤ä¸ºå…¶æˆåŠŸåœ¨äºæ´æ‚‰å¹¶å¹³è¡¡äº†è®¡ç®—ä¸é€šä¿¡ï¼šä¸åƒæ—©æœŸæ¡†æ¶é‚£æ ·å¼ºä¾èµ–æ–°ç¼–è¯‘æŠ€æœ¯ï¼Œè€Œæ˜¯é¡ºåº”å½“ä¸‹PyTorchç”Ÿæ€ï¼Œç”¨æœ€å°æ”¹åŠ¨æ¢å–å·¨å¤§æ”¶ç›Šã€‚è¿™ç§â€œä»¥å·¥ç¨‹æ¢æ€§èƒ½â€çš„åšæ³•éå¸¸ç°å®ï¼Œä½“ç°äº†å·¥ä¸šç•ŒèƒŒæ™¯ç ”ç©¶äººå‘˜çš„æ€è·¯ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒGPipeå’ŒMesh-TFæ›´å…·å‰ç»æ€§ä½†å®ç°é—¨æ§›é«˜ã€æ³›ç”¨æ€§æœ‰é™ã€‚Megatron-LMçš„æ–¹æ¡ˆåˆ™å¿«äººä¸€æ­¥æ»¡è¶³äº†è®­ç»ƒGTçº§æ¨¡å‹çš„ç‡ƒçœ‰ä¹‹æ€¥ï¼Œè¿™ä¹Ÿæ˜¯åæ¥è®¸å¤šå¤§å‹æ¨¡å‹ç›´æ¥é‡‡ç”¨å®ƒçš„åŸå› ã€‚\nå¦‚æœä»æ”¹è¿›ç©ºé—´æ¥çœ‹ï¼Œæˆ‘ä¸ªäººè§‰å¾—Megatron-LMè¿˜æœ‰ä»¥ä¸‹å¯ä»¥è¿›ä¸€æ­¥å®Œå–„ä¹‹å¤„ï¼š\n\nè‡ªåŠ¨åŒ–ç¨‹åº¦ï¼šç›®å‰å¹¶è¡Œåˆ’åˆ†éœ€è¦äººå…ˆéªŒæŒ‡å®šï¼ˆå¦‚æ¨¡å‹å¹¶è¡Œåº¦ã€åˆ†ç»„å¤§å°ï¼‰ã€‚æœªæ¥æˆ‘ä¼šè€ƒè™‘è®¾è®¡è‡ªåŠ¨å¹¶è¡Œè§„åˆ’ç®—æ³•ï¼Œæ ¹æ®é›†ç¾¤æ‹“æ‰‘å’Œæ¨¡å‹ç»“æ„è‡ªåŠ¨å†³å®šåˆ‡åˆ†ç­–ç•¥ï¼Œå‡å°‘äººå·¥è¯•é”™ã€‚ä¾‹å¦‚å¯ä»¥å€Ÿé‰´å¯å‘å¼æœç´¢æˆ–ä½¿ç”¨profilingæ•°æ®æ¥åˆ†é…æœ€ä¼˜å¹¶è¡Œç»´åº¦ç»„åˆã€‚\nå†…å­˜ä¼˜åŒ–é›†æˆï¼šæ­£å¦‚ZeROæ‰€è§£å†³çš„ï¼Œæ¨¡å‹å¹¶è¡Œå°šæœªå¤„ç†ä¼˜åŒ–å™¨å’Œæ¢¯åº¦çš„å†…å­˜ã€‚æˆ‘ä¼šåœ¨MegatronåŸºç¡€ä¸Šé›†æˆZeROæˆ–ç±»ä¼¼æŠ€æœ¯ï¼Œç”šè‡³åœ¨æ¨¡å‹å¹¶è¡Œä¸­å¼•å…¥æ¢¯åº¦ç‰‡æ®µAll-Gatherï¼Œä½¿å¾—æ— è®ºæ­£å‘è¿˜æ˜¯åå‘ï¼Œå„éƒ¨åˆ†å†…å­˜éƒ½èƒ½è¢«ä¸åŒGPUåˆ†æ‹…ã€‚è¿™æ ·èƒ½å¤Ÿè¿›ä¸€æ­¥æå‡å•æœºèƒ½æ”¯æŒçš„å‚æ•°ä¸Šé™ï¼Œä¹Ÿå‡å°‘æ¯å¼ å¡çš„å†…å­˜å‹åŠ›ï¼Œé™ä½OOMé£é™©ã€‚\né€šä¿¡ä¸è®¡ç®—é‡å ï¼šè™½ç„¶è®ºæ–‡å·²æœ‰éƒ¨åˆ†é‡å ï¼ˆä¾‹å¦‚ä¸‹ä¸€å±‚è®¡ç®—å¯åœ¨ç­‰å¾…All-Reduceæ—¶æå‰ï¼‰ï¼Œä½†æˆ‘è®¤ä¸ºä»æœ‰ç©ºé—´é€šè¿‡å¼‚æ­¥é€šä¿¡ã€å‹ç¼©é€šä¿¡ç­‰æ–¹å¼å‰Šå‡åŒæ­¥å¼€é”€ã€‚æ¯”å¦‚å¯¹æ¢¯åº¦All-Reduceä½¿ç”¨ä½ç²¾åº¦å‹ç¼©ã€åˆ†æ®µé€šä¿¡ï¼Œä»è€Œåœ¨ä¸æŸå¤±å¤šå°‘ç²¾åº¦ä¸‹è¿›ä¸€æ­¥æé«˜æ‰©å±•æ•ˆç‡ã€‚å¦‚æœç½‘ç»œå¸¦å®½æˆä¸ºç“¶é¢ˆï¼Œä¹Ÿå¯è€ƒè™‘æ‹“æ‰‘æ„ŸçŸ¥çš„é€šä¿¡è®¡åˆ’ï¼Œè®©é€šä¿¡åˆ©ç”¨åˆ†å¸ƒå¼ç¼“å­˜æˆ–NVSwitchæ›´é«˜æ•ˆã€‚\nè®­ç»ƒç¨³å®šæ€§ç ”ç©¶ï¼šLayerNormçš„ä½ç½®åªæ˜¯ä¸€ä¸ªå› ç´ ï¼Œæˆ‘å€¾å‘äºç³»ç»Ÿæ€§åœ°ç ”ç©¶è¶…å¤§æ¨¡å‹è®­ç»ƒä¸­çš„ä¸ç¨³å®šæ¥æºï¼Œå¦‚ä¼˜åŒ–å™¨è¶…å‚æ•°ã€åˆå§‹åŒ–æ–¹æ¡ˆã€æ¢¯åº¦è£å‰ªé˜ˆå€¼ç­‰ï¼Œå¹¶é’ˆå¯¹æ€§æå‡ºæ”¹è¿›ã€‚Megatron-LMä¸­å¯ä»¥åŠ å…¥è‡ªé€‚åº”ä¼˜åŒ–è°ƒæ•´æ¨¡å—ï¼Œç›‘æ§æ¢¯åº¦èŒƒæ•°å’Œlossæ›²çº¿ï¼Œä¸€æ—¦æ£€æµ‹åˆ°ä¸ç¨³å®šå¾å…†è‡ªåŠ¨è°ƒæ•´å­¦ä¹ ç‡æˆ–grad clippingï¼Œä»¥æå‡å¤§è§„æ¨¡è®­ç»ƒçš„é²æ£’æ€§ã€‚\nè·¨ç¡¬ä»¶æ”¯æŒï¼šç›®å‰Megatron-LMä¸»è¦é’ˆå¯¹NVIDIA GPUã€‚æˆ‘ä¼šè€ƒè™‘å¦‚ä½•è®©ç±»ä¼¼æ€æƒ³æ‹“å±•åˆ°TPUã€ä»¥åŠæ–°çš„AIåŠ é€Ÿå™¨ä¸Šï¼ŒåŒ…æ‹¬åº”å¯¹ä¸åŒç¡¬ä»¶çš„é€šä¿¡æœºåˆ¶å’Œå†…å­˜æ¶æ„ã€‚è®©å¹¶è¡Œæ–¹æ¡ˆå…·æœ‰ç¡¬ä»¶æ— å…³æ€§ï¼Œå°†ä½¿å…¶å¯¹æ›´å¹¿æ³›çš„è®­ç»ƒç¯å¢ƒé€‚ç”¨ï¼Œä¹Ÿæœ‰åˆ©äºå­¦æœ¯ç•Œç”¨TPU podç­‰èµ„æºå¤ç°ã€‚\n\næ€»çš„æ¥è¯´ï¼ŒMegatron-LMçš„æ€è·¯éå¸¸å€¼å¾—å€Ÿé‰´ã€‚æˆ‘åœ¨é˜…è¯»å’Œæ€è€ƒè¿‡ç¨‹ä¸­æ„Ÿå—åˆ°ï¼Œåœ¨AIæ¨¡å‹è§„æ¨¡æ¼”è¿›ä¸­ï¼Œç³»ç»Ÿä¼˜åŒ–å’Œæ¨¡å‹è®¾è®¡å¿…é¡»ååŒæ¨è¿›ã€‚æœ‰æ—¶ç¡¬ä»¶èµ„æºçš„æŠ•å…¥å’Œå·§å¦™çš„å¹¶è¡Œè®¡ç®—è®¾è®¡æœ¬èº«å°±æ˜¯æ¨åŠ¨ç®—æ³•èƒ½åŠ›çš„å…³é”®å› ç´ ã€‚ä½œä¸ºç ”ç©¶è€…ï¼Œæˆ‘ä¹Ÿä¼šè€ƒè™‘åœ¨è‡ªå·±å®éªŒä¸­åˆ©ç”¨ç±»ä¼¼æ¨¡å‹å¹¶è¡ŒæŠ€å·§æ¥å°è¯•è®­ç»ƒæ›´å¤§çš„æ¨¡å‹ï¼Œå¹¶ç•™æ„å¯èƒ½å‡ºç°çš„æ•°å€¼å’Œå·¥ç¨‹é—®é¢˜ï¼ŒåŠæ—¶åº”ç”¨è®ºæ–‡ä¸­çš„ç»éªŒæ¥è§£å†³ã€‚\nå…«ã€åœ¨å®é™…è®­ç»ƒæ ˆä¸­å¦‚ä½•è½åœ°ï¼Ÿ\nå°†Megatron-LMçš„æ–¹æ³•åº”ç”¨åˆ°å®é™…è®­ç»ƒæ ˆï¼Œéœ€è¦ç»¼åˆè€ƒè™‘æ•°æ®å¤„ç†ã€å¹¶è¡Œè°ƒåº¦ã€åº•å±‚ç®—å­å’Œç³»ç»Ÿå·¥ç¨‹ç­‰å¤šæ–¹é¢ã€‚ä»¥ä¸‹æŒ‰ç…§å…³é”®ç¯èŠ‚åˆ†ç±»è¯´æ˜å…¶è½åœ°æ–¹å¼ã€æ‰€éœ€çš„å·¥ç¨‹å·¥ä½œé‡ä»¥åŠæ½œåœ¨é£é™©ç‚¹ï¼š\n\næ•°æ®è½½å…¥ä¸æ ·æœ¬æ‰“åŒ…ï¼šå®é™…è®­ç»ƒæ—¶ï¼Œæ•°æ®ç®¡çº¿éœ€è¦ç¡®ä¿åœ¨å¤šæœºå¤šå¡ç¯å¢ƒä¸‹é«˜æ•ˆä¾›ç»™æ ·æœ¬ã€‚ä¸€æ–¹é¢ï¼Œéœ€è¦ä½¿ç”¨åˆ†å¸ƒå¼æ•°æ®åŠ è½½ï¼ˆä¾‹å¦‚PyTorchçš„DistributedSamplerï¼‰è®©æ¯ä¸ªæ•°æ®å¹¶è¡Œç»„è¯»å–ä¸åŒåˆ†ç‰‡çš„æ•°æ®ï¼Œä»è€Œæ•´ä½“æ¶µç›–å¤§æ•°æ®é›†ï¼›å¦ä¸€æ–¹é¢ï¼Œåœ¨æ¨¡å‹å¹¶è¡Œç»„å†…éƒ¨ï¼ŒåŒç»„GPUåº”æ¥æ”¶å®Œå…¨ç›¸åŒçš„è¾“å…¥æ‰¹æ¬¡ã€‚è¿™é€šå¸¸é€šè¿‡åœ¨ä¸€ä¸ªç»„çš„ä¸»è¿›ç¨‹ä¸ŠåŠ è½½æ•°æ®ï¼Œç„¶åå°†è¯¥batchå¹¿æ’­åˆ°ç»„å†…å…¶ä»–è¿›ç¨‹å®ç°ã€‚å·¥ç¨‹ä¸Šéœ€è¦ä»”ç»†å¤„ç†éšæœºæ•°ç§å­ã€æ•°æ®shuffleä¸€è‡´æ€§ç­‰ï¼Œä»¥å…ä¸åŒGPUçœ‹åˆ°ä¸åŒé¡ºåºçš„æ•°æ®å¯¼è‡´æ¢¯åº¦ä¸å¯¹é½ã€‚æ­¤å¤–ï¼Œå¯¹äºè‡ªå›å½’è¯­è¨€æ¨¡å‹ï¼Œå¸¸ç”¨æ•°æ®æ‰“åŒ…ï¼ˆPackingï¼‰æŠ€å·§å°†å¤šæ®µæ–‡æœ¬æ‹¼æ¥æˆé•¿åºåˆ—ä»¥å……åˆ†åˆ©ç”¨ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œæé«˜æ•ˆç‡ã€‚è¿™éœ€è¦DataLoaderæ”¯æŒæŒ‰epoché¢„å¤„ç†æˆ–åŠ¨æ€æ‰“åŒ…ã€‚é£é™©åœ¨äºï¼šæ•°æ®I/Oå¯èƒ½æˆä¸ºç“¶é¢ˆï¼Œå¦‚æœä¸èƒ½æä¾›ç¨³å®šçš„é«˜ååè¯»å–ï¼ˆä¾‹å¦‚NVMe SSDæˆ–é«˜é€Ÿç½‘ç»œæ–‡ä»¶ç³»ç»Ÿï¼‰ï¼ŒGPUä¼šå› ç­‰å¾…æ•°æ®è€Œç©ºè½¬ã€‚è§£å†³æ–¹æ³•åŒ…æ‹¬é¢„å…ˆå¤„ç†æ•°æ®ä¸ºå†…å­˜æ˜ å°„æ ¼å¼ã€å¯ç”¨å¤šçº¿ç¨‹/å¤šè¿›ç¨‹è¯»å–ç”šè‡³é‡‡ç”¨Streamingæ–¹å¼æŒ‰éœ€æ‹‰å–æ•°æ®ã€‚æ€»ä½“æ¥è¯´ï¼Œè¿™ä¸€é˜¶æ®µéœ€è¦å·¥ç¨‹å›¢é˜Ÿç¡®ä¿æ•°æ®æµæ°´çº¿è¶³å¤Ÿå¼ºå£®ï¼Œå¯æŒç»­åœ°å–‚é¥±æ•°ç™¾GPUã€‚\nå¹¶è¡Œè°ƒåº¦ (DP/TP/PP/CP)ï¼šåœ¨å¤šå¹¶è¡ŒèŒƒå¼ç»“åˆä¸‹ï¼Œè°ƒåº¦å’Œåè°ƒå˜å¾—å¤æ‚ã€‚å®é™…è½åœ°æ—¶ï¼Œé€šå¸¸ä½¿ç”¨å¼€æºè®­ç»ƒæ¡†æ¶ï¼ˆå¦‚NVIDIA Megatron-LMåº“ã€DeepSpeedã€Horovodç­‰ï¼‰æ¥éšè—ç»†èŠ‚ã€‚ç”¨æˆ·é€šè¿‡é…ç½®å¹¶è¡Œåº¦å‚æ•°ï¼ˆå¦‚å¼ é‡å¹¶è¡Œå¤§å°ã€æµæ°´å¹¶è¡Œé˜¶æ®µæ•°ã€æ•°æ®å¹¶è¡Œè¿›ç¨‹æ•°ã€ä¸Šä¸‹æ–‡å¹¶è¡Œå¤§å°ï¼‰å³å¯å¯åŠ¨è®­ç»ƒã€‚èƒŒåæ¡†æ¶ä¼šåˆ’åˆ†MPIé€šä¿¡ç»„æˆ–è¿›ç¨‹ç»„ï¼šä¾‹å¦‚512 GPUå¯ä»¥æŒ‰8GPUä¸€ç»„æ„æˆ64ç»„è¿›è¡Œå¼ é‡å¹¶è¡Œï¼Œå†å°†è¿™64ç»„åˆ†åˆ«ç»„åˆæˆè‹¥å¹²æµæ°´çº¿é˜¶æ®µï¼Œç­‰ç­‰ã€‚è¿™æ ·æ¯ä¸ªGPUæœ‰å¤šä¸ªèº«ä»½ï¼ˆæ‰€åœ¨çš„DPç»„ã€TPç»„ã€PPç»„ç­‰ï¼‰ï¼Œæ¡†æ¶è´Ÿè´£åœ¨æ°å½“çš„é˜¶æ®µè°ƒç”¨NCCLé€šä¿¡ã€‚å·¥ç¨‹ä¸Šéœ€è¦éªŒè¯è¿™äº›ç»„çš„åˆ’åˆ†æ˜¯å¦æ­£ç¡®åŒ¹é…ç¡¬ä»¶æ‹“æ‰‘ï¼Œä¾‹å¦‚å°½é‡è®©åŒä¸€æ¨¡å‹å¹¶è¡Œç»„çš„GPUåœ¨åŒä¸€æœåŠ¡å™¨æˆ–åŒä¸€InfiniBandäº¤æ¢æœºä¸‹ï¼Œä»¥é™ä½è·¨èŠ‚ç‚¹é€šä¿¡å»¶è¿Ÿã€‚å¹¶è¡Œè°ƒåº¦éƒ¨åˆ†è¿˜æœ‰ä¸€ä¸ªéš¾ç‚¹æ˜¯é”™è¯¯å¤„ç†ï¼šåœ¨è¶…å¤§è§„æ¨¡è¿è¡Œä¸­ï¼Œä»»ä¸€èŠ‚ç‚¹æ•…éšœéƒ½å¯èƒ½å¯¼è‡´æ•´ä½“å´©æºƒï¼Œéœ€è¦æœ‰æ£€æŸ¥ç‚¹æ¢å¤ï¼ˆè§åï¼‰ä»¥åŠå¼¹æ€§è®­ç»ƒçš„è€ƒè™‘ã€‚å¦‚æœä½¿ç”¨è¯¸å¦‚PyTorch DDPï¼Œè‡ªèº«æœ‰åŸºæœ¬çš„å®¹é”™ä½†è¿˜ä¸å®Œå–„ï¼Œå·¥ç¨‹ä¸Šå¯èƒ½éœ€è¦è„šæœ¬ç›‘æ§è®­ç»ƒè¿›ç¨‹ã€å‡ºç°å®•æœºè‡ªåŠ¨é‡å¯å¹¶åŠ è½½æœ€è¿‘checkpointï¼Œä»¥å‡å°‘é•¿æ—¶é—´è®­ç»ƒä¸­æ–­çš„æŸå¤±ã€‚å¹¶è¡Œè°ƒåº¦çš„æ­£ç¡®æ€§ä¸æ•ˆç‡ç›´æ¥å†³å®šäº†è®­ç»ƒèƒ½å¦é¡ºåˆ©è¿è¡Œå’Œè¾¾åˆ°è®ºæ–‡ä¸­çš„æ‰©å±•æ•ˆç‡æŒ‡æ ‡ï¼Œè¿™æ˜¯è½åœ°ä¸­çš„å…³é”®ç¯èŠ‚ä¹‹ä¸€ã€‚\nç®—å­å®ç°ä¸Kernelä¼˜åŒ–ï¼šMegatron-LMä¾èµ–çš„ä¸€äº›å…³é”®ç®—å­å¦‚GEMMã€LayerNormåœ¨æ·±åº¦å­¦ä¹ æ¡†æ¶ä¸­å·²æœ‰é«˜æ•ˆå®ç°ã€‚ä½†ä¸ºäº†è¿›ä¸€æ­¥æå‡æ€§èƒ½ï¼Œå·¥ç¨‹å®è·µä¸­å¾€å¾€ä¼šå¼•å…¥è‡ªå®šä¹‰Kernelæˆ–èåˆå†…æ ¸ã€‚ä¾‹å¦‚ï¼Œé‡‡ç”¨CUDAå†…æ ¸å®ç°QKVæŠ•å½±çš„èåˆï¼Œå°†åŸæœ¬ä¸‰ä¸ªçŸ©é˜µä¹˜åˆå¹¶ä¸ºä¸€ä¸ªä»¥å‡å°‘å†…å­˜è¯»å†™ï¼›åˆå¦‚å°†BiasåŠ å’ŒDropoutèåˆè¿›GEMMè¾“å‡ºï¼Œä»¥å‡å°‘ä¸­é—´ç»“æœå­˜å–ã€‚è¿™äº›ä¼˜åŒ–åœ¨NVIDIAçš„APExåº“ã€FlashAttentionç­‰é¡¹ç›®ä¸­å·²æœ‰ç¤ºä¾‹ã€‚å°†å…¶åº”ç”¨åœ¨è®­ç»ƒæ ˆä¸­éœ€è¦ç†Ÿæ‚‰CUDAç¼–ç¨‹å¹¶æ·±åˆ»ç†è§£æ¨¡å‹è®¡ç®—æµç¨‹ã€‚åœ¨æ²¡æœ‰è¿™äº›ä¼˜åŒ–æ—¶ï¼ŒMegatron-LMä¹Ÿèƒ½è¿è¡Œï¼Œä½†å…¶FLOPsåˆ©ç”¨ç‡å¯èƒ½è¾¾ä¸åˆ°æœ€ä¼˜ã€‚é€‰æ‹©æ ¸å¿ƒç®—å­åšå®šåˆ¶ä¼˜åŒ–å¾€å¾€å¸¦æ¥5-20%çš„æ€§èƒ½æå‡ã€‚ç›¸åº”çš„é£é™©æ˜¯å¼•å…¥è‡ªå®šä¹‰ç®—å­å¯èƒ½å¼•å‘æ•°å€¼è¯¯å·®ç§¯ç´¯æˆ–è°ƒè¯•å›°éš¾ï¼Œéœ€è¦ç¡®ä¿å…¶ä¸æ ‡å‡†å®ç°ç»“æœä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œä¸åŒGPUæ¶æ„ï¼ˆå¦‚A100, H100ï¼‰å¯èƒ½éœ€è¦é‡æ–°è°ƒä¼˜å†…æ ¸å‚æ•°æ‰èƒ½å‘æŒ¥æœ€ä½³æ€§èƒ½ã€‚å› æ­¤å·¥ç¨‹å›¢é˜Ÿéœ€è¦è¯„ä¼°æ”¶ç›Šå’Œç»´æŠ¤æˆæœ¬ï¼Œåœ¨è¿½æ±‚æè‡´æ€§èƒ½æ—¶æŠ•å…¥Kernelä¼˜åŒ–èµ„æºã€‚åœ¨ç®—å­æ–¹é¢å¦ä¸€ä¸ªè€ƒè™‘æ˜¯æ··åˆç²¾åº¦ï¼šæ¡†æ¶åº”ä½¿ç”¨FP16/BF16è¿›è¡ŒçŸ©é˜µè¿ç®—ï¼ŒåŒæ—¶ä¿è¯LayerNormã€æ®‹å·®ç´¯åŠ åœ¨FP32ç´¯ç§¯é¿å…ç²¾åº¦æŸå¤±ã€‚è¿™äº›ç»†èŠ‚é€šå¸¸ç”±æ¡†æ¶çš„AMP (Automatic Mixed Precision)æ¨¡å—å¤„ç†ï¼Œä½†åœ¨å¤§è§„æ¨¡å¹¶è¡Œæƒ…å†µä¸‹ï¼Œéœ€è¦ç¡®ä¿æ‰€æœ‰rankä¸€è‡´è¿›è¡Œloss scalingç­‰æ“ä½œï¼Œé¿å…ä¸ªåˆ«GPUä¸Šæº¢æˆ–ä¸‹æº¢å¯¼è‡´æ¢¯åº¦å¼‚å¸¸ã€‚\né€šä¿¡æ¨¡å¼ä¸Collectiveæ“ä½œï¼šå¤§è§„æ¨¡è®­ç»ƒä¸­é€šä¿¡å¾€å¾€æˆä¸ºæ€§èƒ½ç“¶é¢ˆï¼Œå› æ­¤åœ¨å·¥ç¨‹ä¸Šéœ€è¦ç²¾å¿ƒè®¾è®¡å’Œé…ç½®é€šä¿¡backendã€‚NCCLæ˜¯äº‹å®æ ‡å‡†ï¼Œå®ƒä¼šä¾æ®æ‹“æ‰‘è‡ªåŠ¨é€‰æ‹©All-Reduceç®—æ³•ï¼ˆç¯å½¢ã€æ ‘å½¢ã€æ··åˆæ‹“æ‰‘ç­‰ï¼‰ã€‚å¯¹äº512å¡è¿™ç§è§„æ¨¡ï¼Œå¤šæœºå¤šå±‚äº¤æ¢æœºæ‹“æ‰‘ä¸‹ï¼ŒNCCLå¯èƒ½ä½¿ç”¨åˆ†çº§All-Reduceï¼ˆå…ˆæœºæ¶å†…ã€å†æœºæ¶é—´ï¼‰ã€‚å·¥ç¨‹å®è·µä¸­ï¼Œåº”ç»‘å®šCPUäº²å’Œã€åˆ’åˆ†é€šä¿¡è½¨é“ï¼šä¾‹å¦‚åœ¨NVSwitch/InfiniBandåŒæ—¶å­˜åœ¨æ—¶ï¼Œè®©äº¤å‰èŠ‚ç‚¹é€šä¿¡ç”¨PCIe+InfiniBandï¼Œæœºå†…ç”¨NVLinkï¼Œé¿å…èµ„æºäº‰ç”¨ã€‚å¦å¤–å¯ä»¥ä½¿ç”¨åˆ†ç»„All-Reduceï¼ˆHierarchical Reductionï¼‰ä¼˜åŒ–å»¶è¿Ÿã€‚é…ç½®æ–¹é¢ï¼Œéœ€è¦ç¡®ä¿MPIæˆ–torch.distributedåˆå§‹åŒ–é€šä¿¡æ—¶ï¼Œç¯å¢ƒå˜é‡å¦‚NCCL_TREE_THRESHOLDç­‰è°ƒä¼˜å¾—å½“ã€‚å¾ˆå¤šè®­ç»ƒæ¡†æ¶ï¼ˆMegatron-LM, DeepSpeedï¼‰ä¼šç»™å‡ºæ¨èNCCLå‚æ•°å’Œlaunchè„šæœ¬ã€‚é€šä¿¡é‡å ä¹Ÿæ˜¯å·¥ç¨‹å…³æ³¨ç‚¹ï¼Œå³åœ¨GPUæ‰§è¡Œè®¡ç®—çš„åŒæ—¶ï¼Œé€šä¿¡åœ¨åå°æµå¼è¿›è¡Œã€‚PyTorchçš„å¼‚æ­¥é€šä¿¡ä»¥åŠCUDAæµçš„æ­£ç¡®ä½¿ç”¨å¯ä»¥å®ç°è®¡ç®—-é€šä¿¡å¹¶è¡Œã€‚é£é™©æ–¹é¢ï¼Œé€šä¿¡æœ€æ€•é‡åˆ°æ­»é”æˆ–hangï¼šä»»ä½•ä¸€æ¬¡All-Reduceç­‰å¾…ä¸åˆ°å¯¹ç«¯éƒ½ä¼šå…¨ä½“å¡ä½ã€‚è¿™é€šå¸¸ç”±å¹¶è¡Œä»£ç é€»è¾‘é”™è¯¯æˆ–ç½‘ç»œä¸ç¨³å®šå¼•èµ·ã€‚å·¥ç¨‹ä¸Šéœ€è¦å…·å¤‡é€šä¿¡debugèƒ½åŠ›ï¼Œä¾‹å¦‚ä½¿ç”¨NCCL_DEBUG=INFOè·Ÿè¸ªæ¯æ¬¡é€šä¿¡è°ƒåº¦ï¼Œæˆ–è€…ä½¿ç”¨å·¥å…·æ£€æŸ¥ç½‘ç»œå¥åº·åº¦ã€‚é›†ç¾¤ç¯å¢ƒçš„å¤æ‚æ€§ä¹Ÿæ„å‘³ç€å¯èƒ½å‡ºç°å¸¦å®½è·‘ä¸æ»¡çš„æƒ…å†µï¼Œå¦‚PCIeæ‹“æ‰‘æ¬¡ä¼˜å¯¼è‡´NCCLæ•ˆç‡ä½ï¼Œè¿™éœ€è¦åœ¨éƒ¨ç½²å‰é€šè¿‡é€šä¿¡benchmarksæµ‹è¯•åŠ ä»¥è°ƒæ•´ã€‚æ€»ä¹‹ï¼Œåœ¨è½åœ°é˜¶æ®µï¼Œå¯¹é€šä¿¡éƒ¨åˆ†è¦æŠ•å…¥ä¸“é—¨å·¥ç¨‹ç²¾åŠ›ä¼˜åŒ–ï¼Œæ¯æé«˜ç™¾åˆ†ä¹‹ä¸€çš„é“¾è·¯åˆ©ç”¨ç‡ï¼Œå¯¹åº”æ•´ä½“ååæå‡å¯èƒ½å°±æ˜¯æ•°å°æ—¶è®­ç»ƒæ—¶é—´çš„èŠ‚çœã€‚\né…ç½®æœç´¢ä¸è‡ªåŠ¨è°ƒå‚ï¼šè¶…å¤§è§„æ¨¡è®­ç»ƒæ¶‰åŠä¼—å¤šå¯è°ƒå‚æ•°ï¼ŒåŒ…æ‹¬å¹¶è¡Œå‚æ•°ï¼ˆDP/TP/PPåˆ’åˆ†æ–¹æ¡ˆã€micro-batchå¤§å°ç­‰ï¼‰ã€ä¼˜åŒ–å™¨å‚æ•°ï¼ˆå­¦ä¹ ç‡ã€betaã€weight decayï¼‰ã€è°ƒåº¦ç­–ç•¥ï¼ˆå­¦ä¹ ç‡warmupã€æ¢¯åº¦è£å‰ªé˜ˆå€¼ï¼‰ç­‰ã€‚è¿™äº›å‚æ•°åœ¨å¤§æ¨¡å‹æƒ…å¢ƒä¸‹å½¼æ­¤å½±å“å¤æ‚ã€‚ä¾‹å¦‚ï¼Œæ€»æ‰¹æ¬¡å¤§å°=å¾®æ‰¹å¤§å°Ã—æ•°æ®å¹¶è¡Œåº¦ï¼Œè¿‡å¤§å¯èƒ½å¯¼è‡´æ³›åŒ–å˜å·®ï¼Œè¿‡å°åˆæ— æ³•å……åˆ†åˆ©ç”¨ç®—åŠ›ã€‚è½åœ°æ—¶ï¼Œå¾€å¾€éœ€è¦è¿›è¡Œä¸€äº›è¶…å‚æœç´¢æˆ–å€Ÿé‰´ç»éªŒå€¼ã€‚è®¸å¤šå›¢é˜Ÿä¼šåŸºäºè®ºæ–‡æä¾›çš„è®¾ç½®ä½œä¸ºèµ·ç‚¹ï¼ˆå¦‚Megatron-LMä½œè€…ç»™å‡ºçš„3.9B BERTåœ¨512GPUä¸Šçš„å­¦ä¹ ç‡å’Œæ‰¹é‡é…ç½®ï¼‰ï¼Œç„¶ååœ¨æœ¬ä»»åŠ¡ä¸Šå¾®è°ƒã€‚è‡ªåŠ¨è°ƒå‚æ–¹é¢ï¼Œå¯ä»¥è€ƒè™‘ä½¿ç”¨å·¥å…·ï¼ˆå¦‚Optunaæˆ–è‡ªå®šä¹‰è„šæœ¬ï¼‰å¯¹å…³é”®å‚æ•°åšç½‘æ ¼æˆ–è´å¶æ–¯ä¼˜åŒ–ï¼Œä½†ç”±äºæ¯æ¬¡è¯•éªŒæˆæœ¬æé«˜ï¼ˆè®­ç»ƒä¸€ä¸ªæ¨¡å‹éœ€æ•°å¤©ï¼‰ï¼Œè°ƒå‚åŸºæœ¬ä¸Šä¾èµ–ç»éªŒå’Œå±€éƒ¨è¯•æ¢ã€‚ä¸ºäº†å‡å°‘åå¤å°è¯•ï¼Œå®è·µä¸­å¸¸æ¸è¿›æ‰©å±•ï¼šå…ˆç”¨è¾ƒå°‘GPUæˆ–å°æ¨¡å‹è¯•è¿è¡ŒéªŒè¯ï¼Œå†æŒ‰æ¯”ä¾‹æ”¾å¤§é…ç½®ã€‚è¿™éœ€è¦æ³¨æ„ä¸€äº›éçº¿æ€§å˜åŒ–ï¼šæ¯”å¦‚æ›´å¤šGPUæ—¶é€‚å½“æé«˜å­¦ä¹ ç‡ï¼Œä½†ä¸èƒ½çº¿æ€§æé«˜ï¼Œå¦åˆ™æŸå¤±å¯èƒ½éœ‡è¡ã€‚é£é™©æ˜¯ï¼Œå¦‚æœé…ç½®ä¸å½“ï¼Œå¤§è§„æ¨¡è®­ç»ƒå¯èƒ½ä¸­é€”å‘æ•£ï¼Œå¯¼è‡´è®¡ç®—èµ„æºæµªè´¹ã€‚å› æ­¤åœ¨å‘èµ·å¤§Jobä¹‹å‰ï¼Œå·¥ç¨‹å›¢é˜Ÿä¼šå……åˆ†éªŒè¯é…ç½®çš„ç¨³å®šæ€§ï¼Œç›‘æ§åˆæœŸlossæ›²çº¿ï¼Œå¿…è¦æ—¶ä¸­æ­¢è°ƒæ•´ã€‚å¼•å…¥è‡ªåŠ¨åŒ–è°ƒå‚å¯ä»¥åœ¨ä¸€å®šç¨‹åº¦ä¸Šç¼“è§£äººå·¥è´Ÿæ‹…ï¼Œä½†ä»éœ€äººå·¥æ™ºæ…§ä»‹å…¥å…³é”®å†³ç­–ã€‚å¯¹å®é™…è®­ç»ƒæ ˆè€Œè¨€ï¼Œå»ºç«‹ä¸€å¥—é…ç½®åŸºçº¿å’Œç›‘æ§æŠ¥è­¦ç³»ç»Ÿå°¤ä¸ºé‡è¦ï¼Œä¸€æ—¦æ£€æµ‹åˆ°è®­ç»ƒæŒ‡æ ‡å¼‚å¸¸ï¼ˆå¦‚lossçˆ†ç‚¸ï¼‰ï¼Œèƒ½åŠæ—¶ä»‹å…¥è°ƒæ•´ï¼Œé¿å…é•¿æ—¶é—´è®¡ç®—æµªè´¹åœ¨é”™è¯¯çš„å‚æ•°ä¸Šã€‚\nCheckpoint ä¸å®¹é”™æ¢å¤ï¼šå¤§æ¨¡å‹è®­ç»ƒé€šå¸¸æŒç»­æ•°å‘¨ï¼ŒæœŸé—´å¯èƒ½å› ä¸ºä½œä¸šè°ƒåº¦ã€ç¡¬ä»¶æ•…éšœç­‰åŸå› ä¸­æ–­ã€‚å› æ­¤å®ç°å¯é çš„æ–­ç‚¹ç»­è®­(checkpointing)æœºåˆ¶æ˜¯è½åœ°å¿…å¤‡ã€‚Megatron-LMçš„è®­ç»ƒæ ˆä¼šå®šæœŸä¿å­˜æ¨¡å‹checkpointï¼ŒåŒ…æ‹¬æ¨¡å‹å„åˆ†ç‰‡æƒé‡ã€ä¼˜åŒ–å™¨çŠ¶æ€ã€éšæœºæ•°ç§å­ç­‰ã€‚å·¥ç¨‹ä¸Šè¦ç¡®ä¿æ¯ä¸ªæ¨¡å‹å¹¶è¡ŒGPUå°†è‡ªå·±çš„æƒé‡å¿«ç…§ä¿å­˜åˆ°å­˜å‚¨ï¼ˆé€šå¸¸æ¯ä¸ªrankä¸€ä¸ªæ–‡ä»¶ï¼‰ï¼Œæ–‡ä»¶å‘½åå’Œç›®å½•ç»“æ„è¦æ¸…æ™°ï¼ˆä¾‹å¦‚åŒ…å«è¿­ä»£å·å’Œrank idï¼‰ã€‚ç”±äºå•ä¸ªæ¨¡å‹æƒé‡å°±å¯èƒ½æ•°åGBï¼Œ512 GPUå†™checkpointéœ€è¦å¹¶è¡ŒIOï¼Œè¿™å¯¹æ–‡ä»¶ç³»ç»Ÿæ˜¯å·¨å¤§å‹åŠ›ã€‚ç»éªŒä¸Šéœ€è¦é…ç½®é«˜æ€§èƒ½å¹¶è¡Œå­˜å‚¨ï¼ˆå¦‚Lustreã€BeeGFSï¼‰æˆ–è€…åˆ†æ•£æ¯èŠ‚ç‚¹æœ¬åœ°å­˜å‚¨ç„¶åå†æ±‡æ€»ã€‚Checkpointé¢‘ç‡éœ€è¦æƒè¡¡ï¼šè¿‡äºé¢‘ç¹ä¼šä¸¥é‡æ‹–æ…¢è®­ç»ƒï¼ˆæ¯æ¬¡å¯èƒ½è€—æ—¶æ•°åˆ†é’Ÿï¼‰ï¼Œå¤ªå°‘åˆ™ä¸€æ—¦ä¸­æ–­æŸå¤±è¿›åº¦è¿‡å¤šã€‚å¸¸è§ç­–ç•¥æ˜¯åœ¨è®­ç»ƒæ—©æœŸé¢‘ç¹checkpointï¼ˆæ¨¡å‹ä¸ç¨³å®šå®¹æ˜“å‘æ•£æ—¶å¯ä»¥å›é€€ï¼‰ï¼ŒåæœŸæ”¶æ•›å¥½äº†é€‚å½“æ‹‰é•¿é—´éš”ã€‚æ¢å¤æ—¶ï¼Œè®­ç»ƒæ¡†æ¶åº”èƒ½æ–¹ä¾¿åœ°åŠ è½½å…ˆå‰ä¿å­˜çš„åˆ‡ç‰‡æ¨¡å‹ã€‚Megatron-LMæä¾›äº†åˆ†å¸ƒå¼åŠ è½½åŠŸèƒ½ï¼Œå³æ¯ä¸ªGPUåªè¯»å–å±äºè‡ªå·±çš„å‚æ•°æ–‡ä»¶ä»¥é‡å»ºä¼˜åŒ–å™¨å’Œæ¨¡å‹çŠ¶æ€ã€‚å·¥ç¨‹è½åœ°éœ€è¦æµ‹è¯•è¿™ä¸€è¿‡ç¨‹ï¼Œç¡®ä¿è·¨ç‰ˆæœ¬å…¼å®¹ã€æ–­ç‚¹æ–‡ä»¶å¯é æ€§ã€‚å¦ä¸€ä¸ªå®¹é”™ç‚¹æ˜¯ç¬æ—¶é€šä¿¡é”™è¯¯æˆ–å•æœºæ‰çº¿ï¼Œå¦‚ä½•è‡ªåŠ¨æ¢å¤ã€‚é€šå¸¸é…åˆä¸Šå±‚ä½œä¸šè°ƒåº¦å™¨å®ç°ï¼šæ¯”å¦‚æ£€æµ‹åˆ°æŸGPUå¤±è”ï¼Œåˆ™é‡å¯æ•´ä¸ªMPIä½œä¸šä»ä¸Šä¸€ä¸ªcheckpointç»§ç»­ã€‚ç†æƒ³æƒ…å†µä¸‹ï¼Œå¯è¡Œçš„æ”¹è¿›æ˜¯å®ç°å±€éƒ¨æ•…éšœéš”ç¦»ï¼Œä¾‹å¦‚æŸèŠ‚ç‚¹æ‰çº¿èƒ½å¦ç”¨å†—ä½™èŠ‚ç‚¹æ¥æ›¿å¹¶åŠ è½½å¯¹åº”checkpointç»§ç»­è®­ç»ƒï¼Œè€Œä¸å¿…æ•´ä¸ªjobé‡å¯ã€‚ä½†å½“å‰è®­ç»ƒæ ˆæ”¯æŒæœ‰é™ï¼Œå¤§å¤šé‡‡ç”¨å…¨ä½œä¸šé‡å¯ç­–ç•¥ï¼Œè¿™ä¼šé€ æˆæ•°åˆ†é’Ÿåˆ°æ•°å°æ—¶çš„æŸè€—ï¼ˆé‡å¯åŠ é‡æ–°åˆ†é…èµ„æºæ—¶é—´ï¼‰ã€‚å› æ­¤ï¼Œæé«˜å®¹é”™æ€§çš„å…³é”®åœ¨äºåŠ å¿«checkpointå’Œæ¢å¤é€Ÿåº¦ï¼Œä»¥åŠæé«˜é›†ç¾¤ç¨³å®šæ€§ã€‚å·¥ç¨‹ä¸Šä¼šåœ¨è®­ç»ƒå‰åšå‹åŠ›æµ‹è¯•ç¡®ä¿ç¡¬ä»¶å¯é ï¼Œå¹¶åœ¨è®­ç»ƒä¸­å®æ—¶ç›‘æ§èµ„æºçŠ¶å†µï¼Œå°½é‡æå‰é¢„é˜²æ•…éšœã€‚æ€»è€Œè¨€ä¹‹ï¼Œåœ¨å®é™…è½åœ°æ—¶ï¼Œéœ€è¦å°†checkpointæœºåˆ¶èå…¥è®­ç»ƒLoopï¼Œä½œä¸ºå’Œå‰å‘åå‘åŒç­‰é‡è¦çš„ä¸€éƒ¨åˆ†æ¥å¯¹å¾…ï¼Œæ‰èƒ½ä¿è¯é•¿æ—¶é—´çš„å¤§è§„æ¨¡è®­ç»ƒé¡ºåˆ©å®Œæˆã€‚\n\nä»¥ä¸Šå„æ–¹é¢æ„æˆäº†ä¸€ä¸ªå¤§å‹æ¨¡å‹è®­ç»ƒæ ˆè½åœ°Megatron-LMæ–¹æ³•æ‰€éœ€çš„å·¥ç¨‹å·¥ä½œã€‚å¯ä»¥çœ‹åˆ°ï¼Œè½åœ°å¹¶éæ˜“äº‹ï¼šæ—¢è¦å†™ä»£ç å±‚é¢çš„å®ç°ï¼Œåˆè¦è€ƒè™‘åˆ†å¸ƒå¼ç³»ç»Ÿè°ƒä¼˜ï¼Œè¿˜è¦å‡†å¤‡æ•…éšœé¢„æ¡ˆã€‚è¿™ä¹Ÿè§£é‡Šäº†ä¸ºä½•æœ‰äº†è®ºæ–‡æ–¹æ³•åï¼Œä¸šå†…ä»èŠ±è´¹å¤§é‡ç²¾åŠ›æ‰“é€ å®Œå–„çš„è®­ç»ƒæ¡†æ¶ï¼ˆå¦‚Megatron-LMåº“ã€DeepSpeedã€Horovodç­‰ï¼‰æ¥æ”¯æ’‘è¿™äº›éœ€æ±‚ã€‚å¯¹äºä¸€ä¸ªå…¸å‹çš„è®­ç»ƒå›¢é˜Ÿæ¥è¯´ï¼Œå……åˆ†åˆ©ç”¨å·²æœ‰å¼€æºå·¥å…·å¹¶æ ¹æ®è‡ªå·±é›†ç¾¤ç‰¹ç‚¹åšé’ˆå¯¹æ€§ä¼˜åŒ–ï¼Œæ˜¯å®è·µä¸­è¡Œä¹‹æœ‰æ•ˆçš„ç­–ç•¥ã€‚\nä¹ã€å€¼å¾—è¿›ä¸€æ­¥æ¢ç´¢çš„ç ”ç©¶æ–¹å‘\né¢å‘æœªæ¥çš„å¤§æ¨¡å‹è®­ç»ƒï¼ŒMegatron-LMæ‰“å¼€äº†ä¸€ä¸ªèµ·ç‚¹ï¼Œä½†ä»æœ‰è®¸å¤šæ–¹å‘å€¼å¾—æ·±å…¥ï¼Œä»¥æå‡æ€§èƒ½ã€é™ä½æˆæœ¬å¹¶æ‰©å±•é€‚ç”¨æ€§ï¼š\n\nè‡ªåŠ¨å¹¶è¡Œåˆ’åˆ†ä¸ç¼–è¯‘ä¼˜åŒ–ï¼šå‘å±•æ™ºèƒ½çš„å¹¶è¡Œåˆ’åˆ†ç®—æ³•ï¼Œå°†æ‰‹å·¥æŒ‡å®šå¹¶è¡Œåº¦è½¬å˜ä¸ºç¼–è¯‘å™¨è‡ªåŠ¨æ¢ç´¢ã€‚è¿™æ–¹é¢å¯ä»¥å€Ÿé‰´DeepMindçš„GSPMDã€OpenAIçš„FTXç¼–è¯‘ç­‰ï¼Œè®©ç³»ç»Ÿæ ¹æ®æ¨¡å‹è®¡ç®—å›¾è‡ªåŠ¨å†³å®šåœ¨å“ªäº›ç»´åº¦åˆ‡åˆ†ã€ä½•æ—¶æ’å…¥All-Reduceï¼Œç”šè‡³å¼•å…¥å¼ é‡åˆ‡ç‰‡è¯­è¨€ä½¿å¼€å‘è€…å£°æ˜å¹¶è¡Œç­–ç•¥ã€‚è‡ªåŠ¨åŒ–å¹¶è¡Œèƒ½æå‡æ˜“ç”¨æ€§ï¼Œå‡å°‘äººä¸ºè°ƒå‚ï¼Œå¹¶å¯èƒ½æ‰¾åˆ°éç›´è§‰çš„æ€§èƒ½æœ€ä¼˜åˆ’åˆ†æ–¹æ¡ˆï¼Œæé«˜ç¡¬ä»¶åˆ©ç”¨ç‡ã€‚\næ›´å¤§è§„æ¨¡ä¸æ··åˆå¹¶è¡Œç­–ç•¥ï¼šæŒç»­æ¢ç´¢ç™¾äº¿åˆ°åƒäº¿å‚æ•°æ¨¡å‹çš„é«˜æ•ˆè®­ç»ƒæ–¹æ¡ˆã€‚ç›®å‰æ™®éé‡‡ç”¨çš„æ•°æ®+å¼ é‡+æµæ°´çº¿ä¸‰é‡å¹¶è¡Œå¯ä»¥è¿›ä¸€æ­¥æ‰©å±•ï¼Œæ¯”å¦‚å¼•å…¥MoEä¸“å®¶å¹¶è¡Œï¼ˆå°†æ¨¡å‹ä¸åŒéƒ¨åˆ†è·¯ç”±åˆ°ä¸åŒä¸“å®¶æ¨¡å—ï¼‰æˆ–Sequence Parallelï¼ˆåºåˆ—å¹¶è¡Œï¼‰ï¼ˆåœ¨åºåˆ—é•¿åº¦ç»´åº¦æ‹†åˆ†è®¡ç®—ï¼‰ç­‰æ–°å¹¶è¡Œç»´åº¦ã€‚è¿™äº›æ··åˆç­–ç•¥æœ‰æœ›çªç ´å•ä¸€å¹¶è¡ŒèŒƒå¼çš„ç“¶é¢ˆï¼Œä½¿å¾—è®­ç»ƒæ›²çº¿åœ¨å¢åŠ è®¡ç®—èµ„æºåä¿æŒæ¥è¿‘çº¿æ€§ã€‚ç‰¹åˆ«æ˜¯å¯¹äºè¶…è¿‡GPUæ˜¾å­˜å¤šä¸ªæ•°é‡çº§çš„å¤§æ¨¡å‹ï¼Œç»“åˆåˆ†å¸ƒå¼å­˜å‚¨ã€CPUå†…å­˜æ¢å…¥æ¢å‡ºç­‰æŠ€æœ¯ï¼Œä¹Ÿæ˜¯é‡è¦æ–¹å‘ã€‚ç›®æ ‡æ˜¯åœ¨ä¸ç‰ºç‰²è®­ç»ƒé€Ÿåº¦çš„æƒ…å†µä¸‹ï¼Œå®ç°å‚æ•°è§„æ¨¡å†æå‡ä¸€ä¸ªæ•°é‡çº§ï¼ŒåŒæ—¶å°½é‡å‡å°‘é€šä¿¡å¼€é”€çš„è¶…çº¿æ€§å¢é•¿ã€‚\né€šä¿¡ä¼˜åŒ–ä¸ç½‘ç»œæ¶æ„å…±è®¾ï¼šéšç€å¹¶è¡Œè§„æ¨¡æ‰©å¤§ï¼Œé€šä¿¡æˆæœ¬å¯èƒ½è·ƒå‡ä¸ºä¸»è¦çŸ›ç›¾ã€‚å› æ­¤ï¼Œä¸€ä¸ªæ–¹å‘æ˜¯åœ¨è½¯ç¡¬ä»¶ä¸¤ç«¯ä¼˜åŒ–é€šä¿¡æ•ˆç‡ã€‚åœ¨è½¯ä»¶ä¸Šï¼Œå¯ä»¥ç ”ç©¶æ–°çš„é€šä¿¡ç®—æ³•ï¼ˆä¾‹å¦‚åˆ†ç»„All-Reduceã€æ··åˆæ‹“æ‰‘è°ƒåº¦ï¼‰ä»¥åŠé€šä¿¡å‹ç¼©æŠ€æœ¯ï¼ˆå¦‚8-bitæˆ–æ¢¯åº¦æˆªæ–­å‹ç¼©ï¼‰æ¥é™ä½å¸¦å®½éœ€æ±‚ã€‚åœ¨ç¡¬ä»¶ä¸Šï¼Œæ¨åŠ¨æ›´é«˜é€Ÿä½å»¶è¿Ÿçš„äº’è”ï¼ˆå¦‚NVLinkæ›´æ–°ã€æ›´å¼ºå¤§çš„äº¤æ¢æœºæ¶æ„ï¼‰å’Œç½‘ç»œæ‹“æ‰‘æ„ŸçŸ¥çš„è°ƒåº¦ï¼Œå‡å°‘è¿œè·ç¦»é€šä¿¡å æ¯”ã€‚è¿™éœ€è¦æœºå™¨å­¦ä¹ å’Œç³»ç»Ÿæ¶æ„ç¤¾åŒºååŒåˆ›æ–°ã€‚ä¾‹å¦‚ï¼ŒNVIDIAè¿‘æœŸæå‡ºçš„NVLink Switchå’Œåˆ†å¸ƒå¼Shard TraderæŠ€æœ¯ï¼Œå°±æ˜¯æœç€é™ä½å¤§è§„æ¨¡é€šä¿¡å¼€é”€è¿ˆè¿›ã€‚é€šä¿¡ä¼˜åŒ–ç›´æ¥å…³ç³»åˆ°æ€§èƒ½å’Œæˆæœ¬æ¯”ï¼šæå‡5-10%é€šä¿¡æ•ˆç‡ï¼Œåœ¨æ•°æœˆçš„è®­ç»ƒä½œä¸šä¸­å°†èŠ‚çœå¯è§‚çš„æ—¶é—´ä¸ç»è´¹ã€‚\nè®­ç»ƒé²æ£’æ€§ä¸å®¹é”™ï¼šå½“è®­ç»ƒè·¨è¶Šæˆç™¾ä¸ŠåƒGPUã€å†æ—¶æ•°å‘¨ï¼Œå¦‚ä½•ä¿è¯è®­ç»ƒè¿‡ç¨‹ä¸å› é”™è¯¯ä¸­æ–­ä¸”æ¨¡å‹æ”¶æ•›ç¨³å¥æ˜¯é‡å¤§è¯¾é¢˜ã€‚ä¸€æ–¹é¢ï¼Œå¯ä»¥æ¢ç´¢åˆ†å¸ƒå¼è®­ç»ƒçš„å®¹é”™ç®—æ³•ï¼Œä¾‹å¦‚å±€éƒ¨checkpointã€å†—ä½™è®¡ç®—ã€æŒ‰éœ€é‡æ–°åŒæ­¥ç­‰ï¼Œä½¿å¾—å¶å‘çš„èŠ‚ç‚¹æ•…éšœä¸ä¼šå¯¼è‡´æ•´ä¸ªè®­ç»ƒåœæ‘†ã€‚è°·æ­Œçš„Checkpointingå¾®è°ƒå’Œè®ºæ–‡å·²ç»æœ‰åˆæ­¥æ¢è®¨ï¼Œä½†ä»æœ‰æ”¹è¿›ç©ºé—´ã€‚å¦ä¸€æ–¹é¢ï¼Œè¶…é•¿æ—¶é—´è®­ç»ƒä¸‹æ¨¡å‹å¯èƒ½å‡ºç°æ„å¤–çš„ä¸ç¨³å®šï¼ˆå¦‚çªç„¶lossçˆ†ç‚¸ï¼‰ã€‚å¼€å‘åœ¨çº¿ç›‘æ§å’Œè‡ªé€‚åº”è°ƒæ•´ç³»ç»Ÿï¼ŒåŸºäºæ£€æµ‹åˆ°çš„å‘æ•£å¾å…†è‡ªåŠ¨é‡‡å–æªæ–½ï¼ˆé™ä½å­¦ä¹ ç‡ã€é‡ç½®æ¢¯åº¦ç­‰ï¼‰æå‡é²æ£’æ€§ã€‚å¢å¼ºå®¹é”™å’Œé²æ£’æ€§æ„å‘³ç€æ›´é«˜çš„è®­ç»ƒæˆåŠŸç‡å’Œèµ„æºåˆ©ç”¨ç‡ï¼Œå¯¹äºå·¥ä¸šç•Œçš„å¤§æ¨¡å‹è®­ç»ƒä»»åŠ¡æœ‰å·¨å¤§çš„å®é™…ä»·å€¼ã€‚\nèƒ½æ•ˆå’Œæˆæœ¬ä¼˜åŒ–ï¼šå¤§æ¨¡å‹è®­ç»ƒæˆæœ¬é«˜æ˜‚ï¼Œå› æ­¤æœªæ¥ä¸€ä¸ªé‡è¦æ–¹å‘æ˜¯æå‡èƒ½æ•ˆå’Œé™ä½æˆæœ¬ã€‚è¿™åŒ…æ‹¬ç®—æ³•å±‚é¢çš„æ”¹è¿›ï¼Œå¦‚åˆ©ç”¨ä½ç²¾åº¦è®¡ç®—ï¼ˆFP8ã€INT8æ··åˆè®­ç»ƒï¼‰ã€ç¨€ç–æ¿€æ´»æˆ–ç½‘ç»œå‰ªæåœ¨è®­ç»ƒä¸­åŠ¨æ€é™ä½è®¡ç®—é‡ï¼Œä»¥åŠä¼˜åŒ–å™¨å±‚é¢çš„é©æ–°ï¼ˆå¦‚æ›´å¿«é€Ÿæ”¶æ•›çš„æ–°ä¼˜åŒ–ç®—æ³•å‡å°‘è¿­ä»£æ¬¡æ•°ï¼‰ã€‚ä¹ŸåŒ…å«å·¥ç¨‹å±‚é¢ï¼Œå¦‚æ›´å¥½åœ°åˆ©ç”¨äº‘é—²ç½®ç®—åŠ›ã€æŒ‰éœ€å¼¹æ€§æ‰©å±•/æ”¶ç¼©GPUæ•°ä»¥ä¼˜åŒ–èµ„æºã€‚åœ¨èƒ½è€—æ–¹é¢ï¼Œå¯ä»¥ç ”ç©¶å°†éƒ¨åˆ†è®¡ç®—ç§»åˆ°æ›´èƒ½æ•ˆæ¯”é«˜çš„ç¡¬ä»¶ï¼ˆå¦‚TPUï¼‰æˆ–åœ¨å†·å´ã€ä¾›ç”µä¸Šåšç³»ç»Ÿä¼˜åŒ–ã€‚ç»ˆæç›®æ ‡æ˜¯åœ¨ä¿è¯æ¨¡å‹æ€§èƒ½çš„åŒæ—¶ï¼Œè®©æ¯æå‡1ç‚¹å‡†ç¡®ç‡æ‰€èŠ±çš„ç¾å…ƒå’Œç¢³æ’æ”¾å°½å¯èƒ½å‡å°‘ã€‚è¿™ä¸ä»…å¯¹ä¼ä¸šæˆæœ¬é‡è¦ï¼Œä¹Ÿæ˜¯AIå¯æŒç»­å‘å±•çš„è¦æ±‚ã€‚\n\nä»¥ä¸Šç ”ç©¶æ–¹å‘å„æœ‰ä¾§é‡ï¼šæœ‰çš„ç€çœ¼äºæ€§èƒ½æé™ï¼Œæœ‰çš„æŒ‡å‘è®­ç»ƒç¨³å®šå’Œæ˜“ç”¨ï¼Œä¹Ÿæœ‰çš„å…³æ³¨ç°å®æˆæœ¬ä¸å¯æŒç»­æ€§ã€‚å¯ä»¥é¢„è§ï¼Œå¯¹è¿™äº›æ–¹å‘çš„æ¢ç´¢å°†ç›¸äº’ä¿ƒè¿›ï¼Œæ„æˆæœªæ¥å‡ å¹´è¶…å¤§è§„æ¨¡æ¨¡å‹è®­ç»ƒæŠ€æœ¯çš„ä¸»æ—‹å¾‹ã€‚\nåã€çŸ¥è¯†å›¾è°±æ€ç»´é“¾\nåœ¨æœ¬è®ºæ–‡ä¸ç›¸å…³èƒŒæ™¯ä¸­ï¼Œå¯ä»¥æ„å»ºå¦‚ä¸‹çš„çŸ¥è¯†è„‰ç»œé“¾æ¡ï¼Œå°†é—®é¢˜ã€æ–¹æ³•ä¸æ•ˆæœä¸²è”èµ·æ¥ï¼š\n\næ¨¡å‹è§„æ¨¡å—é™ (å†…å­˜ç“¶é¢ˆ) â†’ å¼•å…¥å¹¶è¡ŒåŒ–ç­–ç•¥æ‰“ç ´é™åˆ¶ â†’ æ¨¡å‹å¹¶è¡Œ (å¼ é‡å¹¶è¡Œ) å°†å•å±‚è®¡ç®—åˆ†ç‰‡è‡³å¤šè®¾å¤‡ â†’ å•è®¾å¤‡å†…å­˜å‹åŠ›é™ä½ï¼Œè®­ç»ƒè¶…å¤§æ¨¡å‹æˆä¸ºå¯èƒ½\nTransformer ç»“æ„è§„åˆ™ â†’ è®¡ç®—å¯æ‹†è§£ä¸ºç‹¬ç«‹éƒ¨åˆ† + å°‘é‡åŒæ­¥ (All-Reduce) â†’ å±€éƒ¨è®¡ç®— + å…¨å±€é€šä¿¡ å¹¶è¡ŒèŒƒå¼æˆç«‹ â†’ å¹¶è¡Œè®¡ç®—ä¸é€šä¿¡åè°ƒå®ç°é«˜æ•ˆæ‰©å±•\nè®¡ç®—èµ„æºå¢åŠ  â†’ å¯è®­ç»ƒæ¨¡å‹å‚æ•°å¢å¤š â†’ æ¨¡å‹æ€§èƒ½æå‡ (å›°æƒ‘åº¦é™ä½ã€ä¸‹æ¸¸ç²¾åº¦æé«˜) â†’ å¤§æ¨¡å‹å±•ç°å‡ºæ›´ä¼˜NLPä»»åŠ¡è¡¨ç°ï¼Œè¯å®â€œè§„æ¨¡æœ‰å¥‡æ•ˆâ€\nBERTå¤§æ¨¡å‹ä¸ç¨³å®š â†’ åˆ†æç“¶é¢ˆ (LayerNormä½ç½®) â†’ æ¶æ„æ”¹è¿› (Pre-LN) æ¶ˆé™¤æ¢¯åº¦é˜»å¡ â†’ æˆåŠŸè®­ç»ƒæ›´å¤§BERTï¼Œæå‡ä¸‹æ¸¸ä»»åŠ¡å‡†ç¡®ç‡\nç³»ç»Ÿå®ç°ä¸ç®—æ³•ç»“åˆ â†’ å¼€æºæ¡†æ¶ (Megatron-LMä»£ç ) å¤ç°æ–¹æ¡ˆ â†’ ç¤¾åŒºè·Ÿè¿› (å„å¤§æ¨¡å‹é‡‡ç”¨ç±»ä¼¼å¹¶è¡Œ) â†’ è¶…å¤§æ¨¡å‹è®­ç»ƒæˆä¸ºæ–°å¸¸æ€ï¼Œæ¨åŠ¨NLP SOTAä¸æ–­åˆ·æ–°\n\nä¸Šè¿°æ€ç»´é“¾è¡¨æ˜ï¼Œä»é—®é¢˜å‡ºå‘ï¼ˆå†…å­˜ä¸è§„æ¨¡ç“¶é¢ˆï¼‰ï¼Œé€šè¿‡æ¨¡å‹å¹¶è¡Œçš„åˆ›æ–°æ‰‹æ®µï¼Œç»“åˆå¯¹Transformerç»“æ„çš„ç†è§£ä¸æ¶æ„è°ƒæ•´ï¼Œæœ€ç»ˆå®ç°äº†å¤§æ¨¡å‹çš„è®­ç»ƒä¸åº”ç”¨çªç ´ã€‚è¿™æ¡è·¯å¾„æ—¢æ¶‰åŠè®¡ç®—æœºä½“ç³»ç»“æ„å’Œå¹¶è¡Œè®¡ç®—çŸ¥è¯†ï¼Œä¹Ÿè´¯ç©¿ç€å¯¹æ·±åº¦å­¦ä¹ æ¨¡å‹è¡Œä¸ºçš„è§‚å¯Ÿå’Œæ”¹è¿›ï¼Œä½“ç°äº†è·¨é¢†åŸŸçš„èåˆåˆ›æ–°ã€‚\n10.1 ä¸ªäººæ”¶è·ä¸åæ€\né˜…è¯»å¹¶æ¶ˆåŒ–Megatron-LMè¿™ç¯‡è®ºæ–‡ï¼Œæˆ‘æ”¶è·è‰¯å¤šã€‚é¦–å…ˆï¼Œå®ƒè®©æˆ‘æ·±åˆ»ä½“ä¼šåˆ°å·¥ç¨‹å®è·µå¯¹AIå‰æ²¿çš„é‡è¦æ€§ï¼šè®¸å¤šçœ‹ä¼¼æ— æ³•çªç ´çš„ç“¶é¢ˆï¼ˆå¦‚æ˜¾å­˜é™åˆ¶ï¼‰å¾€å¾€å¯ä»¥é€šè¿‡å·§å¦™çš„ç³»ç»Ÿè®¾è®¡åŠ ä»¥è§£å†³ï¼Œä»è€ŒæŠŠå­¦æœ¯ä¸Šâ€œæ›´å¤§æ¨¡å‹=æ›´å¥½æ•ˆæœâ€çš„æƒ³æ³•çœŸæ­£è½åœ°æˆä¸ºç°å®ã€‚ä½œè€…åœ¨ä¸å¼•å…¥å…¨æ–°æ¡†æ¶çš„æƒ…å†µä¸‹ï¼Œç”¨å°‘é‡é€šä¿¡æ“ä½œæ”¹å˜äº†æ¸¸æˆè§„åˆ™ï¼Œå¯å‘æˆ‘åœ¨è‡ªå·±ç ”ç©¶ä¸­ä¹Ÿåº”å–„äºåˆ©ç”¨ç°æœ‰å·¥å…·ï¼Œé€šè¿‡å·§æ€æ•´åˆæ¥å®ç°åˆ›æ–°ã€‚\nå…¶æ¬¡ï¼Œæˆ‘åæ€åˆ°ï¼Œå¤§è§„æ¨¡åˆ†å¸ƒå¼è®­ç»ƒéœ€è¦å…¼é¡¾å…¨å±€ä¸å±€éƒ¨ã€‚ä¸€æ–¹é¢è¦ç«™åœ¨æ•´ä½“ç³»ç»Ÿè§’åº¦è€ƒè™‘é€šä¿¡å’Œè®¡ç®—åˆ†å·¥ï¼Œå¦ä¸€æ–¹é¢åˆè¦å¤„ç†åº•å±‚ç»†èŠ‚ï¼ˆå¦‚æ•°å€¼ç¨³å®šæ€§ã€é€šä¿¡æ­»é”ç­‰ï¼‰ã€‚è®ºæ–‡ä¸­é’ˆå¯¹BERT LayerNormçš„å°è°ƒæ•´ï¼Œå°±æ˜¯ä»æ¨¡å‹å†…éƒ¨ç»†èŠ‚å‡ºå‘è§£å†³å¤§é—®é¢˜çš„å…¸å‹ï¼Œè®©æˆ‘æ„è¯†åˆ°å®è§‚æ€§èƒ½æå‡å¾€å¾€ä¾èµ–å¾®è§‚æœºåˆ¶ä¿éšœã€‚è¿™ä¿ƒä½¿æˆ‘åœ¨ä»Šåç ”ç©¶ä¸­ï¼Œä¸ä»…å…³æ³¨ç®—æ³•å±‚åˆ›æ–°ï¼Œä¹Ÿå¤šè€ƒè™‘å®ç°å±‚æŒ‘æˆ˜ï¼Œæå‰è®¾è®¡åº”å¯¹æ–¹æ¡ˆã€‚\næœ€åï¼Œè¿™é¡¹å·¥ä½œä¹Ÿæ¿€å‘äº†æˆ‘å¯¹ååŒä¼˜åŒ–çš„å…´è¶£ã€‚AIæ¨¡å‹ã€è½¯ä»¶æ¡†æ¶ã€ç¡¬ä»¶èµ„æºä¸‰è€…ç›¸è¾…ç›¸æˆï¼Œå…±åŒå†³å®šäº†æœ€ç»ˆæ•ˆæœã€‚Megatron-LMçš„æˆåŠŸå½’åŠŸäºå¯¹Transformerç»“æ„çš„æ´å¯Ÿï¼ˆç®—æ³•ï¼‰å’Œå¯¹PyTorch/NCCLçš„æ·±å…¥æŠŠæ¡ï¼ˆè½¯ä»¶ï¼‰ï¼Œä»¥åŠå……åˆ†åˆ©ç”¨äº†512 GPUé›†ç¾¤ï¼ˆç¡¬ä»¶ï¼‰ã€‚è¿™è®©æˆ‘è®¤è¯†åˆ°ï¼Œåœ¨è¿½æ±‚æè‡´AIæ€§èƒ½æ—¶ï¼Œä»»ä½•å•ä¸€å±‚é¢çš„æ”¹è¿›éƒ½å¯èƒ½ä¸è¶³ï¼Œå”¯æœ‰è”åˆä¼˜åŒ–æ‰èƒ½å–å¾—é£è·ƒã€‚æˆ‘ä¼šå°†è¿™ç§æ€ç»´è¿ç”¨åˆ°è‡ªå·±çš„è¯¾é¢˜ä¸­ï¼Œä¾‹å¦‚è€ƒè™‘æ–°çš„æ¨¡å‹è®¾è®¡æ—¶åŒæ­¥è€ƒè™‘è®­ç»ƒå¹¶è¡Œç­–ç•¥ï¼Œä»ä¸€å¼€å§‹å°±ä¸ºå¤§è§„æ¨¡å®ç°åšå¥½å‡†å¤‡ã€‚\n\næ€»ä½“è€Œè¨€ï¼ŒMegatron-LMè®ºæ–‡åœ¨å·¥ç¨‹å®è·µä¸­æˆåŠŸæ‰©å±•äº†Transformeræ¨¡å‹çš„è§„æ¨¡ä¸Šé™ï¼Œä»¥ç®€æ´æœ‰æ•ˆçš„æ¨¡å‹å¹¶è¡Œç­–ç•¥è®©æ•°åäº¿å‚æ•°çº§çš„è®­ç»ƒæˆä¸ºç°å®ï¼Œä¸ä»…å–å¾—äº†å‡ºè‰²çš„æ€§èƒ½æå‡ï¼Œä¹Ÿä¸ºåæ¥è¶…å¤§æ¨¡å‹çš„è®­ç»ƒæ–¹æ³•å¥ å®šäº†åŸºç¡€ã€‚ç„¶è€Œï¼Œå®ƒä¹Ÿæé†’æˆ‘ä»¬å¤§æ¨¡å‹æ—¶ä»£ä¼´ç”Ÿçš„ç³»ç»Ÿå¤æ‚åº¦å’Œèµ„æºä»£ä»·ï¼Œéœ€è¦æŒç»­çš„æŠ€æœ¯åˆ›æ–°æ¥å¹³è¡¡è§£å†³ã€‚\n\n","categories":["è®ºæ–‡é˜…è¯»"],"tags":["paper"]}]