[{"title":"attentionä¸­å¼ é‡å¹¶è¡Œä¸GQA","url":"/2025/08/17/distribute/attention/","content":"\n\n\nä¾‹å­é…ç½®ï¼ˆè´¯ç©¿å…¨æ–‡ï¼‰ï¼š hidden_size=4096, num_attention_heads=32, tensor_parallel_size=4, num_query_groups=8ï¼ˆGQAï¼‰, kv_channels=hidden/heads=128ã€‚ è¾“å…¥å½¢çŠ¶ç”¨ [B, S, H] è®°ï¼ˆæ‰¹ã€åºåˆ—ã€éšè—ï¼‰ã€‚\n\n\n1. åè¯ä¸æ´¾ç”Ÿå˜é‡ï¼ˆå…ˆæŠŠé‡ç®—æ¸…æ¥šï¼‰\n\nå•å¤´ç»´åº¦ï¼ˆä¹Ÿæ˜¯ç¼©æ”¾ç”¨çš„ \\(d_k\\)ï¼‰ï¼škv_channels = 4096 / 32 = 128\nQ æŠ•å½±æ€»ç»´ï¼šquery_projection_size = kv_channels * num_attention_heads = 128*32 = 4096\nK/V æŠ•å½±æ€»ç»´ï¼ˆGQAï¼‰ï¼škv_projection_size = kv_channels * num_query_groups = 128*8 = 1024\næ¯å¡ Q å¤´æ•°ï¼šnum_attention_heads_per_partition = 32 / TP = 8\næ¯å¡ KV ç»„æ•°ï¼šnum_query_groups_per_partition = 8 / TP = 2\næ¯å¡æŠ•å½±ç»´ï¼ˆåˆ—å¹¶è¡Œåæœ¬åœ°è¾“å‡ºç»´ï¼‰ï¼šhidden_size_per_partition = 4096 / TP = 1024\n\n\nGQA çš„å«ä¹‰ï¼šå½“ num_key_value_heads (=num_query_groups) å°äº num_attention_heads æ—¶ï¼Œä¸ºè¾ƒå°‘çš„ KV å¤´/ç»„ äº§å‡º K/Vï¼Œè®©å¤šä¸ª Q å¤´å…±äº«å®ƒä»¬ï¼›=heads é€€åŒ–ä¸º MHAï¼Œ=1 æ˜¯ MQAã€‚è¿™ä¸€ç‚¹åœ¨ HF æ¨¡å‹æ–‡æ¡£ä¸­æ˜¯æ˜ç¡®çš„å®šä¹‰ã€‚(Hugging Face)\n\n\n2. ç«¯åˆ°ç«¯è®¡ç®—ä¸å½¢çŠ¶æµï¼ˆä»¥å•å±‚è‡ªæ³¨æ„åŠ›ä¸ºä¾‹ï¼‰\nMegatron ç»å…¸åšæ³•ï¼šQ/K/V çš„çº¿æ€§å±‚ç”¨åˆ—å¹¶è¡Œï¼ˆColumn-Parallelï¼‰ï¼ŒæŒ‰è¾“å‡ºåˆ—åˆ‡ç»™å„å¡ï¼›è¾“å‡ºæŠ•å½±ç”¨è¡Œå¹¶è¡Œï¼ˆRow-Parallelï¼‰ï¼ŒæŒ‰è¾“å…¥è¡Œåˆ‡ç»™å„å¡ï¼Œå‰å‘åªåœ¨è¾“å‡ºæŠ•å½±åšä¸€æ¬¡ all-reduceã€‚è¿™æ˜¯ Megatron-LM è®ºæ–‡ä¸ Megatron-Core æ–‡æ¡£æ¨èçš„å¼ é‡å¹¶è¡Œåˆ‡æ³•ã€‚(arXiv, NVIDIA Docs)\n2.1 çº¿æ€§æŠ•å½±ï¼ˆåˆ—å¹¶è¡Œï¼‰\n\nQ æŠ•å½±ï¼ˆå…¨å±€æƒé‡ [4096,4096] â†’ æ¯å¡ [4096,1024]ï¼‰ï¼š æœ¬å¡è¾“å‡º Q_local: [B,S,1024] â†’ reshape ä¸º [B, 8, S, 128]ï¼ˆæœ¬å¡ 8 ä¸ª Q å¤´ï¼‰ã€‚\nK æŠ•å½±ï¼ˆå…¨å±€æƒé‡ [4096,1024] â†’ æ¯å¡ [4096,256]ï¼‰ï¼š K_local: [B,S,256] â†’ reshape ä¸º [B, 2, S, 128]ï¼ˆæœ¬å¡ 2 ä¸ª KV ç»„ï¼‰ã€‚\nV æŠ•å½± åŒ Kã€‚\n\n\nä¸ºä»€ä¹ˆå¿…é¡» reshape å‡º head ç»´ï¼Ÿ å¤šå¤´æ³¨æ„åŠ›çš„è¯­ä¹‰æ˜¯â€œå¤´å†…ç‹¬ç«‹â€çš„ç‚¹ç§¯æ³¨æ„åŠ›ï¼Œå†…æ ¸ï¼ˆSDPA/FlashAttentionï¼‰ä¸å¹¿æ’­ï¼ˆmaskã€RoPEã€repeat_kvï¼‰éƒ½è¦æ±‚æ˜¾å¼çš„ head ç»´ [B,H,S,D] æˆ–å±•å¹³ä¸º [BÂ·H,S,D]ã€‚ä¸æ‹†å¤´ä¼šæŠŠä¸åŒ head çš„å­ç©ºé—´æ··åœ¨ä¸€èµ·ï¼Œä¹Ÿæ— æ³•è‡ªç„¶æ‰§è¡Œ GQA çš„ repeat_kvã€‚(PyTorch)\n\n2.2 GQA çš„ K/V å¯¹é½ï¼ˆrepeat/expandï¼‰\næœ¬å¡åªæœ‰ 2 ä¸ª KV ç»„ï¼Œä½†è¦æœåŠ¡ 8 ä¸ª Q å¤´ â‡’ åœ¨å¤´ç»´åšé€»è¾‘é‡å¤/å¹¿æ’­ï¼š [B, 2, S, 128] â†’ [B, 8, S, 128]ï¼ˆæ¯ä¸ª KV ç»„æœåŠ¡ 4 ä¸ª Q å¤´ï¼‰ã€‚ä¸»æµå®ç°ç›´æ¥åœ¨ head ç»´åš repeat_kvã€‚(Hugging Face)\n2.3 Scaled Dot-Product Attentionï¼ˆæ¯å¡åªç®—è‡ªå·±çš„ 8 ä¸ªå¤´ï¼‰\n\nscores = (Q @ K^T) / sqrt(128) â†’ softmax(scores) @ V\nå¾—åˆ°ä¸Šä¸‹æ–‡ ctx_local: [B, 8, S, 128] â†’ æ‹¼æ¥ä¸º [B,S,1024]\nè¿™ä¸€æ­¥å¯ä»¥ç”± PyTorch SDPA æˆ–é—ªå­˜æ³¨æ„åŠ›å†…æ ¸é«˜æ•ˆå®Œæˆã€‚(PyTorch)\n\n2.4 è¾“å‡ºæŠ•å½±ï¼ˆè¡Œå¹¶è¡Œ + 1 æ¬¡ all-reduceï¼‰\n\næ¯å¡æŠŠ [B,S,1024] ä¹˜ä»¥æœ¬å¡çš„è¾“å‡ºæƒé‡åˆ†ç‰‡ï¼Œå¾—åˆ° Y_local: [B,S,4096] çš„éƒ¨åˆ†å’Œï¼›\nè·¨å¡åš all-reduce(sum) å¾—åˆ°æœ€ç»ˆ Y: [B,S,4096]ã€‚ Megatron è®ºæ–‡æŒ‡å‡ºï¼šè‡ªæ³¨æ„åŠ›æœ¬ä½“ä¸éœ€é€šä¿¡ï¼Œåªåœ¨è¾“å‡ºæŠ•å½±å¤„åšä¸€æ¬¡è§„çº¦å³å¯ã€‚(arXiv)\n\n\n3. åˆ—å¹¶è¡Œ / è¡Œå¹¶è¡Œçš„æ•°å­¦ç­‰ä»·ï¼ˆä¸ºä½•â€œåˆ‡äº†å†æ‹¼/æ±‚å’Œâ€ä»ç­‰ä»·å•å¡ï¼‰\næŠŠ [B,S,Â·] å±•å¹³ä¸ºçŸ©é˜µ \\(X\\in\\mathbb{R}^{N\\times(HD)}\\)ï¼ˆ\\(N=B\\cdot S\\)ï¼‰ï¼Œè¾“å‡ºéšè—è®°ä¸º \\(H\\)ã€‚\n3.1 åˆ—å¹¶è¡Œï¼ˆColumn-Parallel Linearï¼‰â‰¡ æ‹¼æ¥\nè®¾ Q çš„å…¨é‡æƒé‡ \\(W_Q\\in\\mathbb{R}^{(HD)\\times(HD)}\\)ï¼Œæ²¿åˆ—åˆ‡æˆ \\(p\\) å—ï¼š\n\\[\nW_Q=\\big[W_Q^{(0)}\\;\\;W_Q^{(1)}\\;\\;\\cdots\\;\\;W_Q^{(p-1)}\\big],\n\\quad W_Q^{(i)}\\in\\mathbb{R}^{(HD)\\times(H/p\\cdot D)}.\n\\]\nåˆ™\n\\[\nQ=XW_Q=\\big[XW_Q^{(0)}\\;\\;XW_Q^{(1)}\\;\\;\\cdots\\;\\;XW_Q^{(p-1)}\\big]\n      =\\operatorname{Concat}(Q^{(0)},\\dots,Q^{(p-1)}).\n\\]\næ¯å¡ç‹¬ç«‹è®¡ç®—è‡ªå·±çš„ \\(Q^{(i)}\\)ï¼Œæ— é¡»é€šä¿¡ã€‚K/V åŒç†ã€‚è¿™å°±æ˜¯ Column-Parallel çš„ç²¾ç¡®å®šä¹‰ã€‚(arXiv, NVIDIA Docs)\n3.2 æ¯å¤´ç‹¬ç«‹ â‡’ æŒ‰å¤´åˆ‡ç»™å„å¡ä»ç„¶æ­£ç¡®\nå•å¤´/å•ç»„æ³¨æ„åŠ›ï¼š\n\\[\nY_h=\\operatorname{softmax}\\!\\Big(\\tfrac{Q_hK_{g(h)}^\\top}{\\sqrt{D}}\\Big)V_{g(h)}.\n\\]\nGQA ä¸‹ \\(g(h)\\) æŠŠå¤šä¸ª Q å¤´æ˜ å°„åˆ°åŒä¸€ KV ç»„ï¼›ç”±äºå¤´é—´äº’ä¸ç›¸å¹²ï¼ŒæŠŠ 32 ä¸ªå¤´å¹³å‡åˆ†æˆ 4 ä»½åˆ° 4 å¼ å¡ï¼Œå„å¡åªä¾èµ–è‡ªå·±çš„ KV ç»„ï¼Œå°±ä¸å•å¡ä¸€è‡´ã€‚repeat_kv æ­£æ˜¯æ²¿ head ç»´æŠŠ KV å¯¹é½åˆ° Q å¤´æ•°ã€‚(Hugging Face)\n3.3 è¡Œå¹¶è¡Œï¼ˆRow-Parallel Linearï¼‰â‰¡ æ±‚å’Œï¼ˆall-reduceï¼‰\næŠŠæ³¨æ„åŠ›è¾“å‡ºçš„æ‹¼æ¥å¼ é‡ \\(C\\in\\mathbb{R}^{N\\times(HD)}\\) æŒ‰åˆ—ï¼ˆç‰¹å¾ï¼‰åˆ‡å—ï¼š\n\\[\nC=\\big[C^{(0)}\\;\\;C^{(1)}\\;\\;\\cdots\\;\\;C^{(p-1)}\\big],\\quad\nC^{(i)}\\in\\mathbb{R}^{N\\times(H/p\\cdot D)}.\n\\]\nè¾“å‡ºæƒé‡ \\(W_O\\in\\mathbb{R}^{(HD)\\times H}\\) æŒ‰è¡Œåˆ‡å—ï¼š\n\\[\nW_O=\\begin{bmatrix}\nW_O^{(0)}\\\\ W_O^{(1)}\\\\ \\vdots\\\\ W_O^{(p-1)}\n\\end{bmatrix},\n\\quad W_O^{(i)}\\in\\mathbb{R}^{(H/p\\cdot D)\\times H}.\n\\]\nå—ä¹˜æ³•æ’ç­‰å¼ï¼š\n\\[\nC\\,W_O=\\sum_{i=0}^{p-1} C^{(i)}W_O^{(i)}.\n\\]\nå› æ­¤å„å¡è®¡ç®— \\(Y^{(i)}=C^{(i)}W_O^{(i)}\\)ï¼Œå† all-reduce(sum)ï¼Œå°±å¾—åˆ°ä¸å•å¡å®Œå…¨ç›¸åŒçš„ \\(Y\\)ã€‚è¿™æ­£æ˜¯ Row-Parallel çš„æœ¬è´¨ã€‚(arXiv)\n\n4. ä¸ºä»€ä¹ˆ GQA ä¼šè®© kv_projection_size å˜å°ã€KV cache å˜çœï¼Ÿ\n\nK/V çº¿æ€§å±‚åªä¸º num_query_groups äº§å‡ºé€šé“ï¼šä» 4096ï¼ˆ=32Ã—128ï¼‰é™ä¸º 1024ï¼ˆ=8Ã—128ï¼‰ï¼ŒK/V æŠ•å½±çš„ å‚æ•°é‡ä¸ FLOPs çº¦ä¸ºåŸæ¥çš„ 1/4ï¼›\næ¨ç†é˜¶æ®µçš„ KV cache ä»¥ã€ŒKV å¤´ Ã— åºåˆ— Ã— å¤´ç»´ã€è®¡é‡ï¼ŒKV å¤´ä» 32 å˜ 8ï¼Œç¼“å­˜ä¸ç›¸å…³å¸¦å®½å‡ç›¸åº”ä¸‹é™ã€‚HF æ–‡æ¡£æ˜ç¡®ä»¥ num_key_value_heads æè¿°è¯¥è¡Œä¸ºã€‚(Hugging Face)\n\n\n5. å½¢çŠ¶é€ŸæŸ¥ï¼ˆä»¥æœ¬ä¾‹ä¸ºå‡†ï¼‰\n\n\n\nå¼ é‡/æ­¥éª¤\nå…¨å±€ï¼ˆä¸åˆ†ç‰‡ï¼‰\næ¯å¡ï¼ˆTP=4ï¼‰\nè¯´æ˜\n\n\n\n\nQ çº¿æ€§è¾“å‡ºç»´\n4096\n1024\nColumn-Parallelï¼Œæ— é€šä¿¡\n\n\nK çº¿æ€§è¾“å‡ºç»´\n1024\n256\nGQAï¼šåªå‡º 8 ä¸ª KV ç»„\n\n\nV çº¿æ€§è¾“å‡ºç»´\n1024\n256\nåŒä¸Š\n\n\nQ å¤´æ•°\n32\n8\næœ¬å¡åªç®—è‡ªå·± 8 ä¸ªå¤´\n\n\nKV ç»„æ•°\n8\n2\næ¯ç»„æœåŠ¡ 4 ä¸ª Q å¤´\n\n\nå¤´ç»´ \\(D\\)\n128\n128\nç”¨äº \\(1/\\sqrt{D}\\)\n\n\næœ¬å¡æ³¨æ„åŠ›è¾“å‡ºï¼ˆæ‹¼å¤´åï¼‰\nâ€“\n[B,S,1024]\nè¿›å…¥è¾“å‡ºæŠ•å½±\n\n\næœ€ç»ˆè¾“å‡ºï¼ˆall-reduce åï¼‰\n[B,S,4096]\n[B,S,4096]\nRow-Parallel + sum\n\n\n\nï¼ˆè‹¥å¯ç”¨ Sequence Parallelï¼Œåªä¼šæ²¿ S å†åˆ‡ä¸€ç»´ï¼Œä¸å½±å“ä¸Šè¿°å¤´/é€šé“ç»´é€»è¾‘ã€‚åˆ—/è¡Œå¹¶è¡Œä¸ä¸€æ¬¡é€šä¿¡çš„ç»“æ„æ˜¯ Megatron-LM çš„â€œç»å…¸æ‹†åˆ†â€ã€‚ï¼‰(awsdocs-neuron.readthedocs-hosted.com, Better Tomorrow with Computer Science)\n\n6. Mermaidï¼šä¸€å¼ â€œç»´åº¦/å¹¶è¡Œæ–¹å¼â€å°å›¾\n%%&#123;init: &#123; &quot;flowchart&quot;: &#123; &quot;htmlLabels&quot;: true, &quot;wrap&quot;: true &#125; &#125;&#125;%%flowchart TB  X[&quot;Input X: [B,S,4096]&quot;] --&gt; QKV[&quot;Column-Parallel Q/K/V&lt;br/&gt;Q:[B,S,1024]  K/V:[B,S,256]&quot;]  QKV --&gt; Reshape[&quot;Reshape by heads&lt;br/&gt;Q:[B,8,S,128]&lt;br/&gt;K/V:[B,2,S,128]&quot;]  Reshape --&gt; RepeatKV[&quot;repeat_kv on head dim&lt;br/&gt;K/V:[B,8,S,128]&quot;]  RepeatKV --&gt; SDPA[&quot;SDPA per head&lt;br/&gt;ctx_local:[B,8,S,128]&lt;br/&gt;concat-&gt;[B,S,1024]&quot;]  SDPA --&gt; OutProj[&quot;Row-Parallel OutProj&lt;br/&gt;Y_local:[B,S,4096]&quot;]  OutProj --&gt; AllReduce[&quot;all-reduce(sum)&quot;]  AllReduce --&gt; Y[&quot;Final Y: [B,S,4096]&quot;]\n\n7. æç®€ä¼ªç ï¼ˆPyTorch é£æ ¼ï¼‰\n# åˆ—å¹¶è¡Œçš„çº¿æ€§ï¼šæ¯å¡æ‹¿åˆ° Q/K/V çš„ä¸€æ®µè¾“å‡ºåˆ—Q_local = linear_col_parallel_Q(X)   # [B,S,1024] -&gt; view [B,8,S,128]K_local = linear_col_parallel_K(X)   # [B,S,256]  -&gt; view [B,2,S,128]V_local = linear_col_parallel_V(X)   # [B,S,256]  -&gt; view [B,2,S,128]Q = Q_local.view(B, S, 8, 128).transpose(1, 2)  # [B,8,S,128]K = K_local.view(B, S, 2, 128).transpose(1, 2)  # [B,2,S,128]V = V_local.view(B, S, 2, 128).transpose(1, 2)  # [B,2,S,128]# GQA: è®© 2 ä¸ª KV ç»„åŒ¹é… 8 ä¸ª Q å¤´ï¼ˆé€»è¾‘ repeat/expandï¼‰K = repeat_kv(K, n_rep=4)   # [B,8,S,128]V = repeat_kv(V, n_rep=4)   # [B,8,S,128]# SDPAï¼ˆæ¯å¡åªç®—è‡ªå·±çš„ 8 ä¸ªå¤´ï¼‰ctx = torch.nn.functional.scaled_dot_product_attention(Q, K, V)  # [B,8,S,128]ctx = ctx.transpose(1, 2).reshape(B, S, 1024)                    # [B,S,1024]# è¡Œå¹¶è¡Œè¾“å‡º + ä¸€æ¬¡ all-reduce(sum)Y_local = linear_row_parallel_out(ctx)   # partial: [B,S,4096]Y = all_reduce_sum(Y_local)              # final:   [B,S,4096]\n\nSDPA çš„æ¥å£ä¸è¯­ä¹‰è§ PyTorch æ–‡æ¡£ï¼›repeat_kv çš„è¯­ä¹‰ä¸ GQA çš„é…ç½®åœ¨ HF æ–‡æ¡£/å®ç°ä¸­æœ‰æ˜ç¡®å®šä¹‰ã€‚(PyTorch, Hugging Face)\n\n\n8. æ­£ç¡®æ€§ Checklistï¼ˆå®è·µä¸­æœ€å¸¸è§çš„å‘ï¼‰\n\næ•´é™¤å…³ç³»ï¼š num_attention_heads % TP == 0ï¼Œnum_query_groups % TP == 0ï¼Œä¸” num_attention_heads % num_query_groups == 0ï¼ˆGQAï¼‰ã€‚(Hugging Face)\næ˜¾å¼ head ç»´ï¼šå½¢çŠ¶åº”ä¸º [B,H,S,D] æˆ–å±•å¹³ä¸º [BÂ·H,S,D]ï¼Œä»¥å¥‘åˆ SDPA/FlashAttention ä¸ repeat_kvã€‚(PyTorch)\né€šä¿¡ä½ç½®ï¼šè‡ªæ³¨æ„åŠ›æœ¬ä½“æ— è·¨å¡é€šä¿¡ï¼›ä»…è¾“å‡ºæŠ•å½±éœ€è¦ä¸€æ¬¡ all-reduceã€‚(arXiv)\n\n\nå‚è€ƒä¸å»¶ä¼¸é˜…è¯»\n\nMegatron-LM è®ºæ–‡ï¼šæå‡ºå±‚å†…ï¼ˆå¼ é‡ï¼‰å¹¶è¡Œï¼Œæ³¨æ„åŠ›ç”¨åˆ—å¹¶è¡Œï¼Œè¾“å‡ºç”¨è¡Œå¹¶è¡Œï¼Œå‰å‘ä»…ä¸€å¤„é€šä¿¡ã€‚(arXiv, ar5iv)\nMegatron-Core æ–‡æ¡£ï¼šTensor Parallel API/ç”¨æˆ·æŒ‡å—ï¼ˆNVIDIA å®˜æ–¹ï¼‰ã€‚(NVIDIA Docs)\nPyTorch SDPA æ–‡æ¡£/æ•™ç¨‹ï¼šå®˜æ–¹çš„ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›æ¥å£ä¸é«˜æ€§èƒ½å®ç°ã€‚(PyTorch, PyTorch Docs)\nHF æ–‡æ¡£ï¼ˆLlama/Qwen ç³»åˆ—ï¼‰ï¼šnum_key_value_heads çš„å®šä¹‰ã€GQA/MQA/MHA çš„å…³ç³»ï¼›å®ç°é‡Œ repeat_kv çš„ç”¨æ³•ã€‚(Hugging Face)\nåˆ—å¹¶è¡Œ/è¡Œå¹¶è¡Œå¯è§†åŒ–è®²è§£ï¼šå¯¹ ColumnParallelLinear / RowParallelLinear çš„ç›´è§‚å›¾è§£ã€‚(awsdocs-neuron.readthedocs-hosted.com, Better Tomorrow with Computer Science)\n\n\n","categories":["åˆ†å¸ƒå¼åŸºç¡€"],"tags":["attention"]},{"title":"pytorch devicemesh","url":"/2025/06/14/distribute/device_mesh/","content":"\n\nä¸€ã€ä¸ºä½•ä½¿ç”¨ DeviceMeshï¼Ÿ\nåœ¨æ··åˆå¹¶è¡Œï¼ˆDP/TP/PP/HSDP/â€¦ï¼‰ä¸­ï¼Œéœ€è¦ç®¡ç†å¤šä¸ªå­é€šä¿¡ç»„ï¼ˆProcessGroupï¼‰ï¼Œå¯¹åº”å¤æ‚çš„è®¾å¤‡æ‹“æ‰‘ç»“æ„ã€‚DeviceMesh æä¾›äº†ï¼š\n\nç†è®ºä¸Šæ— ç¼æ”¯æŒä»»æ„ç»´åº¦çš„å¤šç»´æ‹“æ‰‘ï¼›\nè‡ªåŠ¨æ‹†åˆ†è¿›ç¨‹ç»„(new_group/split_group)ï¼›\nçµæ´»åˆ‡ç‰‡å­ Meshï¼›\nç»å†è®¾è®¡å‘¨å…¨çš„é«˜æ•ˆåˆå§‹åŒ–æ–¹æ¡ˆ (docs.pytorch.org, pytorch.org)ã€‚\n\n\näºŒã€åˆå§‹åŒ–æµç¨‹\ninit_device_mesh(...) çš„ä½œç”¨\nä¸€ä¸ªä¸€è¡Œæå®šçš„æ–¹æ³•ï¼Œå®ƒä¼šï¼š\n\nåˆå§‹åŒ–å…¨å±€ init_process_group(...)ï¼ˆè‹¥æœªåˆå§‹åŒ–ï¼‰ï¼›\næ ¹æ® mesh_shape è‡ªåŠ¨æ„é€  CPU ä¸Šçš„ torch.arange(...).view(...)ï¼›\nåˆ›å»º DeviceMesh(...)ã€‚å†…éƒ¨å®Œæˆå­ç»„æ‹†åˆ†åŸç†ï¼ˆè§ä¸‹ä¸€èŠ‚ï¼‰ã€‚\n\n\nDeviceMesh.__init__() + _init_process_groups()\n\nå­˜å‚¨ï¼šdevice_typeã€meshã€mesh_dim_namesï¼›\né€šä¿¡ç»„æ‹†åˆ†ï¼šéå†æ¯ä¸ªç»´åº¦ dimï¼š\n\nä½¿ç”¨ mesh.swapdims(-1, dim).reshape(-1, size(dim)) åˆ—å‡ºè¯¥ç»´æ‰€æœ‰å­ç»„ rankï¼›\nè‹¥ NCCL å·²ç»‘å®š GPUï¼Œå³å¯ç”¨ split_group ä¸€æ¬¡æ‹†å‡ºå…¨éƒ¨å­ç»„ï¼›\nå¦åˆ™ä½¿ç”¨ new_group() åˆ† group æ‹†ï¼›\nå¹¶å°†å½“å‰ rank å±äºçš„é‚£ç»„ä¿¡æ¯æ”¾å…¥ self._dim_group_infos[dim]ï¼›\n\nç»“æœï¼šæ¯ä¸ªç»´åº¦å¯¹åº”ä¸€ä¸ªåŒ…å«å½“å‰ rank çš„ ProcessGroup ä¿¡æ¯åˆ—è¡¨ã€‚\n\n#ppmesh = torch.tensor([  [0, 1],  # pp=0  [2, 3],  # pp=1  [4, 5],  # pp=2  [6, 7]   # pp=3])mesh.swapdims(-1, 0)tensor([[0,2,4,6],        [1,3,5,7]])pg_ranks_by_dim = tmp.reshape(-1, mesh.size(0))[  [0,2,4,6],  # å¯¹åº” tp è¡Œ 0 å„ pp æ®µ  [1,3,5,7]   # å¯¹åº” tp è¡Œ 1 å„ pp æ®µ]#tptmp = mesh.swapdims(-1, 1)  # ç­‰äº transpose(1,1)ï¼Œæœ¬èº«æ— å˜åŒ–pg_ranks_by_dim = tmp.reshape(-1, mesh.size(1))[  [0,1],  # pp=0  [2,3],  [4,5],  [6,7]]\n\nä¸‰ã€æ ¸å¿ƒæ¥å£ä¸å†…éƒ¨å®ç°è§£æ\n1. å±æ€§ä¸æ–¹æ³•\nmesh.shape  # tuple(self.mesh.shape)mesh.ndim   # int(self.mesh.ndim)mesh.size(dim=None)  # æ€»å…ƒç´ æ•° or self.mesh.size(dim)\nç”¨äºè·å– mesh å…ƒç»“æ„å’Œè§„æ¨¡ï¼Œé€‚ç”¨äºåˆ¤æ–­ç»´åº¦æ•°é‡ã€å¾ªç¯è¿­ä»£ã€å¹¶è¡Œç­–ç•¥é…ç½®ç­‰åœºæ™¯ã€‚\n\n2. Rank ä¸åæ ‡\n\nget_rank()ï¼šç­‰ä»·äº torch.distributed.get_rank()ï¼Œè¿”å›å…¨å±€ rankï¼›\nget_local_rank(mesh_dim)ï¼šå†…éƒ¨è°ƒç”¨ get_rank(self.get_group(mesh_dim)) â†’ å½“å‰ç»´åº¦çš„å°ç»„å†…ç¼–å·ï¼›\nget_coordinate()ï¼šè¿”å› self._coordinate_on_dimï¼Œå…¶åœ¨åˆå§‹åŒ–ä¸­é€šè¿‡ (self.mesh==global_rank).nonzero() è·å¾—ã€‚\n\nç¤ºä¾‹ï¼šmesh_shape=(4,2)ï¼Œrank=5 â†’ local_pp=2ã€local_tp=1ï¼Œcoordinate [2,1]ã€‚\n\n3. é€šä¿¡ç»„è·å–\n\nget_group(mesh_dim)ï¼š\n\nè‹¥ 1D ä¸”ä¸ä¼ å‚ï¼Œç›´æ¥è¿”å›å”¯ä¸€å­è¿›ç¨‹ç»„ï¼›\nå¤šç»´åˆ™æ ¹æ® mesh_dimï¼ˆç´¢å¼•æˆ–åå­—ï¼‰æ£€ç´¢ self._dim_group_infos[dim]ï¼Œç”¨ _find_pg_by_ranks_and_tag() è·å–å¯¹åº” ProcessGroupã€‚\n\nget_all_groups()ï¼šè¿”å›æ‰€æœ‰ç»´åº¦çš„ group åˆ—è¡¨ï¼›\n__getitem__(dims)ï¼šåˆ‡ç‰‡æ¥å£è°ƒç”¨ _mesh_resources._get_slice_mesh_dims(...)ï¼Œåˆ›å»ºæ–°çš„å­ meshï¼Œä¿ç•™åº•å±‚ communicatorï¼Œä½†ç»´åº¦é™ã€‚\n\næ”¯æŒå•ç»´æˆ–å¤šç»´åˆ‡ç‰‡ï¼Œä¸”è¿”å›çš„ submesh é¡ºåºæŒ‰ä¼ å…¥é¡ºåºæ’åˆ— (discuss.ray.io, gemfury.com, pytorch.org)ã€‚\n\n\n\n4. from_group(...) æ–¹æ³•\n\nå¯æ¥å—å• group æˆ– group åˆ—è¡¨ï¼›\nåˆ›å»ºæ–°çš„ DeviceMesh æ—¶ä¸ä¼šè°ƒç”¨ backend åˆå§‹åŒ–ï¼›\nä¼šå¤ç”¨ç°æœ‰ ProcessGroupï¼Œå¹¶å¡«å…… _dim_group_infosï¼Œå› æ­¤ get_group(...) å°†ç›´æ¥è¿”å›ä¼ å…¥çš„å®ä¾‹ï¼Œé¿å…é‡å¤åˆ›å»º groupã€‚\n\n\nå››ã€å®Œæ•´å•æœº 8 å¡ Demoï¼štp=2, pp=4\nä¸‹é¢æ¼”ç¤ºå¦‚ä½•è°ƒç”¨æ‰€æœ‰æ¥å£å¹¶è¾“å‡ºç»“æœã€‚æ³¨æ„ï¼šéœ€åœ¨ torchrun --nproc_per_node=8 ä¸‹è¿è¡Œã€‚\nimport os, torch, torch.distributed as distfrom torch.distributed.device_mesh import init_device_meshdef run_device_mesh_demo():    dist.init_process_group(&quot;nccl&quot;)    # â¬‡ï¸ åˆå§‹åŒ– 2-ç»´ meshï¼špp=4, tp=2    mesh = init_device_mesh(&quot;cuda&quot;, mesh_shape=(4, 2), mesh_dim_names=(&quot;pp&quot;, &quot;tp&quot;))        # âœ… rank å’Œåæ ‡    gr = mesh.get_rank()            # å…¨å±€ rank    coord = mesh.get_coordinate()   # [pp_idx, tp_idx]    local_pp = mesh.get_local_rank(&quot;pp&quot;)    local_tp = mesh.get_local_rank(&quot;tp&quot;)        # â¬‡ï¸ mesh åŸºæœ¬ç»“æ„    total = mesh.size()    pp_size, tp_size = mesh.size(&quot;pp&quot;), mesh.size(&quot;tp&quot;)    ndim = mesh.ndim    shape = mesh.shape        # â¬‡ï¸ è·å–é€šä¿¡ç»„    pp_group = mesh.get_group(&quot;pp&quot;)    tp_group = mesh.get_group(&quot;tp&quot;)    all_groups = mesh.get_all_groups()        # â¬‡ï¸ åˆ‡ç‰‡å‡ºå­ mesh    tp_mesh = mesh[&quot;tp&quot;]    pp_mesh = mesh[&quot;pp&quot;]        # â¬‡ï¸ è¾“å‡ºç»“æœ    print(f&quot;rank=&#123;gr&#125;, coord=&#123;coord&#125;, local_pp=&#123;local_pp&#125;, local_tp=&#123;local_tp&#125;&quot;)    print(f&quot;ndim=&#123;ndim&#125;, shape=&#123;shape&#125;, total=&#123;total&#125;, pp=&#123;pp_size&#125;, tp=&#123;tp_size&#125;&quot;)    print(&quot;pp_group ranks:&quot;, dist.get_process_group_ranks(pp_group))    print(&quot;tp_group ranks:&quot;, dist.get_process_group_ranks(tp_group))    print(&quot;all_groups sizes:&quot;, [len(dist.get_process_group_ranks(g)) for g in all_groups])    print(&quot;tp_mesh ndim, shape:&quot;, tp_mesh.ndim, tp_mesh.shape)    print(&quot;pp_mesh ndim, shape:&quot;, pp_mesh.ndim, pp_mesh.shape)if __name__ == &quot;__main__&quot;:    run_device_mesh_demo()\nğŸ’¬ é¢„æœŸè¾“å‡ºï¼ˆä¾‹å¦‚ rank = 5ï¼‰ï¼š\nrank=5, coord=[2,1], local_pp=2, local_tp=1 ndim=2, shape=(4,2), total=8, pp=4, tp=2 pp_group ranks: [4,5,6,7] tp_group ranks: [5,7] all_groups sizes: [4,2] tp_mesh ndim, shape: 1 (2,) pp_mesh ndim, shape: 1 (4,)\nè¯´æ˜ï¼š - rank=5 ä½äº pipeline æ®µ 2ï¼Œtp å†…ç¼–å· 1ï¼› - pp_group åŒ…å«ä¸å…¶åŒ segment çš„ 4 å¼ å¡ï¼› - tp_group åŒ…å«åŒ segment tp ç»´åº¦çš„ä¸¤å¼ å¡ï¼› - åˆ‡ç‰‡å tp_meshã€pp_mesh æˆä¸º 1 ç»´ç»“æ„ï¼Œç”¨äºåç»­ parallelizationã€‚\n\nğŸ‘ æ€»ç»“\n\nDeviceMesh æ„å»ºè‡ªèº«é€šè¿‡ init_device_mesh() å®Œæˆåˆå§‹åŒ–ä¸å­ç»„æ‹†åˆ†ï¼›\næ¥å£å†…éƒ¨å®ç°é€»è¾‘ä¸ Group ç®¡ç†æœºåˆ¶æ¸…æ™°ã€é«˜æ•ˆï¼›\n__getitem__ä¸ºå¤šç»´å¹¶è¡Œä¸‹å­ Mesh åˆ‡ç‰‡å…³é”®å·¥å…·ï¼Œå¯¹é›†æˆ parallel APIs è‡³å…³é‡è¦ï¼›\né€šè¿‡è¯¥æœºåˆ¶ï¼Œå¯ä»¥ç®€å•åœ°ç»„ç»‡å¤æ‚çš„ hybrid-parallel pipelinesï¼ŒåŒæ—¶å……åˆ†å¤ç”¨ communicator èµ„æºå¹¶ç®€åŒ–å¼€å‘æµç¨‹ã€‚\n\n","categories":["åˆ†å¸ƒå¼åŸºç¡€"],"tags":["devicemesh"]},{"title":"pytorch send and recv","url":"/2025/06/14/distribute/send_recv/","content":"\n\n1. åŸºæœ¬æ¦‚å¿µä¸è¿›ç¨‹ç»„\n2. åŸºæœ¬å¼ é‡é€šä¿¡\n3. å¯¹è±¡åˆ—è¡¨é€šä¿¡\n4. æ˜“é”™ç‚¹ä¸å¸¸è§é—®é¢˜\n5. æ‰¹é‡ç‚¹å¯¹ç‚¹é€šä¿¡æ¥å£\n6. æ€»ç»“è¡¥å……\n7. å‚è€ƒèµ„æ–™\n\n\n1. åŸºæœ¬æ¦‚å¿µä¸è¿›ç¨‹ç»„\n\ngroupï¼ˆé€šä¿¡ç»„ï¼‰ï¼šåˆ†å¸ƒå¼é€šä¿¡æ—¶çš„ã€Œå­é›†ã€ï¼Œå…è®¸åªåœ¨ä¸€éƒ¨åˆ† rank ä¹‹é—´é€šä¿¡ã€‚\nglobal rankï¼šå…¨å±€è¿›ç¨‹ç¼–å·ï¼ˆè¿›ç¨‹å¯åŠ¨æ—¶åˆ†é…çš„ç¼–å·ï¼‰ã€‚\ngroup rankï¼šç»„å†…è¿›ç¨‹ç¼–å·ï¼Œç»„å†…ç¬¬å‡ ä¸ªè¿›ç¨‹ï¼ˆä¸ global rank æ— å¿…ç„¶å¯¹åº”å…³ç³»ï¼‰ã€‚\nsrc/dstï¼šé€šä¿¡ç›®æ ‡ï¼ˆæº/ç›®çš„ï¼‰rankï¼Œæ³¨æ„ï¼šå¦‚æœæŒ‡å®š groupï¼Œè¿™é‡Œæ˜¯ç»„å†…ç¼–å·ï¼Œä¸æ˜¯å…¨å±€ç¼–å·ã€‚\n\nè¿›ç¨‹ç»„ä¸¾ä¾‹\nå‡å¦‚ group = [2, 4, 6, 8, 10]ï¼š\n\n\n\ngroup_rank\nglobal_rank\n\n\n\n\n0\n2\n\n\n1\n4\n\n\n2\n6\n\n\n3\n8\n\n\n4\n10\n\n\n\n\n2. åŸºæœ¬å¼ é‡é€šä¿¡\n2.1 send / recv / isend / irecv\nå‚æ•°è¯´æ˜\n\nsend(tensor, dst, group=None, tag=0) å‘é€ tensor åˆ°ç»„å†… rank=dst çš„è¿›ç¨‹ã€‚\nrecv(tensor, src, group=None, tag=0) ä»ç»„å†… rank=src çš„è¿›ç¨‹æ¥æ”¶ tensorã€‚\nisend/irecv å¼‚æ­¥ç‰ˆæœ¬ï¼Œè¿”å› Work å¥æŸ„ï¼Œéœ€è¦ work.wait()ã€‚\n\ntag\n\ntag æ˜¯æ¶ˆæ¯ç¼–å·/æ ‡ç­¾ï¼Œç”¨äºåŒºåˆ†å¤šæ¡å¹¶å‘æ¶ˆæ¯ï¼Œåªæœ‰ tag ä¸€è‡´æ‰èƒ½æ­£ç¡®é…å¯¹ã€‚\n\ngroup_dst/group_src\n\nä¸€èˆ¬ä¸ç”¨æ‰‹åŠ¨ä¼ ï¼Œæ¡†æ¶ä¼šæ ¹æ® dst/src å’Œ group è‡ªåŠ¨æ¨ç®—ã€‚\n\n\n2.2 é€šä¿¡æµç¨‹ç¤ºæ„å›¾\nä»¥ group = [2, 4, 6, 8, 10]ï¼Œè®© rank=2 å‘ï¼Œrank=10 æ”¶ä¸ºä¾‹ï¼š\ngraph TD    subgraph group [group: [2, 4, 6, 8, 10]]        A[&quot;global_rank=2&lt;br&gt;group_rank=0&quot;]        B[&quot;global_rank=10&lt;br&gt;group_rank=4&quot;]    end    A -- send(tensor, dst=4, group=group) --&gt; B    B -- recv(tensor, src=0, group=group) --&gt; A\n\nå‘é€ç«¯ï¼ˆglobal_rank=2ï¼Œgroup_rank=0ï¼‰ï¼šsend(tensor, dst=4, group=group)\næ¥æ”¶ç«¯ï¼ˆglobal_rank=10ï¼Œgroup_rank=4ï¼‰ï¼šrecv(tensor, src=0, group=group)\n\n\n2.3 ä»£ç å®ä¾‹\n# å‘é€ç«¯ï¼ˆglobal_rank=2ï¼‰group = dist.new_group([2, 4, 6, 8, 10])tensor = torch.tensor([123])dist.send(tensor, dst=4, group=group)   # dst=4 æ˜¯ group å†… rank=4 â†’ global_rank=10# æ¥æ”¶ç«¯ï¼ˆglobal_rank=10ï¼‰group = dist.new_group([2, 4, 6, 8, 10])tensor = torch.zeros(1, dtype=torch.int)dist.recv(tensor, src=0, group=group)   # src=0 æ˜¯ group å†… rank=0 â†’ global_rank=2print(tensor)\n\nâš ï¸ åªè¦ç”¨äº† groupï¼Œsrc/dst éƒ½æ˜¯ç»„å†… rankï¼Œä¸æ˜¯ global rankï¼\n\n\n2.4 å¼‚æ­¥é€šä¿¡ï¼ˆisend/irecvï¼‰\nwork = dist.isend(tensor, dst=4, group=group)work.wait()  # ç­‰å¾…å‘é€å®Œæˆ\nå¼‚æ­¥ recv åŒç†ã€‚\n\n3. å¯¹è±¡åˆ—è¡¨é€šä¿¡\n3.1 send_object_list / recv_object_list ç”¨æ³•\n\nç”¨äºå‘é€/æ¥æ”¶åŒ…å«ä»»æ„ Python å¯¹è±¡çš„ listï¼Œåº•å±‚é€šè¿‡åºåˆ—åŒ–å®ç°ã€‚\nå‘é€è¿‡ç¨‹æ‹†ä¸ºä¸¤æ­¥ï¼šå…ˆå‘æ¯ä¸ªå¯¹è±¡åºåˆ—åŒ–åçš„ sizeï¼Œå†å‘æ‰€æœ‰å†…å®¹æ‹¼æ¥åçš„ tensorã€‚\n\n\n3.2 å¯¹è±¡é€šä¿¡æµç¨‹å›¾\nsequenceDiagram    participant Sender    participant Receiver    Sender-&gt;&gt;Receiver: send(object_sizes_tensor)    Sender-&gt;&gt;Receiver: send(object_tensor)    Receiver-&gt;&gt;Receiver: 1. è¯»å– object_sizes_tensor    Receiver-&gt;&gt;Receiver: 2. æŒ‰ size æ‹† object_tensor    Receiver-&gt;&gt;Receiver: 3. ååºåˆ—åŒ–ä¸ºå¯¹è±¡\n\n3.3 å…¸å‹ä»£ç ç¤ºä¾‹\nå‘é€ç«¯\nobject_list = [&quot;hello&quot;, 123, [1, 2, 3]]dist.send_object_list(object_list, dst=4, group=group)\næ¥æ”¶ç«¯\nrecv_list = [None, None, None]dist.recv_object_list(recv_list, src=0, group=group)print(recv_list)  # [&#x27;hello&#x27;, 123, [1, 2, 3]]\n\n3.4 æ¥å£å®ç°æ ¸å¿ƒä»£ç \n# æ¥æ”¶ç«¯åˆ†å‰²ååºåˆ—åŒ–offset = 0for i, obj_size in enumerate(object_sizes_tensor):    obj_view = object_tensor[offset : offset + obj_size]    object_list[i] = _tensor_to_object(obj_view, obj_size, group)    offset += obj_size\n\nobject_sizes_tensor è®°å½•æ¯ä¸ªå¯¹è±¡çš„åºåˆ—åŒ–é•¿åº¦\nobject_tensor æ˜¯æ‰€æœ‰å†…å®¹æ‹¼èµ·æ¥çš„ä¸€ç»´ tensor\næŒ‰é¡ºåºåˆ‡ç‰‡å’Œååºåˆ—åŒ–ï¼Œå¡«å› object_list\n\n\n3.5 å…³äº rank_objects\n\nrank_objects æ˜¯ recv çš„è¿”å›å€¼ï¼Œè¡¨ç¤ºæ¶ˆæ¯æ¥è‡ªå“ªä¸ª rankï¼ˆä¸€èˆ¬ç­‰äº srcï¼‰\nåœ¨å¤šå¯¹å¤šé€šä¿¡æˆ– src=ANY_SOURCE æ—¶ç”¨æ¥ç¡®è®¤æ¶ˆæ¯æ¥æºï¼Œå’Œå®é™…å¯¹è±¡å†…å®¹è¿˜åŸæ— å…³\n\n\n4. æ˜“é”™ç‚¹ä¸å¸¸è§é—®é¢˜\n\nåªè¦ç”¨äº† groupï¼Œsrc/dst éƒ½æ˜¯ç»„å†… rankï¼Œä¸æ˜¯ global rankã€‚\ntag ç”¨äºåŒºåˆ†å¤šæ¡æ¶ˆæ¯ï¼Œå¿…é¡» send å’Œ recv ä¸€è‡´ã€‚\nsend_object_list/recv_object_list å¿…é¡» object_list é•¿åº¦ã€é¡ºåºä¸€è‡´ã€‚\ngroup_src/group_dst æ­£å¸¸ä¸šåŠ¡ä¸éœ€è¦è‡ªå·±ä¼ ã€‚\n\n4.1. groupã€src/dstã€group_src/group_dst å‚æ•°å…³ç³»\n\ngroup å†³å®šé€šä¿¡å­é›†ï¼Œsrc/dst å†³å®šæ”¶å‘ç›®æ ‡ç¼–å·ã€‚\nå¦‚æœæŒ‡å®š groupï¼Œåˆ™ src/dst ä¸ºç»„å†… rankï¼Œä¸æ˜¯ global rankã€‚\ngroup_src/group_dst ä¸€èˆ¬ä¸ç”¨æ‰‹åŠ¨ä¼ ï¼Œæ¡†æ¶è‡ªåŠ¨æ¨ç®—ã€‚\næ˜ å°„å…³ç³»ï¼š\n\nå…¨å±€è½¬ç»„å†…ï¼šgroup_ranks.index(global_rank)\nç»„å†…è½¬å…¨å±€ï¼šgroup_ranks[group_rank]\n\n\n\n5. æ‰¹é‡ç‚¹å¯¹ç‚¹é€šä¿¡æ¥å£\n5.1 æ¥å£ç®€ä»‹\ntorch.distributed.batch_isend_irecv æ”¯æŒåŒæ—¶å‘èµ·å¤šç»„å¼‚æ­¥ç‚¹å¯¹ç‚¹é€šä¿¡æ“ä½œï¼ˆisend/irecvï¼‰ï¼Œæ˜¾è‘—æé«˜å¤§æ‰¹é‡æ•°æ®åˆ†å‘/æ”¶é›†çš„æ•ˆç‡ã€‚ åº•å±‚æ”¯æŒ NCCLã€Glooã€UCC ç­‰åˆ†å¸ƒå¼åç«¯ï¼Œå¸¸ç”¨äºåˆ†å¸ƒå¼æ·±åº¦å­¦ä¹ çš„ pipeline/é€šä¿¡ pattern ä¼˜åŒ–ã€‚\nå‡½æ•°ç­¾å\ntorch.distributed.batch_isend_irecv(p2p_op_list: list[P2POp]) -&gt; list[Work]\n\np2p_op_listï¼šä¸€ç»„ torch.distributed.P2POp å®ä¾‹ï¼Œæ¯ä¸ªå®ä¾‹æè¿°ä¸€æ¬¡ isend/irecvã€‚\nè¿”å›ï¼šæ‰€æœ‰æ“ä½œçš„ request å¥æŸ„ï¼ˆWork å¯¹è±¡ï¼‰åˆ—è¡¨ï¼Œå¯é€šè¿‡ .wait() åŒæ­¥ã€‚\n\n\n5.2 å…¸å‹ä½¿ç”¨åœºæ™¯\n\nå¤§æ‰¹é‡ç‚¹å¯¹ç‚¹é€šä¿¡ï¼Œä¾‹å¦‚ pipeline å¹¶è¡Œã€ç¯å½¢ allreduce æ‰‹å†™ä¼˜åŒ–ç­‰åœºæ™¯ã€‚\næ”¯æŒ isend/irecv æ··åˆï¼Œèƒ½æ‰¹é‡æå‡ååé‡ã€‚\n\n\n5.3 è°ƒç”¨æµç¨‹ä¸å‚æ•°è¯´æ˜\nP2POp ç”¨æ³•\næ¯ä¸ª P2POp å®šä¹‰ä¸€æ¬¡é€šä¿¡æ“ä½œï¼Œå¦‚ä¸‹ï¼š\nP2POp(op, tensor, peer, group=None, tag=0)\n\nopï¼šæ“ä½œç±»å‹ï¼ˆdist.isend æˆ– dist.irecvï¼‰\ntensorï¼šè¦å‘é€/æ¥æ”¶çš„ tensor\npeerï¼šç›®æ ‡ peer çš„ç¼–å·ï¼ˆç»„å†… rankï¼‰\ngroupï¼ˆå¯é€‰ï¼‰ï¼šé€šä¿¡ç»„ï¼ˆé»˜è®¤ä¸º worldï¼‰\ntagï¼ˆå¯é€‰ï¼‰ï¼šæ¶ˆæ¯ç¼–å·/æ ‡ç­¾\n\n\n5.4 ä»£ç å®ä¾‹\nå‡è®¾ world_size=2ï¼Œrank 0 å’Œ rank 1 åšä¸€ä¸ªç¯å½¢é€šä¿¡ï¼š\nimport torchimport torch.distributed as distrank = dist.get_rank()world_size = dist.get_world_size()send_tensor = torch.arange(2, dtype=torch.float32) + 2 * rankrecv_tensor = torch.zeros(2, dtype=torch.float32)send_op = dist.P2POp(dist.isend, send_tensor, (rank + 1) % world_size)recv_op = dist.P2POp(dist.irecv, recv_tensor, (rank - 1 + world_size) % world_size)reqs = dist.batch_isend_irecv([send_op, recv_op])for req in reqs:    req.wait()print(f&quot;Rank &#123;rank&#125; æ”¶åˆ°: &#123;recv_tensor&#125;&quot;)\nè¿è¡Œç»“æœï¼š\nRank 0 æ”¶åˆ°: tensor([2., 3.])Rank 1 æ”¶åˆ°: tensor([0., 1.])\n\n5.5 é€šä¿¡æµç¨‹å›¾\nsequenceDiagram    participant Rank0    participant Rank1    Rank0-&gt;&gt;Rank1: isend(send_tensor, dst=1)    Rank1-&gt;&gt;Rank0: isend(send_tensor, dst=0)    Rank0-&gt;&gt;Rank0: irecv(recv_tensor, src=1)    Rank1-&gt;&gt;Rank1: irecv(recv_tensor, src=0)    Note over Rank0,Rank1: batch_isend_irecv([send_op, recv_op])&lt;br&gt;å¹¶å‘å‘èµ·é€šä¿¡å¹¶ç­‰å¾…å®Œæˆ\n\n5.6 é‡è¦æ³¨æ„äº‹é¡¹\n\næ³¨æ„\n\nå¦‚æœä½¿ç”¨ NCCL åç«¯ï¼Œå¿…é¡»æå‰ç”¨ torch.cuda.set_device è®¾ç½®å¥½å½“å‰ GPUï¼\nå¦‚æœè¿™æ˜¯æŸä¸ª group çš„ç¬¬ä¸€æ¬¡é€šä¿¡ï¼Œgroup é‡Œçš„æ‰€æœ‰ rank å¿…é¡»éƒ½è°ƒç”¨ batch_isend_irecvï¼Œå¦åˆ™è¡Œä¸ºæœªå®šä¹‰ã€‚\nä»¥ååªè¦ä¸æ˜¯ç¬¬ä¸€æ¬¡ collectiveï¼Œå…è®¸åªç”¨éƒ¨åˆ† rank å‚ä¸ã€‚\n\n\n\n5.7 æºç å®ç°è¦ç‚¹\n\nè‡ªåŠ¨åˆ¤æ–­é€šä¿¡åç«¯æ˜¯å¦æ”¯æŒæ“ä½œåˆå¹¶ï¼ˆcoalescingï¼‰ï¼Œå¦‚ NCCL ä¼šåœ¨åŒä¸€ä¸ªä¸Šä¸‹æ–‡ä¸‹æ‰¹é‡å¯åŠ¨ï¼Œæå‡æ€§èƒ½ã€‚\nè¿”å›æ‰€æœ‰ requestï¼ˆWorkï¼‰å¯¹è±¡ï¼Œç”¨æˆ·å¯ wait()ã€‚\n\n\n5.8 API æ–‡æ¡£é“¾æ¥\n\nPyTorch å®˜æ–¹ batch_isend_irecv æ–‡æ¡£\nP2POp å®˜æ–¹è¯´æ˜\n\n\n6. æ€»ç»“è¡¥å……\n\nå¼ é‡ç‚¹å¯¹ç‚¹é€šä¿¡ï¼šsend/recv/isend/irecv/batch_isend_irecv\nå¯¹è±¡é€šä¿¡ï¼šsend_object_list/recv_object_list\næ‰¹é‡ç‚¹å¯¹ç‚¹é€šä¿¡èƒ½æå¤§æå‡ pipeline é€šä¿¡æ•ˆç‡\nç»Ÿä¸€è¿”å› Work å¥æŸ„ï¼Œæ”¯æŒåŒæ­¥æˆ–å¼‚æ­¥\ngroup/src/dst ä½¿ç”¨æ–¹å¼åŒä¸Šæ–‡æè¿°\n\n\n7. å‚è€ƒèµ„æ–™\n\nPyTorch Distributed å®˜æ–¹æ–‡æ¡£\nPyTorch distributed_c10d.py æºç \nMermaid Live Editor\n\n\n","categories":["åˆ†å¸ƒå¼åŸºç¡€"],"tags":["send recv"]},{"title":"pytorch Shard","url":"/2025/06/20/distribute/shard/","content":"\n\n1. _split_tensoråˆ†æ\n1.1 ä»£ç å®ç°æµç¨‹å›¾ï¼ˆMermaidï¼‰\nflowchart TD  A[&quot;è¾“å…¥ï¼štensor, num_chunks, with_padding, contiguous&quot;] --&gt; B&#123;&quot;dim â‰¤ tensor.ndim?&quot;&#125;  B -- å¦ --&gt; E[&quot;AssertionError æŠ›å‡º&quot;]  B -- æ˜¯ --&gt; C[&quot;è°ƒç”¨ torch.chunk æ²¿ dim åˆ†å—&quot;]  C --&gt; D[&quot;tensor_list, è®¡ç®— num_empty_tensors = num_chunks - len(tensor_list)&quot;]  D --&gt; F&#123;&quot;æ— éœ€ padding æˆ– å‡åŒ€å¯åˆ†?&quot;&#125;  F -- æ˜¯ --&gt; G[&quot;(å¯é€‰) å¯¹æ¯å—è°ƒç”¨ .contiguous()&quot;]  G --&gt; H[&quot;è°ƒç”¨ fill_empty_tensor_to_shards è¡¥ç©º shard&quot;]  H --&gt; I[&quot;è¿”å› shards åˆ—è¡¨ å’Œ ç©º pad_sizes []&quot;]  F -- å¦ --&gt; J[&quot;è®¡ç®— full_chunk_size = ceil(dim_size / num_chunks)&quot;]  J --&gt; K[&quot;æ”¶é›†åŸå§‹ chunk_sizes&quot;]  K --&gt; L[&quot;pad_sizes = full_chunk_size - chunk_size&quot;]  L --&gt; M[&quot;è°ƒç”¨ fill_empty_tensor_to_shards è¡¥ç©º shard&quot;]  M --&gt; N[&quot;å¯¹æ¯ä¸ª shardï¼šè‹¥ pad_size &gt; 0ï¼Œåˆ™ pad_tensor(shard, dim, pad_size)&quot;]  N --&gt; O[&quot;(å¯é€‰) shard.contiguous()&quot;]  O --&gt; P[&quot;æ”¶é›† shard_list å’Œ pad_sizes&quot;]  P --&gt; Q[&quot;è¿”å› shard_list å’Œ pad_sizes&quot;]\n\n1.2 å…³é”®ç‚¹è¯¦è§£\nğŸ§  ä¸ºä»€ä¹ˆè¦ Paddingï¼Ÿ\nç”¨äºä¿è¯åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸­ï¼ˆæ¯”å¦‚ scatterã€all_gather ç­‰ collective æ“ä½œï¼‰æ¯ä¸ª rank çš„ shard å¤§å°ä¸€è‡´ï¼Œé¿å…å› ä¸ºå°ºå¯¸ä¸å¯¹é½å¯¼è‡´é€šä¿¡å¤±è´¥ã€‚åªæœ‰ tensor.size(dim) % num_chunks â‰  0 ä¸” with_padding=True æ—¶ï¼Œæ‰ä¼šè¿›è¡Œ paddingã€‚\nğŸ§© fill_empty_tensor_to_shards\ntorch.chunk åœ¨å°ºå¯¸è¾ƒå°æˆ– num_chunks æ›´å¤§æ—¶ä¸ä¼šè¾“å‡ºç©º tensorã€‚è¯¥å‡½æ•°ç”¨äºè¡¥å…¨ï¼šåœ¨ tensor_list å°‘äº num_chunks æ—¶ï¼Œè¡¥å……å½¢çŠ¶åˆæ³•ä½† dim ä¸Šä¸º 0 çš„ç©º tensorï¼Œä½¿ shard æ•°ç›®ä¸€è‡´ï¼Œä¾¿äºåç»­ç»Ÿä¸€å¤„ç†ã€‚\nğŸ§¼ pad_tensor\nè‹¥å½“å‰ shard å°äº full_chunk_sizeï¼Œåˆ™åœ¨æŒ‡å®šç»´åº¦æœ«å°¾è¡¥é›¶ï¼Œç¡®ä¿æ‰€æœ‰ shard çš„å½¢çŠ¶ä¸€è‡´ã€‚\nğŸ§± contiguous\nä¸ºæå‡å†…å­˜è¿è´¯æ€§å’Œé€šä¿¡æ•ˆç‡ï¼Œå¯è°ƒç”¨ .contiguous() é‡æ’å†…å­˜å¸ƒå±€ã€‚\n\n1.3 å®é™…è°ƒç”¨ç¤ºä¾‹ï¼ˆéœ€ Paddingï¼‰\nä»¥ä¸‹ä¸ºæ— æ³•å‡åŒ€åˆ†ç‰‡ï¼Œå›  num_chunks=4 è€Œè§¦å‘ pad çš„åœºæ™¯ï¼š\nimport torchfrom torch.distributed.tensor.placement_types import Shard# æ„é€ å¼ é‡tensor = torch.arange(1, 13).reshape(2, 6)  # shape [2, 6]# åœ¨ dim=1 ä¸Šæ‹†ä¸º 4 ä»½ï¼Œä¸æ•´é™¤å°†è§¦å‘ paddingsharder = Shard(dim=1)shards, pad_sizes = sharder._split_tensor(tensor, num_chunks=4, with_padding=True)print(&quot;Pad sizes:&quot;, pad_sizes)for i, (sh, pad) in enumerate(zip(shards, pad_sizes)):    print(f&quot;Shard &#123;i&#125; shape: &#123;tuple(sh.shape)&#125;, pad: &#123;pad&#125;&quot;)    print(sh)\nâœ… é¢„æœŸç»“æœ\n\ntensor.size(1)=6, num_chunks=4 â‡’ full_chunk_size = ceil(6/4) = 2\ntorch.chunk ä¼šå‡º 4 å—ï¼Œä½†æœ€åä¸€ä¸¤å—å¯èƒ½ä¸º empty\npad_sizes å¯èƒ½ä¸º [0, 0, 0, 2]\næœ€ç»ˆæ¯å—å¤§å°éƒ½æ˜¯ [2] (dim=1)ï¼Œpadding è¡¥é½\n\nPad sizes: [0, 0, 0, 2]Shard 0 shape: (2, 2), pad: 0tensor([[1, 2],        [7, 8]])Shard 1 shape: (2, 2), pad: 0tensor([[ 3,  4],        [ 9, 10]])Shard 2 shape: (2, 2), pad: 0tensor([[ 5,  6],        [11, 12]])Shard 3 shape: (2, 2), pad: 2tensor([[0, 0],        [0, 0]])\n\n1.4 æ€»ç»“\n\n_split_tensor çš„ä½œç”¨æ˜¯å°†ä¸€ä¸ª Tensor æ²¿æŒ‡å®šç»´åº¦åˆ‡åˆ†ä¸ºå›ºå®šä»½æ•°ï¼Œå¹¶åœ¨ ä¸èƒ½æ•´é™¤æ—¶è‡ªåŠ¨è¡¥é½ã€‚\nå®ƒä¿éšœäº†å„ shard åœ¨é€šä¿¡é˜¶æ®µå°ºå¯¸ä¸€è‡´ï¼Œé€‚ç”¨äºåˆ†å¸ƒå¼å¼ é‡å¹¶è¡Œåœºæ™¯ã€‚\nå®é™…ä»£ç é€šè¿‡ torch.chunkã€fill_empty_tensor_to_shardsã€pad_tensor ç­‰æ‰‹æ®µï¼Œè½»æ¾å®ç°è¿™ä¸€ç›®æ ‡ã€‚\n\n\n","categories":["åˆ†å¸ƒå¼åŸºç¡€"],"tags":["shard"]},{"title":"pytorchä¸­çš„streamå’Œevent","url":"/2025/09/07/distribute/stream_event/","content":"\n\n\nä¸€å¥è¯æ€»è§ˆï¼šæµï¼ˆstreamï¼‰æ˜¯ GPU ä¸Šçš„â€œæœ‰åºæŒ‡ä»¤é˜Ÿåˆ—â€ï¼Œäº‹ä»¶ï¼ˆeventï¼‰æ˜¯æ’åœ¨æµæ—¶é—´çº¿ä¸Šçš„â€œæ …æ /æ—¶é—´æˆ³â€ã€‚æŠŠ event.record() æ”¾åœ¨ç”Ÿäº§æµä¸Šï¼Œå†åœ¨æ¶ˆè´¹æµé‡Œ wait_event()ï¼Œå°±èƒ½åšåˆ°è®¾å¤‡ä¾§çš„æ— é˜»å¡ä¾èµ–ç¼–æ’ã€‚(docs.pytorch.org)\n\n\n1. åŸºæœ¬æ¦‚å¿µ\n\nStreamï¼ˆæµï¼‰ï¼šåŒä¸€æ¡æµå†…æŒ‰æäº¤é¡ºåºï¼ˆFIFOï¼‰æ‰§è¡Œï¼›ä¸åŒæµå½¼æ­¤ç‹¬ç«‹ï¼Œå¯å¹¶è¡Œè¿è¡Œã€‚PyTorch çš„ torch.cuda.Stream å°±æ˜¯ CUDA æµçš„å°è£…ï¼Œå¹¶æä¾› record_event / wait_event / wait_stream / synchronize ç­‰æ–¹æ³•ã€‚(docs.pytorch.org)\nEventï¼ˆäº‹ä»¶ï¼‰ï¼šåŒæ­¥æ ‡è®°ã€‚å¯ç”¨äºæµ‹æ—¶ä¸è·¨æµåŒæ­¥ï¼šåœ¨ç”Ÿäº§æµ record()ï¼Œåœ¨æ¶ˆè´¹æµ wait()/wait_event()ã€‚äº‹ä»¶ä¹Ÿå¯ elapsed_time() è¯»å–GPU ç«¯çš„æ¯«ç§’è®¡æ—¶ã€‚(docs.pytorch.org)\né»˜è®¤æµè¯­ä¹‰ï¼š\n\nLegacy default stream ä¼šä¸å…¶å®ƒï¼ˆé˜»å¡å‹ï¼‰æµäº’ç›¸åŒæ­¥ï¼›\nPer-thread default streamï¼ˆPTDSï¼‰ ä¸ä¸å…¶ä»–æµåŒæ­¥ï¼Œè¡Œä¸ºæ›´åƒæ˜¾å¼åˆ›å»ºçš„æµã€‚ ä¸¤è€…å¯åœ¨ç¼–è¯‘/å®å±‚é¢é€‰æ‹©ï¼Œè¡Œä¸ºä¸åŒä¼šå½±å“æ˜¯å¦â€œè‡ªåŠ¨åŒæ­¥â€ã€‚(NVIDIA Docs)\n\n\n\n2. ä¸‰ç§â€œç­‰å¾…â€çš„ä½œç”¨åŸŸï¼ˆè¶Šå°è¶Šå¥½ï¼‰\n\nè®¾å¤‡çº§ï¼štorch.cuda.synchronize(device) â€”â€” ç­‰è¯¥è®¾å¤‡ä¸Šæ‰€æœ‰æµåˆ°å½“å‰ä¸ºæ­¢çš„å·¥ä½œå®Œæˆã€‚æœ€é‡ï¼Œä¸€èˆ¬å°‘ç”¨ã€‚ï¼ˆè¯­ä¹‰ç­‰åŒ cudaDeviceSynchronizeï¼‰(developer.download.nvidia.com)\nå•æµçº§ï¼šstream.synchronize() â€”â€” åªç­‰è¿™ä¸€æ¡æµå·²æäº¤çš„å·¥ä½œï¼Œç­‰åŒ cudaStreamSynchronizeã€‚(docs.pytorch.org)\näº‹ä»¶çº§ï¼ševent.synchronize() â€”â€” åªç­‰è¯¥äº‹ä»¶æ‰€æ•è·çš„å·¥ä½œï¼Œç­‰åŒ cudaEventSynchronizeã€‚ç²’åº¦æœ€ç»†ï¼Œæ¨èä¼˜å…ˆç”¨äº‹ä»¶æ¥è¡¨è¾¾ä¾èµ–ã€‚(docs.pytorch.org)\n\n\nå£è¯€ï¼šdevice &gt; stream &gt; eventï¼ˆç­‰å¾…èŒƒå›´ä»å¤§åˆ°å°ï¼‰ã€‚é€‰æœ€å°å¿…è¦èŒƒå›´ï¼Œä¿ç•™å¹¶è¡Œåº¦ã€‚(developer.download.nvidia.com)\n\n\n3. è·¨æµåŒæ­¥çš„ä¸‰ç§æ–¹å¼\n\näº‹ä»¶æ …æ ï¼ˆæ¨èï¼‰\n\nç”Ÿäº§æµï¼ševent.record()\næ¶ˆè´¹æµï¼šconsumer.wait_event(event)ï¼ˆæˆ– event.wait(consumer)ï¼‰ è¯¥è°ƒç”¨ç«‹å³è¿”å›ï¼Œåªæ˜¯æŠŠâ€œç­‰å¾… eâ€è¿™æ¡ä¾èµ–å†™è¿›äº†æ¶ˆè´¹æµçš„é˜Ÿåˆ—ï¼›åç»­æäº¤çš„å·¥ä½œéƒ½ä¼šåœ¨ e å®Œæˆåæ‰§è¡Œã€‚(docs.pytorch.org)\n\næµ-æµç­‰å¾…\n\nthis.wait_stream(that)ï¼šè®© this æµåç»­å·¥ä½œï¼Œç­‰å¾… that æµå½“å‰å·²æäº¤çš„å·¥ä½œå®Œæˆã€‚(docs.pytorch.org)\n\né»˜è®¤æµè¯­ä¹‰ï¼ˆå†å²å…¼å®¹ï¼‰\n\nè‹¥ä½¿ç”¨ legacy default streamï¼Œå®ƒä¼šä¸å…¶å®ƒé˜»å¡æµäº’ç›¸åŒæ­¥ï¼›PTDS åˆ™ä¸ä¼šã€‚æ–°ä»£ç ä¸å»ºè®®ä¾èµ–è¿™ç§â€œéšå¼åŒæ­¥â€ã€‚(NVIDIA Docs)\n\n\n\n4. å¼ é‡ç”Ÿå‘½å‘¨æœŸçš„å®‰å…¨ï¼ˆsafeï¼‰ç”¨æ³•\nè·¨æµå…±äº«åŒä¸€å—æ˜¾å­˜æ—¶ï¼Œé™¤äº†â€œå†™æ¸…æ¥šä¾èµ–â€ï¼ˆäº‹ä»¶/æµç­‰å¾…ï¼‰ï¼Œè¿˜åº”åœ¨ä½¿ç”¨è¯¥å¼ é‡çš„æµä¸Šè°ƒç”¨ï¼š\ntensor.record_stream(consumer_stream)\nè¿™ä¼šå‘Šè¯‰ CUDA ç¼“å­˜åˆ†é…å™¨ï¼šè¯¥å¼ é‡ä¹Ÿåœ¨ consumer_stream ä¸Šè¢«ç”¨è¿‡ï¼Œä»è€Œé¿å…åœ¨ç”Ÿäº§æµé‡Šæ”¾åè¢«è¿‡æ—©å¤ç”¨ï¼Œé€ æˆæ½œåœ¨è¯»å†™ç«æ€ã€‚å¦åˆ™éœ€è¦åœ¨é‡Šæ”¾å‰æŠŠä½¿ç”¨åŒæ­¥å›åˆ›å»ºæµã€‚(docs.pytorch.org)\n\n5. CPUâ†”GPU æ‹·è´ä¸ non_blocking / pinned memory\n\nåªæœ‰å½“é¡µé”å®šå†…å­˜ï¼ˆpinnedï¼‰å‚ä¸æ—¶ï¼Œå¾ˆå¤šæ‹·è´æ‰èƒ½çœŸæ­£å¼‚æ­¥åŒ–å¹¶ä¸è®¡ç®—é‡å ï¼›PyTorch æ•™ç¨‹å¯¹ pin_memory() ä¸ non_blocking=True çš„è¡Œä¸ºåšäº†ç³»ç»Ÿè¯´æ˜ã€‚(docs.pytorch.org)\nè¯»å– D2H ç»“æœå‰ï¼Œåº”ç­‰å¾…æ‹·è´å®Œæˆï¼ˆäº‹ä»¶æˆ–åŒæ­¥ï¼‰ï¼Œä¸è¦ç›´æ¥åœ¨ CPU ç«¯æ¶ˆè´¹å¼‚æ­¥ç»“æœã€‚(docs.pytorch.org)\n\næ¨èæ¨¡å¼ï¼ˆD2H æ‹·è´ä¸â€œå¡ä½â€æ•´æœºï¼Œåªåœ¨ç”¨åˆ°ç»“æœæ—¶å°èŒƒå›´ç­‰å¾…ï¼‰ï¼š\nimport torchx  = torch.randn(1_000_000, device=&quot;cuda&quot;)dst = torch.empty_like(x, device=&quot;cpu&quot;, pin_memory=True)  # pinned CPU buffercopy_stream = torch.cuda.Stream()copy_done   = torch.cuda.Event()with torch.cuda.stream(copy_stream):    dst.copy_(x, non_blocking=True)  # å¼‚æ­¥ D2H    copy_done.record()               # ä»…æ‹·è´å®Œæˆå¤„æ‰“ç‚¹# â€¦â€¦CPU å¯ä»¥å…ˆåšåˆ«çš„æ´»â€¦â€¦copy_done.synchronize()              # åªæœ‰åœ¨çœŸæ­£è¦ç”¨ dst æ—¶æ‰ç­‰è¿™ä¸€æ¬¡print(dst[:5])\n\nè¦ç‚¹ï¼špinned + ä¸“ç”¨æ‹·è´æµ + äº‹ä»¶ï¼›é¿å…ç”¨è®¾å¤‡çº§ torch.cuda.synchronize() ç²—æš´â€œåˆ¹è½¦â€ã€‚(docs.pytorch.org, developer.download.nvidia.com)\n\n\n6. å¯è¿è¡Œæœ€å°ç¤ºä¾‹\n6.1 è®¡ç®—æµ â†’ é€šä¿¡/åå¤„ç†æµï¼ˆäº‹ä»¶æ …æ ï¼‰\nimport torchdevice = &quot;cuda&quot;compute = torch.cuda.Stream()comm    = torch.cuda.Stream()done    = torch.cuda.Event()x = torch.randn(1_000_000, device=device)with torch.cuda.stream(compute):    y = x.relu()    done.record()           # è®°å½•â€œy å·²å°±ç»ªâ€comm.wait_event(done)       # è®© comm æµç­‰åˆ° y å°±ç»ªwith torch.cuda.stream(comm):    z = y * 2               # åœ¨ GPU ç«¯è‡ªåŠ¨ç­‰å¾…ï¼Œä¸é˜»å¡ CPUtorch.cuda.synchronize()    # ç¤ºä¾‹æ”¶å°¾ï¼šçœŸå®å·¥ç¨‹é‡Œå¯ç»§ç»­æäº¤åç»­å·¥ä½œ\næœºåˆ¶è¯´æ˜ï¼šwait_event æŠŠâ€œç­‰å¾… eâ€æ’å…¥åˆ°æ¶ˆè´¹æµé˜Ÿåˆ—ï¼Œåªæœ‰äº‹ä»¶è§¦å‘åï¼Œæ¶ˆè´¹æµåç»­ kernel æ‰ä¼šæ‰§è¡Œï¼›è¿™éƒ½æ˜¯è®¾å¤‡ä¾§å®Œæˆï¼ŒCPU ä¸è¢«é˜»å¡ã€‚(docs.pytorch.org)\n6.2 ä¸‰æµç¤ºä¾‹ï¼ˆS2 ä¸ S3 éƒ½ç­‰ S1ï¼‰\ns1, s2, s3 = torch.cuda.Stream(), torch.cuda.Stream(), torch.cuda.Stream()e = torch.cuda.Event()with torch.cuda.stream(s1):    a = torch.randn(1024, 1024, device=&quot;cuda&quot;) @ torch.randn(1024, 1024, device=&quot;cuda&quot;)    e.record()s2.wait_event(e)s3.wait_event(e)with torch.cuda.stream(s2):    b = a.relu_()with torch.cuda.stream(s3):    c = a.sum()\n\nåŒä¸€ä¸ªäº‹ä»¶å¯ä»¥è¢«å¤šæ¡æµç­‰å¾…ï¼Œé€‚åˆâ€œä¸€å¯¹å¤šâ€çš„ä¾èµ–ã€‚(docs.pytorch.org)\n\n6.3 GPU ç«¯ç²¾å‡†è®¡æ—¶ï¼ˆEvent elapsed_timeï¼‰\nimport torchs = torch.cuda.Stream()start = torch.cuda.Event(enable_timing=True)end   = torch.cuda.Event(enable_timing=True)x = torch.randn(4096, 4096, device=&quot;cuda&quot;)w = torch.randn(4096, 4096, device=&quot;cuda&quot;)# é¢„çƒ­for _ in range(2): (x @ w).sum().relu_()with torch.cuda.stream(s):    start.record()    y = (x @ w).relu_()    end.record()end.synchronize()print(f&quot;elapsed = &#123;start.elapsed_time(end):.3f&#125; ms&quot;)\n\nelapsed_time è¿”å› start.record ä¸ end.record ä¹‹é—´çš„ GPU æ¯«ç§’æ•°ï¼›end.synchronize() ç¡®ä¿æµ‹é‡é—­åŒºé—´å·²å®Œæˆã€‚(docs.pytorch.org)\n\n\n7. å¸¸è§å‘ä¸é€Ÿè®°\n\näº‹ä»¶ä½ç½®è¦å¯¹ï¼šrecord() åªè¦†ç›–å®ƒä¹‹å‰å·²å…¥é˜Ÿçš„å·¥ä½œï¼›ä¹‹åæ–°æäº¤çš„å·¥ä½œä¸åŒ…å«åœ¨æœ¬äº‹ä»¶å†…ã€‚ä½¿ç”¨æ—¶å°† record() æ”¾åœ¨ç”Ÿäº§ç»“æŸç‚¹ã€‚(docs.pytorch.org)\nwait_event/wait_stream å‡ä¸ºâ€œå†™ä¾èµ–ã€ç«‹å³è¿”å›â€ï¼šå®ƒä»¬ä¸ä¼šé˜»å¡ CPUï¼Œåªå½±å“åç»­æäº¤åˆ°è¯¥æµçš„å·¥ä½œã€‚(docs.pytorch.org)\né»˜è®¤æµé™·é˜±ï¼šLegacy ä¸ PTDS è¯­ä¹‰ä¸åŒã€‚æ··ç”¨æ—¶ï¼Œlegacy ä¼šä¸é˜»å¡æµäº’ç›¸ç­‰å¾…ï¼›PTDS ä¸ä¼šã€‚æ–°å·¥ç¨‹å»ºè®®æ˜¾å¼å»ºæµ + æ˜¾å¼åŒæ­¥ï¼Œé¿å…è¸©éšå¼åŒæ­¥ã€‚(NVIDIA Docs)\næµä¼˜å…ˆçº§ï¼šä½æ•°å­—=é«˜ä¼˜å…ˆçº§ï¼›åªæ˜¯â€œå€¾å‘â€ï¼Œä¸æŠ¢å å·²åœ¨è¿è¡Œçš„ kernelã€‚(NVIDIA Docs)\n\n\n8. æœ¯è¯­ä¸€é¡µçº¸\n\nStreamï¼šè®¾å¤‡ä¸Šç‹¬ç«‹çš„æœ‰åºæ‰§è¡Œé˜Ÿåˆ—ã€‚record_eventã€wait_eventã€wait_streamã€synchronizeã€‚(docs.pytorch.org)\nEventï¼šè®¾å¤‡ä¾§æ …æ /æ—¶é—´æˆ³ï¼›recordã€waitã€synchronizeã€elapsed_timeã€‚(docs.pytorch.org)\nå®‰å…¨è·¨æµï¼šå†™ä¾èµ– + tensor.record_stream(consumer)ï¼ˆæˆ–æ‰‹åŠ¨ç¡®ä¿é‡Šæ”¾å‰åŒæ­¥å›åˆ›å»ºæµï¼‰ã€‚(docs.pytorch.org)\né«˜æ•ˆ D2Hï¼špinned + ä¸“ç”¨æ‹·è´æµ + äº‹ä»¶ï¼›æŒ‰éœ€ç­‰å¾…ï¼Œé¿å…å…¨è®¾å¤‡åŒæ­¥ã€‚(docs.pytorch.org)\n\n\nå‚è€ƒèµ„æ–™ï¼ˆå¼ºçƒˆå»ºè®®ç»†è¯»åŸæ–‡ï¼‰\n\nPyTorchï¼štorch.cuda.Stream APIï¼ˆå« wait_event / wait_stream / synchronizeï¼‰ä¸æ–‡æ¡£æ³¨é‡Šã€‚(docs.pytorch.org)\nPyTorchï¼štorch.cuda.Event APIï¼ˆrecord / wait / synchronize / elapsed_timeï¼‰ã€‚(docs.pytorch.org)\nPyTorchï¼štensor.record_streamï¼ˆè·¨æµå†…å­˜ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼‰ã€‚(docs.pytorch.org)\nPyTorch æ•™ç¨‹ï¼špin_memory() ä¸ non_blocking ä½¿ç”¨ä¸æ³¨æ„äº‹é¡¹ã€‚(docs.pytorch.org)\nNVIDIA CUDA æ–‡æ¡£ï¼šé»˜è®¤æµï¼ˆLegacy vs PTDSï¼‰è¯­ä¹‰ä¸æµä¼˜å…ˆçº§è¯´æ˜ã€‚(NVIDIA Docs)\nNVIDIA åŸ¹è®­è®²ä¹‰ï¼šcudaDeviceSynchronize / cudaStreamSynchronize / cudaEvent* çš„åŒæ­¥å¯¹æ¯”ä¸ç¤ºä¾‹ã€‚(developer.download.nvidia.com)\n\n\n","categories":["åˆ†å¸ƒå¼åŸºç¡€"],"tags":["stream"]},{"title":"pytorchä¸­TCPStore Rendezvousæœºåˆ¶","url":"/2025/06/14/distribute/tcpstore_rendezvous/","content":"\n\nğŸ§  èƒŒæ™¯æ¦‚è¿°\n\nç›®æ ‡ï¼šåœ¨ init_process_group ä¸­å®ç°è·¨è¿›ç¨‹æ³¨å†Œã€æ’åºåŠ barrier åŒæ­¥ï¼Œä¸º NCCL/Gloo é€šä¿¡ç»„æ„å»ºåˆ›å»ºä¸€è‡´ä¸Šä¸‹æ–‡ã€‚\næ—¶åºï¼šæ‰€æœ‰ set/get/wait æ“ä½œå‡å‘ç”Ÿåœ¨ NCCL é€šä¿¡åˆå§‹åŒ–ä¹‹å‰ï¼ˆå³ rendezvous é˜¶æ®µï¼‰ã€‚\næœºåˆ¶ï¼šsocket å®¢æˆ·ç«¯â€”æœåŠ¡å™¨æ¨¡å‹ + backend æ§åˆ¶åŒæ­¥é€»è¾‘ã€‚\n\n\n1. æ¶ˆæ¯åè®®æ ¼å¼\nå®¢æˆ·ç«¯å‘ master å‘é€çš„åŒ…æ ¼å¼ä¸ºï¼š\n\\[4â€¯B æ€»é•¿åº¦]\\[1â€¯B æ“ä½œç ]\\[4â€¯B key\\_len]\\[4â€¯B value\\_len]\\[key]\\[value]\n\næ€»é•¿åº¦ï¼šç½‘ç»œå­—èŠ‚åºï¼Œä¸å«è‡ªèº«ï¼›\næ“ä½œç ï¼š1=SET, 2=GET, 3=WAITï¼›\nkey_len, value_lenï¼šåç»­å­—æ®µé•¿åº¦ï¼›\nkey, valueï¼šå®é™…æ•°æ®ï¼›\nMaster è§£æåï¼Œå›å¤ï¼šOK / value å†…å®¹ / READY ç­‰ã€‚\n\n\n2. Rendezvous é˜¶æ®µæµç¨‹ï¼ˆ2 æœºï¼Œ4 å¡ eachï¼Œèšç„¦ rank1 &amp; rank5ï¼‰\nflowchart TB  subgraph A[&quot;Machine A (rank0-3)&quot;]    master[&quot;TCPStoreBackend (master)&quot;]    r1[Worker rank1]    master --- r1  end  subgraph B[&quot;Machine B (rank4-7)&quot;]    r5[Worker rank5]    master --- r5  end  r1 --&gt;|SET key rank1_addr| master  r5 --&gt;|SET key rank5_addr| master  r1 --&gt;|WAIT  rendezvous_done| master  r5 --&gt;|WAIT  rendezvous_done| master  %% Server: waits until all ranks set, then:  master --&gt;|write READY| r1  master --&gt;|write READY| r5  %% å®Œæˆ WAIT è¿”å›ï¼Œè¿›å…¥ NCCL åˆå§‹åŒ–  r1 --&gt;|recv READY â†’ NCCL init| NCCL_1[NCCL Init rank1]  r5 --&gt;|recv READY â†’ NCCL init| NCCL_5[NCCL Init rank5]\nğŸ§© æ­¥éª¤è§£æ\n\nMaster åœ¨ç«¯å£ï¼ˆå¦‚ 29500ï¼‰ä¾¦å¬ï¼Œæ¥æ”¶è¿æ¥ï¼›\nrank1 / rank5 åˆ†åˆ«å‘é€ SETï¼ˆæ³¨å†Œåœ°å€ï¼‰ï¼›\néšåå‘é€ WAIT(\"rendezvous_done\")ï¼ŒSocket å¤„äºé˜»å¡çŠ¶æ€ï¼›\nMaster æ”¶é›†æ‰€æœ‰ 8 ä¸ª rank çš„ SET åï¼Œéå† wait é˜»å¡çš„è¿æ¥ï¼Œé€ä¸€å†™å…¥ READYï¼›\nWorker æ”¶åˆ° READYï¼Œé€€å‡ºé˜»å¡ï¼Œè¿›å…¥ NCCL åˆå§‹åŒ–é˜¶æ®µï¼›\néšååœ¨è¿™ä¸€é˜¶æ®µå†…ï¼šäº¤æ¢ ncclUniqueId (via store), è°ƒç”¨ ncclCommInitRank æ„å»ºé€šä¿¡ç»„ (github.com, pytorch.org)ã€‚\n\n\n3. Backend ç»†èŠ‚å¯¹æ¯”\n\n\n\n\n\n\n\n\nBackend\nI/O æ¨¡å‹\nç‰¹ç‚¹ä¸é€‚åº”æ€§\n\n\n\n\nç»å…¸ TCPStoreBackend\naccept() + per-conn é˜»å¡/POLL\nç®€å•ï¼Œè¿æ¥è¾ƒå¤šæ—¶æ‰©å±•æ€§å·®\n\n\nlibuv å¼‚æ­¥ Backend\nå•çº¿ç¨‹ event-loop, readable/writeable\né»˜è®¤å¯ç”¨ï¼ˆv2.4+ï¼‰ï¼Œé«˜å¹¶å‘æ›´ä¼˜ (docs.pytorch.org)\n\n\n\n\nlibuv backend ä½¿ç”¨ uv_read_start è‡ªåŠ¨åˆ†å—è¯»å–ï¼Œæ ¹æ® header æ§åˆ¶æ‹¼åŒ…ï¼›\næ³¨å†Œ WAIT æ—¶ï¼Œå°† conn ä¿å­˜åœ¨ map ä¸­ï¼Œä¸ç«‹å³å›å†™ï¼›å½“æ¡ä»¶æ»¡è¶³ï¼Œè§¦å‘ uv_write() â†’ uv_write_cb å®ç°å”¤é†’ã€‚\n\n\n4. partial-key WAIT æœºåˆ¶\n\nå®¢æˆ·ç«¯å¯ä»¥æ‰§è¡Œ store.wait([\"kA\", \"kB\"])ï¼›\nMaster å°†æ­¤ç­‰å¾…ç™»è®°è‡³ MultiWaitRegistryï¼›\nå½“ æ‰€æœ‰ç›¸å…³ key å‡è¢« SET åï¼Œæ‰ç»Ÿä¸€å‘è¯¥è¿æ¥å†™ READYï¼Œè§¦å‘å”¤é†’ã€‚\n\n\n5. â€œå¹¿æ’­ READYâ€ çš„å®ç°æœºåˆ¶\n\nä¸æ˜¯é€šè¿‡ NCCL/Gloo broadcast ç®—å­ï¼›\nMaster éå†æŒ‚èµ·çš„ WAIT socketsï¼Œé€ä¸ªå†™ READYï¼›\nä¸º rendezvous è¿‡ç¨‹è‡ªèº«æä¾›åŒæ­¥æœºåˆ¶ï¼Œé€šä¿¡ç»„å°šæœªåˆ›å»ºã€‚\n\n\n6. æ—¶é—´çº¿æ¦‚è§ˆ\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚ SET/WAIT via TCP Store   â”‚  # rendezvous é˜¶æ®µâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â†“â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚ recv READY â†’ wait returnsâ”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â†“â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚ NCCL Init                â”‚  # è°ƒç”¨ ncclUniqueId, CommInitRankâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â†“â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚ Collective Ops (DDP)     â”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nâœ… æ€»ç»“è¦ç‚¹\n\næ ‡æ³¨ rank1 / rank5 çš„æµç¨‹å›¾ï¼Œæ›´ç›´è§‚ï¼›\nSET + WAIT æ“ä½œå…¨éƒ¨å‘ç”Ÿäº rendezvous é˜¶æ®µï¼Œè§å›¾ï¼›\nMaster â€œå¹¿æ’­ READYâ€ æ˜¯ socket å†™æ“ä½œï¼Œä¸æ˜¯é€šä¿¡åº“å¹¿æ’­ï¼›\nNCCL åˆå§‹åŒ–åœ¨ rendezvous å®Œæˆåè¿›è¡Œï¼›\nlibuv backend æä¾›æ›´é«˜æ•ˆ I/O å¤„ç†åŠ message æ‹¼æ¥å¤„ç†èƒ½åŠ› (docs.pytorch.org, pytorch.org, github.com)ã€‚\n\n\n","categories":["åˆ†å¸ƒå¼åŸºç¡€"],"tags":["tcpstore"]},{"title":"NVIDIA Resiliency Extension (NVRx) ç®€ä»‹","url":"/2026/01/14/other/nvrx/","content":"\n\ngithubåœ°å€ï¼šhttps://github.com/NVIDIA/nvidia-resiliency-ext\n\n1. ä»€ä¹ˆæ˜¯ NVRxï¼Ÿ\nNVIDIA Resiliency Extensionï¼ˆNVRxï¼‰æ ¸å¿ƒåŠŸèƒ½ç¤ºæ„ï¼šæ”¯æŒè‡ªåŠ¨é‡å¯ã€åˆ†å±‚ï¼ˆå±‚æ¬¡åŒ–ï¼‰Checkpointã€æ•…éšœæ£€æµ‹å’Œå¥åº·æ£€æŸ¥ç­‰ã€‚è¯¥æ‰©å±•é¢å‘å¤§è§„æ¨¡åˆ†å¸ƒå¼è®­ç»ƒï¼Œé€šè¿‡æ¨¡å—åŒ–é›†æˆå¤šç§å®¹é”™æœºåˆ¶ï¼Œæé«˜å› æ•…éšœä¸­æ–­é€ æˆçš„è®­ç»ƒåœæœºæ—¶é—´ï¼Œä½¿è®­ç»ƒä¿æŒé«˜Goodputï¼ˆæœ‰æ•ˆååé‡ï¼‰ã€‚NVRx æä¾›äº†ç³»ç»Ÿçº§å¥åº·æ£€æŸ¥ã€è¿è¡Œæ—¶æ•…éšœå¿«é€Ÿæ£€æµ‹ä»¥åŠè‡ªåŠ¨æ¢å¤èƒ½åŠ›ï¼Œå¹¶ç»“åˆå¿«é€Ÿé¢‘ç¹çš„Checkpoint*å°†å·¥ä½œæŸå¤±é™åˆ°æœ€ä½ã€‚ä¸‹é¢å°†å›´ç»•é—®é¢˜æ‰€åˆ—è¦ç‚¹ï¼Œå¯¹NVRxé¡¹ç›®çš„æ•…éšœå®¹é”™åŸç†ã€åº”ç”¨åœºæ™¯ã€ç›‘æ§æ®µåˆ’åˆ†ã€é‡è¿è¡ŒçŠ¶æ€æœºã€æ•…éšœè¯Šæ–­æµç¨‹å’Œåˆ†å¸ƒå¼Checkpointæœºåˆ¶è¿›è¡Œè¯¦å°½è°ƒç ”è¯´æ˜ã€‚\n\n2. æ•…éšœå®¹é”™å®ç°åŸç†\n\nè®¾è®¡ç†å¿µï¼šNVRxçš„æ•…éšœå®¹é”™æ¨¡å—ï¼ˆFault Toleranceï¼‰é‡‡ç”¨ç‹¬ç«‹ç›‘æ§è¿›ç¨‹ + å®šæœŸå¿ƒè·³/ä»£ç æ®µæ£€æŸ¥çš„æ¶æ„ï¼Œå®ç°å¯¹è®­ç»ƒè¿›ç¨‹æŒ‚èµ·æˆ–å¤±å»å“åº”çš„æ£€æµ‹å’Œè‡ªåŠ¨æ¢å¤ã€‚åœ¨æ¯ä¸ªè®¡ç®—èŠ‚ç‚¹ä¸Šï¼ŒNVRxæä¾›ä¸€ä¸ªå®šåˆ¶çš„å¯åŠ¨å™¨ft_launcherï¼ˆåŸºäºPyTorchçš„torchrunï¼‰ï¼Œè´Ÿè´£å¯åŠ¨æ‰€æœ‰è®­ç»ƒè¿›ç¨‹ï¼ˆranksï¼‰åŠå¯¹åº”çš„ç›‘è§†è¿›ç¨‹ï¼ˆrank monitorï¼‰ã€‚æ¯ä¸ªè®­ç»ƒè¿›ç¨‹éƒ½ä¼šå’Œè‡ªå·±çš„ç›‘è§†è¿›ç¨‹å»ºç«‹è¿æ¥ï¼Œå¹¶å®šæœŸå‘é€çŠ¶æ€æ›´æ–°ï¼ˆæ¯”å¦‚æ¯æ¬¡è®­ç»ƒè¿­ä»£å‘é€â€œå¿ƒè·³â€ä¿¡å·ï¼Œæˆ–æ ‡è®°ä»£ç æ®µçš„è¿›å…¥/é€€å‡ºï¼‰ä»¥è¯æ˜è‡ªèº«å­˜æ´»ã€‚å¦‚æœç›‘è§†è¿›ç¨‹åœ¨æŒ‡å®šè¶…æ—¶æ—¶é—´å†…æœªæ”¶åˆ°æ›´æ–°ï¼Œåˆ™åˆ¤æ–­è¯¥è®­ç»ƒè¿›ç¨‹å¯èƒ½å·²å®•æŒ‚ï¼Œä»è€Œä¸»åŠ¨ç»ˆæ­¢å‡ºé—®é¢˜çš„è¿›ç¨‹ã€‚å„ç›‘è§†è¿›ç¨‹ä¹‹é—´å½¼æ­¤ç‹¬ç«‹ï¼Œä¸ç›´æ¥é€šä¿¡ï¼›è€Œft_launcheré€šè¿‡PyTorchå¼¹æ€§æ¡†æ¶çš„ rendezvous æœºåˆ¶æ„ŸçŸ¥è¿›ç¨‹å­˜æ´»çŠ¶æ€ã€‚å½“ä»»æ„ä¸€ä¸ªè®­ç»ƒè¿›ç¨‹å¼‚å¸¸ç»ˆæ­¢æˆ–è¢«ç›‘è§†è¿›ç¨‹æ€æ‰æ—¶ï¼Œft_launcherèƒ½å¤Ÿæ•è·åˆ°è¯¥äº‹ä»¶ï¼Œå¹¶æ ¹æ®é…ç½®çš„ç­–ç•¥å†³å®šæ˜¯å¦åœ¨ä¸é€€å‡ºä½œä¸šçš„å‰æä¸‹é‡å¯æ•´ä¸ªè®­ç»ƒä½œä¸šæˆ–éƒ¨åˆ†è¿›ç¨‹\nå…³é”®æœºåˆ¶ï¼šNVRxçš„æ•…éšœå®¹é”™æä¾›ä¸¤ç§æŒ‚èµ·æ£€æµ‹APIï¼Œå¯æ ¹æ®åº”ç”¨éœ€æ±‚é€‰ç”¨ï¼šä¸€æ˜¯å¿ƒè·³æœºåˆ¶ï¼ˆHeartbeats APIï¼‰ï¼Œåœ¨è®­ç»ƒä»£ç ä¸­å®šæœŸå‘é€è½»é‡â€œå¿ƒè·³â€ä¿¡å·åˆ°ç›‘è§†è¿›ç¨‹ï¼Œå¦‚æœè¶…è¿‡é˜ˆå€¼æ—¶é—´æœªæ”¶åˆ°å¿ƒè·³åˆ™åˆ¤å®šè®­ç»ƒæŒ‚èµ·ã€‚å¿ƒè·³æ–¹å¼å®ç°ç®€å•ä½†éœ€è¦è®¾ç½®è¾ƒå®½æ¾çš„è¶…æ—¶æ—¶é—´æ¥æ¶µç›–å¿ƒè·³é—´å¯èƒ½å­˜åœ¨çš„æœ€é•¿æ“ä½œæ—¶é—´ã€‚äºŒæ˜¯ä»£ç æ®µæ ‡è®°æœºåˆ¶ï¼ˆSections APIï¼‰ï¼Œå³åœ¨ç”¨æˆ·è®­ç»ƒè„šæœ¬çš„å…³é”®åŒºåŸŸæ‰‹åŠ¨æ’å…¥ä»£ç ç‰‡æ®µæ ‡è®°ï¼ˆå¦‚start_section(â€œåç§°â€)/end_section()ï¼‰ï¼Œç›‘è§†è¿›ç¨‹é’ˆå¯¹æ¯ä¸ªæ ‡è®°æ®µå„è‡ªè®¡ç®—è€—æ—¶å¹¶è®¾å®šè¶…æ—¶é˜ˆå€¼å¦‚æœæŸä»£ç æ®µè‡ªè¿›å…¥åæŒç»­æ‰§è¡Œè¶…è¿‡å…¶è¶…æ—¶ä¸Šé™ï¼Œåˆ™åˆ¤å®šè®­ç»ƒåœæ»ã€‚ç›¸æ¯”å¿ƒè·³ï¼Œåˆ†æ®µç›‘æ§å¯ä»¥é’ˆå¯¹ä¸åŒé˜¶æ®µç²¾ç»†åœ°è®¾ç½®è¶…æ—¶æ—¶é—´ï¼Œæ›´è¿…é€Ÿåœ°å‘ç°å¡é¡¿ï¼Œä½†éœ€è¦å¯¹è®­ç»ƒä»£ç è¿›è¡Œæ”¹é€ æ¥æ’å…¥æ ‡è®°ã€‚ä¸¤ç§æœºåˆ¶å¯ä»¥åŒæ—¶ä½¿ç”¨ï¼Œäº’ä¸ºè¡¥å……ã€‚ä¸€æ—¦æ£€æµ‹åˆ°æŒ‚èµ·æˆ–è¿›ç¨‹æ•…éšœï¼ŒNVRxä¼šè§¦å‘å®¹é”™å“åº”æœºåˆ¶ï¼šé¦–å…ˆåˆ©ç”¨æœ€æ–°Checkpointè‡ªåŠ¨é‡å¯ä½œä¸šï¼Œä½¿è®­ç»ƒä»ä¸­æ–­ç‚¹ç»§ç»­ï¼Œæ— éœ€äººå·¥å¹²é¢„ï¼›å¦å¤–NVRxè¿˜æ”¯æŒè¿›ç¨‹å†…é‡å¯ï¼ˆIn-Process Restartï¼‰ç­‰æŠ€æœ¯ï¼Œåœ¨å¯èƒ½æƒ…å†µä¸‹ç›´æ¥åœ¨å·²æœ‰è¿›ç¨‹ä¸­æ¢å¤ï¼Œä»¥è¿›ä¸€æ­¥åŠ å¿«æ•…éšœæ¢å¤ã€‚\nå®¹é”™èƒ½åŠ›ï¼šé€šè¿‡ä¸Šè¿°æœºåˆ¶ï¼ŒNVRxå¯ä»¥æœ‰æ•ˆåº”å¯¹è®­ç»ƒè¿‡ç¨‹ä¸­å¸¸è§çš„æ— å“åº”å¡é¡¿ã€è¿›ç¨‹å´©æºƒä»¥åŠæŸäº›ç¡¬ä»¶æ•…éšœå¯¼è‡´çš„é”™è¯¯ã€‚åœ¨é›†ç¾¤ä½œä¸šä¸­ï¼Œå®ƒå®ç°äº†ä½œä¸šå†…è‡ªåŠ¨é‡å¯ï¼šæ•…éšœå‘ç”Ÿæ—¶æ— éœ€é‡æ–°æ’é˜Ÿç”³è¯·è®¡ç®—èŠ‚ç‚¹èµ„æºï¼Œft_launcherä¼šåœ¨åŸæœ‰ä½œä¸šä¸Šä¸‹æ–‡ä¸­é‡æ–°æ‹‰èµ·è¿›ç¨‹ï¼Œæœ€å¤§ç¨‹åº¦å‡å°‘åœæœºæ—¶é—´ã€‚æ­¤å¤–ï¼ŒNVRxé…åˆå…¶Checkpointç»„ä»¶ï¼Œèƒ½å¤Ÿåšåˆ°å¿«é€Ÿä¸”é¢‘ç¹åœ°ä¿å­˜è®­ç»ƒçŠ¶æ€ï¼Œä½¿å¾—æ— è®ºæ˜¯æŒ‚èµ·è¿˜æ˜¯èŠ‚ç‚¹æ€æ­»ï¼Œè®­ç»ƒéƒ½å¯ä»æœ€è¿‘ä¸€æ¬¡checkpointæ¢å¤ï¼Œé¿å…é•¿æ—¶é—´è®¡ç®—æˆæœçš„ä¸¢å¤±ã€‚NVRxè¿˜æä¾›ç³»ç»Ÿçº§å¥åº·æ£€æŸ¥ï¼ˆå¦‚èŠ‚ç‚¹å¥åº·æœåŠ¡ã€å­˜å‚¨ç³»ç»Ÿè¿é€šæ€§æ£€æŸ¥ç­‰ï¼‰æ¥é¢„å…ˆå‘ç°æ½œåœ¨é—®é¢˜ã€‚æ•´ä½“è€Œè¨€ï¼Œå…¶è®¾è®¡ç†å¿µæ˜¯åœ¨ä¸ä¸­æ–­æ•´ä¸ªä½œä¸šçš„å‰æä¸‹ï¼Œâ€œæ—©æ£€æµ‹ã€å¿«æ¢å¤â€ï¼Œä»è€Œæé«˜å¤§è§„æ¨¡è®­ç»ƒçš„å¥å£®æ€§å’Œæœ‰æ•ˆè¿è¡Œæ—¶é—´ã€‚\n\n\n3. é€‚ç”¨åœºæ™¯\nNVRxçš„å®¹é”™æœºåˆ¶ä¸»è¦é¢å‘å¤§å‹åˆ†å¸ƒå¼æ·±åº¦å­¦ä¹ è®­ç»ƒï¼Œåœ¨ä»¥ä¸‹åœºæ™¯ä¸­ç‰¹åˆ«é€‚ç”¨ï¼š\n\nè¶…å¤§è§„æ¨¡é›†ç¾¤è®­ç»ƒï¼šå½“è®­ç»ƒä½œä¸šè·¨è¶Šå¤§é‡èŠ‚ç‚¹å’ŒGPUæ—¶ï¼Œå‡ºç°ä¸ªåˆ«èŠ‚ç‚¹æ•…éšœã€ç½‘ç»œé—ªæ–­æˆ–GPUå¤±æ•ˆçš„æ¦‚ç‡å¢åŠ ã€‚NVRxæ—¨åœ¨åº”å¯¹è¿™ç§â€œå¤§è§„æ¨¡ã€é•¿å‘¨æœŸâ€è®­ç»ƒä¸­çš„ä¸å¯é å› ç´ ã€‚ä¾‹å¦‚ï¼Œåœ¨ç¡¬ä»¶å¯é æ€§æ¬ ä½³æˆ–ä½¿ç”¨æˆç™¾ä¸Šåƒå¼ GPUçš„ç¯å¢ƒä¸­ï¼ŒNVRxçš„æ•…éšœå®¹å¿å¯å°†å•ç‚¹æ•…éšœå¯¹æ•´ä½“ä½œä¸šçš„å½±å“é™åˆ°æœ€ä½ã€‚å®ƒå¯ä»¥è‡ªåŠ¨æ£€æµ‹è®­ç»ƒä¸­å‘ç”Ÿçš„æŒ‚èµ·æˆ–å¼‚å¸¸ï¼Œå¹¶ä»æœ€è¿‘checkpointæ¢å¤è®­ç»ƒï¼Œæ— éœ€äººå·¥ä»‹å…¥ï¼Œå¤§å¹…å‡å°‘å› èŠ‚ç‚¹/GPUé—®é¢˜å¯¼è‡´çš„åœæœºæŸå¤±ã€‚\næ˜“å‘ç”Ÿç¬æ—¶é”™è¯¯çš„ç¯å¢ƒï¼šå¦‚æœæ‰€å¤„çš„è®¡ç®—ç¯å¢ƒä¸­ç¬æ€æ•…éšœè¾ƒä¸ºå¸¸è§ï¼ˆä¾‹å¦‚äº‘ç¯å¢ƒä¸­å¶å‘çš„GPUè®¡ç®—é”™è¯¯ã€NCCLé€šä¿¡è¶…æ—¶ï¼Œæˆ–å­˜å‚¨è®¿é—®æŠ–åŠ¨ï¼‰ï¼ŒNVRxæä¾›çš„ç›‘æ§å’Œé‡å¯æœºåˆ¶éå¸¸æœ‰ç”¨ã€‚å®ƒèƒ½å¤ŸåŒºåˆ†æš‚æ—¶çš„å¼‚å¸¸ï¼ˆä¾‹å¦‚ä¸€æ¬¡æ€§çš„NaNç»“æœæˆ–çŸ­æš‚æŒ‚èµ·ï¼‰ä¸æŒç»­æ€§é—®é¢˜ï¼Œå¹¶å¯¹æš‚æ—¶æ€§æ•…éšœè‡ªåŠ¨æ¢å¤ç»§ç»­è®­ç»ƒã€‚\näº‘ç«¯å¼¹æ€§è®­ç»ƒå’Œä»»åŠ¡æŠ¢å ï¼šåœ¨äº‘è®¡ç®—æˆ–å…±äº«é›†ç¾¤ä¸­ï¼Œä½œä¸šå¯èƒ½å› é¢„ç•™æ—¶é—´åˆ°æœŸæˆ–é«˜ä¼˜å…ˆçº§ä»»åŠ¡æ’å…¥è€Œè¢«ä¸­æ–­ã€‚NVRxä¸ä½œä¸šè°ƒåº¦å™¨ç»“åˆï¼Œå¯å®ç°ä½œä¸šè‡ªåŠ¨ç»­è·‘ï¼šå½“åŸä½œä¸šå› éé”™è¯¯åŸå› ç»“æŸæ—¶ï¼Œå¯åœ¨è°ƒåº¦å™¨ï¼ˆç›®å‰æ”¯æŒSlurmï¼‰ä¸Šè‡ªåŠ¨æäº¤åç»­ä½œä¸šå¹¶æ¥åŠ›è®­ç»ƒã€‚è¿™ç§æ–¹å¼å¯¹äºè®­ç»ƒå¤§æ¨¡å‹ä¸”å•ä¸ªä½œä¸šæ—¶é•¿å—é™çš„æƒ…å†µï¼ˆä¾‹å¦‚å­¦é™¢é›†ç¾¤æ¯æ¬¡ä½œä¸šæœ€å¤šè·‘48å°æ—¶ç­‰ï¼‰ç‰¹åˆ«æœ‰å¸®åŠ©ï¼Œä½¿è®­ç»ƒåœ¨å¤šä¸ªä½œä¸šçª—å£å†…è‡ªåŠ¨è¡”æ¥å®Œæˆã€‚\næ·±åº¦å­¦ä¹ æ¡†æ¶é›†æˆï¼šNVRxå·²é›†æˆåˆ°PyTorch Lightningå›è°ƒå’ŒNVIDIA NeMoç­‰æ¡†æ¶ä¸­ï¼Œæ–¹ä¾¿ç ”ç©¶è€…åœ¨ä¸Šè¿°æ¡†æ¶ä¸‹å¯ç”¨å®¹é”™ã€‚å…¸å‹åº”ç”¨å¦‚LLMï¼ˆå¤§å‹è¯­è¨€æ¨¡å‹ï¼‰ã€è¯­éŸ³/å¤šæ¨¡æ€æ¨¡å‹çš„é¢„è®­ç»ƒï¼Œè¿™äº›â€œå‰æ²¿AIæ¨¡å‹â€çš„è®­ç»ƒå¾€å¾€å‘¨æœŸé•¿ã€èµ„æºå¤šï¼Œä½¿ç”¨NVRxå¯ä»¥åœ¨è¿™äº›å¤æ‚åœºæ™¯ä¸‹æä¾›æ‰€éœ€çš„å¯é æ€§ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œç›®å‰NVRxå®¹é”™åŠŸèƒ½ä¸»è¦åœ¨Linux + Slurmçš„åˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒä¸­æµ‹è¯•æ”¯æŒã€‚å› æ­¤ï¼Œæœ€å¥‘åˆçš„åœºæ™¯æ˜¯åœ¨ä½¿ç”¨Slurmè°ƒåº¦çš„GPUé›†ç¾¤ä¸Šè¿›è¡Œå¤§è§„æ¨¡PyTorchè®­ç»ƒã€‚å½“æ»¡è¶³è¿™äº›æ¡ä»¶æ—¶ï¼ŒNVRxèƒ½æœ€å¤§ç¨‹åº¦å‘æŒ¥ä½œç”¨ï¼Œåœ¨ç¡¬ä»¶ä¸ç¨³å®šã€è§„æ¨¡åºå¤§çš„è®­ç»ƒä¸­æ˜¾è‘—å‡å°‘å› æ•…éšœå¯¼è‡´çš„åœæœºæ—¶é—´ã€‚\n\n\n4. è®­ç»ƒè¿‡ç¨‹çš„ä¸‰ä¸ªç›‘æ§æ®µåŠä½œç”¨\nNVRxçš„æ•…éšœç›‘æ§é‡‡ç”¨â€œåˆ†æ®µç›‘æ§â€æ€æƒ³ï¼Œå°†è®­ç»ƒè¿‡ç¨‹åˆ’åˆ†ä¸ºä¸‰ä¸ªå…³é”®æ®µè½è¿›è¡Œé’ˆå¯¹æ€§ç›‘æµ‹ï¼Œæ¯æ®µè®¾ç½®ç‹¬ç«‹çš„è¶…æ—¶é˜ˆå€¼å’Œç›‘æ§ç›®æ ‡ï¼š\n\nåˆå§‹åŒ–æ®µï¼ˆSetup Sectionï¼‰ï¼šè¦†ç›–è®­ç»ƒå¯åŠ¨åçš„åˆå§‹åŒ–è¿‡ç¨‹ï¼ŒåŒ…æ‹¬æ¨¡å‹æ„å»ºã€æ•°æ®åŠ è½½å’Œæ¢å¤Checkpointç­‰æ­¥éª¤ã€‚è¿™ä¸€é˜¶æ®µé€šå¸¸è€—æ—¶å›ºå®šä¸”å¯é¢„ä¼°ã€‚NVRxä¸ºåˆå§‹åŒ–æ®µè®¾ç½®å•ç‹¬çš„è¶…æ—¶æ—¶é—´ï¼Œç”¨äºç›‘æ§è®­ç»ƒåœ¨å‡†å¤‡é˜¶æ®µæ˜¯å¦å¡é¡¿æˆ–æ­»é”ã€‚ä¾‹å¦‚ï¼Œå¦‚æœrankåœ¨åˆå§‹åŒ–ï¼ˆå¦‚åˆ†é…æ˜¾å­˜ã€åŠ è½½æ•°æ®ï¼‰æ—¶é™·å…¥é•¿æ—¶é—´ç­‰å¾…ï¼Œç›‘è§†è¿›ç¨‹å°†æ®æ­¤è§¦å‘è¶…æ—¶æŠ¥è­¦å¹¶ç»ˆæ­¢æŒ‚èµ·çš„rankã€‚é€šè¿‡ç›‘æ§åˆå§‹åŒ–æ®µï¼Œå¯ä»¥å°½æ—©å‘ç°å¯åŠ¨æ—¶çš„é…ç½®é—®é¢˜æˆ–èµ„æºä¸å¯ç”¨æƒ…å†µï¼Œæé«˜è®­ç»ƒä½œä¸šä¸€å¼€å§‹çš„å¯é æ€§ã€‚\nè®­ç»ƒè¿­ä»£æ®µï¼ˆStep Sectionï¼‰ï¼šæ¶µç›–æ¯ä¸ªè®­ç»ƒæ­¥éª¤/è¿­ä»£çš„æ‰§è¡Œè¿‡ç¨‹ï¼ŒåŒ…æ‹¬æ­£å‘ä¼ æ’­ã€åå‘ä¼ æ’­åŠæ¢¯åº¦åŒæ­¥ç­‰ã€‚è¿™æ˜¯è®­ç»ƒè¿‡ç¨‹ä¸­å¾ªç¯å¾€å¤çš„ä¸»ä½“ã€‚NVRxä¼šåœ¨ä»£ç ä¸­å°†æ¯æ¬¡è¿­ä»£çš„èµ·ç‚¹å’Œç»ˆç‚¹æ ‡è®°ä¸ºä¸€ä¸ªâ€œstepâ€ç›‘æ§æ®µï¼Œå¹¶é’ˆå¯¹å…¶æŒç»­æ—¶é—´è®¾ç½®è¶…æ—¶ã€‚å¦‚æœæŸæ¬¡è¿­ä»£ç”±äºæŸç§åŸå› ï¼ˆå¦‚æŸä¸ªGPUå¡æ­»ã€é€šä¿¡é˜»å¡ï¼‰æ‰§è¡Œæ—¶é—´è¶…å‡ºæ­£å¸¸èŒƒå›´ï¼Œç›‘æ§ç³»ç»Ÿä¼šåˆ¤å®šè®­ç»ƒå·²â€œæŒ‚èµ·â€å¹¶ç»ˆæ­¢ç›¸åº”è¿›ç¨‹ã€‚ç›‘æ§è®­ç»ƒæ®µèƒ½å¤ŸåŠæ—¶æ•æ‰è®­ç»ƒä¸­å‘ç”Ÿçš„å¼‚å¸¸å¡é¡¿ï¼Œé˜²æ­¢æ•´ä¸ªä½œä¸šæ— é™åˆ¶åœ°åœæ»ä¸‹å»ã€‚\nCheckpointä¿å­˜æ®µï¼ˆCheckpointing Sectionï¼‰ï¼šç›‘æ§ä¿å­˜æ£€æŸ¥ç‚¹æ–‡ä»¶çš„è¿‡ç¨‹ã€‚åœ¨å¤§å‹æ¨¡å‹è®­ç»ƒä¸­ï¼Œä¿å­˜checkpointå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼ˆå°¤å…¶å½“å†™å…¥è¿œç«¯å­˜å‚¨æ—¶ï¼‰ï¼Œä¹Ÿå®¹æ˜“å—åˆ°I/Oæ€§èƒ½æ³¢åŠ¨å½±å“ã€‚NVRxå¯¹æ­¤ç”¨ç‹¬ç«‹æ®µè¿›è¡Œç›‘æ§ï¼Œè®¾ç½®è¾ƒå®½è£•ä½†æœ‰é™çš„è¶…æ—¶æ—¶é—´ã€‚ä¾‹å¦‚checkpointä¿å­˜é€šå¸¸å‡ åˆ†é’Ÿå†…å®Œæˆï¼Œå¦‚æœè¶…è¿‡é˜ˆå€¼ï¼ˆå¦‚30åˆ†é’Ÿï¼‰ä»æœªå®Œæˆï¼Œç›‘æ§è¿›ç¨‹å°†è§†ä¸ºcheckpointæ­¥éª¤å¡æ­»ï¼Œä»è€Œé‡‡å–æªæ–½ç»ˆæ­¢æˆ–é‡å¯ã€‚ç›‘æ§Checkpointæ®µå¯ä»¥å‘ç°ç”±äºå­˜å‚¨æ•…éšœæˆ–æ–‡ä»¶ç³»ç»ŸæŒ‚èµ·å¯¼è‡´çš„ä¿å­˜å¤±è´¥ï¼Œä¿éšœè®­ç»ƒä¸ä¼šæ— é™ç­‰å¾…ä¿å­˜å®Œæˆã€‚\n\nä¸Šè¿°ä¸‰ä¸ªç›‘æ§æ®µå„è‡ªå¯¹åº”è®­ç»ƒæµç¨‹çš„å…³é”®ç¯èŠ‚ï¼Œåˆ†åˆ«èšç„¦åˆå§‹åŒ–ã€è¿­ä»£è®­ç»ƒã€æ¨¡å‹ä¿å­˜çš„è¶…æ—¶ç›‘æµ‹ã€‚é€šè¿‡ä¸ºä¸åŒé˜¶æ®µå®šåˆ¶è¶…æ—¶é˜ˆå€¼ï¼ŒNVRxå®ç°äº†æ›´ç²¾ç»†çš„æŒ‚èµ·æ£€æµ‹ï¼šåˆå§‹åŒ–å’ŒCheckpointé˜¶æ®µé€šå¸¸æ—¶é—´è·¨åº¦è¾ƒé•¿ï¼Œå…è®¸è®¾ç½®è¾ƒé•¿çš„å®¹å¿æ—¶é—´ï¼Œè€Œè®­ç»ƒè¿­ä»£å¾€å¾€é¢‘ç¹ä¸”æœ‰è§„å¾‹ï¼Œå¯è®¾ç½®è¾ƒçŸ­çš„è¶…æ—¶å¿«é€Ÿå‘ç°å¼‚å¸¸ã€‚éœ€è¦è¡¥å……çš„æ˜¯ï¼Œé™¤è¿™ä¸‰æ®µå¤–ï¼ŒNVRxè¿˜è®¾æœ‰æ®µå¤–ç›‘æ§ï¼ˆOut-of-Sectionï¼‰è¶…æ—¶ç”¨äºç›‘æµ‹å„æ®µä¹‹é—´çš„ç©ºé—²æ—¶é—´ã€‚ä¾‹å¦‚ä¸¤æ¬¡è¿­ä»£ä¹‹é—´æˆ–è®­ç»ƒä¸è¯„ä¼°ä¹‹é—´çš„é—´éš”ä¹Ÿä¸èƒ½æ— é™åˆ¶æ‹–å»¶ï¼Œå¦åˆ™ä¹Ÿä¼šè§¦å‘è­¦æŠ¥ã€‚æ€»ä½“è€Œè¨€ï¼Œä¸‰æ®µç›‘æ§æœºåˆ¶ä½¿å¾—å®¹é”™ç³»ç»Ÿèƒ½é’ˆå¯¹è®­ç»ƒå…¨è¿‡ç¨‹çš„ä¸åŒé˜¶æ®µè¿›è¡Œåˆ†ç±»ç›‘æ§ï¼Œæ—¢é¿å…äº†ç²—ä¸€ç»Ÿçš„å¿ƒè·³è¶…æ—¶è¿‡äºä¿å®ˆï¼Œåˆèƒ½åœ¨å„ç¯èŠ‚å¿«é€Ÿå®šä½å’Œå¤„ç†å¯èƒ½å‡ºç°çš„å¡é¡¿æ•…éšœã€‚\n\n5. é‡è¿è¡ŒçŠ¶æ€æœºçš„å·¥ä½œæ–¹å¼ä¸ç”¨é€”\n\nå®šä¹‰ï¼šâ€œé‡è¿è¡ŒçŠ¶æ€æœºâ€ï¼ˆRe-run State Machineï¼‰æ˜¯NVRxæä¾›çš„ä¸€ç§å®éªŒæ€§åŠŸèƒ½ï¼Œç”¨äºåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯¹å¼‚å¸¸ç»“æœè¿›è¡Œè‡ªåŠ¨å¤æ ¸å’Œå½’å› åˆ†æã€‚è¿™é‡Œçš„â€œå¼‚å¸¸ç»“æœâ€é€šå¸¸æŒ‡è®­ç»ƒä¸­å‡ºç°çš„ä¸æ­£å¸¸è®¡ç®—ç°è±¡ï¼Œä¾‹å¦‚æŸå¤±å€¼çªå˜ï¼ˆlossçªç„¶å¼‚å¸¸å¢å¤§ï¼‰æˆ–å‡ºç°NaN/Infç­‰æ•°å€¼å¼‚å¸¸ã€‚ä¼ ç»Ÿè®­ç»ƒéš¾ä»¥åŠæ—¶åˆ¤æ–­è¿™ç±»å¼‚å¸¸ç©¶ç«Ÿæºäºä¸€æ¬¡å¶å‘çš„ç¡¬ä»¶é”™è¯¯è¿˜æ˜¯ç®—æ³•æœ¬èº«é—®é¢˜ï¼Œè€Œé‡è¿è¡ŒçŠ¶æ€æœºé€šè¿‡å¤šæ¬¡é‡å¤è®¡ç®—æ¥å¸®åŠ©åŒºåˆ†ç¬æ—¶é”™è¯¯è¿˜æ˜¯æŒç»­æ€§é”™è¯¯ã€‚\nå·¥ä½œæ–¹å¼ï¼šé‡è¿è¡ŒçŠ¶æ€æœºæ’å…¥åœ¨è®­ç»ƒæ­¥éª¤çš„æ ¸å¿ƒè®¡ç®—æµç¨‹ä¸­ï¼Œå¯¹æ¯ä¸€æ¬¡å‰å‘/åå‘è®¡ç®—ç»“æœè¿›è¡ŒéªŒè¯ï¼Œå¹¶æŒ‰ç…§é¢„å®šä¹‰é€»è¾‘å†³å®šæ˜¯å¦éœ€è¦é‡ç®—ã€‚å…¶å†…éƒ¨ç»´æŠ¤äº†ä¸€å¥—çŠ¶æ€è½¬æ¢è§„åˆ™ï¼Œå¤§è‡´å¯åˆ†ä¸ºä»¥ä¸‹é˜¶æ®µï¼š\n\næ­£å¸¸æ‰§è¡Œé˜¶æ®µï¼ˆInitial Runï¼‰ï¼šé¦–å…ˆæŒ‰æ­£å¸¸æµç¨‹æ‰§è¡Œå½“å‰çš„è®­ç»ƒè¿­ä»£ï¼ˆé€šå¸¸æŒ‡ä¸€æ¬¡forward-backwardï¼‰ã€‚å®Œæˆåå¯¹å…³é”®ç»“æœè¿›è¡Œæ ¡éªŒï¼Œä¾‹å¦‚æ£€æŸ¥lossæ˜¯å¦ä¸ºNaNæˆ–æ˜¯å¦è¶…å‡ºåˆç†èŒƒå›´ã€‚å¦‚æœç»“æœçœ‹èµ·æ¥æ­£å¸¸ï¼Œåˆ™çŠ¶æ€æœºä¿æŒâ€œé€šè¿‡â€ï¼Œè®­ç»ƒç»§ç»­è€Œæ— éœ€é‡è¿è¡Œã€‚è‹¥æ£€æµ‹åˆ°å¼‚å¸¸ç»“æœï¼ŒçŠ¶æ€æœºè½¬å…¥â€œéœ€è¦é‡è¿è¡Œâ€çŠ¶æ€ï¼Œå‡†å¤‡å¯åŠ¨è¿›ä¸€æ­¥çš„éªŒè¯æ­¥éª¤ã€‚\nç¬¬ä¸€æ¬¡é‡è¿è¡Œï¼ˆFirst Re-run, In-placeï¼‰ï¼šåœ¨åŒä¸€å—GPUä¸Šé‡æ–°æ‰§è¡Œåˆšæ‰çš„è®­ç»ƒæ­¥éª¤è®¡ç®—ã€‚ä¸ºäº†ç¡®ä¿å¤ç°æ€§ï¼ŒçŠ¶æ€æœºä¼šé‡ç½®éšæœºæ•°ç§å­å’Œæ•°æ®åŠ è½½å™¨çŠ¶æ€ï¼Œå°½å¯èƒ½ç¡®ä¿ä¸¤æ¬¡è®¡ç®—åœ¨ç›¸åŒæ¡ä»¶ä¸‹è¿›è¡Œã€‚ç„¶åå†æ¬¡æ£€æŸ¥ç»“æœï¼šå¦‚æœè¿™æ¬¡é‡è¿è¡Œçš„ç»“æœä¸åˆæ¬¡ä¸åŒï¼Œå³å¼‚å¸¸æœªé‡ç°ï¼Œåˆ™è¯´æ˜ä¸Šä¸€æ¬¡å¼‚å¸¸å¯èƒ½æ˜¯ä¸€æ¬¡æ€§å¶å‘é”™è¯¯ï¼ŒçŠ¶æ€æœºè®°å½•â€œéç¡®å®šæ€§/ç¬æ—¶â€ç°è±¡ã€‚å¦‚æœç»“æœé‡ç°äº†ç›¸åŒçš„å¼‚å¸¸ï¼Œåˆ™è¡¨æ˜é—®é¢˜å…·æœ‰ç¡®å®šæ€§ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒæŸ¥å…¶æ¥æºã€‚çŠ¶æ€æœºä¼šæ®æ­¤å†³å®šä¸‹ä¸€æ­¥åŠ¨ä½œï¼šæœªé‡ç°åˆ™è®¤ä¸ºæ˜¯ç¬æ—¶é”™è¯¯ï¼ŒçŠ¶æ€æœºå¯è·³è¿‡åç»­æ­¥éª¤ï¼›é‡ç°åˆ™è¿›å…¥ä¸‹ä¸€ä¸ªçŠ¶æ€ã€‚\nç¬¬äºŒæ¬¡é‡è¿è¡Œï¼ˆSecond Re-run, Different GPUï¼‰ï¼šè‹¥å¼‚å¸¸åœ¨åŒä¸€è®¾å¤‡ä¸Šå¯ä»¥ç¨³å®šé‡ç°ï¼Œä¸ºäº†åˆ¤æ–­æ˜¯å¦ä¸å½“å‰GPU/ç¡¬ä»¶æœ‰å…³ï¼ŒçŠ¶æ€æœºä¼šè§¦å‘è·¨è®¾å¤‡é‡è¿è¡Œã€‚å…·ä½“åšæ³•æ˜¯ï¼šå…ˆå°†å½“å‰è®­ç»ƒçŠ¶æ€ä¿å­˜ä¸ºCheckpointï¼Œç„¶ååœ¨å¦ä¸€å—GPUä¸Šé‡æ–°åŠ è½½è¯¥Checkpointå¹¶æ‰§è¡Œç›¸åŒè®¡ç®—ã€‚é€šè¿‡æ›´æ¢ç¡¬ä»¶ç¯å¢ƒï¼Œå†æ¬¡è§‚å¯Ÿå¼‚å¸¸æ˜¯å¦å‡ºç°ã€‚å¦‚æœåœ¨ä¸åŒGPUä¸Šæ²¡æœ‰å‡ºç°ä¹‹å‰çš„å¼‚å¸¸ï¼Œåˆ™è¯´æ˜åŸå…ˆçš„å¼‚å¸¸å¾ˆå¯èƒ½æ˜¯ç”±äºç¬¬ä¸€å—GPUå­˜åœ¨éšå«æ•…éšœï¼ˆä¾‹å¦‚GPU DRAMé”™è¯¯æˆ–è¿ç®—å•å…ƒä¸å¯é ï¼‰é€ æˆçš„ã€‚åä¹‹ï¼Œå¦‚æœåœ¨ä¸åŒGPUä¸Šä¾ç„¶å‡ºç°åŒæ ·çš„å¼‚å¸¸ç»“æœï¼Œé‚£ä¹ˆå¯ä»¥æ¨æ–­é—®é¢˜ä¸æ˜¯ç¡¬ä»¶åŸå› ï¼Œè€Œæ˜¯ç®—æ³•æœ¬èº«å›ºæœ‰çš„ï¼ˆä¾‹å¦‚æ¨¡å‹/æ•°æ®é—®é¢˜å¯¼è‡´çš„ç¡®å®šæ€§å¼‚å¸¸ï¼‰ã€‚å®Œæˆç¬¬äºŒæ¬¡é‡è¿è¡Œåï¼ŒçŠ¶æ€æœºè¿›å…¥â€œå½’å› åˆ†æâ€çŠ¶æ€ã€‚\nç»“æœå½’å› é˜¶æ®µï¼ˆAttributionï¼‰ï¼šç»¼åˆåˆæ¬¡åŠå¤šæ¬¡é‡è¿è¡Œçš„ç»“æœï¼Œé‡è¿è¡ŒçŠ¶æ€æœºå¯¹å¼‚å¸¸çš„æ€§è´¨è¿›è¡Œåˆ†ç±»ã€‚ä¸»è¦åˆ†ä¸ºä¸‰ç±»ï¼šâ‘ ç¬æ—¶é”™è¯¯ï¼šä»…ç¬¬ä¸€æ¬¡å‡ºç°ï¼Œåç»­é‡ç®—æœªå†ç°ï¼Œåˆ¤å®šä¸ºä¸€æ¬¡éšæœºå¶å‘æ•…éšœï¼ˆTransient Errorï¼‰ï¼›â‘¡æŒä¹…é”™è¯¯ï¼ˆç¡¬ä»¶æ•…éšœï¼‰ï¼šåœ¨åŒç¡¬ä»¶ä¸Šå¯é‡å¤å‡ºç°ï¼Œä½†æ›´æ¢ç¡¬ä»¶åæ¶ˆå¤±ï¼Œåˆ¤å®šä¸ºæŸä¸€è®¾å¤‡çš„æ½œåœ¨ç¼ºé™·å¼•å‘çš„é”™è¯¯ï¼ˆPersistent Hardware Errorï¼‰ï¼›â‘¢ç¡®å®šæ€§ç»“æœï¼šæ— è®ºåŒç¡¬ä»¶è¿˜æ˜¯è·¨ç¡¬ä»¶é‡è·‘éƒ½åå¤å‡ºç°ï¼Œè¯´æ˜è¯¥å¼‚å¸¸å…¶å®æ˜¯å¯ç¡®å®šé‡ç°çš„ï¼Œå¯èƒ½å¹¶éç¡¬ä»¶æ•…éšœè€Œæ˜¯ä»£ç é€»è¾‘æˆ–æ•°å€¼ç¨³å®šæ€§é—®é¢˜ï¼Œç”šè‡³å¯èƒ½å…¶å®æ˜¯æ­£ç¡®è¡Œä¸ºçš„è¯¯åˆ¤ã€‚çŠ¶æ€æœºæ®æ­¤åˆ†ç±»åï¼Œä¼šè¾“å‡ºç›¸åº”çš„ä¿¡æ¯æˆ–é‡‡å–åŠ¨ä½œï¼šä¾‹å¦‚å¯¹å¯èƒ½çš„ç¡¬ä»¶æ•…éšœç»™äºˆè­¦å‘Šï¼ˆæ ‡è®°å¯ç–‘GPUï¼‰ï¼Œå¯¹äºç¬æ—¶é”™è¯¯åˆ™è®°å½•ç»Ÿè®¡ä½†è®­ç»ƒç»§ç»­ï¼Œå¯¹äºæŒç»­é‡ç°çš„é”™è¯¯åˆ™å¯ä»¥é€‰æ‹©ç»ˆæ­¢è®­ç»ƒä»¥é˜²æ­¢é”™è¯¯ä¼ æ’­ã€‚\n\nç”¨é€”å’Œä½œç”¨ï¼šé‡è¿è¡ŒçŠ¶æ€æœºçš„ä¸»è¦ç”¨é€”åœ¨äºæ•…éšœå½’å› å’Œç³»ç»Ÿå¥å£®æ€§åˆ†æã€‚å®ƒå¸®åŠ©è®­ç»ƒä»»åŠ¡è‡ªåŠ¨åˆ¤åˆ«å¼‚å¸¸æ˜¯â€œè™šæƒŠä¸€åœºâ€è¿˜æ˜¯çœŸæ­£çš„é—®é¢˜æ‰€åœ¨ï¼Œä»è€Œé‡‡å–ä¸åŒæªæ–½ï¼šæ¯”å¦‚ï¼Œæ£€æµ‹åˆ°å¯èƒ½çš„ç¬æ—¶è®¡ç®—é”™è¯¯ï¼Œç³»ç»Ÿå¯ä»¥åœ¨æ— éœ€äººå·¥å¹²é¢„æƒ…å†µä¸‹è‡ªåŠ¨é‡è·‘è®¡ç®—å¹¶ç»§ç»­è®­ç»ƒï¼Œæé«˜è®­ç»ƒå¯¹çŸ­æš‚ç¡¬ä»¶æ¯›åˆºçš„å®¹å¿åº¦ï¼›è‹¥åˆ¤å®šä¸ºç¡¬ä»¶æ°¸ä¹…æ€§æ•…éšœï¼ˆå³æŸGPUé‡å¤äº§ç”Ÿé”™è¯¯ï¼‰ï¼Œåˆ™å¯ä»¥æ ‡è®°è¯¥GPUä¸å¥åº·å¹¶è§¦å‘è®­ç»ƒåœ¨æ–°ç¡¬ä»¶ä¸Šé‡å¯ï¼ˆé€šè¿‡é€€å‡ºè¿›ç¨‹è®©è°ƒåº¦å™¨æˆ–ä¸Šå±‚æ¡†æ¶å°†è¯¥rankæ˜ å°„åˆ°å…¶ä»–GPUï¼‰ã€‚æ­¤å¤–ï¼Œåœ¨æ•°å€¼ç¡®å®šæ€§æ–¹é¢ï¼Œé‡è¿è¡ŒçŠ¶æ€æœºè¿˜å¯ç”¨äºç»Ÿè®¡è®­ç»ƒè¿‡ç¨‹ä¸­çš„éç¡®å®šæ€§å› ç´ ï¼šä¾‹å¦‚å¼€å¯â€œreport_statsâ€æ¨¡å¼ï¼Œè®©æ¯ä¸€æ­¥éƒ½é‡å¤è®¡ç®—ä¸€æ¬¡ï¼Œå¯¹æ¯”ç»“æœå·®å¼‚ï¼Œä»è€Œé‡åŒ–æµ®ç‚¹è®¡ç®—çš„ä¸ç¨³å®šæ€§ã€‚æ€»çš„æ¥è¯´ï¼Œé‡è¿è¡ŒçŠ¶æ€æœºä¸ºå¤§è§„æ¨¡åˆ†å¸ƒå¼è®­ç»ƒæä¾›äº†ä¸€ç§è‡ªåŠ¨åŒ–çš„ç»“æœéªŒè¯ä¸è¯Šæ–­å·¥å…·ã€‚åœ¨å®éªŒé˜¶æ®µï¼Œå®ƒæœ‰åŠ©äºå‘ç°éšè”½çš„ç¡¬ä»¶é—®é¢˜ï¼Œä¿éšœè®­ç»ƒåœ¨ä¸å¯é ç¡¬ä»¶ä¸Šçš„æ­£ç¡®æ€§ï¼›å¯¹äºç ”å‘äººå‘˜ï¼Œå®ƒä¹Ÿæä¾›äº†å®šä½NaNç­‰å¼‚å¸¸çš„çº¿ç´¢ï¼Œä½¿å¾—åœ¨å‡ºç°å¯ç–‘ç»“æœæ—¶ï¼Œç³»ç»Ÿèƒ½å¤Ÿç»™å‡ºæ›´æ˜ç¡®çš„æ•…éšœç±»å‹åˆ¤æ–­ï¼Œæ–¹ä¾¿è¿›ä¸€æ­¥é‡‡å–ä¿®å¤æªæ–½ã€‚\n\n\n6. æ•…éšœè¯Šæ–­æµç¨‹ï¼šé‡è¿è¡Œåˆ¤æ–­ç¬æ—¶æˆ–æ°¸ä¹…é”™è¯¯\nNVRxé€šè¿‡ä¸Šè¿°é‡è¿è¡ŒçŠ¶æ€æœºå®ç°æ•…éšœè¯Šæ–­ï¼Œå…¶åˆ¤æ–­æµç¨‹æ­£å¦‚é¢˜è¿°ï¼š\n\nç¬¬ä¸€æ¬¡é‡è¿è¡Œï¼šæ£€æŸ¥ç»“æœé‡ç°æ€§ã€‚å½“ç›‘æµ‹åˆ°å¼‚å¸¸ç»“æœï¼ˆå¦‚Lossä¸ºNaNï¼‰æ—¶ï¼Œç³»ç»Ÿé¦–å…ˆåœ¨ç›¸åŒç¯å¢ƒä¸‹å†æ‰§è¡Œä¸€æ¬¡ç›¸åŒè®¡ç®—ï¼Œä»¥éªŒè¯é—®é¢˜æ˜¯å¦é‡å¤å‡ºç°ã€‚å¦‚æœåœ¨è¿™æ¬¡é‡è·‘ä¸­å¼‚å¸¸ä¸å†å‡ºç°ï¼Œåˆ™æ„å‘³ç€ä¸Šä¸€æ¬¡å¼‚å¸¸å¯èƒ½æ˜¯ä¸€æ¬¡éšæœºäº‹ä»¶ï¼Œå¹¶éæŒç»­æ€§é—®é¢˜ã€‚è¿™ç§ä¸å¯é‡ç°çš„æ•…éšœè¢«è®¤ä¸ºæ˜¯ç¬æ—¶é”™è¯¯ï¼ˆTransient Errorï¼‰ï¼Œä¾‹å¦‚ç”±äºä¸´æ—¶çš„æ•°å€¼ä¸ç¨³å®šæˆ–ç¡¬ä»¶çš„ç¬æ—¶å¹²æ‰°å¯¼è‡´ã€‚åœ¨æ­¤æƒ…å†µä¸‹ï¼ŒNVRxä¼šè®°å½•è¯¥ç°è±¡ä½†è§†ä½œçŸ­æš‚æ‰°åŠ¨ï¼Œè®­ç»ƒå¯ç»§ç»­è¿›è¡Œã€‚\nç¬¬äºŒæ¬¡é‡è¿è¡Œï¼šåœ¨ä¸åŒGPUä¸ŠéªŒè¯ç»“æœã€‚å¦‚æœå¼‚å¸¸åœ¨åŒä¸€GPUä¸Šç¬¬ä¸€æ¬¡é‡è·‘æ—¶å†æ¬¡é‡ç°ï¼Œåˆ™è¡¨æ˜é—®é¢˜å…·æœ‰ç¡®å®šæ€§ï¼Œè¿™æ—¶ç³»ç»Ÿä¼šå°†è®­ç»ƒçŠ¶æ€ä¿å­˜Checkpointå¹¶åˆ‡æ¢åˆ°å¦ä¸€å—GPUæ‰§è¡Œç›¸åŒè®¡ç®—ã€‚è¿™æ ·å¯æ£€éªŒé—®é¢˜æ˜¯å¦ä¸ç¡¬ä»¶ç›¸å…³ï¼šå¦‚æœæ¢GPUåå¼‚å¸¸æœªèƒ½é‡ç°ï¼Œè¯´æ˜åŸå…ˆçš„é—®é¢˜åªåœ¨ç‰¹å®šGPUç¯å¢ƒå‡ºç°ï¼Œå¾ˆå¯èƒ½è¯¥GPUå­˜åœ¨ç¡¬ä»¶ç¼ºé™·æˆ–éšå«é”™è¯¯ï¼Œå³åˆ¤å®šä¸ºæ°¸ä¹…æ€§é”™è¯¯ï¼ˆPersistent Errorï¼‰ã€‚ç›¸åº”åœ°ï¼ŒNVRxä¼šå°†æ­¤è§†ä¸ºä¸¥é‡é—®é¢˜â€”â€”å¯èƒ½ä¼šç»ˆæ­¢å½“å‰ä½œä¸šå¹¶æ ‡è®°è¯¥GPUèŠ‚ç‚¹ä¸å¥åº·ï¼Œä»¥é˜²æ­¢é”™è¯¯å†æ¬¡å‘ç”Ÿã€‚è€Œå¦‚æœåœ¨ä¸åŒGPUä¸Šä¾ç„¶é‡ç°äº†ç›¸åŒå¼‚å¸¸ï¼Œé‚£ä¹ˆå¯ä»¥æ–­å®šè¯¥å¼‚å¸¸ä¸ç¡¬ä»¶æ— å…³ï¼Œè€Œæ˜¯è®­ç»ƒæœ¬èº«äº§ç”Ÿçš„ç¡®å®šæ€§é”™è¯¯æˆ–æ•°å€¼é—®é¢˜ã€‚è¿™ç§æƒ…å†µä¸å±äºç¬æ—¶ç¡¬ä»¶æ•…éšœï¼Œä¹Ÿä¸å½’ç±»ä¸ºè®¾å¤‡ç¼ºé™·ï¼Œè€Œæ˜¯æç¤ºå¯èƒ½å­˜åœ¨ç®—æ³•é€»è¾‘bugæˆ–æ•°æ®é—®é¢˜ï¼ˆæˆ–è€…äº‹å®ä¸Šè¿™ä¸ªâ€œå¼‚å¸¸â€ç»“æœå°±æ˜¯ç¡®å®šçš„æ­£ç¡®è¡Œä¸ºï¼Œä¾‹å¦‚æ¨¡å‹å‘æ•£å¯¼è‡´lossä¸ºNaNï¼‰ã€‚NVRxåœ¨è¿™ç§æƒ…å†µä¸‹ä¼šè§¦å‘ä¸åŒçš„å¤„ç†ç­–ç•¥ï¼Œä¾‹å¦‚ç›´æ¥åœæ­¢è®­ç»ƒå¹¶æŠ¥å‘ŠéªŒè¯å¤±è´¥ï¼Œä»¥ä¾¿å¼€å‘è€…æ£€æŸ¥ä»£ç /æ•°æ®é—®é¢˜ã€‚\nåŸºäºé‡ç°æ€§åˆ¤æ–­ç¬æ—¶æˆ–æ°¸ä¹…æ•…éšœï¼šé€šè¿‡ä¸Šè¿°ä¸¤æ¬¡é‡è¿è¡Œçš„é‡ç°æƒ…å†µï¼Œç³»ç»Ÿå®ç°äº†å¯¹æ•…éšœæ€§è´¨çš„è‡ªåŠ¨åˆ¤æ–­ã€‚ä¸å¯é‡ç°çš„è§†ä½œç¬æ—¶æ•…éšœâ€”â€”è®­ç»ƒå°†é€šè¿‡é‡è·‘è·³è¿‡è¯¥æ¬¡å¼‚å¸¸å¹¶ç»§ç»­ï¼Œä»è€Œæé«˜å®¹é”™æ€§ï¼›å¯é‡ç°ä¸”å±€é™äºç‰¹å®šç¡¬ä»¶çš„è§†ä½œç¡¬ä»¶æ°¸ä¹…æ•…éšœâ€”â€”æ­¤æ—¶ç³»ç»Ÿå¯é‡‡å–æªæ–½å¦‚æ›´æ¢è®¾å¤‡é‡æ–°è®­ç»ƒæˆ–æé†’è¿ç»´æ’æŸ¥è¯¥ç¡¬ä»¶ï¼›å¯åœ¨ä¸åŒç¯å¢ƒé‡å¤çš„åˆ™è¢«è®¤å®šä¸ºéç¡¬ä»¶åŸå› çš„é—®é¢˜â€”â€”ç³»ç»Ÿå¯èƒ½ç»ˆæ­¢è®­ç»ƒå¹¶ä¸ŠæŠ¥ï¼Œä»¥é¿å…æµªè´¹ç®—åŠ›åœ¨ä¸€ä¸ªæœ‰æ ¹æœ¬é—®é¢˜çš„ä½œä¸šä¸Šã€‚æ•´ä¸ªæµç¨‹ä½¿NVRxä¸ä»…èƒ½æ¢å¤è®­ç»ƒï¼Œè¿˜èƒ½æ™ºèƒ½åŒºåˆ†æ•…éšœç±»å‹ã€‚ä¾‹å¦‚ï¼Œæ—¥å¿—ä¸­ä¼šæ˜ç¡®æç¤ºâ€œå¯èƒ½çš„ç¬æ—¶é”™è¯¯â€æˆ–â€œå¯èƒ½çš„æŒä¹…é”™è¯¯â€ï¼Œå¸®åŠ©ç”¨æˆ·äº†è§£æ˜¯å¶å‘äº‹ä»¶è¿˜æ˜¯éœ€è¦æ›´æ¢ç¡¬ä»¶æˆ–ä¿®æ­£ä»£ç ã€‚è¿™ç§ä¸¤çº§é‡è¿è¡Œçš„è¯Šæ–­æ–¹å¼ç¡®ä¿äº†æ›´é«˜çš„å‡†ç¡®æ€§ï¼šæ—¢é¿å…æŠŠä¸€æ¬¡æ€§æ•…éšœè¯¯åˆ¤ä¸ºç¡¬ä»¶é—®é¢˜åå¤é‡å¯æµªè´¹æ—¶é—´ï¼Œä¹Ÿé¿å…æŒç»­æ€§é”™è¯¯è¢«å½“ä½œå¶å‘ç°è±¡è€Œè¢«å¿½ç•¥ã€‚å› æ­¤å¯ä»¥ç¡®è®¤ï¼ŒNVRxçš„æ•…éšœè¯Šæ–­æµç¨‹ç¡®å®å¦‚é¢˜è¿°ï¼Œé€šè¿‡ç¬¬ä¸€æ¬¡æœ¬åœ°é‡è·‘å’Œç¬¬äºŒæ¬¡è·¨è®¾å¤‡é‡è·‘ä¸¤æ­¥ï¼Œä¾æ®ç»“æœé‡ç°ä¸å¦æ¥åŒºåˆ†é”™è¯¯çš„æš‚æ—¶æ€§æˆ–æ°¸ä¹…æ€§ï¼Œå¹¶æ®æ­¤é‡‡å–ç›¸åº”æªæ–½\n\n\n7. åˆ†å¸ƒå¼Checkpointæœºåˆ¶åŸç†ä¸ä¼˜åŠ¿\n\nNVRxæä¾›çš„åˆ†å¸ƒå¼Checkpointæœºåˆ¶æ—¨åœ¨ä½¿æ¨¡å‹å­˜æ¡£ä¸æ¢å¤åœ¨ä¸åŒå¹¶è¡Œé…ç½®ä¸‹å˜å¾—çµæ´»å¯è¡Œï¼Œä»è€Œæ”¯æŒå¼¹æ€§æ‰©å±•å’Œé«˜æ•ˆå®¹é”™ã€‚å…¶æ ¸å¿ƒåŸç†æ˜¯ä½¿ç”¨NVIDIA Megatronç­‰å·¥å…·æä¾›çš„â€œåˆ†å¸ƒå¼Checkpointâ€æ ¼å¼ï¼ˆtorch distributed checkpointï¼‰ï¼Œä½¿å¾—â€œåœ¨ä¸€ç§å¹¶è¡Œæ¨¡å¼ä¸‹ä¿å­˜çš„checkpointå¯ä»¥åœ¨å¦ä¸€ç§å¹¶è¡Œæ¨¡å¼ä¸‹é‡æ–°åŠ è½½â€ã€‚è¿™æ„å‘³ç€ï¼Œå‡å¦‚ä¸€ä¸ªæ¨¡å‹åœ¨æ•°æ®å¹¶è¡Œåº¦=8ã€å¼ é‡æ¨¡å‹å¹¶è¡Œåº¦=1çš„é…ç½®ä¸‹è®­ç»ƒå¹¶ä¿å­˜äº†checkpointï¼Œé‚£ä¹ˆå€ŸåŠ©è¯¥æœºåˆ¶ï¼Œå¯ä»¥åœ¨æ—¥åç”¨æ•°æ®å¹¶è¡Œåº¦=4ã€å¼ é‡å¹¶è¡Œåº¦=2ç­‰ä¸åŒé…ç½®æ¥åŠ è½½è¿™ä¸ªcheckpointå¹¶ç»§ç»­è®­ç»ƒã€‚è¿™ç§è·¨é…ç½®çš„å…¼å®¹æ€§èµ‹äºˆè®­ç»ƒä½œä¸šå¼¹æ€§æ‰©å±•èƒ½åŠ›ï¼šå½“éœ€è¦æ‰©å±•åˆ°æ›´å¤šGPUæˆ–è€…åœ¨èµ„æºä¸è¶³æ—¶ç¼©å‡GPUæ•°é‡æ—¶ï¼Œæ— éœ€ä»å¤´è®­ç»ƒï¼Œåªéœ€è°ƒæ•´å¹¶è¡Œå‚æ•°å¹¶åŠ è½½å·²æœ‰checkpointå³å¯ï¼Œæ— ç¼è¡”æ¥æ¨¡å‹çŠ¶æ€ç»§ç»­è®­ç»ƒã€‚è¿™å¯¹é•¿æ—¶é—´å¤§æ¨¡å‹è®­ç»ƒæ¥è¯´éå¸¸å…³é”®ï¼Œå› ä¸ºé›†ç¾¤çš„å¯ç”¨èµ„æºå¯èƒ½éšæ—¶é—´å˜åŒ–ï¼ŒCheckpointçš„è·¨é…ç½®å¯ç”¨æ€§ä½¿è®­ç»ƒèƒ½å¤Ÿçµæ´»åœ°åˆ©ç”¨å½“å‰èµ„æºï¼Œå®ç°çœŸæ­£çš„å¼¹æ€§è®­ç»ƒã€‚\nåˆ†å¸ƒå¼ä¼˜åŒ–å™¨çŠ¶æ€æ ¼å¼ï¼šåœ¨å®ç°ä¸Šè¿°çµæ´»æ€§çš„è¿‡ç¨‹ä¸­ï¼ŒCheckpointä¸­ä¼˜åŒ–å™¨çŠ¶æ€ï¼ˆoptimizer statesï¼‰çš„å­˜å‚¨æ ¼å¼èµ·äº†å…³é”®ä½œç”¨ã€‚NVRxé‡‡ç”¨Megatron-Coreå¼•å…¥çš„ä¸¤ç§ä¼˜åŒ–å™¨checkpointæ ¼å¼ï¼šdp_reshardableï¼ˆæ•°æ®å¹¶è¡Œå¯é‡åˆ†ç‰‡ï¼‰å’Œfully_reshardableï¼ˆå®Œå…¨å¯é‡åˆ†ç‰‡ï¼‰ã€‚äºŒè€…çš„æ„ä¹‰ã€ç”¨é€”å’ŒåŒºåˆ«å¦‚ä¸‹ï¼š\n\ndp_reshardableï¼ˆé»˜è®¤æ ¼å¼ï¼‰ï¼šé¡¾åæ€ä¹‰åé‡æ•°æ®å¹¶è¡Œï¼ˆData Parallelï¼‰é‡æ–°åˆ‡åˆ†çš„æ–¹æ¡ˆã€‚ä½¿ç”¨è¯¥æ ¼å¼ä¿å­˜çš„Checkpointåœ¨ç›¸åŒçš„æ¨¡å‹å¹¶è¡Œåº¦é…ç½®ä¸‹å¯ä»¥é«˜æ•ˆåœ°æ¢å¤ï¼Œä½†ä¸æ”¯æŒæ”¹å˜æ¨¡å‹å¹¶è¡Œç»´åº¦ã€‚å®ƒçš„ä¸»è¦ä¼˜ç‚¹æ˜¯ä¿å­˜å’ŒåŠ è½½é€Ÿåº¦å¿«ï¼Œå› ä¸ºåªéœ€æŒ‰æ•°æ®å¹¶è¡Œå°†ä¼˜åŒ–å™¨çŠ¶æ€åšç®€å•åˆ‡åˆ†/æ±‡æ€»ï¼Œä¸ç”¨å­˜å‚¨å®Œæ•´çš„å…¨å±€çŠ¶æ€ã€‚å› æ­¤åœ¨ä¸éœ€è¦æ”¹å˜æ¨¡å‹å¹¶è¡Œé…ç½®çš„å¸¸è§„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œdp_reshardableæ˜¯æ¨èä½¿ç”¨çš„æ ¼å¼ï¼Œèƒ½æœ€å¤§åŒ–Checkpointè¯»å†™æ€§èƒ½ã€‚æ¢è¨€ä¹‹ï¼Œå¦‚æœè®­ç»ƒè¿‡ç¨‹ä¸­å§‹ç»ˆä¿æŒæ¨¡å‹å¹¶è¡Œå’Œå¼ é‡å¹¶è¡Œç­‰åˆ’åˆ†ä¸å˜ï¼Œç”¨é»˜è®¤æ ¼å¼å³å¯å¿«é€ŸCheckpointï¼Œé™ä½å­˜å‚¨å¼€é”€å’Œæ—¶é—´ã€‚\nfully_reshardableï¼ˆå®Œå…¨é‡åˆ†ç‰‡æ ¼å¼ï¼‰ï¼šé‡‡ç”¨æ›´é€šç”¨çš„å®Œæ•´é‡åˆ†ç‰‡æ–¹æ¡ˆï¼Œå…è®¸Checkpointåœ¨ä»»æ„å¹¶è¡Œé…ç½®å˜åŒ–çš„æƒ…å†µä¸‹è¢«åŠ è½½ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œä¸è®ºæ•°æ®å¹¶è¡Œæˆ–æ¨¡å‹å¹¶è¡Œåº¦å¦‚ä½•æ”¹å˜ï¼Œæ­¤æ ¼å¼çš„ä¼˜åŒ–å™¨çŠ¶æ€éƒ½æä¾›äº†æ‰€éœ€çš„ä¿¡æ¯ä»¥é‡æ–°åˆ†å¸ƒå‚æ•°ã€‚å®ƒçš„å®ç°é€šå¸¸éœ€è¦åœ¨Checkpointä¸­ä¿å­˜æ›´å¤šå…ƒæ•°æ®æˆ–å…¨å°ºå¯¸çš„ä¼˜åŒ–å™¨çŠ¶æ€ï¼Œä»¥æ”¯æŒè·¨é…ç½®çš„é‡ç»„ã€‚å› æ­¤ä»£ä»·æ˜¯ä¿å­˜/åŠ è½½é€Ÿåº¦è¾ƒdp_reshardableç•¥æ…¢ï¼Œå ç”¨ç©ºé—´ä¹Ÿå¯èƒ½æ›´å¤§ã€‚fully_reshardableé€‚ç”¨äºéœ€è¦åœ¨è®­ç»ƒä¸­æ”¹å˜æ¨¡å‹å¹¶è¡Œåˆ’åˆ†çš„åœºæ™¯ã€‚ä¾‹å¦‚ï¼Œå½“è®¡åˆ’åœ¨ä¸­é€”å¢å‡GPUæˆ–è€…è°ƒæ•´å¹¶è¡Œç­–ç•¥æ—¶ï¼Œå¯åœ¨åˆ‡æ¢é…ç½®å‰å¯ç”¨æ­¤æ ¼å¼ä¿å­˜ä¸€æ¬¡Checkpointï¼Œç„¶ååœ¨æ–°é…ç½®ä¸‹æˆåŠŸåŠ è½½ã€‚å®é™…ç”¨æ³•ä¸Šï¼Œé€šè¿‡è®¾ç½®ç‰¹å®šå¼€å…³ï¼ˆå¦‚å‘½ä»¤è¡Œå‚æ•°â€“dist-ckpt-optim-fully-reshardableï¼‰æ¥å¯ç”¨å®Œå…¨é‡åˆ†ç‰‡æ¨¡å¼ã€‚ä¸€æ—¦å®Œæˆé…ç½®è½¬æ¢å¹¶ä¿å­˜è‡³å°‘ä¸€ä¸ªcheckpointåï¼Œè‹¥åç»­è®­ç»ƒä¸å†éœ€è¦é¢‘ç¹è½¬æ¢ï¼Œä¹Ÿå¯ä»¥å…³é—­æ­¤æ¨¡å¼æ¢å¤ä¸ºæ›´é«˜æ•ˆçš„dp_reshardableæ ¼å¼ç»§ç»­è®­ç»ƒã€‚\n\nåŸç†ä¼˜åŠ¿ï¼šç»¼åˆæ¥çœ‹ï¼Œåˆ†å¸ƒå¼Checkpointæœºåˆ¶é€šè¿‡ä¸Šè¿°ä¸¤ç§æ ¼å¼å…¼é¡¾äº†æ€§èƒ½ä¸çµæ´»æ€§ã€‚å»ºè®®çš„å·¥ä½œæµç¨‹æ˜¯ï¼šå¹³æ—¶é‡‡ç”¨é«˜é€Ÿçš„é»˜è®¤æ ¼å¼è¿›è¡Œå®šæœŸcheckpointï¼›å½“éœ€è¦è°ƒæ•´å¹¶è¡Œåº¦ï¼ˆæ¯”å¦‚æ‰©å®¹ä½œä¸šï¼‰æ—¶ï¼Œåˆ‡æ¢åˆ°fully_reshardableæ ¼å¼ä¿å­˜ä¸€æ¬¡checkpointï¼Œå†ç”¨æ–°é…ç½®åŠ è½½ï¼Œç¡®ä¿æ¨¡å‹æ­£ç¡®è¿ç§»ï¼›ä¹‹åå¯å†åˆ‡æ¢å›é»˜è®¤æ ¼å¼ä»¥ç»§ç»­è®­ç»ƒã€æé«˜æ€§èƒ½ã€‚è¿™ä¸€æœºåˆ¶çš„ä¼˜åŠ¿åœ¨äºï¼š(1) å¼¹æ€§æ‰©å±•ï¼šå…è®¸æ·±åº¦å­¦ä¹ è®­ç»ƒåœ¨ä¸åŒç¡¬ä»¶è§„æ¨¡ä¹‹é—´è¿ç§»ï¼Œæ–¹ä¾¿åœ¨èµ„æºå˜åŒ–æ—¶æ‰©å±•æˆ–æ”¶ç¼©ä½œä¸šè§„æ¨¡ï¼Œè€Œæ¨¡å‹è¿›åº¦ä¸å—å½±å“ï¼›(2) å®¹é”™æ¢å¤ï¼šåœ¨æŸäº›éœ€è¦è½¬ç§»åˆ°æ–°èŠ‚ç‚¹ï¼ˆæ¯”å¦‚åŸèŠ‚ç‚¹æ•…éšœæ›´æ¢ï¼‰æ—¶ï¼Œå¯åˆ©ç”¨fully_reshardableç¡®ä¿checkpointåœ¨æ–°ç¡¬ä»¶ä¸Šæ— éšœç¢æ¢å¤ï¼Œä»è€Œå¢å¼ºå®¹é”™æ€§ï¼›(3) æ€§èƒ½ä¼˜åŒ–ï¼šåœ¨ä¸æ”¹å˜å¹¶è¡Œåº¦æ—¶ä½¿ç”¨dp_reshardableå°½é‡å‡å°‘Checkpointå¼€é”€ï¼Œä¸å½±å“è®­ç»ƒæ•ˆç‡ã€‚æ€»ä¹‹ï¼ŒNVRxçš„åˆ†å¸ƒå¼Checkpointé€šè¿‡å¯é‡åˆ†ç‰‡çš„ä¼˜åŒ–å™¨çŠ¶æ€è®¾è®¡ï¼Œå®ç°äº†â€œè·¨å¹¶è¡Œé…ç½®å¯åŠ è½½â€è¿™ä¸€çªç ´æ€§åŠŸèƒ½ï¼Œä¸ºå¤§è§„æ¨¡åˆ†å¸ƒå¼è®­ç»ƒçš„å¼¹æ€§ä¼¸ç¼©å’Œå¥å£®æ¢å¤æä¾›äº†åšå®æ”¯æ’‘ã€‚\nä¼˜åŒ–å™¨çŠ¶æ€æ ¼å¼ dp_reshardable vs fully_reshardable ä¼˜åŠ£å¯¹æ¯”ï¼š dp_reshardable (é»˜è®¤) ä¼˜åŒ–å™¨çŠ¶æ€æŒ‰æ•°æ®å¹¶è¡Œåº¦åˆ‡åˆ†å­˜å‚¨ï¼ŒCheckpointä½“ç§¯å°ï¼Œä¿å­˜/åŠ è½½å¿«ã€‚é€‚ç”¨äºè®­ç»ƒè¿‡ç¨‹ä¸­å¹¶è¡Œé…ç½®å›ºå®šçš„åœºæ™¯ã€‚ ä¸æ”¯æŒæ¨¡å‹å¹¶è¡Œåº¦è°ƒæ•´å¿«ï¼šè¯»å†™å¼€é”€ä½ã€‚ fully_reshardable ä¼˜åŒ–å™¨çŠ¶æ€å®Œæ•´å­˜å‚¨ï¼Œå«å…¨é‡å…ƒæ•°æ®ï¼Œèƒ½é€‚é…ä»»æ„å¹¶è¡Œåˆ’åˆ†å˜åŒ–[51]ã€‚åœ¨éœ€è¦æ”¹å˜å¹¶è¡Œåº¦ï¼ˆå¢å‡GPUæˆ–è°ƒæ•´æ¨¡å‹å¹¶è¡Œï¼‰æ—¶ä½¿ç”¨ï¼Œä»¥ç¡®ä¿Checkpointå¯ç”¨ã€‚ æ”¯æŒä»»æ„å¹¶è¡Œé…ç½®å˜åŒ–è¾ƒæ…¢ï¼šè¯»å†™è€—æ—¶å’Œå¼€é”€æ›´é«˜ã€‚\n\n\nå‚è€ƒæ–‡çŒ® / é“¾æ¥\n\nGitHub - NVIDIA/nvidia-resiliency-ext: NVIDIA Resiliency Extension is a python package for framework developers and users to implement fault-tolerant features. It improves the effective training time by minimizing the downtime due to failures and interruptions\nUsage guide â€” nvidia-resiliency-ext 0.1 documentation\nResiliency â€” Megatron Bridge\nResiliency Features â€” NVIDIA NeMo Framework User Guide\nSections API Integration â€” nvidia-resiliency-ext 0.1 documentation\ndist_checkpointing package â€” Megatron-LM\n\n","categories":["å…¶å®ƒ"],"tags":["NVRx"]},{"title":"ubuntuå¸¸è§shellå‘½ä»¤","url":"/2025/08/17/other/shell/","content":"\n\n1. ç£ç›˜å ç”¨ä¸æ’åºï¼ˆdu/sortï¼‰\nå¸¸ç”¨å†™æ³•\n# æŒ‰â€œå½“å‰ç›®å½•çš„ç›´æ¥å­é¡¹â€æ±‡æ€»ï¼ˆäººç±»å¯è¯»ï¼‰ï¼Œå¹¶æŒ‰å¤§å°å€’åºdu -h --max-depth=1 . | sort -hr# ä»…ç»Ÿè®¡æ¯ä¸ªæ¡ç›®æ€»å¤§å°ï¼ˆä¸æ˜¾ç¤ºå­å±‚çº§ï¼‰ï¼Œå¹¶å¯¹æ¡ç›®æ’åºdu -sh -- * | sort -h\n2. æ–‡æœ¬æœç´¢ï¼ˆgrepï¼‰\nåŸºç¡€\ngrep &quot;keyword&quot; file.txt          # åœ¨å•ä¸ªæ–‡ä»¶ä¸­æŸ¥æ‰¾grep -n &quot;keyword&quot; file.txt       # æ˜¾ç¤ºè¡Œå·grep -i &quot;keyword&quot; file.txt       # å¿½ç•¥å¤§å°å†™\nç›®å½•é€’å½’ä¸ä¸Šä¸‹æ–‡\ngrep -rin --color=auto &quot;keyword&quot; .      # é€’å½’ã€å¿½ç•¥å¤§å°å†™ã€è¡Œå·ã€é«˜äº®grep -nC 3 &quot;keyword&quot; file.txt           # ä¸Šä¸‹å„ 3 è¡Œgrep -nA 2 &quot;keyword&quot; file.txt           # å 2 è¡Œgrep -nB 2 &quot;keyword&quot; file.txt           # å‰ 2 è¡Œ\nç²¾ç¡®åŒ¹é…ä¸æ­£åˆ™\ngrep -rw &quot;\\&lt;token\\&gt;&quot; .                  # æŒ‰â€œæ•´è¯â€åŒ¹é…grep -E &quot;err(or)?|fail(ed)?&quot; app.log    # æ‰©å±•æ­£åˆ™grep -rF &quot;literal*text&quot; .               # çº¯å­—ç¬¦ä¸²ï¼ˆä¸å½“æ­£åˆ™ï¼‰ï¼Œæ›´å¿«\næ’é™¤æ–‡ä»¶/ç›®å½•\ngrep -rin &quot;keyword&quot; . \\  --exclude-dir=&#123;.git,node_modules,dist&#125; \\  --exclude=&quot;*.min.js&quot;\n\n3. æ–‡ä»¶è·¯å¾„æŸ¥æ‰¾ï¼ˆfind/locateï¼‰\nfindï¼šçµæ´»ä½†å®æ—¶æ‰«æï¼ˆæ…¢ï¼‰\n# æŒ‰æ–‡ä»¶åï¼ˆå¤§å°å†™ä¸æ•æ„Ÿï¼‰find /path -type f -iname &quot;*name*&quot;# é™åˆ¶æœç´¢æ·±åº¦find . -maxdepth 2 -type d -name &quot;build&quot;# æŸ¥æ‰¾å¤§æ–‡ä»¶ï¼ˆ&gt; 100MBï¼‰å¹¶æŒ‰å¤§å°é™åºåˆ—å‡ºå‰ 20 ä¸ªfind /var -type f -size +100M -printf &#x27;%s\\t%p\\n&#x27; | sort -nr | head -20# æŸ¥æ‰¾æœ€è¿‘ 1 å¤©å†…ä¿®æ”¹çš„æ–‡ä»¶find . -type f -mtime -1# å¯¹ç»“æœæ‰§è¡Œå‘½ä»¤ï¼ˆå®‰å…¨å¤„ç†ç©ºæ ¼ï¼‰find . -type f -name &quot;*.log&quot; -print0 | xargs -0 gzip\n\nè·³è¿‡ç³»ç»Ÿç›®å½•ä¸”å‹åˆ¶æŠ¥é”™\n\nfind / \\( -path /proc -o -path /sys -o -path /run \\) -prune -o \\  -type f -name &quot;*.conf&quot; -print 2&gt;/dev/null\nlocate/plocateï¼šåŸºäºç´¢å¼•ï¼ˆå¿«ï¼‰\nsudo apt-get install -y plocatesudo updatedb                 # é€šå¸¸è‡ªåŠ¨å®šæ—¶æ›´æ–°locate filename_or_pattern\n\n4. å¸¸è§ç½‘ç»œå·¥å…·å®‰è£…åŒ…\n# pingsudo apt-get install -y iputils-ping# ifconfigï¼ˆè€å·¥å…·ï¼Œä»å¸¸è§ï¼‰sudo apt-get install -y net-tools# ç°ä»£æ›¿ä»£ï¼šipï¼ˆé€šå¸¸å·²è‡ªå¸¦äº iproute2ï¼‰ip addrip linkip route# killallsudo apt-get install -y psmisc\n\n5. è¿›ç¨‹æŸ¥æ€ï¼ˆkill/pkill/killallï¼‰\nps -ef | grep python3 | awk &#x27;&#123;print $2&#125;&#x27; | xargs kill -9\næ›´å®‰å…¨çš„åšæ³•\n# ä¼˜é›…ç»ˆæ­¢ï¼ˆSIGTERMï¼‰ï¼›æ—  PID æ—¶ä¸æ‰§è¡Œ (-r)pgrep -f python3 | xargs -r kill# ç›´æ¥æŒ‰åç§°åŒ¹é…ï¼ˆä¼˜é›…ç»ˆæ­¢ï¼‰ï¼Œå¿…è¦æ—¶å† -9pkill -f python3pkill -9 -f python3# é¿å…åŒ¹é…åˆ° grep è‡ªèº«ps -ef | grep &#x27;[p]ython3&#x27; | awk &#x27;&#123;print $2&#125;&#x27; | xargs -r kill\n\nå»ºè®®å…ˆå°è¯• SIGTERMï¼ˆé»˜è®¤ï¼‰ï¼Œæ— å“åº”å†ç”¨ SIGKILLï¼ˆ-9ï¼‰ã€‚\n\n\n6. é«˜é¢‘å‘½ä»¤æ¸…å•ä¸ç¤ºä¾‹\nç³»ç»Ÿ/èµ„æº\ntop                     # å®æ—¶æ¦‚è§ˆhtop                    # æ›´å‹å¥½ï¼ˆéœ€ï¼šsudo apt-get install -y htopï¼‰free -h                 # å†…å­˜df -h                   # ç£ç›˜åˆ†åŒºå®¹é‡du -sh * | sort -h      # ç›®å½•å ç”¨uname -a                # å†…æ ¸ä¿¡æ¯lsb_release -a          # å‘è¡Œç‰ˆä¿¡æ¯\nè¿›ç¨‹/ç½‘ç»œ\nps aux | lesspstree -p               # è¿›ç¨‹æ ‘ï¼ˆéœ€ï¼šsudo apt-get install -y psmiscï¼‰lsof -i :8080           # ç«¯å£å ç”¨ï¼ˆéœ€ï¼šsudo apt-get install -y lsofï¼‰ss -lntp                # ç›‘å¬ç«¯å£ + è¿›ç¨‹\næ–‡æœ¬/æ—¥å¿—\nless file.logtail -f file.logwc -l file.txtsort file | uniq -c | sort -nrcut -d&#x27;,&#x27; -f1,3 file.csvsed -n &#x27;1,20p&#x27; file.txtawk -F: &#x27;&#123;print $1,$3&#125;&#x27; /etc/passwd\næ–‡ä»¶/å½’æ¡£/ä¼ è¾“\ntar -czf logs.tgz logs/        # å‹ç¼©tar -xzf logs.tgz              # è§£å‹zip -r src.zip src/            # zipï¼ˆéœ€ï¼šsudo apt-get install -y zip unzipï¼‰rsync -av --progress src/ dst/scp file user@host:/path/\næƒé™/é“¾æ¥\nchmod +x run.shchown user:group fileln -s /real/path link_name\næœåŠ¡ä¸æ—¥å¿—ï¼ˆsystemdï¼‰\nsystemctl status nginxsudo systemctl start nginxjournalctl -u nginx --since &quot;1 hour ago&quot;\nå…¶ä»–\nwhich python3command -v nodedate &quot;+%F %T&quot;nohup python3 app.py &gt;out.log 2&gt;&amp;1 &amp;tmux new -s work              # ç»ˆç«¯å¤ç”¨ï¼ˆéœ€ï¼šsudo apt-get install -y tmuxï¼‰\n\n7. å°è´´å£«ä¸å¸¸è§å‘\n\néšè—æ–‡ä»¶ï¼š* ä¸åŒ¹é…éšè—é¡¹ï¼Œå¯ç”¨ .* * ç»„åˆæˆ–å¼€å¯ dotglobã€‚\né˜²æ­¢å‚æ•°è¢«å½“ä½œé€‰é¡¹ï¼šå½“æ–‡ä»¶åä»¥ - å¼€å¤´æ—¶åŠ  --ï¼Œå¦‚ rm -- -weirdfileã€‚\nxargs å®‰å…¨ï¼šäºŒè¿›åˆ¶æ–‡ä»¶/ç©ºæ ¼ç”¨ -0 é…åˆ -print0ï¼›æ— ç»“æœæ—¶ä¸æ‰§è¡Œç”¨ -rã€‚\nä¼˜é›…åœæœåŠ¡ä¼˜å…ˆï¼škill -TERM â†’ ä¸è¡Œå† kill -KILLã€‚\næƒé™ï¼šç³»ç»Ÿç›®å½•æ“ä½œæ…ç”¨ sudoï¼Œå†™å‰å…ˆ ls/du/stat ç¡®è®¤ã€‚\ngrep æ­£åˆ™ vs å­—ç¬¦ä¸²ï¼šçº¯æ–‡æœ¬åŒ¹é…æ›´ç¨³æ›´å¿«ç”¨ -Fã€‚\nfind æ€§èƒ½ï¼šå¤§ç›®å½•ç”¨ -maxdepth é™åˆ¶å±‚çº§æˆ–æ”¹ç”¨ locate/plocateã€‚\n\n\n","categories":["å…¶å®ƒ"],"tags":["shell"]},{"title":"token ç®€ä»‹","url":"/2025/09/07/other/token/","content":"\n\nğŸ§  ä»€ä¹ˆæ˜¯ Tokenï¼Ÿ\nåœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­ï¼ŒToken æ˜¯æ–‡æœ¬çš„åŸºæœ¬å•ä½ã€‚å®ƒå¯ä»¥æ˜¯ä¸€ä¸ªå­—ç¬¦ã€ä¸€ä¸ªè¯ã€ä¸€ä¸ªå­è¯ï¼Œç”šè‡³æ˜¯ä¸€ä¸ªæ ‡ç‚¹ç¬¦å·ã€‚Token çš„å®šä¹‰å–å†³äºæ‰€é‡‡ç”¨çš„æ ‡è®°åŒ–ï¼ˆtokenizationï¼‰æ–¹æ³•ã€‚\n\nğŸ”„ æ–‡æœ¬å¦‚ä½•è½¬æ¢ä¸ºæ•°å­—ï¼Ÿ\nåœ¨è®­ç»ƒè¯­è¨€æ¨¡å‹æ—¶ï¼Œæ–‡æœ¬éœ€è¦è¢«è½¬æ¢ä¸ºæ•°å­—å½¢å¼ã€‚è¿™ä¸€è¿‡ç¨‹é€šå¸¸åŒ…æ‹¬ä»¥ä¸‹æ­¥éª¤ï¼š\n\næ ‡è®°åŒ–ï¼ˆTokenizationï¼‰ï¼šå°†æ–‡æœ¬åˆ†è§£ä¸º tokensã€‚\næ„å»ºè¯æ±‡è¡¨ï¼ˆVocabularyï¼‰ï¼šä¸ºæ¯ä¸ª token åˆ†é…ä¸€ä¸ªå”¯ä¸€çš„æ•°å­— IDã€‚\næ•°å­—åŒ–ï¼ˆNumericalizationï¼‰ï¼šå°†æ–‡æœ¬ä¸­çš„ tokens æ›¿æ¢ä¸ºå¯¹åº”çš„æ•°å­— IDã€‚\n\nä¾‹å¦‚ï¼Œå¥å­ \"hello world\" å¯èƒ½è¢«æ ‡è®°åŒ–ä¸º [\"hello\", \"world\"]ï¼Œç„¶åæ ¹æ®è¯æ±‡è¡¨è½¬æ¢ä¸º [1, 2]ã€‚\n\nğŸ”¤ å¸¸è§çš„æ ‡è®°åŒ–æ–¹æ³•\n1. Word-based Tokenizationï¼ˆåŸºäºè¯çš„æ ‡è®°åŒ–ï¼‰\nå°†æ–‡æœ¬æŒ‰ç©ºæ ¼æˆ–æ ‡ç‚¹ç¬¦å·åˆ†å‰²æˆå•è¯ã€‚è¿™ç§æ–¹æ³•ç®€å•ç›´è§‚ï¼Œä½†å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š\n\nè¯æ±‡è¡¨è¿‡å¤§ï¼šéœ€è¦ä¸ºæ¯ä¸ªå•è¯åˆ†é…ä¸€ä¸ªå”¯ä¸€çš„ IDï¼Œå¯¼è‡´è¯æ±‡è¡¨åºå¤§ã€‚\nå¤„ç†æœªç™»å½•è¯å›°éš¾ï¼šå¯¹äºè®­ç»ƒæ•°æ®ä¸­æœªå‡ºç°çš„å•è¯ï¼Œæ¨¡å‹éš¾ä»¥å¤„ç†ã€‚\n\nç¤ºä¾‹ï¼š\n\nè¾“å…¥æ–‡æœ¬ï¼š\"I love NLP\"\næ ‡è®°åŒ–ç»“æœï¼š[\"I\", \"love\", \"NLP\"]\næ•°å­—åŒ–è¡¨ç¤ºï¼š[1, 2, 3]\n\n2. Character-based Tokenizationï¼ˆåŸºäºå­—ç¬¦çš„æ ‡è®°åŒ–ï¼‰\nå°†æ–‡æœ¬åˆ†è§£ä¸ºå•ä¸ªå­—ç¬¦ã€‚è¿™ç§æ–¹æ³•å¯ä»¥æœ‰æ•ˆå‡å°‘è¯æ±‡è¡¨å¤§å°ï¼Œä½†å¯èƒ½å¯¼è‡´ä»¥ä¸‹é—®é¢˜ï¼š\n\nä¿¡æ¯ä¸¢å¤±ï¼šå­—ç¬¦çº§åˆ«çš„è¡¨ç¤ºå¯èƒ½æ— æ³•æ•æ‰åˆ°è¯æ±‡çš„å®Œæ•´è¯­ä¹‰ã€‚\nåºåˆ—é•¿åº¦å¢åŠ ï¼šåŒä¸€æ–‡æœ¬çš„ token æ•°é‡å¢åŠ ï¼Œå¯èƒ½å½±å“æ¨¡å‹çš„å¤„ç†æ•ˆç‡ã€‚\n\nç¤ºä¾‹ï¼š\n\nè¾“å…¥æ–‡æœ¬ï¼š\"I love NLP\"\næ ‡è®°åŒ–ç»“æœï¼š[\"I\", \" \", \"l\", \"o\", \"v\", \"e\", \" \", \"N\", \"L\", \"P\"]\næ•°å­—åŒ–è¡¨ç¤ºï¼š[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n\nğŸ”¬ Subword-based Tokenizationï¼šBPEï¼ˆå­—èŠ‚å¯¹ç¼–ç ï¼‰\nBPE æ˜¯ä¸€ç§å­è¯çº§åˆ«çš„æ ‡è®°åŒ–æ–¹æ³•ï¼Œæ—¨åœ¨å¹³è¡¡è¯æ±‡è¡¨å¤§å°å’Œè¯­ä¹‰è¡¨è¾¾èƒ½åŠ›ã€‚å®ƒé€šè¿‡è¿­ä»£åœ°åˆå¹¶æœ€é¢‘ç¹çš„å­—ç¬¦å¯¹æ¥æ„å»ºå­è¯å•å…ƒï¼Œå¹¶è¢«å¹¿æ³›åº”ç”¨äº GPTã€BERT ç­‰å¤§è¯­è¨€æ¨¡å‹ã€‚BPE çš„è¿‡ç¨‹å¯ä»¥æ¦‚æ‹¬ä¸ºä»¥ä¸‹äº”ä¸ªé˜¶æ®µï¼š\n1. åˆå§‹åŒ–è¯æ±‡è¡¨\n\næ‹†åˆ†å­—ç¬¦ï¼šé¦–å…ˆå°†è¯­æ–™åº“æ‹†åˆ†ä¸ºæœ€å°å•ä½â€”â€”å•ä¸ªå­—ç¬¦ã€‚ä¾‹å¦‚ï¼Œå¯¹å•è¯ lower æ‹†åˆ†å¾—åˆ° l o w e r&lt;/w&gt;ï¼Œå¹¶åœ¨æ¯ä¸ªè¯å°¾æ·»åŠ ç‰¹æ®Šç»“æŸç¬¦ï¼ˆå¦‚ &lt;/w&gt;ï¼‰ï¼Œä»¥åŒºåˆ†ä¸åŒè¯ã€‚\næ„å»ºåˆå§‹è¯è¡¨ï¼šè®°å½•æ‰€æœ‰å‡ºç°è¿‡çš„å­—ç¬¦ï¼Œä½œä¸ºåˆå§‹ token é›†ã€‚\n\n2. ç»Ÿè®¡ç›¸é‚»å­—ç¬¦å¯¹é¢‘ç‡\néå†æ‰€æœ‰è¯ï¼Œç»Ÿè®¡æ¯ä¸ªç›¸é‚»å­—ç¬¦ï¼ˆæˆ–å·²åˆå¹¶çš„å­è¯ï¼‰å¯¹çš„å‡ºç°æ¬¡æ•°ã€‚BPE é€šè¿‡è¿™ä¸€ç»Ÿè®¡æ¥è¯†åˆ«è¯­è¨€ä¸­æœ€å¸¸è§çš„æ¨¡å¼ï¼Œä»¥å†³å®šæ¥ä¸‹æ¥è¦åˆå¹¶çš„ç¬¦å·å¯¹ã€‚\n3. åˆå¹¶æœ€é¢‘ç¹çš„ç¬¦å·å¯¹\næ‰¾åˆ°å‡ºç°é¢‘ç‡æœ€é«˜çš„å­—ç¬¦å¯¹ï¼Œå¹¶å°†å®ƒä»¬åœ¨æ•´ä¸ªæ•°æ®é›†ä¸­åˆå¹¶æˆæ–°çš„å­è¯ã€‚ä¾‹å¦‚ï¼Œå¦‚æœ (w, e) æ˜¯æœ€é«˜é¢‘ç»„åˆï¼Œåˆ™å°†å…¶åˆå¹¶ä¸º weï¼›æ›´æ–°æ‰€æœ‰ç›¸å…³è¯ï¼Œå¹¶æŠŠæ–°å­è¯åŠ å…¥è¯æ±‡è¡¨ã€‚\n4. é‡å¤æ­¥éª¤ç›´åˆ°è¾¾åˆ°è¯è¡¨å¤§å°\nBPE æ˜¯ä¸€ä¸ªè¿­ä»£è¿‡ç¨‹ã€‚æ¯æ¬¡åˆå¹¶åï¼Œç»Ÿè®¡æ–°çš„ç›¸é‚»ç¬¦å·å¯¹å¹¶ç»§ç»­åˆå¹¶ï¼Œç›´åˆ°è¯æ±‡è¡¨è¾¾åˆ°é¢„è®¾å¤§å°æˆ–ä¸å†æœ‰éœ€è¦åˆå¹¶çš„ç¬¦å·å¯¹ã€‚\n5. æ„å»ºæœ€ç»ˆè¯æ±‡è¡¨å¹¶åº”ç”¨åˆ°æ–‡æœ¬\næœ€ç»ˆè¯æ±‡è¡¨æ—¢åŒ…å«åˆå§‹çš„å­—ç¬¦ï¼ŒåˆåŒ…å«æ‰€æœ‰åˆå¹¶å¾—åˆ°çš„é«˜é¢‘å­è¯ã€‚æ–°è¯å¯ä»¥é€šè¿‡è¿™äº›å­è¯ç»„åˆè¡¨ç¤ºï¼Œå› æ­¤ä»»ä½•æ–°è¯éƒ½èƒ½æ‹†è§£ä¸ºå·²çŸ¥çš„å­è¯åºåˆ—ã€‚\nç¤ºä¾‹ï¼šBPE åˆ†è¯è¿‡ç¨‹æ¼”ç¤º\nä»¥ä»¥ä¸‹è¯æ±‡é›†ä¸ºä¾‹ï¼šhuggingfaceã€huggingã€faceã€hugã€huggerã€learningã€learnerã€learnã€‚å°†æ¯ä¸ªè¯æ‹†åˆ†ä¸ºå­—ç¬¦å¹¶åŠ ä¸Šç»“æŸç¬¦ï¼Œç„¶åæ‰§è¡Œé¢‘æ¬¡ç»Ÿè®¡å’Œåˆå¹¶ã€‚ä»¥ä¸‹æ˜¯å‰å‡ æ¬¡åˆå¹¶ï¼š\n\n(h, u) â†’ hu\n(hu, g) â†’ hug\n(hug, g) â†’ hugg\n(i, n) â†’ in\n(in, g) â†’ ing\n(l, e) â†’ le\n(le, a) â†’ lea\n(lea, r) â†’ lear\n\næ‰§è¡Œ 8 æ¬¡åˆå¹¶åï¼Œè¯è¡¨æ‰©å¤§è‡³ 20 ä¸ª tokenï¼Œå…¶ä¸­åŒ…æ‹¬åŸºæœ¬å­—ç¬¦ï¼ˆh,u,g,i ç­‰ï¼‰å’Œæ–°åˆæˆçš„å­è¯ï¼ˆhug,hugg,ing,lear ç­‰ï¼‰ã€‚è¯ huggingface ç»è¿‡æ ‡è®°åŒ–åä¸º hugg ing f a c e &lt;/w&gt;ï¼Œlearning åˆ™ä¸º lear n ing &lt;/w&gt;ï¼Œå…¶ä½™è¯ä¹Ÿå¯ä»¥ç”¨ç±»ä¼¼æ–¹å¼è¡¨ç¤ºã€‚\nğŸ§ª BPE çš„ä¼˜ç¼ºç‚¹\nä¼˜ç‚¹ï¼š\n\nå¤„ç†æœªç™»å½•è¯ï¼šé€šè¿‡æŠŠè¯æ‹†è§£ä¸ºå­è¯ï¼ŒBPE å¯ä»¥ç”¨å·²æœ‰çš„å­è¯ç»„åˆæ¥è¡¨ç¤ºè®­ç»ƒé›†ä¸­æœªå‡ºç°çš„è¯æ±‡ã€‚\nå‡å°‘è¯æ±‡è¡¨å¤§å°ï¼šç›¸æ¯”åŸºäºè¯çš„æ ‡è®°åŒ–ï¼ŒBPE å¯ä»¥æ˜¾è‘—ç¼©å°è¯è¡¨è§„æ¨¡ï¼Œä½¿æ¨¡å‹æ›´é«˜æ•ˆã€‚\næå‡æ³›åŒ–èƒ½åŠ›ï¼šå­è¯çº§è¡¨ç¤ºå…è®¸æ¨¡å‹å­¦ä¹ æ›´ç»†ç²’åº¦çš„è¯­è¨€ç»“æ„ï¼Œå¯¹ä¸åŒé¢†åŸŸã€ä¸åŒè¯­è¨€å…·æœ‰æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚\n\nç¼ºç‚¹ï¼š\n\nåˆå¹¶è§„åˆ™ä¾èµ–è¯­æ–™ï¼šä¸åŒè¯­æ–™å¾—åˆ°çš„åˆå¹¶è§„åˆ™å·®å¼‚è¾ƒå¤§ï¼Œå¤šè¯­è¨€åœºæ™¯ä¸‹å¯èƒ½éœ€è¦å¤æ‚çš„å¤„ç†ã€‚\nè¯­ä¹‰å®Œæ•´æ€§å¯èƒ½å—æŸï¼šå¦‚æœåˆå¹¶è¿‡åº¦ï¼ŒæŸäº›åˆæˆè¯çš„è¯­ä¹‰ä»å¯èƒ½åˆ†å‰²ï¼Œéœ€æ ¹æ®ä»»åŠ¡é€‰æ‹©åˆé€‚çš„è¯è¡¨å¤§å°ã€‚\n\n\nğŸ“ æ€»ç»“\næ ‡è®°åŒ–æ˜¯è‡ªç„¶è¯­è¨€å¤„ç†çš„æ ¸å¿ƒæ­¥éª¤ï¼Œå®ƒå°†æ–‡æœ¬è½¬æ¢ä¸ºæ¨¡å‹å¯å¤„ç†çš„æ•°å­—å½¢å¼ã€‚åŸºäºè¯å’ŒåŸºäºå­—ç¬¦çš„æ ‡è®°åŒ–æ–¹æ³•ç®€å•æ˜“ç†è§£ï¼Œä½†åˆ†åˆ«å­˜åœ¨è¯æ±‡è¡¨è¿‡å¤§å’Œåºåˆ—è¿‡é•¿çš„é—®é¢˜ã€‚BPE ä½œä¸ºä¸€ç§å­è¯çº§æ ‡è®°åŒ–ç®—æ³•ï¼Œä»¥åˆå§‹åŒ–å­—ç¬¦é›†ä¸ºåŸºç¡€ï¼Œé€šè¿‡è¿­ä»£åˆå¹¶é«˜é¢‘ç¬¦å·å¯¹æ„å»ºæ–°çš„å­è¯å•å…ƒã€‚è¿™ç§æ–¹æ³•å…¼é¡¾äº†è¯è¡¨å¤§å°å’Œè¯­ä¹‰è¡¨è¾¾èƒ½åŠ›ï¼Œæ—¢èƒ½å¤„ç†æœªç™»å½•è¯ï¼Œä¹Ÿèƒ½ä¿ç•™è¶³å¤Ÿçš„è¯­ä¹‰ä¿¡æ¯ã€‚å› æ­¤ï¼Œç°ä»£å¤§è¯­è¨€æ¨¡å‹é€šå¸¸é‡‡ç”¨ BPE æˆ–å…¶å˜ç§ï¼ˆå¦‚ WordPieceã€SentencePieceï¼‰ä½œä¸ºé»˜è®¤çš„æ ‡è®°åŒ–æ–¹æ¡ˆã€‚\n","categories":["å…¶å®ƒ"],"tags":["token"]},{"title":"ubuntuæ­å»ºæŠ€æœ¯åšå®¢æŒ‡å—","url":"/2025/06/14/other/web_init/","content":"\n\n1. å®‰è£… Hexo ç¯å¢ƒ\n2. é€‰æ‹©ä¸é…ç½® Hexo ä¸»é¢˜\n3. æ’°å†™ä¸ç®¡ç†åšå®¢å†…å®¹\n4. SEO ä¼˜åŒ–\n5. åšå®¢éƒ¨ç½²\n6. ç»´æŠ¤ä¸ä¼˜åŒ–\n\næœ¬æŒ‡å—è¯¦ç»†ä»‹ç»äº†å¦‚ä½•åœ¨ Ubuntu æœåŠ¡å™¨ä¸Šæ­å»ºå¹¶éƒ¨ç½²ä¸€ä¸ª Hexo æŠ€æœ¯åšå®¢ï¼ŒåŒ…æ‹¬ä»ç¯å¢ƒå®‰è£…åˆ°åæœŸç»´æŠ¤çš„å®Œæ•´æ­¥éª¤ã€‚\n1. å®‰è£… Hexo ç¯å¢ƒ\næ­å»º Hexo åšå®¢é¦–å…ˆéœ€è¦å®‰è£… Node.jsï¼ˆHexo åŸºäº Node.jsï¼‰ã€npmã€Git ä»¥åŠ Hexo CLI å·¥å…·ã€‚è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤é…ç½®ç¯å¢ƒï¼š\nå®‰è£… Node.js å’Œ npmï¼š\nåœ¨ Ubuntu ä¸Šï¼Œé€šè¿‡åŒ…ç®¡ç†å™¨æˆ– Node å®˜æ–¹ä»“åº“å®‰è£… Node.jsã€‚å»ºè®®å®‰è£… LTS ç‰ˆæœ¬ï¼ˆå¦‚ Node 14+ï¼‰ã€‚æ‰§è¡Œä»¥ä¸‹å‘½ä»¤æ·»åŠ  NodeSource ä»“åº“å¹¶å®‰è£… Node.jsï¼š\ncurl -sL https://deb.nodesource.com/setup_18.x | sudo -E bash -sudo apt-get install -y nodejs\nå®‰è£…å®Œæˆåï¼Œæ£€æŸ¥ç‰ˆæœ¬ä»¥ç¡®ä¿ Node æ­£å¸¸å¯ç”¨ï¼š\nnode -v  # åº”è¿”å›ç±»ä¼¼ v18.20.6 çš„ç‰ˆæœ¬å·npm -v   # éªŒè¯ npm æ˜¯å¦æ­£å¸¸å®‰è£…\nå®‰è£… Gitï¼š\nGit æ˜¯ Hexo éƒ¨ç½²å’Œå¤‡ä»½çš„å¸¸ç”¨å·¥å…·ã€‚Ubuntu é€šå¸¸é¢„è£… Gitï¼Œè‹¥æœªå®‰è£…ï¼Œè¯·æ‰§è¡Œï¼š\nsudo apt-get install -y git\nå®‰è£…åï¼Œé…ç½® Git çš„å…¨å±€ç”¨æˆ·åå’Œé‚®ç®±ï¼š\ngit config --global user.name &quot;Your Name&quot;git config --global user.email &quot;youremail@example.com&quot;\nå®‰è£… Hexo CLIï¼š\né€šè¿‡ npm å…¨å±€å®‰è£… Hexo CLIï¼š\nsudo npm install -g hexo-cli\nå®‰è£…æˆåŠŸåï¼Œé€šè¿‡ hexo -v æ£€æŸ¥ç‰ˆæœ¬ï¼Œç¡®ä¿ Hexo CLI å¯ç”¨ã€‚\nåˆå§‹åŒ– Hexo åšå®¢ï¼š\né€‰æ‹©åšå®¢æ–‡ä»¶å¤¹ï¼ˆä¾‹å¦‚ /var/www/hexo æˆ–å½“å‰ç”¨æˆ·ä¸»ç›®å½•ä¸‹çš„ my-blog æ–‡ä»¶å¤¹ï¼‰ï¼Œå¹¶åœ¨è¯¥ç›®å½•ä¸‹åˆå§‹åŒ– Hexo åšå®¢ï¼š\nsudo mkdir -p /var/www/hexo &amp;&amp; sudo chown $USER:$USER /var/www/hexocd /var/www/hexohexo initnpm install\nåˆå§‹åŒ–å®Œæˆåï¼ŒHexo ä¼šç”Ÿæˆé»˜è®¤çš„åšå®¢ç»“æ„ï¼ŒåŒ…æ‹¬ _config.yml é…ç½®æ–‡ä»¶ã€scaffolds/ æ¨¡æ¿ç›®å½•ã€source/ å†…å®¹ç›®å½•å’Œ themes/ ä¸»é¢˜ç›®å½•ç­‰ã€‚å¯ä»¥é€šè¿‡è¿è¡Œ hexo server é¢„è§ˆæœ¬åœ°åšå®¢ã€‚\nå¼€å¯é˜²ç«å¢™ï¼š\nä¸ºäº†ç¡®ä¿æœåŠ¡å™¨å®‰å…¨ï¼Œå»ºè®®å¼€å¯é˜²ç«å¢™ã€‚Ubuntu è‡ªå¸¦ UFW é˜²ç«å¢™ï¼Œå¯ä»¥å¼€å¯ SSHã€HTTP(S) ä»¥åŠ Hexo é»˜è®¤é¢„è§ˆç«¯å£ 4000ï¼š\nsudo apt-get install ufw  sudo ufw allow &quot;OpenSSH&quot;  sudo ufw allow 4000  sudo ufw allow http  sudo ufw allow https  sudo ufw enable\n2. é€‰æ‹©ä¸é…ç½® Hexo ä¸»é¢˜\nHexo é»˜è®¤ä¸»é¢˜ä¸º Landscapeï¼Œä½†ä¸ºäº†æ‰“é€ ä¸€ä¸ªç®€æ´ç¾è§‚çš„æŠ€æœ¯åšå®¢ï¼Œæˆ‘ä»¬æ¨èä½¿ç”¨ NexT ä¸»é¢˜ï¼Œå®ƒåŠŸèƒ½å¼ºå¤§ä¸”å¤–è§‚ä¼˜é›…ã€‚ä»¥ä¸‹æ˜¯ä¸»é¢˜çš„å®‰è£…å’Œé…ç½®æ­¥éª¤ï¼š\nè·å– NexT ä¸»é¢˜ï¼š\nåœ¨ Hexo åšå®¢æ ¹ç›®å½•ä¸‹æ‰§è¡Œä»¥ä¸‹å‘½ä»¤æ¥å…‹éš† NexT ä¸»é¢˜ï¼š\ncd /var/www/hexogit clone https://github.com/theme-next/hexo-theme-next themes/next\nä¿®æ”¹ä¸»é¢˜é…ç½®ï¼š\nå…‹éš†å®Œæˆåï¼Œæ‰“å¼€ _config.yml é…ç½®æ–‡ä»¶ï¼Œå°† theme é…ç½®ä»é»˜è®¤çš„ landscape æ”¹ä¸º nextï¼š\n# _config.ymltheme: next\nå®‰è£…ä¸»é¢˜ä¾èµ–ï¼š\næ ¹æ®éœ€è¦å®‰è£… NexT ä¸»é¢˜çš„ä¾èµ–ï¼Œå¹¶å¯ç”¨ä½ æ‰€éœ€çš„åŠŸèƒ½ã€‚\nç”Ÿæˆå¸¸ç”¨é¡µé¢ï¼š\nä¸ºäº†å®Œå–„ç½‘ç«™ç»“æ„ï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ç”Ÿæˆæ ‡ç­¾ã€åˆ†ç±»ã€å½’æ¡£ç­‰é¡µé¢ï¼š\nhexo new page &quot;tags&quot;hexo new page &quot;categories&quot;hexo new page &quot;archives&quot;hexo new page &quot;about&quot;\nç¼–è¾‘æ¯ä¸ªé¡µé¢çš„ index.mdï¼Œåœ¨ Front-matter ä¸­æŒ‡å®šé¡µé¢ç±»å‹ï¼š\ntitle: æ ‡ç­¾date: 2025-03-06 15:00:00type: &quot;tags&quot;\nå¯¼èˆªæ èœå•å®šåˆ¶ï¼š\nåœ¨ themes/next/_config.yml ä¸­æ‰¾åˆ° menu è®¾ç½®ï¼Œå¹¶æ·»åŠ æ–°åˆ›å»ºçš„é¡µé¢ï¼š\nmenu:  home: / || home  categories: /categories/ || th  tags: /tags/ || tags  archives: /archives/ || archive  about: /about/ || user\nä¿å­˜ä¿®æ”¹åï¼Œé‡æ–°ç”Ÿæˆç«™ç‚¹ï¼Œæ–°çš„å¯¼èˆªæ èœå•å³ä¼šæ˜¾ç¤ºã€‚\n3. æ’°å†™ä¸ç®¡ç†åšå®¢å†…å®¹\nHexo ä½¿ç”¨ Markdown æ ¼å¼æ¥æ’°å†™æ–‡ç« ï¼Œéå¸¸é€‚åˆæŠ€æœ¯åšå®¢ã€‚ä»¥ä¸‹æ˜¯å¦‚ä½•ç®¡ç†å’Œç¼–å†™æ–‡ç« çš„æ­¥éª¤ï¼š\næ–°å»ºåšæ–‡ï¼š\nä½¿ç”¨ Hexo CLI åˆ›å»ºæ–°çš„æ–‡ç« ï¼š\nhexo new &quot;æ–‡ç« æ ‡é¢˜&quot;\nè¿™å°†åœ¨ source/_posts/ ç›®å½•ä¸‹åˆ›å»ºä¸€ä¸ª Markdown æ–‡ä»¶ï¼Œæ–‡ä»¶çš„å¼€å¤´æ˜¯ Front-matterï¼Œç”¨äºé…ç½®æ–‡ç« çš„å…ƒæ•°æ®ï¼ˆå¦‚æ ‡é¢˜ã€æ—¥æœŸã€åˆ†ç±»å’Œæ ‡ç­¾ç­‰ï¼‰ï¼š\ntitle: æ·±åº¦å­¦ä¹ å…¥é—¨æŒ‡å—  date: 2025-03-06 15:00:00  categories:    - äººå·¥æ™ºèƒ½    - æ·±åº¦å­¦ä¹   tags:    - ç¥ç»ç½‘ç»œ    - å…¥é—¨æ•™ç¨‹ \nä½¿ç”¨ Markdown æ’°å†™å†…å®¹ï¼š\nåœ¨ Front-matter ä¸‹æ–¹ï¼Œç”¨ Markdown è¯­æ³•æ’°å†™æ­£æ–‡ã€‚Hexo é»˜è®¤æ”¯æŒ GFMï¼ˆGitHub Flavored Markdownï¼‰ï¼Œå¯ä»¥æ–¹ä¾¿åœ°ä¹¦å†™æ ¼å¼ï¼Œä¾‹å¦‚ï¼š\n# ä¸€çº§æ ‡é¢˜## äºŒçº§æ ‡é¢˜**ç²—ä½“**ã€*æ–œä½“*å¼ºè°ƒ\næ’å…¥å›¾ç‰‡å’Œèµ„æºï¼š\nå¯ç”¨ post_asset_folder: true åï¼Œæ¯ç¯‡æ–‡ç« ä¼šæœ‰ç‹¬ç«‹çš„èµ„æºç›®å½•ã€‚å¯ä»¥å°†å›¾ç‰‡æ–‡ä»¶æ”¾å…¥è¯¥æ–‡ä»¶å¤¹ï¼Œå¹¶åœ¨æ–‡ç« ä¸­å¼•ç”¨ï¼š\n![](my-post/images/example.png)\nè‰ç¨¿ç®¡ç†ä¸å‘å¸ƒï¼š\nå¯ç”¨è‰ç¨¿åŠŸèƒ½åï¼Œæ–°åˆ›å»ºçš„æ–‡ç« ä¼šå…ˆæ”¾åœ¨ _drafts/ ä¸‹ã€‚å®Œæˆåï¼Œä½¿ç”¨ hexo publish \"æ–‡ç« æ ‡é¢˜\" å°†å…¶å‘å¸ƒã€‚\næ–‡ç« ç»“æ„å’Œåˆ†é¡µï¼š\nHexo æ”¯æŒæ–‡ç« åˆ†ç±»å’Œæ ‡ç­¾è‡ªåŠ¨æ•´ç†ã€‚ä½ ä¹Ÿå¯ä»¥é€šè¿‡ &lt;!-- more --&gt; æ¥æ‰‹åŠ¨æˆªæ–­æ‘˜è¦ï¼Œæé«˜é¦–é¡µåŠ è½½é€Ÿåº¦ã€‚\n4. SEO ä¼˜åŒ–\nä¸ºäº†è®©æ›´å¤šäººçœ‹åˆ°ä½ çš„æŠ€æœ¯åšå®¢ï¼Œè¿›è¡Œ SEOï¼ˆæœç´¢å¼•æ“ä¼˜åŒ–ï¼‰éå¸¸é‡è¦ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›ä¼˜åŒ–æªæ–½ï¼š\nç«™ç‚¹æ ‡é¢˜ä¸å…ƒä¿¡æ¯ï¼š\nåœ¨ _config.yml ä¸­å¡«å†™æœ‰åŠ©äº SEO çš„ç«™ç‚¹åŸºæœ¬ä¿¡æ¯ï¼ŒåŒ…æ‹¬ titleï¼ˆæ ‡é¢˜ï¼‰ã€descriptionï¼ˆæè¿°ï¼‰å’Œ keywordsï¼ˆå…³é”®è¯ï¼‰ã€‚\né“¾æ¥ä¼˜åŒ–ï¼š\nä¿®æ”¹æ°¸ä¹…é“¾æ¥æ ¼å¼ï¼Œç®€åŒ– URL ç»“æ„ï¼š\npermalink: :category/:title/\nç«™ç‚¹åœ°å›¾ï¼š\nç”Ÿæˆç«™ç‚¹åœ°å›¾å¸®åŠ©æœç´¢å¼•æ“æŠ“å–æ‰€æœ‰é¡µé¢ï¼š\nnpm install hexo-generator-sitemap hexo-generator-baidu-sitemap --save\nå¹¶åœ¨ _config.yml ä¸­æ·»åŠ é…ç½®ï¼š\nsitemap:  path: sitemap.xmlbaidusitemap:  path: baidusitemap.xml\næœºå™¨äººåè®®ï¼š\nåœ¨ source/ ç›®å½•ä¸‹åˆ›å»º robots.txt æ–‡ä»¶ï¼Œå¹¶å†™å…¥è§„åˆ™ï¼š\nUser-agent: *Allow: /Disallow: /admin/Sitemap: https://ä½ çš„åŸŸå/sitemap.xml\nå¥½çš„ï¼Œä»¥ä¸‹æ˜¯æˆ‘é‡æ–°ç”Ÿæˆå¹¶ä¿æŒå®Œæ•´çš„ Hexo Deploy è‡ªåŠ¨éƒ¨ç½²éƒ¨åˆ†ï¼Œç¡®ä¿æ²¡æœ‰çœç•¥ä»»ä½•ç»†èŠ‚ï¼š\n\n5. åšå®¢éƒ¨ç½²\nå®Œæˆå†…å®¹åˆ›ä½œå’Œä¼˜åŒ–åï¼Œå°±éœ€è¦å°†åšå®¢éƒ¨ç½²ä¸Šçº¿ã€‚Hexo ç”Ÿæˆçš„æ˜¯çº¯é™æ€ç½‘é¡µï¼Œå¯ä»¥éƒ¨ç½²åœ¨ä»»æ„é™æ€æœåŠ¡å™¨æˆ–æ‰˜ç®¡å¹³å°ä¸Šã€‚è¿™é‡Œä»‹ç»åœ¨ Ubuntu æœåŠ¡å™¨ä¸Šä½¿ç”¨ Nginx éƒ¨ç½²çš„æ–¹æ¡ˆï¼Œå¹¶è®¨è®º Nginx é…ç½®å’Œ Git è‡ªåŠ¨éƒ¨ç½²æ–¹æ³•ã€‚\næœ¬åœ°ç”Ÿæˆé™æ€æ–‡ä»¶ï¼š\nHexo æä¾›å‘½ä»¤å°† Markdown å†…å®¹ç”Ÿæˆé™æ€ç½‘é¡µã€‚ä¸€èˆ¬åœ¨æœ¬åœ°æˆ–æœåŠ¡å™¨ä¸Šè¿è¡Œï¼š\nhexo clean        # æ¸…ç†ä¸Šæ¬¡ç”Ÿæˆçš„æ–‡ä»¶hexo generate (hexo g)   # ç”Ÿæˆæœ€æ–°é™æ€ç½‘é¡µ\nç”Ÿæˆçš„æ–‡ä»¶ä½äºåšå®¢ç›®å½•ä¸‹çš„ public/ æ–‡ä»¶å¤¹ï¼Œå…¶ä¸­åŒ…å«åšå®¢çš„æ‰€æœ‰ HTMLã€CSSã€JSã€å›¾ç‰‡ç­‰é™æ€èµ„æºã€‚è¿™ä¸ª public æ–‡ä»¶å¤¹å³æ˜¯æœ€ç»ˆéƒ¨ç½²çš„ç½‘ç«™å†…å®¹ã€‚\nNginx éƒ¨ç½²é™æ€ç«™ç‚¹ï¼š\nåœ¨æœåŠ¡å™¨ä¸Šå®‰è£… Nginx å¹¶é…ç½®ç«™ç‚¹ï¼Œä»¥æä¾› Web æœåŠ¡ï¼š\nå®‰è£… Nginxï¼š\nsudo apt-get install -y nginx\nå®‰è£…åå¯åŠ¨ Nginx æœåŠ¡ï¼š\nsudo systemctl start nginx  # å¯è®¾ç½®å¼€æœºè‡ªå¯\né…ç½®ç«™ç‚¹ï¼šåœ¨ /etc/nginx/sites-available/ ç›®å½•ä¸‹åˆ›å»ºé…ç½®æ–‡ä»¶ï¼Œå¦‚ hexo.confï¼Œå†…å®¹å¦‚ä¸‹ï¼š\nserver &#123;    listen 80;    server_name example.com;  # å°†æ­¤æ›¿æ¢ä¸ºä½ çš„åŸŸåæˆ–æœåŠ¡å™¨IP    root /var/www/hexo/public;    index index.html index.htm;    location / &#123;        try_files $uri $uri/ =404;    &#125;&#125;\nä¸Šè¿°é…ç½®æŒ‡å®šæœåŠ¡å™¨ç›‘å¬ 80 ç«¯å£ï¼Œserver_name ä¸ºä½ çš„åŸŸåï¼ˆéœ€è¦å°†åŸŸåè§£ææŒ‡å‘è¯¥æœåŠ¡å™¨ï¼‰ã€‚root æŒ‡å‘ Hexo ç”Ÿæˆçš„ public ç›®å½•ï¼Œindex å£°æ˜é»˜è®¤é¦–é¡µæ–‡ä»¶ã€‚\nå¯ç”¨ç«™ç‚¹é…ç½®ï¼šå°†é…ç½®æ–‡ä»¶é“¾æ¥åˆ° sites-enabledï¼š\nln -s /etc/nginx/sites-available/hexo.conf /etc/nginx/sites-enabled/nginx -t  # æµ‹è¯•é…ç½®è¯­æ³•æ­£ç¡®æ€§systemctl reload nginx  # é‡æ–°åŠ è½½ Nginx é…ç½®\næ‰§è¡Œä»¥ä¸Šå‘½ä»¤åï¼Œåšå®¢ç«™ç‚¹å³å¯é€šè¿‡åŸŸåè®¿é—®ã€‚å¦‚æœæš‚æ—¶æ²¡æœ‰åŸŸåï¼Œä½¿ç”¨æœåŠ¡å™¨ IP ä¹Ÿèƒ½è®¿é—®ï¼ˆæ­¤æ—¶å¯å°† server_name æ”¹ä¸º _ é€šé…ç¬¦ï¼‰ã€‚\né…ç½® HTTPSï¼ˆå¯é€‰ï¼‰ï¼š\nå»ºè®®ä¸ºåšå®¢é…ç½® SSL è¯ä¹¦ã€‚å¯ä»¥ä½¿ç”¨ Certbot è·å– Letâ€™s Encrypt å…è´¹è¯ä¹¦ã€‚æ­¥éª¤å¦‚ä¸‹ï¼š\napt-get install -y certbot python3-certbot-nginx  certbot --nginx -d example.com -d www.example.com\næŒ‰æç¤ºå®ŒæˆåŸŸåæ‰€æœ‰æƒéªŒè¯åï¼ŒCertbot ä¼šè‡ªåŠ¨ç”Ÿæˆè¯ä¹¦å¹¶é…ç½® Nginx å°†ç«™ç‚¹å‡çº§ä¸º HTTPSã€‚\nHexo Deploy è‡ªåŠ¨éƒ¨ç½²ï¼š\næ¯æ¬¡æ›´æ–°å†…å®¹åéƒ½è¦é‡æ–°ç”Ÿæˆå¹¶ä¸Šä¼ æ–‡ä»¶ï¼Œä½¿ç”¨ Hexo çš„éƒ¨ç½²åŠŸèƒ½å¯ä»¥ç®€åŒ–æµç¨‹ã€‚Hexo æ”¯æŒå¤šç§éƒ¨ç½²æ–¹å¼ï¼Œå…¶ä¸­ Git éƒ¨ç½²æ˜¯å¸¸ç”¨æ–¹æ¡ˆä¹‹ä¸€ã€‚åŸºæœ¬æ€è·¯æ˜¯åˆ©ç”¨ Git æŠŠç”Ÿæˆçš„é™æ€æ–‡ä»¶æ¨é€åˆ°æœåŠ¡å™¨æˆ–æ‰˜ç®¡æœåŠ¡ã€‚æ¦‚æ‹¬äº†è¿™ç§æ€è·¯ï¼šåœ¨æœåŠ¡å™¨ä¸Šå®‰è£… Nginx æä¾›ç½‘é¡µæœåŠ¡ï¼Œç”¨ Git å®ç°ä»£ç ä¸Šä¼ è‡ªåŠ¨åŒ–ï¼Œè¿™æ ·æœ¬åœ°æ‰§è¡Œä¸€æ¬¡ hexo dï¼ˆdeployï¼‰å°±èƒ½è®©ç½‘ç«™æ›´æ–°ã€‚\næ¨é€åˆ°è¿œç¨‹æ‰˜ç®¡ï¼š\nå°†åšå®¢é™æ€æ–‡ä»¶éƒ¨ç½²åˆ°åƒ GitHub Pagesã€Coding Pages è¿™ç±»å¹³å°ã€‚è¿™éœ€è¦åœ¨ _config.yml ä¸­é…ç½®ï¼š\ndeploy:  type: git  repo: https://github.com/yourname/yourrepo.git  branch: main  # æˆ– gh-pages åˆ†æ”¯ç­‰\nç„¶åè¿è¡Œ hexo generate &amp;&amp; hexo deployï¼ŒHexo ä¼šæŠŠ public æ–‡ä»¶å¤¹å†…å®¹æ¨é€åˆ°æŒ‡å®šä»“åº“çš„åˆ†æ”¯ã€‚å¯¹äº GitHub Pagesï¼Œå¦‚æœ repo æ˜¯ yourname.github.io åˆ™ç›´æ¥ç”¨ä¸»åˆ†æ”¯ï¼›è‹¥æ˜¯é¡¹ç›®ä»“åº“ï¼Œå¯ä»¥ç”¨ gh-pages åˆ†æ”¯æ‰˜ç®¡ã€‚\néƒ¨ç½²åï¼ŒGitHub Pages æœåŠ¡å°†æ‰˜ç®¡ä½ çš„é™æ€åšå®¢ï¼Œä½ å¯ä»¥ä½¿ç”¨è‡ªå®šä¹‰åŸŸåç»‘å®šå®ƒã€‚ä½†æ³¨æ„ï¼šå¦‚æœä½ å¸Œæœ›åšå®¢è¿è¡Œåœ¨è‡ªå·±çš„æœåŠ¡å™¨ä¸Šï¼ˆè€Œéç¬¬ä¸‰æ–¹å¹³å°ï¼‰ï¼Œåˆ™è¿™ç§æ–¹æ¡ˆä¸æ¶‰åŠä½ çš„æœåŠ¡å™¨ Nginxã€‚å¦å¤–ï¼Œå›½å†…è®¿é—® GitHub Pages å¯èƒ½ä¸ç¨³å®šï¼Œéœ€ç»“åˆå®é™…æƒ…å†µè€ƒè™‘ã€‚\næ¨é€åˆ°è‡ªå·±æœåŠ¡å™¨ï¼š\næ­å»ºå±äºè‡ªå·±çš„ Git è‡ªåŠ¨åŒ–éƒ¨ç½²æµç¨‹ï¼Œå®ç°å°†æœ¬åœ°æ›´æ–°ä¸€é”®éƒ¨ç½²åˆ°æœåŠ¡å™¨ã€‚æ­¥éª¤å¦‚ä¸‹ï¼š\n\nåœ¨æœåŠ¡å™¨ä¸Šåˆ›å»ºä¸€ä¸ªè£¸ä»“åº“ï¼ˆbare repositoryï¼‰ï¼Œç”¨äºæ¥æ”¶æ¨é€ã€‚ä¾‹å¦‚åˆ›å»º /home/git/hexo.git è£¸ä»“åº“ã€‚\nç¼–å†™ Git é’©å­ï¼ˆpost-receiveï¼‰ï¼šè£¸ä»“åº“çš„ hooks/post-receive è„šæœ¬ä¼šåœ¨æ”¶åˆ°æ–°æ¨é€æ—¶æ‰§è¡Œã€‚è„šæœ¬å†…å®¹å¯ä»¥æ˜¯å°†æ›´æ–°çš„å†…å®¹æ£€å‡ºåˆ° Nginx ç›®å½•ã€‚ä¾‹å¦‚ï¼š\nGIT_WORK_TREE=/var/www/hexo git checkout -f  # å°†ä»“åº“å†…å®¹å¼ºåˆ¶æ£€å‡ºåˆ° /var/www/hexocd /var/www/hexo &amp;&amp; hexo generate            # ï¼ˆè‹¥æ¨é€çš„æ˜¯æºç è€Œéç”Ÿæˆæ–‡ä»¶ï¼Œåˆ™éœ€è¦åœ¨æœåŠ¡å™¨æ‰§è¡Œç”Ÿæˆï¼‰\nç»™è„šæœ¬å¯æ‰§è¡Œæƒé™ï¼š\nchmod +x post-receive\nè¿™æ ·ï¼Œæ¯å½“æ¨é€åˆ°è¯¥ä»“åº“æ—¶ï¼Œå®ƒå°±ä¼šæŠŠæ›´æ–°éƒ¨ç½²åˆ°åšå®¢ç›®å½•å¹¶ç”Ÿæˆæœ€æ–°é¡µé¢ã€‚\næœ¬åœ° Hexo é…ç½®éƒ¨ç½²ï¼šå°† _config.yml ä¸­çš„ deploy.repo è®¾ç½®ä¸ºä¸Šè¿°è£¸ä»“åº“çš„åœ°å€ï¼ˆé€šè¿‡ SSHï¼‰ã€‚ä¾‹å¦‚ï¼š\ndeploy:  type: git  repo: ssh://[emailÂ protected]/home/git/hexo.git  branch: master\nç„¶åæ‰§è¡Œ hexo clean &amp;&amp; hexo deployã€‚Hexo ä¼šé€šè¿‡ Git æ¨é€åˆ°æœåŠ¡å™¨ä»“åº“ï¼Œè§¦å‘ post-receive é’©å­ï¼Œå®ç°è‡ªåŠ¨éƒ¨ç½²ã€‚å®Œæˆåï¼ŒNginx ä¼šç«‹åˆ»æä¾›æ–°å†…å®¹æœåŠ¡ï¼Œæ— éœ€æ‰‹åŠ¨ç™»å½•æœåŠ¡å™¨æ“ä½œã€‚\n\né€šè¿‡è¿™ç§æ–¹æ¡ˆï¼Œå¯ä»¥åœ¨æœ¬åœ°å†™å¥½æ–‡ç« åä¸€æ¡å‘½ä»¤å®Œæˆéƒ¨ç½²ï¼Œéå¸¸é«˜æ•ˆã€‚è®¸å¤šå¼€æºåšå®¢éƒ¨ç½²è„šæœ¬å’Œå·¥å…·ä¹Ÿæ˜¯åŸºäºç±»ä¼¼åŸç†å®ç°çš„ã€‚åˆæ¬¡è®¾ç½®å¯èƒ½ç¨æ˜¾ç¹çï¼Œä½†ä¸€æ—¦é…ç½®æˆåŠŸï¼Œæ—¥å¸¸æ›´æ–°å°†éå¸¸ä¾¿æ·ã€‚\næç¤ºï¼š ä½¿ç”¨ Git è‡ªåŠ¨éƒ¨ç½²éœ€ç¡®ä¿æœåŠ¡å™¨å¼€æ”¾ Git æ‰€ç”¨çš„ SSH ç«¯å£ï¼ˆé»˜è®¤ä¸º 22ï¼‰ï¼Œå¹¶é…ç½®å¥½å…¬é’¥å…å¯†ç™»å½•ï¼Œä»¥ä¾¿ Hexo åœ¨æœ¬åœ°èƒ½é¡ºåˆ©æ¨é€åˆ°æœåŠ¡å™¨ã€‚å¦‚æœä½ çš„æœåŠ¡å™¨ SSH ç«¯å£ä¸æ˜¯ 22ï¼Œå¯åœ¨éƒ¨ç½²é…ç½®ä¸­åŠ å…¥ç«¯å£å·æˆ–åœ¨ .ssh/config ä¸­é…ç½®åˆ«åã€‚å¯¹äºä¸ç†Ÿæ‚‰ Git é’©å­çš„æ–°æ‰‹ï¼Œä¹Ÿå¯ä»¥è€ƒè™‘ä½¿ç”¨ç®€å•çš„ rsync è„šæœ¬åŒæ­¥æ–‡ä»¶æˆ–å€ŸåŠ© CI å¹³å°å®ç°éƒ¨ç½²ï¼Œä½†åŸç†ç±»ä¼¼ã€‚\n\n6. ç»´æŠ¤ä¸ä¼˜åŒ–\nåšå®¢æ­å»ºå®Œæˆå¹¶ä¸æ„å‘³ç€ä¸€åŠ³æ°¸é€¸ï¼Œå®šæœŸçš„ç»´æŠ¤å’Œä¼˜åŒ–èƒ½ä¿è¯åšå®¢ç¨³å®šã€å®‰å…¨ï¼Œå¹¶æŒç»­æå‡ç”¨æˆ·ä½“éªŒã€‚\n\næ’ä»¶æ‰©å±•ï¼š Hexo æ‹¥æœ‰ä¸°å¯Œçš„æ’ä»¶ç”Ÿæ€ï¼Œå¯æ ¹æ®éœ€è¦å®‰è£…æ’ä»¶ä»¥å¢å¼ºåŠŸèƒ½ã€‚\nå¤‡ä»½ä¸ç‰ˆæœ¬æ§åˆ¶ï¼š ä½¿ç”¨ Git ç®¡ç†åšå®¢æºç ï¼Œå®šæœŸå¤‡ä»½ã€‚\næ›´æ–°ä¸å‡çº§ï¼š å…³æ³¨ Hexo çš„ç‰ˆæœ¬æ›´æ–°ã€æ’ä»¶æ›´æ–°ç­‰ã€‚\n\n","categories":["å…¶å®ƒ"]},{"title":"InstructCoder: Instruction Tuning Large Language Models for Code Editing","url":"/2025/11/22/paper/InstructCoder/","content":"\n\nä¸€ã€è®ºæ–‡é€Ÿè§ˆ\nInstructCoder å…³æ³¨çš„æ˜¯ã€Œæ ¹æ®è‡ªç„¶è¯­è¨€æŒ‡ä»¤å¯¹ç°æœ‰ä»£ç è¿›è¡Œä¿®æ”¹ã€è¿™ä¸€ç±»ä»£ç ç¼–è¾‘ä»»åŠ¡ï¼Œè€Œä¸æ˜¯ä»é›¶ç”Ÿæˆä»£ç ã€‚ä½œè€…å‘ç°ï¼Œå³ä¾¿æ˜¯ GPT-4 çº§åˆ«çš„æ¨¡å‹ï¼Œåœ¨ä¸¥æ ¼çš„æ‰§è¡Œæµ‹è¯•ä¸‹ä¹Ÿç»å¸¸æ— æ³•æ­£ç¡®å®Œæˆç¼–è¾‘ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡æ„å»ºäº†ä¸€ä¸ªæ–°çš„æ‰§è¡Œå¼è¯„æµ‹åŸºå‡† EditEvalï¼Œå¹¶æå‡ºä¸“é—¨ä¸ºä»£ç ç¼–è¾‘è®¾è®¡çš„æŒ‡ä»¤å¾®è°ƒæ•°æ®é›† InstructCoderï¼ŒåŒ…å« 11 ä¸‡+ çœŸå®åœºæ™¯é£æ ¼çš„ä»£ç ç¼–è¾‘æ ·æœ¬ã€‚å®éªŒè¡¨æ˜ï¼šåœ¨ LLaMA / BLOOM ç­‰å¼€æºæ¨¡å‹ä¸Šä½¿ç”¨ LoRA æ–¹å¼ï¼ŒåŸºäº InstructCoder è¿›è¡ŒæŒ‡ä»¤å¾®è°ƒåï¼Œæ¨¡å‹åœ¨ EditEval ä¸Šçš„å‡†ç¡®ç‡å¯ä»¥ä»ä¸ªä½æ•°ç›´æ¥æå‡åˆ°å‡ åä¸ªç™¾åˆ†ç‚¹ï¼Œç”šè‡³è®© Code LLaMA-13B çš„è¡¨ç°æ¥è¿‘ ChatGPTã€‚(arXiv)\näºŒã€è®ºæ–‡ç»“æ„\n\nå¼•è¨€ä¸åŠ¨æœº è¯´æ˜ä»£ç ç¼–è¾‘ä¸ä»£ç è¡¥å…¨çš„å·®å¼‚ï¼ŒæŒ‡å‡ºå½“å‰ç¼ºä¹é’ˆå¯¹ã€Œè‡ªç„¶è¯­è¨€æŒ‡ä»¤ + ä»£ç ç¼–è¾‘ã€çš„ç³»ç»Ÿæ€§æ•°æ®ä¸è¯„æµ‹ï¼Œç»™å‡º InstructCoder ä¸ EditEval çš„æ•´ä½“ç›®æ ‡ã€‚(arXiv)\nç›¸å…³å·¥ä½œ å›é¡¾é€šç”¨ LLMã€ä»£ç  LLMã€æŒ‡ä»¤å¾®è°ƒã€è‡ªæŒ‡ä»¤ï¼ˆSelf-Instructï¼‰å’Œå·²æœ‰çš„ä»£ç ä»»åŠ¡æ•°æ®é›†ï¼ˆå¦‚ HumanEvalã€MBPPã€PIE ç­‰ï¼‰ï¼Œå¯¹æ¯”å®ƒä»¬åœ¨ã€Œæ˜¯å¦é¢å‘ä»£ç ç¼–è¾‘ã€ã€Œæ˜¯å¦æ‰§è¡Œè¯„æµ‹ã€ç­‰ç»´åº¦ä¸Šçš„ä¸è¶³ï¼Œä¸ºæœ¬æ–‡å®šä½åšé“ºå«ã€‚(arXiv)\nEditEvalï¼šä»£ç ç¼–è¾‘è¯„æµ‹åŸºå‡† ä»‹ç» EditEval çš„æ„é€ æ–¹å¼ï¼šä» GitHub commitsã€MBPPã€HumanEval ä¸­æŠ½å–ä»£ç ï¼Œå¯¹æ¯ä¸ªæ ·æœ¬æ„é€ è‡ªç„¶è¯­è¨€ç¼–è¾‘æŒ‡ä»¤å’Œã€Œç¼–è¾‘åçš„å‚è€ƒå®ç°ã€ï¼Œå¹¶é…å¥—è‡ªåŠ¨æµ‹è¯•ç”¨ä¾‹ï¼Œç”¨ã€Œæ˜¯å¦é€šè¿‡æ‰€æœ‰æµ‹è¯•ã€ä½œä¸ºå‡†ç¡®ç‡æŒ‡æ ‡ã€‚è¿™éƒ¨åˆ†é€‚åˆå¸Œæœ›è‡ªå·±å¤ç°è¯„æµ‹ç¯å¢ƒã€æ‰©å±•æ–°æ¨¡å‹æ—¶é‡ç‚¹é˜…è¯»ã€‚(arXiv)\nInstructCoderï¼šæŒ‡ä»¤å¾®è°ƒæ•°æ®æ„å»ºæµç¨‹ è¯¦ç»†è¯´æ˜ä» GitHub commits æŠ½å– seed æ•°æ®ã€ç”¨ ChatGPT è¿›è¡Œè‡ªæŒ‡ä»¤æ‰©å±•ã€å¼•å…¥ã€Œåœºæ™¯æ¡ä»¶ç”Ÿæˆã€ã€ä»¥åŠç”¨ ROUGE-L + MinHash/LSH åšå»é‡å’Œæ¸…æ´—çš„å®Œæ•´æµæ°´çº¿ã€‚è¿™éƒ¨åˆ†å¯¹åšæ•°æ®å·¥ç¨‹ã€æƒ³ä»¿ç…§æ„å»ºè‡ªå®¶ä»£ç ç¼–è¾‘æ•°æ®çš„è¯»è€…éå¸¸å…³é”®ã€‚(arXiv)\næ•°æ®åˆ†æ ä»ä»»åŠ¡å¤šæ ·æ€§ï¼ˆintent / verbï¼‰ã€åœºæ™¯å¤šæ ·æ€§ã€å¤æ‚åº¦ï¼ˆç¼–è¾‘è¡Œæ•°ä¸ç¼–è¾‘æ¯”ä¾‹ï¼‰ã€ä»¥åŠäººå·¥è´¨æ£€ç»“æœç­‰è§’åº¦åˆ†æ InstructCoder çš„æ•°æ®ç‰¹æ€§ã€‚è¿™ä¸€èŠ‚å¸®åŠ©ä½ åˆ¤æ–­ã€Œè¿™ç±»æ•°æ®æ˜¯å¦é€‚åˆç›´æ¥æ‹¿æ¥å¾®è°ƒã€ä»¥åŠã€Œéœ€è¦ä¸è¦å†é¢å¤–è¡¥å……è‡ªå·±çš„åœºæ™¯ã€ã€‚(arXiv)\nå®éªŒä¸ç»“æœ è¯´æ˜ä½¿ç”¨çš„åŸºç¡€æ¨¡å‹å®¶æ—ï¼ˆLLaMA / LLaMA-2 / Code LLaMA / BLOOM ç­‰ï¼‰ã€LoRA å¾®è°ƒè®¾ç½®ã€åŸºçº¿æ¨¡å‹ï¼ˆChatGPTã€GPT-4ã€Alpacaã€CodeAlpaca ç­‰ï¼‰ï¼Œå¹¶ç»™å‡ºåœ¨ EditEval ä¸Šã€Œå¾®è°ƒå‰/åã€çš„å‡†ç¡®ç‡å¯¹æ¯”ã€æ•°æ®è§„æ¨¡ç¼©æ”¾å®éªŒã€ä¸åŒç¼–è¾‘æ¯”ä¾‹ä¸‹çš„è¡¨ç°ã€‚é€‚åˆå¸Œæœ›çœ‹åˆ°ã€ŒæŠ•å…¥å¤šå°‘ç®—å€¼å¾—ã€çš„å·¥ç¨‹åŒå­¦é˜…è¯»ã€‚(arXiv)\nç»“è®ºä¸å±€é™ æ€»ç»“ InstructCoder + EditEval çš„è´¡çŒ®ï¼Œå¹¶å¦é™ˆå½“å‰åªè¦†ç›– Python å•æ–‡ä»¶ã€å°è§„æ¨¡ç¼–è¾‘ã€ä¸å«å¤šæ–‡ä»¶ä¸Šä¸‹æ–‡ç­‰å±€é™ï¼Œä¸ºåç»­æ‰©å±•æŒ‡æ˜æ–¹å‘ã€‚(arXiv)\n\n\næ ¸å¿ƒæ€æƒ³ï¼šé’ˆå¯¹ã€Œè‡ªç„¶è¯­è¨€æŒ‡ä»¤é©±åŠ¨çš„ä»£ç ç¼–è¾‘ã€è¿™ä¸€å®é™…å¼€å‘åœºæ™¯ï¼ŒInstructCoder é€šè¿‡è‡ªæŒ‡ä»¤ç”Ÿæˆ + åœºæ™¯æ¡ä»¶ç”Ÿæˆæ„å»ºå‡ºé«˜è´¨é‡æŒ‡ä»¤å¾®è°ƒæ•°æ®ï¼Œå¹¶é…å¥—æ‰§è¡Œå¼è¯„æµ‹åŸºå‡† EditEvalï¼Œç³»ç»ŸéªŒè¯äº†åœ¨åˆé€‚çš„æ•°æ®å’Œè½»é‡å¾®è°ƒç­–ç•¥ä¸‹ï¼Œå¼€æºä»£ç æ¨¡å‹çš„ä»£ç ç¼–è¾‘èƒ½åŠ›å¯ä»¥è¢«å¤§å¹…æ¿€å‘ï¼Œé€¼è¿‘å•†ä¸šé—­æºæ¨¡å‹çš„æ°´å¹³ã€‚(arXiv)\n\n\nä¸‰ã€æ–¹æ³•ä¸ç³»ç»Ÿè®¾è®¡\nInstructCoder çš„æ ¸å¿ƒæ€è·¯å¯ä»¥æ¦‚æ‹¬ä¸ºï¼šå…ˆé€ ä¸€ä¸ªä¸¥æ ¼ã€æ‰§è¡Œé©±åŠ¨çš„è¯„æµ‹åŸºå‡† EditEvalï¼Œç„¶åå›´ç»•è¿™ä¸ªè¯„æµ‹ç›®æ ‡ï¼Œç”¨è‡ªæŒ‡ä»¤æ–¹æ³•æ„å»ºå¤§é‡é«˜å¤šæ ·æ€§ã€é«˜å¤æ‚åº¦çš„ä»£ç ç¼–è¾‘æŒ‡ä»¤æ•°æ®ï¼Œç”¨ LoRA æ–¹å¼å¯¹ç°æœ‰ä»£ç  LLM åšä¸“é—¨çš„æŒ‡ä»¤å¾®è°ƒã€‚ä»å·¥ç¨‹è§†è§’çœ‹ï¼Œå®ƒæ›´åƒæ˜¯ã€Œä¸€ä¸ªæ•°æ®ä¸è®­ç»ƒæµæ°´çº¿è®¾è®¡ã€ï¼Œè€Œä¸æ˜¯æ–°æ¨¡å‹ç»“æ„ã€‚(arXiv)\n3.0 è¦è§£å†³çš„å­é—®é¢˜\n\nå­é—®é¢˜ 1ï¼šå¦‚ä½•æ„é€ ä¸€ä¸ªæ‰§è¡Œå¯éªŒè¯ã€è¦†ç›–å¤šç§ä»£ç ç¼–è¾‘åœºæ™¯çš„è¯„æµ‹åŸºå‡†ï¼Œè€Œä¸æ˜¯åªçœ‹ token çº§åˆ«ç›¸ä¼¼åº¦ï¼Ÿ\nå­é—®é¢˜ 2ï¼šåœ¨æ²¡æœ‰å¤§é‡äººå·¥æ ‡æ³¨çš„å‰æä¸‹ï¼Œå¦‚ä½•æ‰¹é‡è·å¾—ã€Œè‡ªç„¶è¯­è¨€ç¼–è¾‘æŒ‡ä»¤ + è¾“å…¥ä»£ç  + ç¼–è¾‘åä»£ç ã€ä¸‰å…ƒç»„ï¼Ÿ\nå­é—®é¢˜ 3ï¼šå¦‚ä½•ä¿è¯è‡ªåŠ¨ç”Ÿæˆæ•°æ®çš„å¤šæ ·æ€§ä¸æ­£ç¡®æ€§ï¼Œé¿å…æ¨¡å‹å­¦åˆ°ä¸€å †ã€Œæ”¹å˜é‡åã€ã€ŒåŠ  printã€å¼çš„å»‰ä»·ç¼–è¾‘æ¨¡å¼ï¼Ÿ\nå­é—®é¢˜ 4ï¼šå¦‚ä½•ç”¨è¾ƒä½è®¡ç®—æˆæœ¬ï¼Œå°†è¿™ç±»æ•°æ®æœ‰æ•ˆæ³¨å…¥åˆ°ç°æœ‰ä»£ç  LLMï¼Œè€Œä¸å¿…åšä»å¤´ full finetuneï¼Ÿ\n\n3.1 æ ¸å¿ƒæ¨¡å—ä¸€è§ˆ\n\nEditEval æ„é€ æ¨¡å—ï¼šä» GitHubã€MBPPã€HumanEval æŠ½å–ä»£ç ç‰‡æ®µï¼Œäººå·¥ç¼–å†™/æ¶¦è‰²è‡ªç„¶è¯­è¨€ç¼–è¾‘æŒ‡ä»¤ä¸å‚è€ƒç­”æ¡ˆï¼ŒåŠ ä¸Šè‡ªåŠ¨æµ‹è¯•ç”¨ä¾‹ï¼Œå½¢æˆæ‰§è¡Œå¼è¯„æµ‹ä»»åŠ¡ã€‚å¯¹åº”å­é—®é¢˜ 1ã€‚(arXiv)\nSeed æ•°æ®é‡‡é›†æ¨¡å—ï¼šåŸºäº BigQuery æœé›† Python ä»“åº“ä¸­çš„ commitï¼Œç­›é€‰å‡ºå•æ–‡ä»¶ã€å•ä»£ç å—å˜æ›´çš„è®°å½•ï¼Œç”¨ Codex è¾…åŠ©ä¿®æ­£å«ç³Šçš„ commit messageï¼Œæœ€ç»ˆå¾—åˆ°çº¦ 634 æ¡é«˜è´¨é‡åˆå§‹ç¼–è¾‘æ ·æœ¬ï¼Œå†åŠ ä¸Šä¸€æ‰¹äººå·¥ç­›é€‰çš„ ChatGPT ç”Ÿæˆæ ·æœ¬ã€‚å¯¹åº”å­é—®é¢˜ 2ã€‚(arXiv)\nSelf-Instruct å¼æŒ‡ä»¤è‡ªä¸¾æ¨¡å—ï¼šåœ¨æ¯ä¸€è½®è‡ªä¸¾ä¸­ï¼Œä» seed ä¸å·²æœ‰ç”Ÿæˆæ ·æœ¬ä¸­é‡‡æ ·è‹¥å¹²æŒ‡ä»¤ï¼Œé€šè¿‡ few-shot prompt è®© ChatGPT ç”Ÿæˆæ–°æŒ‡ä»¤ï¼Œé€æ­¥æ‰©å±•ä»»åŠ¡ç©ºé—´ã€‚å¯¹åº”å­é—®é¢˜ 2ã€3ã€‚(arXiv)\nåœºæ™¯æ¡ä»¶ä»£ç ç”Ÿæˆæ¨¡å—ï¼šå…ˆè®© LLM ç”Ÿæˆã€ŒçœŸå®ä¸–ç•Œåœºæ™¯ã€æè¿°ï¼Œå†åŸºäºåœºæ™¯ + æŒ‡ä»¤ç”Ÿæˆæˆå¯¹çš„è¾“å…¥/è¾“å‡ºä»£ç ï¼Œä½¿æ ·æœ¬åœ¨é¡¹ç›®ç»“æ„ã€å˜é‡å‘½åç­‰å±‚é¢æ›´è´´è¿‘çœŸå®å·¥ç¨‹ã€‚å¯¹åº”å­é—®é¢˜ 3ã€‚(arXiv)\nå»é‡ä¸è´¨é‡æ§åˆ¶æ¨¡å—ï¼šå¯¹æŒ‡ä»¤ä½¿ç”¨ ROUGE-L é˜ˆå€¼å»é‡ï¼Œå¯¹ä»£ç ä½¿ç”¨ MinHash + LSH æ§åˆ¶ Jaccard ç›¸ä¼¼åº¦ï¼Œå¹¶é€šè¿‡äººå·¥æŠ½æ ·æ£€éªŒæŒ‡ä»¤æœ‰æ•ˆæ€§ä¸è¾“å‡ºæ­£ç¡®æ€§ã€‚å¯¹åº”å­é—®é¢˜ 3ã€‚(arXiv)\nLoRA å¾®è°ƒæ¨¡å—ï¼šåœ¨ LLaMA / LLaMA-2 / Code LLaMA / BLOOM ç­‰åŸºç¡€æ¨¡å‹ä¸Šï¼Œä»…åœ¨ Q/K/V/O ç­‰çº¿æ€§å±‚ä¸Šæ’å…¥ LoRA ä½ç§©çŸ©é˜µï¼Œä»¥è¾ƒä½æ˜¾å­˜æˆæœ¬å®ŒæˆæŒ‡ä»¤å¾®è°ƒã€‚å¯¹åº”å­é—®é¢˜ 4ã€‚(arXiv)\n\n3.2 æ•°æ®æµä¸æ§åˆ¶æµ\næŒ‰ç…§ã€Œæ•°æ® â†’ ä»»åŠ¡ â†’ è®­ç»ƒ â†’ è¯„æµ‹ã€è§†è§’ï¼Œå¯ä»¥æŠŠæ•´ä¸ªæµç¨‹æ‹†æˆä»¥ä¸‹æ­¥éª¤ï¼š\n\nåŸå§‹ä»£ç æ•°æ®æ”¶é›†\n\n\n1.1 ä½¿ç”¨ BigQuery æŠ½å–æ»¡è¶³ã€ŒPythonã€æ˜Ÿæ ‡æ•°â‰¥100ã€å¼€æºè®¸å¯ã€çº¦æŸçš„ä»“åº“æäº¤è®°å½•ã€‚\n1.2 ä½¿ç”¨ git diff æ£€æµ‹å•æ–‡ä»¶ã€å•ä»£ç å—çš„ä¿®æ”¹ï¼Œè¿‡æ»¤æ‰å·¨å¤§æˆ–è·¨å¤šæ–‡ä»¶çš„ commitsã€‚(arXiv)\n\n\nSeed æ ·æœ¬æ„å»º\n\n\n2.1 å¯¹äºè¯­ä¹‰ä¸æ¸…çš„ commit messageï¼Œç”¨ Codex è‡ªåŠ¨ç”Ÿæˆæ›´ç²¾ç¡®çš„æè¿°ï¼Œç„¶åäººå·¥ä¿®è®¢ã€‚\n2.2 å°†ã€Œcommit message â†’ ç¼–è¾‘å‰ä»£ç  â†’ ç¼–è¾‘åä»£ç ã€ç»Ÿä¸€è½¬æ¢ä¸ºã€Œè‡ªç„¶è¯­è¨€æŒ‡ä»¤ â†’ è¾“å…¥ä»£ç  â†’ è¾“å‡ºä»£ç ã€å½¢å¼ã€‚\n2.3 é¢å¤–è®© ChatGPT ç”Ÿæˆä¸€æ‰¹é«˜è´¨é‡ç¼–è¾‘æ ·æœ¬ï¼Œç»äººå·¥ç­›é€‰ååŠ å…¥ seed é›†ã€‚(arXiv)\n\n\nè‡ªæŒ‡ä»¤æ‰©å±•\n\n\n3.1 åœ¨æ¯æ¬¡è¿­ä»£ä¸­ï¼ŒéšæœºæŠ½å–è‹¥å¹² seed æŒ‡ä»¤ä¸éƒ¨åˆ†å·²æœ‰ç”ŸæˆæŒ‡ä»¤ï¼Œæ„é€ æˆ few-shot æç¤ºã€‚\n3.2 ç”¨ ChatGPT ç”Ÿæˆæ–°çš„ä»£ç ç¼–è¾‘æŒ‡ä»¤ï¼Œè¦†ç›–å¤šç§ç¼–è¾‘æ„å›¾ï¼ˆæ·»åŠ åŠŸèƒ½ã€æ€§èƒ½ä¼˜åŒ–ã€é‡æ„ã€å¢åŠ æ³¨é‡Šç­‰ï¼‰ã€‚\n3.3 æŠŠæ–°æŒ‡ä»¤åŠ å…¥å€™é€‰æŒ‡ä»¤æ± ã€‚(arXiv)\n\n\nåœºæ™¯æ¡ä»¶æ ·æœ¬ç”Ÿæˆ\n\n\n4.1 å¯¹æ¯æ¡æŒ‡ä»¤ï¼Œè®© LLM å…ˆç”Ÿæˆè‹¥å¹²ã€Œåœºæ™¯æè¿°ã€ï¼ˆä¾‹å¦‚ï¼šweb åç«¯æœåŠ¡ã€å›¾åƒå¤„ç†è„šæœ¬ã€å®‰å…¨æ‰«æå·¥å…·ç­‰ï¼‰ã€‚\n4.2 éšæœºé€‰æ‹©ä¸€ä¸ªåœºæ™¯ï¼Œå† prompt LLM æ ¹æ®ã€Œåœºæ™¯ + æŒ‡ä»¤ã€ç”Ÿæˆè¾“å…¥/è¾“å‡ºä»£ç å¯¹ã€‚\n4.3 å¯¹ç”Ÿæˆæ ·æœ¬åšåŸºæœ¬åˆæ³•æ€§æ£€æŸ¥ï¼ˆèƒ½å¦è§£æã€æ˜¯å¦åŒ…å«æ ¸å¿ƒæ”¹åŠ¨ï¼‰ã€‚(arXiv)\n\n\nå»é‡ä¸è´¨é‡æ§åˆ¶\n\n\n5.1 å¯¹æŒ‡ä»¤æ–‡æœ¬ï¼šè®¡ç®— ROUGE-Lï¼Œç›¸ä¼¼åº¦è¶…è¿‡ 0.7 çš„æ ·æœ¬åªä¿ç•™ä¸€ä¸ªã€‚\n5.2 å¯¹ä»£ç ï¼šä½¿ç”¨ MinHash + LSH åšè¿‘é‡å¤æ£€æŸ¥ï¼ŒJaccard ç›¸ä¼¼åº¦è¶…è¿‡ 0.75 çš„æ ·æœ¬å»é‡ã€‚\n5.3 éšæœºæŠ½æ · 200 æ¡æ•°æ®ï¼Œè®©äººå·¥è¯„ä¼°ã€ŒæŒ‡ä»¤æ˜¯å¦æ¸…æ™°ã€ä¸ã€Œè¾“å‡ºæ˜¯å¦ç¬¦åˆæŒ‡ä»¤ã€ï¼Œä¿è¯æ•°æ®æ•´ä½“å¯é æ€§ã€‚(arXiv)\n\n\næ•°æ®åˆ’åˆ†ä¸è®­ç»ƒå‡†å¤‡\n\n\n6.1 å°†æœ€ç»ˆçº¦ 11.4 ä¸‡æ¡æ ·æœ¬æŒ‰ 95%/5% åˆ’åˆ†ä¸ºè®­ç»ƒé›†/éªŒè¯é›†ã€‚\n6.2 ç»Ÿä¸€æ ¼å¼ä¸ºã€Œè‡ªç„¶è¯­è¨€æŒ‡ä»¤ + è¾“å…¥ä»£ç ã€ä½œä¸ºä¸Šä¸‹æ–‡ï¼Œã€Œè¾“å‡ºä»£ç ã€ä½œä¸ºæ¨¡å‹éœ€è¦é¢„æµ‹çš„ç›®æ ‡åºåˆ—ã€‚\n\n\nLoRA æŒ‡ä»¤å¾®è°ƒ\n\n\n7.1 åœ¨é€‰å®šçš„åŸºç¡€æ¨¡å‹ï¼ˆå¦‚ Code LLaMA-13Bï¼‰ä¸Šï¼Œä¸º Q/K/V/O ç­‰å±‚æ’å…¥ LoRA ä½ç§©çŸ©é˜µï¼Œåªè®­ç»ƒæ–°å¢å‚æ•°ã€‚\n7.2 ä½¿ç”¨æ ‡å‡†è‡ªå›å½’æŸå¤±ï¼Œå¯¹è¾“å‡ºä»£ç  tokens è®¡ç®—äº¤å‰ç†µï¼Œè®­ç»ƒç›´åˆ°åœ¨éªŒè¯é›†ä¸Šæ”¶æ•›ã€‚(arXiv)\n\n\nEditEval è¯„æµ‹\n\n\n8.1 å¯¹æ¯ä¸ª EditEval ä»»åŠ¡ï¼ŒæŠŠã€ŒæŒ‡ä»¤ + è¾“å…¥ä»£ç ã€ç»™åˆ°æ¨¡å‹ï¼Œè®©å…¶ç”Ÿæˆå€™é€‰è¾“å‡ºä»£ç ã€‚\n8.2 å°†å€™é€‰ä»£ç ä¸å‚è€ƒå®ç°ä¸€èµ·ç¼–è¯‘/æ‰§è¡Œï¼Œä½¿ç”¨é¢„å…ˆç¼–å†™çš„å•å…ƒæµ‹è¯•åˆ¤æ–­æ˜¯å¦æ­£ç¡®ã€‚\n8.3 ç»Ÿè®¡æ‰€æœ‰ä»»åŠ¡ä¸Šé€šè¿‡ç‡ï¼Œå¾—åˆ° accuracy æŒ‡æ ‡ã€‚(arXiv)\n\n\næ‰©å±•å®éªŒä¸åˆ†æ\n\n\n9.1 åšã€Œè®­ç»ƒé›†è§„æ¨¡ç¼©æ”¾ã€å®éªŒï¼ˆ1% / 10% / 100%ï¼‰è§‚å¯Ÿæ€§èƒ½ä¸æ•°æ®é‡çš„å…³ç³»ã€‚\n9.2 æŒ‰ç¼–è¾‘æ¯”ä¾‹åˆ†æ¡¶ï¼Œç”¨ GPT-4 å¯¹ç¼–è¾‘è´¨é‡æ‰“åˆ†ï¼Œçœ‹ã€Œæ”¹åŠ¨å¤šå°‘è¡Œã€ä¸æ¨¡å‹éš¾åº¦çš„å…³ç³»ã€‚(arXiv)\n\n3.3 å…³é”®å‡è®¾ä¸é€‚ç”¨èŒƒå›´\n\nå•æ–‡ä»¶ã€å•ä»£ç å—ä¸Šä¸‹æ–‡è¶³ä»¥è¦†ç›–ä¸»è¦ç¼–è¾‘éœ€æ±‚\n\nå‡è®¾ï¼šå¾ˆå¤šæœ‰ä»£è¡¨æ€§çš„ä»£ç ç¼–è¾‘ä»»åŠ¡ï¼ˆå¢åŠ æ³¨é‡Šã€é‡æ„å‡½æ•°ã€ä¼˜åŒ–é€»è¾‘ï¼‰å¯ä»¥åœ¨å•æ–‡ä»¶ã€å•ç‰‡æ®µä¸Šä¸‹æ–‡ä¸­å®Œæˆã€‚\nå¯èƒ½å¤±æ•ˆçš„åœºæ™¯ï¼šæ¶‰åŠè·¨æ¨¡å—é‡æ„ã€å…¬å…±åº“ API è¿ç§»ã€å¤§å‹é‡æ„ï¼ˆä¾‹å¦‚ã€ŒæŠŠé¡¹ç›®çš„åŒæ­¥ IO æ¢æˆ asyncã€ï¼‰æ—¶ï¼Œå•æ–‡ä»¶è§†è§’ä¸å¤Ÿï¼Œæ¨¡å‹å¯èƒ½åœ¨å…¨å±€ä¸€è‡´æ€§ä¸Šå‡ºé”™ã€‚(arXiv)\n\nPython è¯­è¨€å…·æœ‰ä»£è¡¨æ€§ï¼Œå¯è¿ç§»åˆ°å…¶ä»–è¯­è¨€\n\nå‡è®¾ï¼šä»¥ Python ä¸ºä¸»æ„å»ºç¼–è¾‘æ•°æ®ï¼Œä¾ç„¶èƒ½ç»™æ¨¡å‹æä¾›é€šç”¨çš„ã€Œç¼–è¾‘èƒ½åŠ›æ¨¡å¼ã€ï¼Œä¹‹åå¯ä»¥è¿ç§»åˆ°å…¶ä»–è¯­è¨€ã€‚\nå¯èƒ½å¤±æ•ˆçš„åœºæ™¯ï¼šå¼ºç±»å‹è¯­è¨€ï¼ˆC++/Rust/Javaï¼‰ä¸­ï¼Œç±»å‹ç³»ç»Ÿä¸æ„å»ºç³»ç»Ÿçº¦æŸæ›´å¼ºï¼Œã€Œåªæ”¹ä¸€å¤„ã€å¯èƒ½åœ¨ç¼–è¯‘æœŸå°±æŒ‚ï¼Œè¿ç§»æ•ˆæœä¸ä¸€å®šå¥½ï¼Œéœ€è¦ç»“åˆè¯­è¨€ç‰¹æ€§è¿›ä¸€æ­¥å¾®è°ƒã€‚(arXiv)\n\nè‡ªæŒ‡ä»¤ç”Ÿæˆ + å¤§æ¨¡å‹åˆæˆæ•°æ®çš„è´¨é‡è¶³å¤Ÿé«˜\n\nå‡è®¾ï¼šåœ¨æœ‰ seed æ•°æ®çº¦æŸçš„å‰æä¸‹ï¼Œè®© ChatGPT è¿™ç±»æ¨¡å‹æ‰©å†™æŒ‡ä»¤ä¸æ ·æœ¬ï¼Œå¯ä»¥è·å¾—åˆ†å¸ƒä¸çœŸå®å¼€å‘ç›¸è¿‘çš„æ•°æ®ã€‚\nå¯èƒ½å¤±æ•ˆçš„åœºæ™¯ï¼šå¦‚æœç›®æ ‡åœºæ™¯ä¸­æœ‰å¤§é‡é¢†åŸŸç‰¹å®šæ¡†æ¶ï¼ˆé‡‘èé£æ§ DSLã€å†…éƒ¨æœåŠ¡æ¡†æ¶ç­‰ï¼‰æˆ–å¤æ‚éåŠŸèƒ½çº¦æŸï¼ˆæ€§èƒ½ SLAã€å®‰å…¨åˆè§„ï¼‰ï¼Œç¼ºä¹çœŸå®é¡¹ç›®ä»£ç ï¼Œä¼šå‡ºç° domain gapï¼Œå¾®è°ƒåæ¨¡å‹åœ¨çœŸå®åº“ä¸Šçš„è¡¨ç°å¯èƒ½å¤§å¹…ä¸‹é™ã€‚(arXiv)\n\nLoRA è¶³ä»¥å­¦ä¹ ä»£ç ç¼–è¾‘èƒ½åŠ›ï¼Œè€Œä¸ç ´ååŸºç¡€æ¨¡å‹çš„é€šç”¨èƒ½åŠ›\n\nå‡è®¾ï¼šåªåœ¨å°‘é‡å±‚ä¸Šæ’å…¥ LoRAï¼Œé’ˆå¯¹ä»£ç ç¼–è¾‘ä»»åŠ¡å¾®è°ƒï¼Œå¯ä»¥åœ¨ä¿ç•™åŸºç¡€æ¨¡å‹é€šç”¨ä»£ç ç†è§£/ç”Ÿæˆèƒ½åŠ›çš„åŒæ—¶ï¼Œå¢å¼ºç¼–è¾‘èƒ½åŠ›ã€‚\nå¯èƒ½å¤±æ•ˆï¼šå¦‚æœ InstructCoder çš„åˆ†å¸ƒä¸åŸå§‹é¢„è®­ç»ƒè¯­æ–™å·®å¼‚è¾ƒå¤§ï¼Œä¸”ç¼–è¾‘ä»»åŠ¡æœ‰æ˜æ˜¾ã€Œé£æ ¼åå·®ã€ï¼ˆæ¯”å¦‚å¤§é‡æ•™å­¦é£æ ¼æ³¨é‡Šï¼‰ï¼ŒLoRA å±‚å¯èƒ½ä¼šå¯¹è¾“å‡ºé£æ ¼é€ æˆæ˜æ˜¾åç§»ï¼Œåœ¨éƒ¨åˆ†è¯„æµ‹ä¸­è¢«è§†ä¸ºã€Œé€€åŒ–ã€ã€‚\n\næ‰§è¡Œå¼è¯„æµ‹å¯ä½œä¸ºä¸»è¦æŒ‡æ ‡è¡¡é‡ç¼–è¾‘è´¨é‡\n\nå‡è®¾ï¼šåªè¦æ–°ä»£ç é€šè¿‡äº†æ‰€æœ‰è‡ªåŠ¨æµ‹è¯•ï¼Œå°±å¯ä»¥è®¤ä¸ºç¼–è¾‘æ˜¯æ­£ç¡®çš„ã€‚\nå¯èƒ½å¤±æ•ˆï¼šæµ‹è¯•è¦†ç›–ä¸è¶³æ—¶ï¼Œæ¨¡å‹å¯èƒ½é€šè¿‡æ·»åŠ å¤šä½™ä»£ç æˆ–ç¡¬ç¼–ç  hack çš„æ–¹å¼é€šè¿‡æµ‹è¯•ï¼Œä½†ä»å·¥ç¨‹è§†è§’çœ‹å±äºã€Œç³Ÿç³•å®ç°ã€ã€‚\n\n\n3.4 æ•°å­¦å…¬å¼ä¸ç®—æ³•è§£è¯»\nè¿™ç¯‡å·¥ä½œæ•´ä½“ä¸Šæ˜¯ä¸€ä¸ªåç³»ç»Ÿä¸æ•°æ®å·¥ç¨‹çš„è®¾è®¡ï¼Œå¹¶æ²¡æœ‰å¤æ‚çš„ä¼˜åŒ–ç®—æ³•æˆ–æ–°ç›®æ ‡å‡½æ•°ã€‚æ–¹æ³•éƒ¨åˆ†çš„æ•°å­¦ç¬¦å·ä¸»è¦å‡ºç°åœ¨æ•°æ®åˆ†æä¸­ï¼Œç”¨äºå®šä¹‰ï¼š\n\nä¸åŒçš„è¡Œæ•°ï¼ˆdiffering linesï¼‰ï¼šåŸºäº difflib å¯¹è¾“å…¥/è¾“å‡ºä»£ç åšè¡Œçº§ diffï¼Œç»Ÿè®¡å‘ç”Ÿå˜åŒ–çš„è¡Œæ•°ã€‚\nç¼–è¾‘æ¯”ä¾‹ï¼ˆedit ratioï¼‰ï¼šç”¨ã€Œå‘ç”Ÿå˜åŒ–çš„è¡Œæ•°ã€ç›¸å¯¹æ•´ä¸ªä»£ç é•¿åº¦çš„æ¯”å€¼ï¼Œè¡¡é‡ä¸€æ¬¡ç¼–è¾‘çš„è§„æ¨¡å¤§å°ã€‚(arXiv)\n\nä½œè€…å¹¶æœªåœ¨æ­£æ–‡ä¸­ç»™å‡ºå¤æ‚æ¨å¯¼ï¼Œåªæ˜¯ç”¨è¿™äº›æŒ‡æ ‡åšç»Ÿè®¡åˆ†æï¼Œå› æ­¤è¿™é‡Œä¸å†å¼ºè¡Œå†™å‡ºå…¬å¼ç»†èŠ‚ï¼›ä»å·¥ç¨‹è§’åº¦ç†è§£ä¸ºï¼š\n\næŠŠæ¯ä¸ªæ ·æœ¬çš„ã€Œæ”¹åŠ¨è¡Œæ•°ã€å’Œã€Œæ”¹åŠ¨å æ¯”ã€å½“ä½œéš¾åº¦ proxyï¼Œç”¨æ¥è¡¡é‡ InstructCoder çš„ä»»åŠ¡å¤æ‚åº¦æ˜¯å¦è¿‡äºç®€å•æˆ–æç«¯ã€‚\n\nä¸å¸¸è§è®­ç»ƒæ ˆçš„å¯¹åº”å…³ç³»\n\nEditEval + InstructCoder çš„æ•´ä½“è®¾è®¡ï¼Œå¯¹åº”æˆ‘ä»¬è®­ç»ƒæ ˆä¸­çš„ï¼š\n\næ•°æ®æ‰“åŒ…ä¸é¢„å¤„ç†å±‚ï¼šä»ä»“åº“ commit / è„šæœ¬ / benchmark ä¸­æŠ½æ ·ã€æ¸…æ´—ã€æ„é€ æˆã€ŒæŒ‡ä»¤ + ä¸Šä¸‹æ–‡ + ç›®æ ‡ã€ä¸‰å…ƒç»„ã€‚\nä»»åŠ¡å®šä¹‰ä¸æŸå¤±å±‚ï¼šæŠŠã€Œç¼–è¾‘ã€å½’çº¦ä¸ºæ¡ä»¶ç”Ÿæˆä»»åŠ¡ P(code_after | instruction, code_before)ï¼Œç”¨æ ‡å‡†è‡ªå›å½’ loss è®­ç»ƒã€‚\nå‚æ•°é«˜æ•ˆåŒ–å±‚ï¼šç”¨ LoRA/adapter ç±»æ–¹æ³•å®ç°ä½æˆæœ¬æŒ‡ä»¤å¾®è°ƒã€‚\nè¯„æµ‹ä¸ç›‘æ§å±‚ï¼šé€šè¿‡æ‰§è¡Œæµ‹è¯•å’Œ GPT-4 æ‰“åˆ†ï¼Œç›‘æ§ edit accuracy ä¸ edit ratio ä¸Šçš„è¡¨ç°ã€‚\n\n\n\nå››ã€å»ºæ¨¡æ–¹å¼ä¸è¯„ä¼°æŒ‡æ ‡\n4.1 é—®é¢˜æ˜¯å¦‚ä½•å½¢å¼åŒ–çš„ï¼Ÿ\nè®ºæ–‡æŠŠä»£ç ç¼–è¾‘ä»»åŠ¡å½¢å¼åŒ–ä¸ºä¸€ä¸ªæ¡ä»¶ç”Ÿæˆé—®é¢˜ï¼šç»™å®šè‡ªç„¶è¯­è¨€æŒ‡ä»¤ (I) å’Œç°æœ‰ä»£ç ç‰‡æ®µ (C_{})ï¼Œæ¨¡å‹éœ€è¦ç”Ÿæˆä¿®æ”¹åçš„ä»£ç  (C_{})ã€‚ä¼˜åŒ–ç›®æ ‡å°±æ˜¯æœ€å¤§åŒ–åœ¨ InstructCoder æ•°æ®é›†ä¸Šçš„æ¡ä»¶å¯¹æ•°ä¼¼ç„¶ï¼š\n[ P(C_{} I, C_{})]\nå®ç°ä¸Šä½¿ç”¨æ ‡å‡†è‡ªå›å½’è¯­è¨€æ¨¡å‹ï¼Œè®­ç»ƒæ—¶æŠŠã€ŒæŒ‡ä»¤ + è¾“å…¥ä»£ç ã€æ‹¼åœ¨ä¸€èµ·ä½œä¸ºä¸Šä¸‹æ–‡ï¼Œè®©æ¨¡å‹åªåœ¨ã€Œè¾“å‡ºä»£ç ã€éƒ¨åˆ†ç´¯ç§¯ lossã€‚å¾®è°ƒç­–ç•¥é‡‡ç”¨ LoRAï¼Œåœ¨ Transformer çš„éƒ¨åˆ†çº¿æ€§å±‚ä¸Šæ’å…¥ä½ç§©çŸ©é˜µï¼Œä»…æ›´æ–°è¿™äº›æ–°å¢å‚æ•°ï¼Œä»¥æ˜¾è‘—é™ä½æ˜¾å­˜å’Œè®­ç»ƒæˆæœ¬ã€‚(arXiv)\nå»ºæ¨¡æ—¶çš„ç®€åŒ–åŒ…æ‹¬ï¼š\n\nä¸æ˜¾å¼å»ºæ¨¡ã€Œç¼–è¾‘æ“ä½œåºåˆ—ã€ï¼ˆå¦‚æ’å…¥/åˆ é™¤/æ›¿æ¢ï¼‰ï¼Œè€Œæ˜¯ç›´æ¥åœ¨ token åºåˆ—ç©ºé—´ç”Ÿæˆå®Œæ•´çš„ C_afterï¼›\nåªè€ƒè™‘å•è½®æŒ‡ä»¤ï¼Œæ²¡æœ‰å¯¹è¯å¼å¤šè½®æ¾„æ¸…ï¼›\nä¸å¯¹æ‰§è¡Œç»“æœæ˜¾å¼å»ºæ¨¡ï¼ˆä¾‹å¦‚ RL from executionï¼‰ï¼Œè€Œæ˜¯ç”¨æ‰§è¡Œæµ‹è¯•åªä½œä¸ºè¯„ä¼°ï¼Œä¸è¿›å…¥è®­ç»ƒé—­ç¯ã€‚\n\n4.2 æ ¸å¿ƒè¯„ä¼°æŒ‡æ ‡\nè®ºæ–‡ç”¨åˆ°çš„å…³é”®æŒ‡æ ‡åŒ…æ‹¬ï¼š(arXiv)\n\næ‰§è¡Œå‡†ç¡®ç‡ï¼ˆEditEval Accuracyï¼‰\n\nå®šä¹‰ï¼šåœ¨ EditEval ä¸Šï¼Œæ¨¡å‹ç”Ÿæˆçš„ä»£ç èƒ½é€šè¿‡æ‰€æœ‰å•å…ƒæµ‹è¯•çš„æ ·æœ¬æ¯”ä¾‹ã€‚\nå«ä¹‰ï¼šç›´æ¥è¡¡é‡ã€Œè¿™æ¬¡ç¼–è¾‘æ˜¯å¦çœŸçš„æŠŠåŠŸèƒ½æ”¹å¯¹äº†ã€ï¼Œæ˜¯æœ€è´´è¿‘å·¥ç¨‹å®è·µçš„æŒ‡æ ‡ã€‚\n\né›¶æ ·æœ¬ vs å¾®è°ƒå‰åå¢ç›Šï¼ˆÎ” Accuracyï¼‰\n\nå®šä¹‰ï¼šåŒä¸€ä¸ªåŸºç¡€æ¨¡å‹åœ¨ EditEval ä¸Šï¼Œå¾®è°ƒå‰åçš„å‡†ç¡®ç‡å·®å€¼ã€‚\nå«ä¹‰ï¼šè¡¡é‡ InstructCoder + LoRA çš„ã€Œçº¯å¾®è°ƒæ”¶ç›Šã€ï¼Œå¸®åŠ©æˆ‘ä»¬åˆ¤æ–­è¿™å¥—æ–¹æ¡ˆæ˜¯å¦å€¼å¾—åœ¨ç°æœ‰ Code LLM ä¸Šè½åœ°ã€‚\n\næ•°æ®è§„æ¨¡ç¼©æ”¾æ›²çº¿\n\nå®šä¹‰ï¼šåœ¨ä½¿ç”¨ 1% / 10% / 100% InstructCoder æ•°æ®å¾®è°ƒæ—¶ï¼Œåœ¨ EditEval ä¸Šçš„å‡†ç¡®ç‡æ›²çº¿ã€‚\nå«ä¹‰ï¼šå‘Šè¯‰æˆ‘ä»¬åœ¨è®­ç»ƒé¢„ç®—æœ‰é™çš„åœºæ™¯ä¸‹ï¼Œä½¿ç”¨å¤šå°‘æ•°æ®æœ€åˆ’ç®—ã€æ˜¯å¦å­˜åœ¨æ˜æ˜¾çš„æ”¶ç›Šé¥±å’Œç‚¹ã€‚\n\nç¼–è¾‘æ¯”ä¾‹åˆ†æ¡¶è¡¨ç°ï¼ˆby Edit Ratioï¼‰\n\nå®šä¹‰ï¼šæŒ‰ç¼–è¾‘æ¯”ä¾‹æŠŠéªŒè¯é›†æ ·æœ¬åˆ’åˆ†ä¸ºå¤šä¸ªåŒºé—´ï¼ˆå¦‚å°æ”¹åŠ¨/ä¸­ç­‰/å¤§æ”¹åŠ¨ï¼‰ï¼Œä½¿ç”¨ GPT-4 å¯¹ç”Ÿæˆç»“æœæ‰“åˆ†ï¼Œæ¯”è¾ƒä¸åŒ bucket ä¸Šçš„è¡¨ç°ã€‚\nå«ä¹‰ï¼šå¸®åŠ©åˆ†ææ¨¡å‹åœ¨ã€Œåªæ”¹å¾ˆå°‘å‡ è¡Œã€å’Œã€Œå¤§è§„æ¨¡ refactorã€æ—¶çš„ä¸åŒèƒ½åŠ›ï¼Œå¤šæ•°æ¨¡å‹åœ¨å°æ¯”ä¾‹ç¼–è¾‘ä¸Šå®¹æ˜“èµ°ã€Œç›´æ¥å¤åˆ¶è¾“å…¥ã€çš„æ·å¾„ã€‚\n\næ•°æ®è´¨é‡äººå·¥è¯„ä¼°é€šè¿‡ç‡\n\nå®šä¹‰ï¼šåœ¨äººç±»æŠ½æ ·è¯„å®¡ä¸­ï¼Œã€ŒæŒ‡ä»¤æœ‰æ•ˆã€å’Œã€Œè¾“å‡ºç¬¦åˆæŒ‡ä»¤ã€çš„æ¯”ä¾‹ã€‚\nå«ä¹‰ï¼šä¿è¯ InstructCoder æœ¬èº«ä¸æ˜¯ä¸€å †å™ªå£°ï¼Œå¦åˆ™åç»­æ‰€æœ‰å®éªŒç»“è®ºçš„å¯ä¿¡åº¦éƒ½ä¼šæ‰“æŠ˜ã€‚\n\n\n\näº”ã€ä¸»è¦å®éªŒå‘ç°\n\nå½“å‰é€šç”¨æŒ‡ä»¤æ¨¡å‹åœ¨ä»£ç ç¼–è¾‘ä¸Šè¿œæœªã€Œè§£å†³é—®é¢˜ã€ï¼šåœ¨ EditEval ä¸Šï¼ŒGPT-4 çš„å‡†ç¡®ç‡çº¦ 68.6%ï¼ŒChatGPT çº¦ 57.7%ï¼Œè€Œè®¸å¤šå¼€æºæŒ‡ä»¤æ¨¡å‹ï¼ˆAlpaca / LLaMA+CodeAlpacaï¼‰åœ¨ 7B / 13B è§„æ¨¡æ—¶ç”šè‡³ä½äº 20%ã€‚(arXiv)\nInstructCoder å¾®è°ƒå¸¦æ¥æ˜¾è‘—æ”¶ç›Šï¼šåœ¨ BLOOMã€LLaMAã€LLaMA-2ã€Code LLaMA ç­‰åŸºç¡€æ¨¡å‹ä¸Šï¼Œä½¿ç”¨ InstructCoder + LoRA å¾®è°ƒåï¼ŒEditEval å‡†ç¡®ç‡ä»ä¸ªä½æ•°ç›´æ¥æå‡åˆ° 20%â€“50% åŒºé—´ï¼Œå¢ç›Šå¹…åº¦å¸¸å¸¸åœ¨ 20â€“35 ä¸ªç™¾åˆ†ç‚¹ã€‚(arXiv)\nä»£ç é¢„è®­ç»ƒçš„é‡è¦æ€§éå¸¸çªå‡ºï¼šåŒæ ·æ˜¯å¾®è°ƒï¼ŒCode LLaMA ç³»åˆ—æ•´ä½“æ˜¾è‘—ä¼˜äº BLOOM / LLaMA-1 / LLaMA-2ï¼›Code LLaMA-13B + InstructCoder çš„è¡¨ç°è¾¾åˆ° 57.2%ï¼Œå·²ç»éå¸¸æ¥è¿‘ ChatGPTã€‚(arXiv)\næ•°æ®è§„æ¨¡è¶Šå¤§ï¼Œæ”¶ç›Šè¿‘ä¼¼éš log(æ ·æœ¬æ•°) çº¿æ€§å¢é•¿ï¼šåœ¨åªç”¨ 1% æ•°æ®å¾®è°ƒæ—¶ï¼Œæ¨¡å‹å°±èƒ½æ˜æ˜¾è¶…å‡ºé›¶æ ·æœ¬è¡¨ç°ï¼›å¢åŠ åˆ° 10%ã€100% æ—¶ï¼Œå‡†ç¡®ç‡æŒç»­æå‡ï¼Œå‘ˆç°å¹³æ»‘çš„ scaling æ›²çº¿ã€‚\nå°æ”¹åŠ¨åœºæ™¯åè€Œæ›´éš¾ï¼šåœ¨ GPT-4 è¾…åŠ©çš„è´¨é‡è¯„ä¼°ä¸­ï¼Œç¼–è¾‘æ¯”ä¾‹è¶Šå°ï¼Œæ¨¡å‹è¶Šå®¹æ˜“å·æ‡’ç›´æ¥å¤åˆ¶è¾“å…¥ï¼Œå¯¼è‡´ã€Œè¯¥æ”¹ä¸æ”¹ã€çš„é—®é¢˜ï¼›å¤§æ¨¡å‹åœ¨è¿™ä¸€ç‚¹ä¸Šæ¯”å°æ¨¡å‹æ›´é²æ£’ã€‚(arXiv)\n\n5.1 å…³é”®å›¾è¡¨è§£è¯»\n\nEditEval åŸºçº¿ç»“æœè¡¨ï¼ˆç±»ä¼¼ Table 1ï¼‰\n\nç°è±¡ï¼šGPT-4 &gt; GPT-4 Turbo &gt; ChatGPTï¼Œæ˜¾è‘—ä¼˜äºä¸€ä¼—å¼€æºæŒ‡ä»¤æ¨¡å‹ï¼›å¼€æºæ¨¡å‹ä¸­ï¼Œè§„æ¨¡è¶Šå¤§è¡¨ç°è¶Šå¥½ï¼Œä½†æ•´ä½“ä»ç„¶åä½ã€‚\næ”¯æ’‘ä¸»å¼ ï¼šè¯´æ˜ã€Œä»£ç ç¼–è¾‘ã€å¯¹æŒ‡ä»¤ç†è§£ + ä»£ç è¯­ä¹‰ç†è§£çš„è¦æ±‚å¾ˆé«˜ï¼Œç°æœ‰å¼€æºæŒ‡ä»¤æ¨¡å‹å°šæœªé’ˆå¯¹è¿™ç±»ä»»åŠ¡ä¼˜åŒ–ï¼Œå­˜åœ¨å·¨å¤§æå‡ç©ºé—´ã€‚(arXiv)\n\nInstructCoder å¾®è°ƒå‰åå¯¹æ¯”è¡¨ï¼ˆç±»ä¼¼ Table 3ï¼‰\n\nç°è±¡ï¼šä¾‹å¦‚ Code LLaMA-13B ä» 28.9% æå‡åˆ° 57.2%ï¼ŒBLOOM-7B ä» 1.0% æå‡åˆ° 19.6%ï¼ŒLLaMA-33B ä¹Ÿæœ‰ 30%+ çš„ç»å¯¹å¢ç›Šã€‚\næ”¯æ’‘ä¸»å¼ ï¼šè¯æ˜ä¸“é—¨çš„æŒ‡ä»¤å¾®è°ƒæ•°æ®å¯¹äºä»£ç ç¼–è¾‘èƒ½åŠ›è‡³å…³é‡è¦ï¼Œè€Œä¸”è·¨æ¨¡å‹å®¶æ—é€šç”¨ï¼Œåªè¦åŸºç¡€æ¨¡å‹æœ‰ä¸€å®šä»£ç é¢„è®­ç»ƒã€‚(arXiv)\n\næ•°æ®è§„æ¨¡ç¼©æ”¾å›¾ï¼ˆç±»ä¼¼ Figure 5ï¼‰\n\nç°è±¡ï¼š1% æ•°æ®å°±èƒ½å¸¦æ¥ç«‹ç«¿è§å½±çš„æ”¶ç›Šï¼Œ10% â†’ 100% ä¾ç„¶æœ‰ç¨³å®šæå‡ï¼Œä¸”åœ¨ log è½´ä¸Šè¿‘ä¼¼çº¿æ€§ã€‚\næ”¯æ’‘ä¸»å¼ ï¼šåªè¦æ ·æœ¬è´¨é‡é«˜ï¼Œé€‚é‡çš„æ•°æ®å°±èƒ½æ˜¾è‘—æ”¹å–„ä»£ç ç¼–è¾‘èƒ½åŠ›ï¼Œè€Œä¸”ç»§ç»­æ‰©å¢æ•°æ®ä»ç„¶æœ‰æ”¶ç›Šï¼Œä¸ºåç»­ã€Œæ›´å¤§è§„æ¨¡ä»£ç ç¼–è¾‘æŒ‡ä»¤è¯­æ–™ã€æä¾›æ­£å‘ä¿¡å·ã€‚(arXiv)\n\næŒ‰ç¼–è¾‘æ¯”ä¾‹åˆ†æ¡¶çš„è¡¨ç°å›¾ï¼ˆç±»ä¼¼ Figure 6ï¼‰\n\nç°è±¡ï¼šç¼–è¾‘æ¯”ä¾‹å¾ˆä½æ—¶å‡†ç¡®ç‡æ˜¾è‘—ä¸‹é™ï¼›ç¼–è¾‘æ¯”ä¾‹ä¸­é«˜æ—¶æ›´å®¹æ˜“è·å¾—é«˜åˆ†ã€‚\næ”¯æ’‘ä¸»å¼ ï¼šå•çº¯ä¼˜åŒ–ã€Œæ•´ä½“æ­£ç¡®ç‡ã€å¯èƒ½æ©ç›–ã€Œå°æ”¹åŠ¨ã€ä¸Šçš„å›°éš¾ï¼Œéœ€è¦åœ¨æ•°æ®æ„é€ å’ŒæŸå¤±è®¾è®¡ä¸Šæ›´æœ‰é’ˆå¯¹æ€§ï¼ˆæ¯”å¦‚å¢åŠ ã€Œåªæ”¹ä¸€ä¸¤è¡Œã€çš„é«˜æƒé‡æ ·æœ¬ï¼‰ã€‚(arXiv)\n\n\nç»“æœè§£è¯»ä¸è¾¹ç•Œ\næ•´ä½“æ¥çœ‹ï¼Œè®ºæ–‡åœ¨å¯æ§çš„å®éªŒæ¡ä»¶ä¸‹å±•ç¤ºäº†éå¸¸æ¸…æ™°çš„å› æœé“¾æ¡ï¼šé«˜è´¨é‡çš„ä»£ç ç¼–è¾‘æŒ‡ä»¤æ•°æ® + é€‚é…çš„æŒ‡ä»¤å¾®è°ƒç­–ç•¥ï¼Œç¡®å®èƒ½åœ¨æ‰§è¡Œå¼è¯„æµ‹ä¸Šæ˜¾è‘—æŠ¬å‡å¼€æºæ¨¡å‹çš„ä»£ç ç¼–è¾‘èƒ½åŠ›ã€‚ä¸è¿‡ï¼Œå®éªŒä»ç„¶ä¸»è¦é›†ä¸­åœ¨ï¼š\n\nPython å•è¯­è¨€ã€å•æ–‡ä»¶ã€å°åˆ°ä¸­ç­‰è§„æ¨¡çš„ç¼–è¾‘ï¼›\nç¦»çº¿æ‰¹å¤„ç†è¯„ä¼°ï¼Œè€Œä¸æ˜¯äº¤äº’å¼ IDE åœºæ™¯ï¼›\nä»¥ pass@1ã€æ‰§è¡Œé€šè¿‡ç‡ä¸ºä¸»çš„æŒ‡æ ‡ï¼Œå¯¹ä»£ç é£æ ¼ã€å¯ç»´æŠ¤æ€§ç­‰ç»´åº¦å…³æ³¨è¾ƒå°‘ã€‚\n\nåœ¨è¿™äº›è¾¹ç•Œå¤–ï¼ˆå¤šè¯­è¨€ã€å¤§é¡¹ç›®ã€å¤æ‚ refactorã€å¤šè½®å¯¹è¯å¼ç¼–è¾‘ã€å¼ºç±»å‹çº¦æŸç¯å¢ƒç­‰ï¼‰ï¼Œè¿˜éœ€è¦é¢å¤–å®éªŒä¸ç³»ç»ŸåŒ–å·¥ç¨‹å®è·µæ¥éªŒè¯æ³›åŒ–èƒ½åŠ›ã€‚\n\nå…­ã€ä¼˜ç‚¹ä¸å±€é™\näº®ç‚¹ï¼ˆStrengthsï¼‰\n\né—®é¢˜å®šä¹‰æ¸…æ™°ä¸”è´´è¿‘å®ç”¨ï¼šä¸“æ³¨äºã€Œè‡ªç„¶è¯­è¨€æŒ‡ä»¤é©±åŠ¨çš„ä»£ç ç¼–è¾‘ã€è¿™ä¸€å®é™…å¼€å‘ä¸­é«˜é¢‘ä½†é•¿æœŸè¢«å¿½è§†çš„ä»»åŠ¡ã€‚\nè¯„æµ‹è®¾è®¡æ‰å®ï¼šEditEval é‡‡ç”¨æ‰§è¡Œæµ‹è¯•ä½œä¸ºä¸»æŒ‡æ ‡ï¼Œé¿å…äº†ä»…å‡­æ–‡æœ¬ç›¸ä¼¼åº¦è¯„ä¼°ä»£ç è´¨é‡çš„åå·®ã€‚(arXiv)\næ•°æ®æ„å»ºç®¡çº¿å¯å¤ç”¨ï¼šç»“åˆ GitHub commitã€Self-Instructã€åœºæ™¯æ¡ä»¶ç”Ÿæˆå’Œå¤šé‡å»é‡ç­–ç•¥ï¼Œç»™å‡ºäº†ä¸€ä¸ªè¾ƒä¸ºå®Œæ•´çš„ã€Œé«˜è´¨é‡ä»£ç ç¼–è¾‘æŒ‡ä»¤æ•°æ®ã€æ„å»ºæ¨¡æ¿ã€‚(arXiv)\nå®éªŒç»“æœæœ‰æ˜ç¡®å·¥ç¨‹å«ä¹‰ï¼šå±•ç¤ºäº†ä¸åŒåŸºç¡€æ¨¡å‹å®¶æ—ã€ä¸åŒè§„æ¨¡ã€ä¸åŒæ•°æ®é‡ä¸‹çš„è¡¨ç°å·®å¼‚ï¼Œä¸ºå®é™…é€‰æ‹© base model å’Œæ•°æ®è§„æ¨¡æä¾›å‚è€ƒã€‚\nå…³æ³¨ error patternï¼šé€šè¿‡ edit ratio è§†è§’åˆ†ææ¨¡å‹è¡Œä¸ºï¼Œå‘ç°å°æ”¹åŠ¨åœºæ™¯æ›´å®¹æ˜“å‡ºé”™ï¼Œè¿™å¯¹åç»­æ”¹è¿›æŸå¤±å‡½æ•°å’Œæ•°æ®é‡‡æ ·ç­–ç•¥å¾ˆæœ‰æŒ‡å¯¼æ„ä¹‰ã€‚\n\nå±€é™ï¼ˆLimitationsï¼‰\n\nè¯­è¨€ä¸åœºæ™¯è¦†ç›–æœ‰é™ï¼šå½“å‰ä¸»è¦èšç„¦ Python å•è¯­è¨€ï¼Œä¸”å¤šä¸ºå•æ–‡ä»¶ã€å°è§„æ¨¡ç¼–è¾‘ï¼›å¯¹å¤šè¯­è¨€ã€å¤šæ¨¡å—é‡æ„çš„é€‚ç”¨æ€§ä»å¾…éªŒè¯ã€‚\nå¯¹çœŸå®å·¥ä¸šä»£ç åº“çš„è´´åˆåº¦æœ‰é™ï¼šè™½ç„¶ä½¿ç”¨äº† GitHub æ˜Ÿæ ‡ä»“åº“ï¼Œä½†ä»ç„¶æ˜¯æŠ½ç¦»åçš„ç‰‡æ®µï¼Œä¸å¤§å‹ monorepoã€å¤æ‚ä¾èµ–æ ‘é¡¹ç›®å­˜åœ¨å·®è·ã€‚\nåˆæˆæ•°æ®å æ¯”é«˜ï¼šå¤§é‡æ ·æœ¬ç”± ChatGPT ç­‰æ¨¡å‹ç”Ÿæˆï¼Œå³ä¾¿ç»è¿‡å»é‡å’Œäººå·¥æŠ½æ ·è´¨æ£€ï¼Œä¹Ÿéš¾ä»¥å®Œå…¨é¿å…ã€Œæ¨¡å‹è‡ªæˆ‘å¼ºåŒ–ã€çš„é£é™©ã€‚(arXiv)\nè¯„æµ‹ç»´åº¦å•ä¸€ï¼šä¸»è¦çœ‹æ‰§è¡Œæ­£ç¡®æ€§å’Œå°‘é‡äººç±»æ‰“åˆ†ï¼Œå¯¹ä»£ç å¯è¯»æ€§ã€æ€§èƒ½ã€é£æ ¼ä¸€è‡´æ€§ç­‰æŒ‡æ ‡ç¼ºä¹ç³»ç»Ÿè¯„ä¼°ã€‚\nè®­ç»ƒç­–ç•¥ç›¸å¯¹ç®€å•ï¼šä½¿ç”¨æ ‡å‡†è‡ªå›å½’ + LoRA å¾®è°ƒï¼Œæ²¡æœ‰å¼•å…¥ RL from executionã€ç¼–è¾‘æ“ä½œç©ºé—´å»ºæ¨¡ç­‰æ›´åŠ é’ˆå¯¹æ€§çš„ä¼˜åŒ–æ–¹å¼ï¼Œæœ‰è¿›ä¸€æ­¥æŒ–æ˜ç©ºé—´ã€‚\n\n\nä¸ƒã€ä¸šå†…ç›¸å…³å·¥ä½œå¯¹æ¯”\nè¿™é‡Œé€‰ä¸‰ç¯‡ä¸ã€Œä»£ç æŒ‡ä»¤æ•°æ® / ä»£ç ç¼–è¾‘ã€å¯†åˆ‡ç›¸å…³çš„å·¥ä½œåšå¯¹æ¯”ï¼šOctoPackã€Magicoderã€CANITEDITï¼ˆEDITCODERï¼‰ã€‚(arXiv)\n\n\n\n\n\n\n\n\n\nå·¥ä½œ\nå…³æ³¨é—®é¢˜\næ–¹æ³•è·¯çº¿\nè´¡çŒ®ä¸å®ç”¨ä»·å€¼ï¼ˆä¸»è§‚è¯„ä»·ï¼‰\n\n\n\n\nInstructCoder\né€šç”¨ä»£ç ç¼–è¾‘ï¼šæ ¹æ®è‡ªç„¶è¯­è¨€æŒ‡ä»¤ä¿®æ”¹ç°æœ‰ä»£ç å¹¶é€šè¿‡æµ‹è¯•\nåŸºäº GitHub commit çš„ seed + Self-Instruct + åœºæ™¯æ¡ä»¶ç”Ÿæˆï¼Œæ„å»º 11 ä¸‡+ æŒ‡ä»¤ç¼–è¾‘æ•°æ®ï¼›é…å¥— EditEval æ‰§è¡Œå¼è¯„æµ‹åŸºå‡†\nåœ¨ã€Œä»£ç ç¼–è¾‘ã€è¿™ä¸€å…·ä½“ä»»åŠ¡ä¸Šåšäº† end-to-end é—­ç¯ï¼Œå¯¹å®é™…æƒ³åšã€Œç¼–è¾‘åŠ©æ‰‹ã€çš„å›¢é˜Ÿéå¸¸æœ‰å‚è€ƒä»·å€¼\n\n\nOctoPack\nå¹¿ä¹‰ä»£ç æŒ‡ä»¤ä»»åŠ¡ï¼ŒåŒ…æ‹¬ä¿®å¤ã€è§£é‡Šã€ç”Ÿæˆç­‰\nåˆ©ç”¨ Git commits æ„å»ºå¤§è§„æ¨¡ CommitPackï¼Œè®­ç»ƒ OctoCoder ç³»åˆ—ï¼Œç€é‡æå‡ HumanEvalPack ç­‰å¤šä»»åŠ¡è¡¨ç°\né¢å‘ã€Œé€šç”¨ä»£ç åŠ©æ‰‹ã€ï¼Œæ›´å¼ºè°ƒå¤šè¯­è¨€ã€å¤šä»»åŠ¡è¦†ç›–ï¼Œå¯¹ç¼–è¾‘ä»»åŠ¡çš„ä¸“é—¨åˆ†æç›¸å¯¹è¾ƒå°‘ (arXiv)\n\n\nMagicoder\né¢å‘ä»£ç ç”Ÿæˆçš„é«˜è´¨é‡æŒ‡ä»¤æ•°æ® OSS-Instruct\nåˆ©ç”¨å¼€æºä»£ç ç‰‡æ®µæ„é€ å¤šæ ·åŒ–æŒ‡ä»¤æ•°æ®ï¼Œè®­ç»ƒ Magicoder ç³»åˆ—ï¼Œåœ¨ä»£ç ç”Ÿæˆ benchmark ä¸Šæ¥è¿‘æˆ–è¶…è¶Š ChatGPT\næ›´å¤šæ˜¯åœ¨ã€Œç”Ÿæˆã€è€Œéã€Œç¼–è¾‘ã€ç»´åº¦ä¸Š push SOTAï¼Œæ•°æ®æ„é€ æ€æƒ³ï¼ˆåˆ©ç”¨ OSS ç‰‡æ®µï¼‰å¯¹ç¼–è¾‘åœºæ™¯ä¹Ÿæœ‰å€Ÿé‰´æ„ä¹‰ (arXiv)\n\n\nCANITEDIT / EDITCODER\nç³»ç»ŸåŒ–è¯„ä¼°ä¸æå‡ä»£ç ç¼–è¾‘èƒ½åŠ›\næ„å»ºä¸“é—¨çš„ä»£ç ç¼–è¾‘æ•°æ®é›†å’Œæ–°çš„æŒ‡æ ‡ï¼ˆå¦‚ ExcessCodeï¼‰ï¼Œå¹¶åœ¨ DeepSeekCoder ç­‰æ¨¡å‹ä¸Šè¿›è¡Œç³»ç»Ÿè¯„ä¼°ä¸å¾®è°ƒ\næ›´å…³æ³¨ã€Œå¦‚ä½•è¡¡é‡å’Œä¼˜åŒ–ç¼–è¾‘è´¨é‡ã€æœ¬èº«ï¼Œä¸ InstructCoder åœ¨é—®é¢˜å®šä¹‰ä¸Šé«˜åº¦äº’è¡¥ï¼Œå¯è”åˆä½¿ç”¨ (arXiv)\n\n\n\næ•´ä½“æ¥çœ‹ï¼š\n\nåœ¨é—®é¢˜å®šä¹‰ä¸Šï¼ŒInstructCoder ä¸ CANITEDIT éƒ½ä¸“æ³¨äºã€Œç¼–è¾‘ã€ï¼Œè€Œ OctoPack / Magicoder æ›´åã€Œé€šç”¨ä»£ç æŒ‡ä»¤ã€ä¸ã€Œç”Ÿæˆã€ï¼›\nåœ¨æ–¹æ³•è·¯çº¿ä¸Šï¼Œå‡ è€…éƒ½é‡‡ç”¨ä¸åŒå½¢å¼çš„æŒ‡ä»¤æ•°æ®åˆæˆï¼Œä½† InstructCoder æ›´å¼ºè°ƒæ‰§è¡Œæµ‹è¯•ä¸ edit ratio ç­‰ç¼–è¾‘ç‰¹æœ‰è§†è§’ï¼›\nåœ¨å®ç”¨ä»·å€¼ä¸Šï¼Œå¦‚æœä½ çš„ç›®æ ‡æ˜¯ IDE æ’ä»¶é‡Œçš„ã€Œæ ¹æ®è‡ªç„¶è¯­è¨€æ”¹ä»£ç ã€ï¼ŒInstructCoder + CANITEDIT ç±»å‹çš„å·¥ä½œæ˜¯è®¾è®¡æ•°æ®ä¸è¯„æµ‹çš„é¦–é€‰å‚è€ƒï¼›å¦‚æœç›®æ ‡æ˜¯ã€Œä»éœ€æ±‚ç”Ÿæˆæ–°æ–‡ä»¶ã€ï¼ŒOctoPack / Magicoder æ›´æ¥è¿‘éœ€æ±‚ã€‚\n\n7.1 ä¸ªäººè§‚ç‚¹\nä»æ•´ä½“è®ºè¯æ–¹å¼çœ‹ï¼ŒInstructCoder åœ¨ã€Œæ•°æ®ä¸è¯„æµ‹é—­ç¯ã€ä¸Šåšå¾—æ¯”è¾ƒæ‰å®ï¼šå…ˆç»™å‡ºæ¸…æ™°çš„ EditEvalï¼Œå†è®¾è®¡ InstructCoder æ¥æå‡è¿™ä¸€è¯„æµ‹ï¼Œç„¶åç”¨ç³»ç»Ÿå®éªŒå±•ç¤ºæå‡çš„å¹…åº¦ã€‚è¿™ç§ç»“æ„å¯¹å·¥ç¨‹å›¢é˜Ÿå¾ˆå‹å¥½ï¼Œå› ä¸ºä½ å¯ä»¥ç›´æ¥ç…§æ¬ã€Œè¯„æµ‹æŒ‡æ ‡ + æ•°æ®æ„é€ é€»è¾‘ + è®­ç»ƒå¥—è·¯ã€ã€‚\næœ‰ä¸¤ä¸ªæˆ‘è§‰å¾—å¯ä»¥è¿›ä¸€æ­¥åŠ å¼ºçš„ç‚¹ï¼š\n\nåŸºçº¿ä¸ ablation è®¾è®¡ è®ºæ–‡å·²ç»åšäº† InstructCoder æ•°æ®é‡ç¼©æ”¾å®éªŒï¼Œä½†å¦‚æœèƒ½å¢åŠ æ›´å¤šã€Œæ•°æ®æ„é€ ç­–ç•¥ã€çš„ ablationï¼Œæ¯”å¦‚ï¼šåªç”¨ commit seedã€åªç”¨åœºæ™¯æ¡ä»¶ç”Ÿæˆã€åªç”¨ä¸€èˆ¬ Self-Instructï¼Œè€Œä¸æ˜¯ä¸‰è€…ç»“åˆï¼›æˆ–è€…ä¸ OctoPack å¼ commit æ•°æ®ç›´æ¥è®­ç»ƒå¯¹æ¯”ï¼Œä¼šæ›´æ¸…æ™°åœ°å‘Šè¯‰è¯»è€…ã€Œå“ªä¸€æ­¥æœ€å€¼é’±ã€ã€‚\næ›´è´´è¿‘çœŸå®å·¥ç¨‹çš„ case study ç›®å‰çš„ä¾‹å­ä¸»è¦é›†ä¸­åœ¨ç›¸å¯¹ä¸­å°è§„æ¨¡çš„ç‰‡æ®µï¼Œå¦‚æœèƒ½é¢å¤–å±•ç¤ºä¸€äº›ã€Œå¤šå‡½æ•°ååŒã€ã€Œéœ€è¦ç†è§£æµ‹è¯•æ¡†æ¶/é…ç½®æ–‡ä»¶ã€çš„å¤æ‚ç¼–è¾‘æ¡ˆä¾‹ï¼Œå¹¶ç»™å‡ºå¤±è´¥æ¨¡å¼åˆ†æï¼Œå¯¹åç»­ç³»ç»Ÿè½åœ°ä¼šå¾ˆæœ‰æŒ‡å¯¼æ„ä¹‰ã€‚\n\n\nå…«ã€åœ¨å®é™…è®­ç»ƒæ ˆä¸­å¦‚ä½•è½åœ°ï¼Ÿ\nå¦‚æœè¦åœ¨ã€Œæˆ‘çš„å¤§è§„æ¨¡è®­ç»ƒæ ˆï¼ˆå¦‚åŸºäº Megatron / DeepSpeed / vLLM ç­‰ï¼‰ã€ä¸­å¼•å…¥ InstructCoder è¿™ç±»æ–¹æ³•ï¼Œå¤§è‡´éœ€è¦ä»ä»¥ä¸‹å‡ ä¸ªå±‚é¢è€ƒè™‘ï¼š\n\nDataLoader / æ•°æ®æ‰“åŒ…ä¸é¢„å¤„ç†\n\næŒ‰è®ºæ–‡æ ¼å¼ï¼ŒæŠŠæ ·æœ¬ç»Ÿä¸€ä¸ºï¼š \"&lt;instruction&gt;\\n\\n&lt;original code&gt;\" â†’ \"&lt;edited code&gt;\" è¿™æ ·çš„è¾“å…¥/è¾“å‡ºã€‚\néœ€è¦åšçš„å·¥ç¨‹å·¥ä½œï¼š\n\nè®¾è®¡ç»Ÿä¸€çš„æ¨¡æ¿ï¼ˆprompt formatï¼‰ï¼Œé¿å…ä¸åŒæ¥æºæ ·æœ¬é£æ ¼ä¸ä¸€è‡´ï¼›\né’ˆå¯¹é•¿ä»£ç ç‰‡æ®µï¼Œé…åˆå·²æœ‰çš„ pack/CP ç­–ç•¥ï¼ˆä¾‹å¦‚å¤šæ ·æœ¬æ‹¼æ¥ã€æœ€é•¿ä¼˜å…ˆã€pad é™åˆ¶ç­‰ï¼‰æé«˜ GPU åˆ©ç”¨ç‡ï¼›\nåœ¨é¢„å¤„ç†é˜¶æ®µå°±è®°å½•ã€Œç¼–è¾‘æ¯”ä¾‹ã€ã€Œè¯­è¨€ã€ã€Œåœºæ™¯æ ‡ç­¾ã€ç­‰å…ƒä¿¡æ¯ï¼Œæ–¹ä¾¿åç»­åš curriculum æˆ–é‡‡æ ·åŠ æƒã€‚\n\n\nå¹¶è¡Œè°ƒåº¦ï¼ˆDP / TP / PPï¼‰ä¸ä¸Šä¸‹æ–‡é•¿åº¦é…ç½®\n\nä»£ç ç¼–è¾‘ä»»åŠ¡å¾€å¾€æœ‰è¾ƒé•¿ä¸Šä¸‹æ–‡ï¼ˆåŸå§‹ä»£ç  + æ³¨é‡Š + æŒ‡ä»¤ï¼‰ï¼Œéœ€è¦ç»“åˆæ¨¡å‹ä¸Šä¸‹æ–‡é•¿åº¦å’Œæ˜¾å­˜é¢„ç®—ï¼Œåˆç†è®¾ç½® global batch / micro batchï¼š\n\nå¦‚æœå·²æœ‰çš„é¢„è®­ç»ƒ/å¯¹è¯æŒ‡ä»¤å¾®è°ƒç®¡çº¿å·²ç»æ”¯æŒé•¿ä¸Šä¸‹æ–‡ï¼Œå¯ä»¥ç›´æ¥å¤ç”¨å¯¹åº”çš„ PP/TP é…ç½®ï¼›\næ³¨æ„æ˜¾å­˜å³°å€¼ï¼šä»£ç ç‰‡æ®µé€šå¸¸ç»“æ„å¯†é›†ã€token åŒ–åé•¿åº¦ä¼šæ¯”è¾ƒå¯è§‚ï¼Œå¯èƒ½éœ€è¦é€‚å½“å‡å° batch æˆ–å¯ç”¨ activation checkpointã€‚\n\n\nå¼ é‡/ä¸Šä¸‹æ–‡å¹¶è¡Œç­–ç•¥\n\nå¯¹å·²æœ‰ TP/CP ç­–ç•¥ï¼Œä¸€èˆ¬ä¸éœ€è¦ä¸ºä»£ç ç¼–è¾‘ä¸“é—¨æ”¹ kernelï¼›\næ›´éœ€è¦æ³¨æ„çš„æ˜¯ï¼š\n\nä»£ç  token åˆ†å¸ƒä¸è‡ªç„¶è¯­è¨€ä¸åŒï¼ŒBPE merge åå®¹æ˜“å‡ºç°é•¿ identifierï¼Œéœ€è¦ç¡®è®¤åˆ†è¯å™¨æ˜¯å¦é€‚é…ï¼›\nåœ¨å¤šæ¨¡å‹å®¶æ—å…±å­˜çš„è®­ç»ƒå¹³å°ä¸Šï¼ˆå¦‚åŒæ—¶è®­ç»ƒå¯¹è¯æ¨¡å‹å’Œä»£ç æ¨¡å‹ï¼‰ï¼Œè¦ç¡®ä¿ code-specific çš„ tokenizer ä¸ vocab ä¸è¢«æ··ç”¨ã€‚\n\n\nkernel æˆ–ç®—å­å®ç°\n\næœ¬æ–‡é‡‡ç”¨çš„æ˜¯æ ‡å‡† Decoder-only Transformer + LoRAï¼Œå› æ­¤ä¸éœ€è¦æ–°çš„ç®—å­ï¼›\nå¦‚æœä½ çš„æ ˆé‡Œå·²ç»æœ‰ fused attentionã€fused MLP ç­‰é«˜æ€§èƒ½ kernelï¼Œä»£ç ç¼–è¾‘è®­ç»ƒå¯ä»¥ç›´æ¥å¤ç”¨ï¼›\nçœŸæ­£éœ€è¦å…³æ³¨çš„æ˜¯ï¼š\n\nLoRA/adapter çš„å®ç°æ˜¯å¦ä¸è¿™äº› fused kernel å…¼å®¹ï¼›\nå¯¹äº flash-attention ä¸€ç±»ç®—å­ï¼Œè¦ä¿è¯åœ¨é•¿ä»£ç ä¸Šä¸‹æ–‡ä¸‹ç¨³å®šã€ä¸ä¼šå› ä¸ºä¸è§„åˆ™åˆ†å¸ƒè§¦å‘æ…¢è·¯å¾„ã€‚\n\n\né€šä¿¡ä¸é›†ä½“æ“ä½œ\n\nåœ¨ DP/TP/PP å¤šç»´å¹¶è¡Œä¸‹ï¼Œä»£ç ç¼–è¾‘è®­ç»ƒå’Œæ™®é€š pretrain/sft åŸºæœ¬ä¸€è‡´ï¼š\n\nDPï¼šæ ‡å‡† all-reduce gradï¼›\nTPï¼šæ³¨æ„é•¿åºåˆ—ä¸‹ all-gather / reduce-scatter çš„å¸¦å®½å ç”¨ï¼›\nPPï¼šä¿è¯ stage ä¹‹é—´çš„ micro-batch è¶³å¤Ÿå¤§ï¼Œå¦åˆ™æµæ°´çº¿ç©ºæ³¡ä¼šè¢«é•¿ä¸Šä¸‹æ–‡æ”¾å¤§ã€‚\n\nä»å·¥ç¨‹å®è·µçœ‹ï¼Œæœ€å¯èƒ½çš„å‘ä¸åœ¨é€šä¿¡é€»è¾‘ï¼Œè€Œåœ¨äºä¸å‡åŒ€çš„åºåˆ—åˆ†å¸ƒï¼šè‹¥è®¸å¤š batch ä¸­åŒ…å«ã€Œæé•¿ä»£ç ç‰‡æ®µã€ï¼Œä¼šåœ¨æŸä¸€é˜¶æ®µé€ æˆè´Ÿè½½å³°å€¼ï¼Œå»ºè®®é¢„å¤„ç†æ—¶åšé•¿åº¦åˆ†å±‚ã€‚\n\né…ç½®æœç´¢ / è‡ªåŠ¨è°ƒå‚\n\néœ€è¦è°ƒä¼˜çš„å…³é”®å‚æ•°åŒ…æ‹¬ï¼š\n\nLoRA rankã€å­¦ä¹ ç‡ã€å¾®è°ƒæ­¥æ•°ï¼ˆå¤šå¤§ç¨‹åº¦ä¸Šã€Œä¸“é—¨åŒ–ã€æˆ code editorï¼‰ï¼›\nè®­ç»ƒæ•°æ®æ··åˆæ¯”ä¾‹ï¼šInstructCoder vs å…¶ä»–æŒ‡ä»¤æ•°æ®ï¼ˆé€šç”¨å¯¹è¯ã€ä»£ç ç”Ÿæˆç­‰ï¼‰ï¼›\né‡‡æ ·ç­–ç•¥ï¼šæ˜¯å¦å¯¹å°ç¼–è¾‘æ¯”ä¾‹æ ·æœ¬åŠ æƒï¼Œä»¥æŠ‘åˆ¶ã€Œç›´æ¥å¤åˆ¶è¾“å…¥ã€çš„æ·å¾„ã€‚\n\nå¯ä»¥åœ¨ç°æœ‰è¶…å‚æœç´¢æ¡†æ¶ä¸­ï¼ŒæŠŠã€ŒEditEval accuracyã€æˆ–å†…éƒ¨è‡ªå»ºçš„æ‰§è¡Œå¼è¯„æµ‹æŒ‡æ ‡ä½œä¸ºä¸»ç›®æ ‡ã€‚\n\nè°ƒè¯• / ç›‘æ§\n\nåœ¨è®­ç»ƒé˜¶æ®µï¼Œå»ºè®®é¢å¤–ç›‘æ§ï¼š\n\nEditEval / å†…éƒ¨ç¼–è¾‘è¯„æµ‹é›†ä¸Šçš„æ‰§è¡Œé€šè¿‡ç‡ï¼›\nä¸åŒç¼–è¾‘æ¯”ä¾‹åˆ†æ¡¶ä¸Šçš„å‡†ç¡®ç‡ï¼›\nå¯¹ç°æœ‰ä»£ç ç”Ÿæˆ benchmarkï¼ˆå¦‚ HumanEvalï¼‰çš„å½±å“ï¼Œé˜²æ­¢ä¸“ç²¾ç¼–è¾‘èƒ½åŠ›å¯¼è‡´ç”Ÿæˆèƒ½åŠ›é€€åŒ–ã€‚\n\nåœ¨çº¿/æ¨ç†æœåŠ¡ä¾§ï¼š\n\nè®°å½•ç”¨æˆ·çœŸå®ç¼–è¾‘ä»»åŠ¡çš„æˆåŠŸç‡ï¼ˆä¾‹å¦‚é›†æˆåˆ° CI çš„è‡ªåŠ¨æµ‹è¯•é€šè¿‡ç‡ï¼‰ï¼›\nç»Ÿè®¡ã€Œä¿ç•™åŸæ ·ã€ã€Œè¿‡åº¦æ”¹åŠ¨ã€ç­‰é”™è¯¯æ¨¡å¼ï¼Œä¸ºä¸‹ä¸€è½®æ•°æ®æ„é€ æä¾›åé¦ˆã€‚\n\n\n\n\nä¹ã€å€¼å¾—è¿›ä¸€æ­¥æ¢ç´¢çš„ç ”ç©¶æ–¹å‘\næ–¹å‘ä¸€ï¼šå¤šæ–‡ä»¶ã€å¤šæ¨¡å—ä»£ç ç¼–è¾‘\nç°å®å¼€å‘ä¸­ï¼Œå¾ˆå¤šç¼–è¾‘æ“ä½œéœ€è¦è·¨å¤šä¸ªæ–‡ä»¶è¿›è¡Œï¼ˆæ·»åŠ æ–°æ¨¡å—ã€æ›´æ–°æ¥å£å®šä¹‰ä¸æ‰€æœ‰è°ƒç”¨ç‚¹ç­‰ï¼‰ã€‚æœªæ¥å¯ä»¥æ‰©å±• InstructCoder ç±»æ•°æ®ï¼š\n\nè®©æŒ‡ä»¤æ˜ç¡®æè¿°è·¨æ–‡ä»¶é‡æ„ä»»åŠ¡ï¼›\nè¾“å…¥ä¸Šä¸‹æ–‡åŒ…å«å¤šæ–‡ä»¶ç‰‡æ®µæˆ–é¡¹ç›®ç»“æ„æ‘˜è¦ï¼›\nè¯„æµ‹åŸºå‡†æ‰©å±•ä¸ºå¤šæ¨¡å—æ„å»º + é›†æˆæµ‹è¯•ã€‚\n\næ–¹å‘äºŒï¼šå¤šè¯­è¨€ä¸å¼ºç±»å‹åœºæ™¯çš„ç¼–è¾‘\nå½“å‰ä¸»è¦é›†ä¸­åœ¨ Pythonï¼Œåç»­å¯ä»¥é¢å‘ C++/Rust/Java ç­‰å¼ºç±»å‹è¯­è¨€ï¼š\n\nç»“åˆç¼–è¯‘å™¨é”™è¯¯ä¿¡æ¯ã€ç±»å‹ç³»ç»Ÿçº¦æŸï¼Œæ„é€ æ›´å¤æ‚çš„ç¼–è¾‘æŒ‡ä»¤ï¼ˆä¾‹å¦‚ã€Œæ¶ˆé™¤æ‰€æœ‰æœªä½¿ç”¨æ¨¡æ¿å®ä¾‹ã€ã€Œä¿®æ­£ lifetime é”™è¯¯ã€ï¼‰ï¼›\nåˆ©ç”¨é™æ€åˆ†æå·¥å…·ç”Ÿæˆæ›´ç²¾ç¡®çš„ edit targetï¼Œå‡å°‘æœç´¢ç©ºé—´ã€‚\n\næ–¹å‘ä¸‰ï¼šæ˜¾å¼å»ºæ¨¡ã€Œç¼–è¾‘æ“ä½œã€è€Œéå®Œæ•´ä»£ç \nç›®å‰çš„åšæ³•æ˜¯ç›´æ¥ç”Ÿæˆæ–°çš„å®Œæ•´ä»£ç ç‰‡æ®µï¼Œæœªæ¥å¯ä»¥è€ƒè™‘ï¼š\n\næŠŠä»»åŠ¡å»ºæ¨¡ä¸ºã€Œç¼–è¾‘è„šæœ¬ã€ç”Ÿæˆï¼ˆinsert/delete/replace patchï¼‰ï¼Œåœ¨åå¤„ç†ä¸­åº”ç”¨åˆ°åŸå§‹ä»£ç ï¼›\nåœ¨è®­ç»ƒæ—¶çº¦æŸæ¨¡å‹å°½é‡å±€éƒ¨ä¿®æ”¹ï¼Œå‡å°‘ã€Œé‡å†™å…¨éƒ¨æ–‡ä»¶ã€é€ æˆçš„ diff å™ªå£°ï¼›\nåœ¨è¯„æµ‹ä¸­å¢åŠ å¯¹ patch å¤§å°ã€ä¿®æ”¹å®šä½ç²¾ç¡®åº¦çš„æŒ‡æ ‡ã€‚\n\næ–¹å‘å››ï¼šè®­ç»ƒé—­ç¯ä¸­å¼•å…¥æ‰§è¡Œåé¦ˆ\nå½“å‰æ‰§è¡Œæµ‹è¯•åªç”¨äºè¯„æµ‹ï¼Œæœªæ¥å¯ä»¥æ¢ç´¢ï¼š\n\nåœ¨è®­ç»ƒä¸­ä½¿ç”¨ RL from executionï¼Œè®©é€šè¿‡æµ‹è¯•çš„ç¼–è¾‘è·å¾—æ­£å¥–åŠ±ï¼›\næˆ–è€…åœ¨æ•°æ®åˆæˆé˜¶æ®µï¼Œç”¨æ‰§è¡Œæµ‹è¯•æ¥è¿‡æ»¤/åŠ æƒç”Ÿæˆæ ·æœ¬ï¼Œå½¢æˆæ›´å¼ºçš„ self-training é—­ç¯ã€‚\n\næ–¹å‘äº”ï¼šä¸ IDE / CI æµæ°´çº¿æ·±åº¦é›†æˆ\nä»å·¥ç¨‹è½åœ°è§’åº¦ï¼š\n\nå°†ç¼–è¾‘æ¨¡å‹ä¸ IDE æ’ä»¶ã€ä»£ç å®¡æŸ¥å·¥å…·ã€CI ç³»ç»Ÿè¿æ¥ï¼Œæ”¶é›†çœŸå®å¼€å‘è€…äº¤äº’æ•°æ®ï¼ˆç¼–è¾‘æˆåŠŸç‡ã€å›æ»šç‡ç­‰ï¼‰ï¼›\nåˆ©ç”¨è¿™äº›ã€Œäººç±»åé¦ˆã€è¿›ä¸€æ­¥æ„é€ é«˜ä»·å€¼çš„æŒ‡ä»¤/ç¼–è¾‘å¯¹ï¼ŒæŒç»­è¿­ä»£ä»£ç ç¼–è¾‘èƒ½åŠ›ã€‚\n\n\nåã€çŸ¥è¯†å›¾è°±æ€ç»´é“¾\nä»ä½ çš„ã€Œå¤§æ¨¡å‹è®­ç»ƒæ ˆã€è§†è§’ï¼Œè¿™ç¯‡è®ºæ–‡ä¸»è¦æ›´æ–°äº†ä»¥ä¸‹å‡ ä¸ªèŠ‚ç‚¹ï¼š\n\næ•°æ®ã€é¢„å¤„ç†ä¸æ‰“åŒ…ç­–ç•¥\n\nã€Œå¦‚ä½•ä» GitHub commits ä¸­æŠ½å–é«˜è´¨é‡ç¼–è¾‘æ ·æœ¬ã€ï¼Œå¹¶é€šè¿‡è‡ªæŒ‡ä»¤æ‰©å±•å½¢æˆå¤§è§„æ¨¡æŒ‡ä»¤æ•°æ®é›†ã€‚\nã€Œå¦‚ä½•è®¾è®¡æ‰§è¡Œå¼è¯„æµ‹åŸºå‡†ã€ï¼ŒæŠŠ code editing ä»æ–‡æœ¬ä»»åŠ¡æå‡ä¸ºã€Œå¸¦ç¨‹åºè¯­ä¹‰çš„ä»»åŠ¡ã€ã€‚\n\næ¨¡å‹ç»“æ„ä¸æ¶æ„è®¾è®¡\n\nä¸æ”¹åŠ¨åŸºç¡€ Transformer æ¶æ„ï¼Œé€šè¿‡ LoRA è¿™ç±» PEFT æŠ€æœ¯æ³¨å…¥ä»»åŠ¡ç‰¹å®šèƒ½åŠ›ï¼Œè¯´æ˜å¾ˆå¤šã€Œä¸“é—¨èƒ½åŠ›ã€ä¸ä¸€å®šéœ€è¦å¤§æ”¹æ¨¡å‹ã€‚\n\nå¹¶è¡Œä¸è°ƒåº¦\n\nè™½ç„¶è®ºæ–‡æœ¬èº«ä¸å¼ºè°ƒå¹¶è¡Œç»†èŠ‚ï¼Œä½†é•¿ä¸Šä¸‹æ–‡çš„ä»£ç ç¼–è¾‘è®­ç»ƒåœ¨å®é™…æ ˆä¸­ï¼Œä¼šç›´æ¥å½±å“ä½ å¯¹ TP/PP é…ç½®ã€batch å¤§å°å’Œæ¿€æ´»æ£€æŸ¥ç‚¹ç­–ç•¥çš„é€‰æ‹©ã€‚\n\nå†…å­˜ç®¡ç†ä¸æ˜¾å­˜ä¼˜åŒ–\n\nLoRA çš„é‡‡ç”¨æœ¬èº«å°±æ˜¯ä¸€ç§ã€Œå‚æ•°ä¸æ˜¾å­˜ç®¡ç†ã€ç­–ç•¥ï¼šåœ¨ 33B æ¨¡å‹ä¸Šç”¨å•å¡ A100 å®Œæˆå¾®è°ƒï¼Œä¸ºåœ¨èµ„æºå—é™ç¯å¢ƒä¸‹åšä¸“é¡¹èƒ½åŠ›è®­ç»ƒæä¾›äº†ä¾‹å­ã€‚(arXiv)\n\né€šä¿¡ä¸é›†ä½“æ“ä½œ\n\nä»ä»»åŠ¡å½¢æ€çœ‹ï¼Œä»£ç ç¼–è¾‘è®­ç»ƒä¸æ™®é€š SFT ä¸€è‡´ï¼Œä½†é•¿åºåˆ— + ä¸å‡åŒ€é•¿åº¦åˆ†å¸ƒä¼šå¯¹ all-reduce/all-gather ç­‰é€šä¿¡é˜¶æ®µé€ æˆæ–°çš„å‹åŠ›ï¼Œéœ€è¦åœ¨å®é™…ç³»ç»Ÿé‡Œåš profile å’Œè°ƒåº¦ç­–ç•¥ä¼˜åŒ–ã€‚\n\n\n10.1 ä¸ªäººæ”¶è·ä¸åæ€\nå¯¹å¤§æ¨¡å‹è®­ç»ƒä¸ç³»ç»Ÿè®¾è®¡è€Œè¨€ï¼Œè¿™ç¯‡è®ºæ–‡ç»™æˆ‘çš„æœ€å¤§å¯å‘æ˜¯ï¼šå¾ˆå¤šæˆ‘ä»¬ä»¥ä¸ºã€Œæ¨¡å‹ä¸è¡Œã€çš„åœºæ™¯ï¼Œå®é™…ä¸Šæ˜¯ã€Œæ•°æ®å’Œè¯„æµ‹æ²¡è·Ÿä¸Šã€ã€‚ä»…ä»…é€šè¿‡ä¸€ä¸ª carefully designed çš„æ‰§è¡Œå¼ benchmark + é’ˆå¯¹æ€§çš„æŒ‡ä»¤æ•°æ®ï¼Œå°±èƒ½æŠŠå¼€æºæ¨¡å‹çš„ç¼–è¾‘èƒ½åŠ›ä»ã€Œå‡ ä¹ä¸å¯ç”¨ã€æ¨åˆ°ã€Œæ¥è¿‘ ChatGPTã€ï¼Œè¿™è¯´æ˜ï¼š\n\nä¸€æ–¹é¢ï¼ŒåŸºç¡€æ¨¡å‹å·²ç»å…·å¤‡äº†ç›¸å½“å¤šçš„ä»£ç çŸ¥è¯†ä¸æ¨ç†èƒ½åŠ›ï¼›\nå¦ä¸€æ–¹é¢ï¼Œå¦‚æœä¸åœ¨ã€Œä»»åŠ¡å®šä¹‰ + è¯„æµ‹ + æ•°æ®æ„é€ ã€ä¸Šä¸‹åŠŸå¤«ï¼Œå¾ˆå®¹æ˜“ä½ä¼°æˆ–è¯¯ç”¨è¿™äº›èƒ½åŠ›ã€‚\n\nä»å®è·µè§’åº¦ï¼Œæˆ‘ä¼šè€ƒè™‘åœ¨è‡ªå·±çš„æ ˆé‡Œè¿ç§»ä¸¤ç±»ç†å¿µï¼š\n\nä¼˜å…ˆæ­å¥½æ‰§è¡Œå¼è¯„æµ‹é—­ç¯ï¼šåœ¨å¼•å…¥ä»»ä½•æ–°æ¨¡å‹/æ•°æ®ä¹‹å‰ï¼Œå…ˆæ˜ç¡®ã€Œè¿™ä¸ªä»»åŠ¡çš„å¯æ‰§è¡Œè¯„æµ‹æ˜¯ä»€ä¹ˆã€ï¼Œä¾‹å¦‚ä»£ç ç¼–è¾‘ä¸­çš„å•å…ƒæµ‹è¯•ã€ç«¯åˆ°ç«¯å›å½’æµ‹è¯•ï¼Œå†å›´ç»•è¿™ä¸ªè¯„æµ‹æ¥è®¾è®¡æ•°æ®å’Œè®­ç»ƒã€‚\nç”¨ LoRA/adapter åšèƒ½åŠ›ä¸“ç²¾å¾®è°ƒï¼šè€Œä¸æ˜¯ä¸€æ¬¡æ€§åšå·¨å¤§è§„æ¨¡ full finetuneã€‚è¿™æ ·å¯ä»¥åœ¨åŒä¸€å¥—åŸºç¡€æ¨¡å‹ä¸ŠæŒ‚è½½å¤šä¸ªã€Œèƒ½åŠ›å¤´ã€ï¼ˆä»£ç ç¼–è¾‘ã€é™æ€åˆ†æã€refactorã€review ç­‰ï¼‰ï¼ŒæŒ‰éœ€åŠ è½½ï¼Œä¾¿äºå·¥ç¨‹ç®¡ç†ã€‚\n\n\næ€»ä½“è¯„ä»·ï¼šInstructCoder æŠŠã€Œä»£ç ç¼–è¾‘ã€ä»ä¸€ä¸ªæ¨¡ç³Šçš„ä½¿ç”¨åœºæ™¯ï¼Œæ‹‰æˆäº†æœ‰æ˜ç¡®æ•°æ®æ„é€ æ–¹æ³•å’Œæ‰§è¡Œå¼è¯„æµ‹åŸºå‡†çš„ç³»ç»ŸåŒ–é—®é¢˜ï¼Œåœ¨å·¥ç¨‹è½åœ°ä¸Šæœ‰å¾ˆå¼ºçš„å‚è€ƒä»·å€¼ï¼›å¯¹äºå·²ç»æ‹¥æœ‰é€šç”¨ä»£ç  LLM çš„å›¢é˜Ÿï¼ŒæŒ‰ç…§æ–‡ä¸­çš„æ€è·¯æ„å»ºè‡ªå®¶ç¼–è¾‘æ•°æ®å’Œè¯„æµ‹é—­ç¯ï¼Œå¾ˆå¯èƒ½æ˜¯ä¸€ä¸ªæŠ•å…¥ç›¸å¯¹å¯æ§ã€ä½†å›æŠ¥æ˜æ˜¾çš„è·¯çº¿ã€‚\n\n","categories":["è®ºæ–‡é˜…è¯»"],"tags":["paper"]},{"title":"Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM","url":"/2025/11/23/paper/efficient_large_scale/","content":"\n\n\nä¸€ã€è®ºæ–‡é€Ÿè§ˆ\nè¿™ç¯‡ SCâ€™21 è®ºæ–‡èšç„¦çš„æ ¸å¿ƒé—®é¢˜æ˜¯ï¼šåœ¨ä¸Šåƒå— GPU çš„é›†ç¾¤ä¸Šï¼Œå¦‚ä½•é«˜æ•ˆè®­ç»ƒ 100Bï½1T çº§åˆ«çš„ Transformer è¯­è¨€æ¨¡å‹ï¼ŒåŒæ—¶æ—¢ä¸è¢«æ˜¾å­˜é™åˆ¶å¡æ­»ï¼Œåˆä¸è¿‡åº¦æµªè´¹ç®—åŠ›åœ¨é€šä¿¡å’Œæµæ°´ç©ºæ³¡ä¸Šã€‚(people.eecs.berkeley.edu)\nä½œè€…æå‡ºäº†ä¸€å¥—ç»„åˆå¼å¹¶è¡Œæ–¹æ¡ˆ PTD-Pï¼šåœ¨å•æœºå†…åšå¼ é‡å¹¶è¡Œï¼ˆTensor MPï¼‰ï¼Œè·¨æœºåšæµæ°´çº¿å¹¶è¡Œï¼ˆPipeline MPï¼‰ï¼Œæœ€å¤–å±‚å åŠ æ•°æ®å¹¶è¡Œï¼ˆDPï¼‰ï¼Œå¹¶é…å¥—æ–°çš„ interleaved 1F1B æµæ°´è°ƒåº¦ä»¥å‹ç¼© pipeline bubbleã€‚(people.eecs.berkeley.edu)\nåœ¨ä¸€å°å° DGX A100 ç»„æˆçš„é›†ç¾¤ä¸Šï¼Œè¿™å¥—æ–¹æ¡ˆæŠŠ 1T å‚æ•° GPT æ¨¡å‹çš„è®­ç»ƒè¿­ä»£åšåˆ°äº† 3072 å— GPU ä¸Šæ€»è®¡ 502 PFLOP/s çš„ååï¼Œå•å¡çº¦ 163 TFLOP/sï¼Œç›¸å½“äº A100 ç†è®ºå³°å€¼çš„çº¦ 52%ã€‚(people.eecs.berkeley.edu)\nè®ºæ–‡æœ€åç»™å‡ºäº†ä¸€äº›éå¸¸å·¥ç¨‹å‘çš„â€œé€‰å‹æŒ‡å—â€ï¼šTP/PP/DP æ¯”ä¾‹å¦‚ä½•æ­é…ã€micro-batch å¦‚ä½•é€‰ã€é€šä¿¡æ‹“æ‰‘å’Œå¹¶è¡Œç­–ç•¥å¦‚ä½•é€‚é…ï¼Œä¸ºä¹‹åçš„å¤§è§„æ¨¡ LLM è®­ç»ƒå®è·µåŸºæœ¬å®šäº†â€œæ•™ç§‘ä¹¦çº§â€çš„åŸºå‡†ã€‚(people.eecs.berkeley.edu)\näºŒã€è®ºæ–‡ç»“æ„\n\nå¼•è¨€ä¸é—®é¢˜èƒŒæ™¯ è¯´æ˜å¤§æ¨¡å‹è®­ç»ƒåœ¨æ˜¾å­˜å®¹é‡ä¸ç®—åŠ›éœ€æ±‚ä¸Šçš„çŸ›ç›¾ï¼Œå›é¡¾å·²æœ‰çš„ TP / PP / DP å·¥ä½œï¼ˆMegatronã€GPipeã€PipeDreamã€ZeRO ç­‰ï¼‰ï¼Œå¹¶ç‚¹å‡ºè¿™äº›æ–¹æ³•åœ¨â€œä¸Šåƒ GPU è§„æ¨¡â€æ—¶çš„æ ¹æœ¬ç“¶é¢ˆï¼Œé€‚åˆæƒ³å¿«é€ŸçŸ¥é“â€œä¸ºä»€ä¹ˆè¦æ PTD-Pâ€ çš„è¯»è€…å…ˆè¯»ã€‚(people.eecs.berkeley.edu)\nå¹¶è¡Œæ¨¡å¼ç»¼è¿°ä¸ PTD-P æ€»ä½“è®¾è®¡ ç³»ç»Ÿæ€§åœ°è®²è§£æ•°æ®å¹¶è¡Œã€æµæ°´å¹¶è¡Œã€å¼ é‡å¹¶è¡Œä¸‰ç§æ¨¡å¼çš„ä¼˜ç¼ºç‚¹ï¼Œå¹¶ç»™å‡ºä¸‰è€…ç»„åˆï¼ˆPTD-Pï¼‰çš„é«˜å±‚ç»“æ„ç¤ºæ„ä¸å®è·µç»éªŒï¼Œæ˜¯ç†è§£æ•´ä½“ç³»ç»Ÿæ¶æ„ä¸è¿›ç¨‹ç»„å¸ƒå±€çš„å…³é”®éƒ¨åˆ†ã€‚(people.eecs.berkeley.edu)\næµæ°´å¹¶è¡Œè°ƒåº¦ï¼šGPipeã€PipeDream-Flush ä¸ Interleaved 1F1B è¯¦ç»†åˆ†æä¸åŒ pipeline è°ƒåº¦çš„ bubble å¤§å°ã€æ¿€æ´»æ˜¾å­˜å ç”¨ä¸é€šä¿¡é‡ï¼Œå¹¶ç»™å‡º interleaved 1F1B çš„æ–°è°ƒåº¦åŠå®ƒåœ¨ååä¸Šçš„æ”¶ç›Šï¼Œæ˜¯æœ¬æ–‡ç†è®ºåˆ†æçš„æ ¸å¿ƒã€‚(people.eecs.berkeley.edu)\nå¼ é‡å¹¶è¡Œä¸é€šä¿¡ä¼˜åŒ– å›é¡¾ Megatron-LM çš„å¼ é‡å¹¶è¡Œæ‹†åˆ†æ–¹å¼ï¼Œè¯´æ˜åœ¨å¤šæœºå¤šå¡ç¯å¢ƒä¸‹å¦‚ä½•æŠŠ TP å±€é™åœ¨å•æœºå†…éƒ¨ï¼Œé…åˆ InfiniBand ç­‰è·¨èŠ‚ç‚¹é€šä¿¡ä¼˜åŒ–ï¼Œæ˜¯å®é™…æŠŠä»£ç æ”¹å¯¹çš„å·¥ç¨‹æŒ‡å—ã€‚(people.eecs.berkeley.edu)\nå®éªŒè¯„ä¼°ï¼šä» 1B åˆ° 1T çš„ç¼©æ”¾å®è¯ å±•ç¤ºä¸åŒ TP/PP/DP é…ç½®ä¸‹çš„ååä¸æ‰©å±•æ•ˆç‡ï¼Œå¯¹æ¯” ZeRO-3 ç­‰æ–¹æ¡ˆï¼Œä»¥åŠåœ¨ 175B / 530B / 1T æ¨¡å‹ä¸Šçš„æ€§èƒ½æ•°æ®ï¼Œæ˜¯æœ€å€¼å¾—å·¥ç¨‹äººå‘˜ç»†è¯»å¯¹æ ‡è‡ªå·±é›†ç¾¤çš„ä¸€èŠ‚ã€‚(people.eecs.berkeley.edu)\nç›¸å…³å·¥ä½œä¸å°ç»“ å°†æœ¬å·¥ä½œä¸ GPipeã€PipeDreamã€ZeRO ç­‰æ–¹æ³•å¯¹æ¯”ï¼Œå¼ºè°ƒè‡ªèº«çš„å®šä½ï¼ˆä¸¥æ ¼åŒæ­¥è¯­ä¹‰ + ä¸‰ç»´å¹¶è¡Œ + å·¥ç¨‹è½åœ°ï¼‰ï¼Œé€‚åˆä½œä¸ºå†™è‡ªå·±æ–¹æ¡ˆæ—¶çš„â€œRelated Work æ¨¡æ¿â€ã€‚(people.eecs.berkeley.edu)\n\n\næ ¸å¿ƒæ€æƒ³ï¼šé€šè¿‡åœ¨å•æœºå†…åšå¼ é‡å¹¶è¡Œã€è·¨æœºåšæµæ°´å¹¶è¡Œå¹¶å åŠ æ•°æ®å¹¶è¡Œçš„ PTD-P ä¸‰ç»´å¹¶è¡Œæ¶æ„ï¼Œå†é…åˆ interleaved 1F1B æµæ°´è°ƒåº¦å’Œé€šä¿¡ä¼˜åŒ–ï¼Œå¯ä»¥åœ¨ä¿æŒä¸¥æ ¼åŒæ­¥è¯­ä¹‰å’Œæœ‰é™æ˜¾å­˜å ç”¨çš„å‰æä¸‹ï¼ŒæŠŠ GPT ç±»è¯­è¨€æ¨¡å‹é«˜æ•ˆæ‰©å±•åˆ° 1T å‚æ•°å’Œä¸Šåƒ GPU è§„æ¨¡ã€‚(people.eecs.berkeley.edu)\n\n\nä¸‰ã€æ–¹æ³•ä¸ç³»ç»Ÿè®¾è®¡\næ•´ä½“æ€è·¯å¯ä»¥æ¦‚æ‹¬ä¸ºï¼šåœ¨ç»™å®šé›†ç¾¤æ‹“æ‰‘ï¼ˆDGX + NVLink + InfiniBandï¼‰çš„å‰æä¸‹ï¼Œç”¨æœ€é€‚åˆæ‹“æ‰‘çš„æ–¹å¼ç»„åˆ TP / PP / DPï¼Œå¹¶é€šè¿‡æ–°æµæ°´è°ƒåº¦æœ€å¤§åŒ–ç®—åŠ›åˆ©ç”¨ç‡ï¼ŒåŒæ—¶æŠŠè·¨èŠ‚ç‚¹é€šä¿¡å‹åŠ›å‹åˆ°æœ€ä½ã€‚(people.eecs.berkeley.edu)\nä½œè€…é‡ç‚¹è§£å†³äº†å‡ ä¸ªå­é—®é¢˜ï¼š\n\nå­é—®é¢˜ 1ï¼š å¦‚ä½•ç»„åˆ TP / PP / DPï¼Œåœ¨æœ‰é™æ˜¾å­˜ä¸‹æ”¯æ’‘ 1T çº§æ¨¡å‹ï¼Œåˆé¿å…åœ¨ä¸Šåƒ GPU æ—¶è¢«é€šä¿¡æ‹–å®ï¼Ÿ\nå­é—®é¢˜ 2ï¼š ä¼ ç»Ÿ GPipe/1F1B è°ƒåº¦çš„ pipeline bubble è¿‡å¤§ï¼Œå¦‚ä½•åœ¨ä¸æ”¾å¼ƒä¸¥æ ¼åŒæ­¥è¯­ä¹‰çš„å‰æä¸‹è¿›ä¸€æ­¥å‹ç¼© bubbleï¼Ÿ\nå­é—®é¢˜ 3ï¼š åœ¨ç°å®é›†ç¾¤æ‹“æ‰‘ä¸­ï¼ˆå¤šæœºå¤šå¡ã€NVLink + InfiniBandï¼‰ï¼Œå¦‚ä½•èªæ˜åœ°åˆ†é… TP/PP ç»´åº¦ï¼Œå‡å°‘â€œè·¨èŠ‚ç‚¹ all-reduceâ€è¿™ç§æ˜‚è´µé€šä¿¡ï¼Ÿ\nå­é—®é¢˜ 4ï¼š åœ¨å®é™…è®­ç»ƒä¸­ï¼Œå¦‚ä½•é€šè¿‡ micro-batch / global batch / activation recompute ç­‰è¶…å‚è°ƒèŠ‚ï¼Œè·å–æ›´é«˜çš„ååï¼Ÿ(people.eecs.berkeley.edu)\n\n3.1 æ ¸å¿ƒæ¨¡å—ä¸€è§ˆ\nä»¥ä¸‹æ¨¡å—åæ˜¯ç»“åˆè®ºæ–‡å†…å®¹ä¸ Megatron å®ç°çš„å·¥ç¨‹æ‹†è§£ï¼Œä¸æ˜¯åŸæ–‡çš„ section åç§°ï¼š\n\nPTD-P ä¸‰ç»´å¹¶è¡Œå¸ƒå±€æ¨¡å—ï¼šè´Ÿè´£æŠŠå…¨é›†ç¾¤åˆ’åˆ†ä¸ºæ•°æ®å¹¶è¡Œç»„ã€æµæ°´å¹¶è¡Œç»„å’Œå¼ é‡å¹¶è¡Œç»„ï¼Œå¹¶åœ¨ Megatron ä¸­æ˜ å°„ä¸ºä¸€ç³»åˆ—è¿›ç¨‹ç»„ï¼ˆdata / model / pipeline groupsï¼‰ï¼Œè§£å†³â€œç®—åŠ›å’Œæ˜¾å­˜å¦‚ä½•åœ¨ç»´åº¦ä¹‹é—´åˆ†é…â€çš„é—®é¢˜ã€‚(people.eecs.berkeley.edu)\nå¼ é‡å¹¶è¡Œ Transformer å±‚æ¨¡å—ï¼šæ²¿ç”¨ Megatron-LM çš„åˆ—å¹¶è¡Œ / è¡Œå¹¶è¡Œçº¿æ€§å±‚è®¾è®¡ï¼Œåœ¨å¤š GPU ä¸Šåˆ†ç‰‡ QKV / FFN æƒé‡ï¼Œå¹¶æ’å…¥å¿…è¦çš„ all-reduce / all-gather é€šä¿¡ï¼Œè§£å†³â€œå•å±‚æƒé‡è¿‡å¤§ï¼Œå•å¡æ”¾ä¸ä¸‹â€çš„é—®é¢˜ã€‚(people.eecs.berkeley.edu)\næµæ°´å¹¶è¡Œåˆ‡åˆ†ä¸è°ƒåº¦æ¨¡å—ï¼šæŠŠ N å±‚ Transformer å‡åŒ€åˆ‡åˆ†ä¸ºå¤šä¸ª pipeline stageï¼Œå¹¶å®ç° GPipeã€PipeDream-Flushï¼ˆ1F1Bï¼‰å’Œ interleaved 1F1B ä¸‰å¥—è°ƒåº¦é€»è¾‘ï¼Œè§£å†³â€œå¤šæœºè·¨å±‚ä¸²è¡Œå¯¼è‡´é—²ç½®â€çš„é—®é¢˜ã€‚(people.eecs.berkeley.edu)\næ•°æ®å¹¶è¡Œä¸æ¢¯åº¦èšåˆæ¨¡å—ï¼šåœ¨æ¯ä¸ª PT é…ç½®ä¸‹å†å¤åˆ¶è‹¥å¹²æ•°æ®å¹¶è¡Œå‰¯æœ¬ï¼Œé€šè¿‡é«˜æ•ˆçš„ data-parallel all-reduceï¼ˆå…¸å‹å°±æ˜¯ NCCL AllReduceï¼‰åŒæ­¥æ¢¯åº¦ï¼Œè§£å†³â€œå¤§ batch è®­ç»ƒç¨³å®šæ€§ä¸ååâ€çš„é—®é¢˜ã€‚(people.eecs.berkeley.edu)\næ˜¾å­˜ä¸é€šä¿¡ä¼˜åŒ–æ¨¡å—ï¼šåˆ©ç”¨æ··åˆç²¾åº¦ã€æ¿€æ´»é‡è®¡ç®—ã€é€šä¿¡ overlap å’Œæ‹“æ‰‘æ„ŸçŸ¥æ˜ å°„ï¼Œä¿è¯ï¼š1ï¼‰ç»å¤§éƒ¨åˆ† kernel å¤„äº compute-bound çŠ¶æ€ï¼›2ï¼‰æ•°æ®å¹¶è¡Œ / æµæ°´å¹¶è¡Œé€šä¿¡å°½é‡åœ¨è®¡ç®—ä¹‹ä¸‹â€œåŸ‹æ‰â€ã€‚(people.eecs.berkeley.edu)\nå¹¶è¡Œé…ç½®ä¸ç»éªŒå‡†åˆ™æ¨¡å—ï¼šè®ºæ–‡æœ€åæ€»ç»“çš„â€œç»éªŒå…¬å¼â€å’Œ heuristicsï¼Œç”¨æ¥æŒ‡å¯¼å¦‚ä½•é€‰æ‹© TP/PP/DP å› å­ã€micro-batch å¤§å°ç­‰ï¼Œå®é™…å°±æ˜¯ä¸€å¥—â€œäººè‚‰ auto-parallel tunerâ€ã€‚(people.eecs.berkeley.edu)\n\n3.2 æ•°æ®æµä¸æ§åˆ¶æµ\nä»å·¥ç¨‹è§†è§’çœ‹ï¼Œä¸€æ¬¡è®­ç»ƒè¿­ä»£å¯ä»¥åˆ†è§£ä¸ºå¦‚ä¸‹æ­¥éª¤ï¼ˆå¯ä»¥ç›´æ¥æ®æ­¤ç”»æ—¶åºå›¾æˆ– Mermaid æµç¨‹å›¾ï¼‰ï¼š\n\næ•°æ®é¢„å¤„ç†ä¸åˆ†ç‰‡\n\næ–‡æœ¬æ•°æ®ç¦»çº¿åˆ†è¯ã€chunk åŒ–ä¸ºå›ºå®šé•¿åº¦åºåˆ—ï¼ˆä¾‹å¦‚ GPT é£æ ¼çš„ packed datasetï¼‰ã€‚\nè®­ç»ƒå‰é€šè¿‡ index mapping æŠŠå…¨å±€æ ·æœ¬ç´¢å¼•æŒ‰æ•°æ®å¹¶è¡Œ rank å‡åŒ€åˆ‡åˆ†ï¼Œå½¢æˆæ¯ä¸ª DP rank çš„æœ¬åœ° shardã€‚(people.eecs.berkeley.edu)\n\nDataLoader + DistributedSampler\n\nå„ DP rank ä½¿ç”¨åˆ†å¸ƒå¼ Sampler è¿­ä»£è‡ªå·±çš„ shardï¼Œå¾—åˆ°ä¸€ä¸ª global batchã€‚\nglobal batch è¢«è¿›ä¸€æ­¥æ‹†åˆ†ä¸º \\(m\\) ä¸ª micro-batchï¼Œç”¨äºæµæ°´å¹¶è¡Œçš„ç®¡çº¿å¡«å……ã€‚\n\nä¸‰ç»´å¹¶è¡Œè¾“å…¥æ˜ å°„\n\nå¯¹äºæŸä¸ª DP rank å†…çš„ä¸€ä¸ª micro-batchï¼š\n\næ²¿æµæ°´çº¿ç»´åº¦ï¼ˆPPï¼‰æŠŠ micro-batch äº¤ç»™ç¬¬ä¸€ä¸ª stageã€‚\næ²¿å¼ é‡å¹¶è¡Œç»´åº¦ï¼ˆTPï¼‰ï¼Œæ¯ä¸ªå¼ é‡åˆ†ç‰‡åªæ¥æ”¶è‡ªå·±é‚£ä¸€ä»½è¾“å…¥å¼ é‡ï¼ˆä¾‹å¦‚åˆ—å¹¶è¡Œçº¿æ€§å±‚æ¯å¡æ‹¿åˆ°è¾“å…¥çš„å…¨éƒ¨ï¼Œä½†æƒé‡åªæ˜¯åˆ—åˆ†ç‰‡ï¼‰ã€‚(people.eecs.berkeley.edu)\n\n\nå‰å‘ä¼ æ’­ï¼ˆinterleaved 1F1B è°ƒåº¦ï¼‰\n\nè¿›å…¥ warmup åŒºæ®µï¼šä¸åŒ stage æ‰§è¡Œä¸åŒæ•°ç›®çš„ forwardï¼Œä»¥å¡«æ»¡æ•´æ¡ pipelineã€‚\nè¿›å…¥ steady åŒºæ®µï¼šæ¯ä¸ª stage æŒ‰â€œ1 ä¸ª forward + 1 ä¸ª backwardâ€çš„ 1F1B pattern å·¥ä½œï¼Œä½†è¿™é‡Œçš„â€œ1 ä¸ª stageâ€å·²ç»è¢«æ‹†æˆå¤šä¸ª model chunkï¼Œå½¢æˆ interleaved æ—¶é—´è¡¨ã€‚(people.eecs.berkeley.edu)\nåœ¨ TP ç»´åº¦å†…éƒ¨ï¼Œå‰å‘ä¸­çš„çº¿æ€§ / attention å±‚ä¼šæ’å…¥ all-reduce / all-gatherï¼Œé€šå¸¸é™åˆ¶åœ¨å•æœº NVLink å†…ã€‚\n\nåå‘ä¼ æ’­ä¸æ¢¯åº¦åŒæ­¥\n\næ¯ä¸ª micro-batch åœ¨ç®¡çº¿å°¾éƒ¨å®Œæˆ loss è®¡ç®—ï¼ŒæŠŠæ¢¯åº¦å‘å‰ä¸€ç«™ä¸€ç«™ä¼ å›å»ã€‚\næ¯ä¸ª TP åˆ†ç‰‡åœ¨æœ¬æœºå†…å®Œæˆå¼ é‡å¹¶è¡Œç›¸å…³çš„ all-reduce åï¼Œå¾—åˆ°å±€éƒ¨ shard æ¢¯åº¦ã€‚\nDP ç»´åº¦å¯¹æ‰€æœ‰ replica çš„å‚æ•°æ¢¯åº¦åšä¸€æ¬¡ data-parallel all-reduceï¼Œä¿è¯æ‰€æœ‰å‰¯æœ¬æƒé‡ä¸€è‡´ã€‚(people.eecs.berkeley.edu)\n\nå‚æ•°æ›´æ–°ä¸ç®¡çº¿ flush\n\nå½“æœ¬ batch çš„æ‰€æœ‰ micro-batch éƒ½å®Œæˆ forward+backward åï¼Œåœ¨ pipeline flush ä½ç½®ç»Ÿä¸€åšä¸€æ¬¡ optimizer stepï¼ˆä¾‹å¦‚ AdamWï¼‰ï¼Œä»¥ä¿æŒä¸¥æ ¼çš„åŒæ­¥è¯­ä¹‰ã€‚\nç”±äº interleaved 1F1B å‡å°‘äº† bubbleï¼Œflush å‘ç”Ÿå¾—æ›´æ—©ï¼Œæ•´ä½“ idle æ—¶é—´ä¸‹é™ã€‚(people.eecs.berkeley.edu)\n\nç»Ÿè®¡ä¸ç›‘æ§\n\nåœ¨è®­ç»ƒå¾ªç¯ä¸­æŒç»­ç»Ÿè®¡ per-GPU FLOPsã€é€šä¿¡å¸¦å®½ä½¿ç”¨ã€æ¿€æ´»æ˜¾å­˜ã€stage åˆ©ç”¨ç‡ç­‰æŒ‡æ ‡ï¼Œç”¨äºåç»­è°ƒå‚ä¸æ•…éšœæ’æŸ¥ã€‚(people.eecs.berkeley.edu)\n\n\n3.3 å…³é”®å‡è®¾ä¸é€‚ç”¨èŒƒå›´\n\nå‡è®¾ï¼šé›†ç¾¤å…·å¤‡é«˜å¸¦å®½ã€ä½å»¶è¿Ÿçš„ GPU é—´äº’è¿\n\nè®ºæ–‡å®éªŒåŸºäº NVLink/NVSwitchï¼ˆå•æœºï¼‰+ é«˜é€Ÿ InfiniBandï¼ˆè·¨æœºï¼‰ï¼Œæ•°æ®å¹¶è¡Œå’Œæµæ°´çº¿é€šä¿¡ä½¿ç”¨äº†æ¥è¿‘ TB/s çº§åˆ«çš„æœ‰æ•ˆå¸¦å®½ã€‚(people.eecs.berkeley.edu)\nè‹¥æ¢æˆæ™®é€šä»¥å¤ªç½‘æˆ–è€æ—§äº’è¿ï¼ŒTP/PP ä¹‹é—´çš„æœ€ä½³åˆ†é…ç‚¹ä¼šæ˜¾è‘—æ”¹å˜ï¼Œç”šè‡³å¯èƒ½éœ€è¦æ›´é‡çš„è®¡ç®—-é€šä¿¡ overlap æˆ–å‹ç¼©ï¼Œå¦åˆ™ååå¯èƒ½å¤§å¹…è·Œè½ã€‚\n\nå‡è®¾ï¼šæ¨¡å‹ç»“æ„ä¸»è¦æ˜¯å‡åŒ€å †å çš„ Transformer block\n\nPTD-P å’Œ interleaved åˆ‡åˆ†å‡å‡è®¾å„ä¸ª block è®¡ç®—é‡æ¥è¿‘ï¼Œå¯ä»¥ç®€å•â€œå‡åˆ†å±‚æ•°â€å®ç°è´Ÿè½½å‡è¡¡ã€‚(people.eecs.berkeley.edu)\nå¯¹äºå«æœ‰å¤§é‡å¼‚æ„æ¨¡å—ï¼ˆå¦‚è¶…å¤§ embeddingã€MoEã€decoder-only + å¤æ‚å¤´éƒ¨ï¼‰çš„æ¨¡å‹ï¼Œå¦‚æœä¸åšé¢å¤–çš„å±‚çº§é‡åˆ†é…ä¸ profileï¼Œå®¹æ˜“åœ¨æµæ°´çº¿æŸäº› stage å‡ºç°æ˜æ˜¾ç“¶é¢ˆã€‚\n\nå‡è®¾ï¼šé‡‡ç”¨æ··åˆç²¾åº¦ã€æ¿€æ´»é‡è®¡ç®—ç­‰æ˜¾å­˜ä¼˜åŒ–æ‰‹æ®µ\n\nè®ºæ–‡çš„ 1T æ¨¡å‹è®­ç»ƒé»˜è®¤ä½¿ç”¨ mixed precision å’Œ activations recomputeï¼Œå¦åˆ™æ˜¾å­˜å¾ˆéš¾æ”¯æ’‘å¤š micro-batch + å¤š stage çš„ç»„åˆã€‚(people.eecs.berkeley.edu)\nåœ¨åªç”¨ FP32 ä¸”ä¸å¼€é‡è®¡ç®—çš„ç¯å¢ƒä¸‹ï¼Œpipeline æ·±åº¦å’Œ micro-batch æ•°é‡å¿…é¡»æ˜¾è‘—æ”¶ç¼©ï¼Œbubble ç†è®ºåˆ†æä»æˆç«‹ï¼Œä½†å¯é€‰çš„å·¥ä½œç‚¹ä¼šå¤§å¹…å—é™ã€‚\n\nå‡è®¾ï¼šé‡‡ç”¨ä¸¥æ ¼åŒæ­¥çš„ä¼˜åŒ–å™¨è¯­ä¹‰\n\nPTD-P å§‹ç»ˆåœ¨ pipeline flush å¤„æ‰åšä¸€æ¬¡æƒé‡æ›´æ–°ï¼Œä¸ä½¿ç”¨å»¶è¿Ÿæˆ–å¼‚æ­¥æ›´æ–°ã€‚(people.eecs.berkeley.edu)\nå¦‚æœæ”¹ç”¨ PipeDream-2BW ç­‰å…è®¸ stale weights çš„æ–¹æ¡ˆï¼Œè™½ç„¶å¯ä»¥è¿›ä¸€æ­¥ç¼©çŸ­ bubbleï¼Œä½†ä¼šå¼•å…¥è®­ç»ƒç¨³å®šæ€§å’Œæ”¶æ•›è¡Œä¸ºçš„ä¸ç¡®å®šæ€§ï¼Œéœ€è¦é¢å¤–å®éªŒæ”¯æ’‘ã€‚(NVIDIA Developer)\n\n\n3.4 æ•°å­¦å…¬å¼ä¸ç®—æ³•è§£è¯»\nè®ºæ–‡çš„æ–¹æ³•éƒ¨åˆ†åŒ…å«äº†ä¸€äº›å…³äº pipeline bubble ä¸ interleaved è°ƒåº¦ çš„å®šé‡åˆ†æï¼Œè¿™é‡Œé€‰ä¸¤ç»„å…³é”®å…¬å¼åšè§£è¯»ã€‚å…¬å¼çš„å½¢å¼å¿ å®äºåŸæ–‡ï¼Œä½†è®²è§£éƒ¨åˆ†æ˜¯ç­‰ä»·é‡å†™ã€‚(people.eecs.berkeley.edu)\n3.4.1 GPipe è°ƒåº¦çš„ pipeline bubble åˆ†æ\nåŸæ–‡ä¸­çš„å…¬å¼ï¼šç®¡çº¿ç©ºæ³¡å æ¯”\nåœ¨ GPipe é£æ ¼çš„ â€œall-forward-then-all-backwardâ€ è°ƒåº¦ä¸‹ï¼Œè®¾ï¼š\n\n\\(m\\)ï¼šä¸€ä¸ª batch å†…çš„ micro-batch æ•°é‡ã€‚\n\\(p\\)ï¼špipeline stage æ•°ï¼ˆä½¿ç”¨å¤šå°‘è®¾å¤‡åšæµæ°´å¹¶è¡Œï¼‰ã€‚\n\\(t_f\\)ï¼šå•ä¸ª micro-batch çš„å‰å‘æ—¶é—´ã€‚\n\\(t_b\\)ï¼šå•ä¸ª micro-batch çš„åå‘æ—¶é—´ã€‚\n\nåˆ™ï¼š\n\næ‰¹å¤„ç†çš„ç†æƒ³è®¡ç®—æ—¶é—´ä¸º $ t_{} = m (t_f + t_b) $\npipeline bubble çš„æ—¶é—´ä¸º $ t_{} = (p - 1)(t_f + t_b) $\nbubble å ç†æƒ³æ—¶é—´çš„æ¯”ä¾‹ä¸º \\[\n\\text{BubbleFrac} = \\frac{t_{\\text{pb}}}{t_{\\text{id}}}\n= \\frac{p-1}{m}.\n\\](people.eecs.berkeley.edu)\n\nå«ä¹‰ä¸ç›´è§‚ç†è§£\n\nè¿™ç»„å…¬å¼è§£å†³çš„é—®é¢˜ï¼šåœ¨ç»™å®š stage æ•° \\(p\\) å’Œ micro-batch æ•° \\(m\\) æ—¶ï¼Œpipeline èµ·åœé˜¶æ®µâ€œç™½ç™½ç©ºè½¬â€çš„æ—¶é—´å æ¯”æ˜¯å¤šå°‘ã€‚\nå…³é”®ç»“è®ºï¼šæƒ³è®© bubble å°ï¼Œå°±è¦è®© \\(m \\gg p\\)ï¼Œå³â€œmicro-batch æ•°è¿œå¤§äº pipeline æ·±åº¦â€ã€‚\n\nç›´è§‚ç‰ˆæ“ä½œæè¿°\n\nå…ˆæŠŠä¸€ä¸ªå¤§ batch æ‹†æˆå¾ˆå¤š micro-batchã€‚\npipeline çš„æœ€å‰å‡ ä¸ªæ—¶é—´æ­¥é‡Œï¼Œä¸‹æ¸¸ device ä¸€ç›´åœ¨ç­‰ä¸Šæ¸¸çš„ç¬¬ä¸€æ‰¹æ•°æ® â€”â€” è¿™å°±æ˜¯å‰åŠæ®µ bubbleã€‚\nç­‰æ‰€æœ‰ micro-batch éƒ½æµå®Œï¼Œæœ€åå‡ ä¸ªæ—¶é—´æ­¥é‡Œï¼Œä¸Šæ¸¸ device å·²ç»æ²¡æ´»å¹²ï¼Œä¸‹æ¸¸è¿˜åœ¨å¤„ç†å°¾å·´ â€”â€” è¿™æ˜¯ååŠæ®µ bubbleã€‚\næ€»ä½“æ¥è¯´ï¼Œbubble çš„é•¿åº¦å°±æ˜¯â€œä¸¤ç«¯å„ç©ºè½¬ \\((p-1)\\) æ­¥â€çš„æ—¶é—´ä¹‹å’Œï¼Œå¹³å‡åˆ°æ•´ä¸ª batch ä¸Šå°±æ˜¯ \\(\\frac{p-1}{m}\\)ã€‚\n\n3.4.2 Interleaved 1F1B è°ƒåº¦çš„ bubble æ”¹è¿›\nåŸæ–‡ä¸­çš„å…¬å¼ï¼šinterleaved ä¹‹åçš„ bubble å æ¯”\nåœ¨ interleaved 1F1B è°ƒåº¦ä¸­ï¼Œæ¯å— GPU ä¸åªè´Ÿè´£ä¸€æ®µè¿ç»­å±‚ï¼Œè€Œæ˜¯è¢«åˆ‡æˆ \\(v\\) ä¸ªåŒ…å«æ›´å°‘å±‚çš„â€œmodel chunksâ€ï¼Œæ¢å¥è¯è¯´ æ¯ä¸ª device ä¸Šæœ‰ \\(v\\) ä¸ª pipeline stageã€‚\nåœ¨è¿™æ ·çš„æƒ…å†µä¸‹ï¼Œè®ºæ–‡ç»™å‡ºçš„ç»“æœæ˜¯ï¼ˆè¿™é‡Œå½¢å¼ä¸Šç­‰ä»·äºåŸæ–‡çš„æ¨å¯¼ï¼‰ï¼š(people.eecs.berkeley.edu)\n\næ¯ä¸ª chunk çš„å‰å‘ / åå‘æ—¶é—´è¿‘ä¼¼å˜ä¸º \\(t_f / v\\)ã€\\(t_b / v\\)ã€‚\nbubble æ—¶é—´å˜ä¸ºï¼š \\[\nt^{\\text{int}}_{\\text{pb}} = \\frac{(p-1)(t_f + t_b)}{v}\n\\]\nå¯¹åº”çš„ bubble å æ¯”ä¸ºï¼š \\[\n\\text{BubbleFrac}^{\\text{int}}\n= \\frac{t^{\\text{int}}*{\\text{pb}}}{t*{\\text{id}}}\n= \\frac{1}{v} \\cdot \\frac{p-1}{m}.\n\\]\n\nå«ä¹‰ä¸ç›´è§‚ç†è§£\n\nç›¸å½“äºæŠŠåŸæ¥çš„â€œ\\(p\\) ä¸ª big-stage pipelineâ€ç»†åˆ†æˆâ€œ\\(p \\cdot v\\) ä¸ªå° stageâ€ï¼Œä½†è¿™äº›å° stage è¢«â€œæ‰“åŒ…åˆ†é…â€åˆ°åŒä¸€å— GPU ä¸Šé¡ºåºæ‰§è¡Œã€‚\næ—¶é—´è½´ä¸Šï¼Œpipe flush ä¼šæ›´æ—©åœ°å‘ç”Ÿï¼Œç›¸å½“äºâ€œç”¨æ›´å¯†é›†çš„è®¡ç®—å—å¡«è¡¥äº†åŸæ¥ä¸¤ç«¯çš„ç©ºæ´â€ï¼Œbubble è¢«ç¼©çŸ­äº†çº¦ \\(v\\) å€ã€‚\n\nä»£ä»·ä¸æƒè¡¡\n\nè¿™å¹¶ä¸æ˜¯å…è´¹çš„ï¼šç”±äºä¸€ä¸ª micro-batch è¦ç»è¿‡æ›´å¤š stageï¼Œstage ä¹‹é—´çš„æ¿€æ´»é€šä¿¡æ¬¡æ•°ä¹Ÿä¼šå¢åŠ  \\(v\\) å€ã€‚è®ºæ–‡æŒ‡å‡ºï¼Œå¯¹åº”çš„é€šä¿¡é‡ä¹Ÿçº¿æ€§æ”¾å¤§ï¼Œéœ€è¦ä¾é å¤šç½‘å¡ / æ‹“æ‰‘æ„ŸçŸ¥é€šä¿¡æŠŠä»£ä»·å‹ä¸‹å»ã€‚(people.eecs.berkeley.edu)\n\n3.4.3 è®­ç»ƒæ—¶é—´ä¼°ç®—å…¬å¼\nè®ºæ–‡ä¸å®˜æ–¹åšå®¢è¿›ä¸€æ­¥ç»™å‡ºä¸€ä¸ªâ€œä¼°ç®—æ€»è®­ç»ƒæ—¶é—´â€çš„ç®€å•å…¬å¼ï¼ˆå¯¹å¤§æ¨¡å‹å¸¸è§ï¼‰ï¼š(NVIDIA Developer)\nè®¾ï¼š\n\n\\(P\\)ï¼šæ¨¡å‹å‚æ•°é‡ï¼›\n\\(T\\)ï¼šè®­ç»ƒ token æ€»æ•°ï¼›\n\\(N\\)ï¼šGPU æ•°é‡ï¼›\n\\(X\\)ï¼šå•å¡å®é™…ååï¼ˆTFLOP/sï¼‰ï¼›\n\nåˆ™è®­ç»ƒæ—¶é—´çº¦ä¸ºï¼š \\[\n\\text{TrainTime(sec)} \\approx 8 \\cdot \\frac{T \\cdot P}{N \\cdot X}.\n\\]\nè¿™ä¸ª \\(8\\) æ˜¯æŠŠä¸€æ¬¡å‰å‘ + åå‘çš„ FLOPs ç³»æ•°æŠ˜åˆåçš„è¿‘ä¼¼å› å­ï¼ˆå¯¹ GPT ç±»æ¨¡å‹å¸¸è§ä¼°è®¡ï¼‰ã€‚åœ¨å·¥ç¨‹å®è·µé‡Œï¼Œè¿™ä¸ªå…¬å¼å¯ä»¥ç”¨æ¥åšâ€œé¢„ç®—çº§â€ä¼°ç®—ï¼šç»™å®šæ¨¡å‹è§„æ¨¡ã€token æ•°å’Œé›†ç¾¤é…ç½®ï¼Œå¤§è‡´åˆ¤æ–­è¦è®­å‡ å‘¨ã€‚\n\nä¸å¸¸è§è®­ç»ƒæ ˆçš„å¯¹åº”å…³ç³»\nå¦‚æœæŠŠä¸Šé¢çš„æ¨¡å—æ”¾è¿›â€œæˆ‘çš„è®­ç»ƒæ ˆï¼ˆå¦‚ Megatron / DeepSpeed / vLLM ç­‰ï¼‰â€é‡Œï¼Œå¤§è‡´å¯ä»¥å¯¹åº”åˆ°ï¼š\n\nDataLoader / æ•°æ®é¢„å¤„ç†å±‚ï¼šè´Ÿè´£ global batch æ‹†åˆ†ã€åˆ†å¸ƒå¼é‡‡æ ·ã€packed dataset æ„å»ºï¼Œå¯¹åº”è®ºæ–‡é‡Œçš„æ•°æ®åˆ†ç‰‡ä¸ micro-batch æ‹†åˆ†é€»è¾‘ã€‚\nå¹¶è¡Œè°ƒåº¦å±‚ï¼ˆlauncher + parallel engineï¼‰ï¼šè´Ÿè´£æ„å»º PTD-P çš„è¿›ç¨‹ç»„ã€å†³å®š TP/PP/DP å› å­å’Œ rank æ˜ å°„ï¼Œå®ç°åœ¨é›†ç¾¤ä¸Šçš„ 3D å¹¶è¡Œå¸ƒå±€ã€‚\næ¨¡å‹å®šä¹‰å±‚ï¼ˆnn.Module + sharded layersï¼‰ï¼šå°† Transformer å±‚æ”¹å†™ä¸ºå¼ é‡å¹¶è¡Œç‰ˆæœ¬ï¼ˆåˆ—å¹¶è¡Œ/è¡Œå¹¶è¡Œçº¿æ€§ã€åˆ†ç‰‡ attention ç­‰ï¼‰ã€‚\né€šä¿¡ backend å±‚ï¼ˆNCCL / RCCL / è‡ªç ”ï¼‰ï¼šå®ç°æ•°æ®å¹¶è¡Œ all-reduceã€å¼ é‡å¹¶è¡Œ all-reduce / all-gather ä»¥åŠæµæ°´çº¿ stage ä¹‹é—´çš„ point-to-point ä¼ è¾“ã€‚\nkernel / ç®—å­ä¼˜åŒ–å±‚ï¼šä¸ºå¤§çŸ©é˜µä¹˜ã€softmaxã€layernorm ç­‰æä¾›é«˜æ•ˆ kernelï¼Œå¹¶é…åˆ activation recomputeï¼Œè®©å¤§éƒ¨åˆ† step å¤„äº compute-boundã€‚\nç›‘æ§ä¸è‡ªåŠ¨è°ƒå‚å±‚ï¼šæ”¶é›† per-stage ååã€bubble å æ¯”ã€é€šä¿¡å¸¦å®½ç­‰æŒ‡æ ‡ï¼Œæ ¹æ®è®ºæ–‡ heuristics è‡ªåŠ¨æœç´¢åˆé€‚çš„ TP/PP/DP ä¸ micro-batchã€‚\n\n\nå››ã€å»ºæ¨¡æ–¹å¼ä¸è¯„ä¼°æŒ‡æ ‡\n4.1 é—®é¢˜æ˜¯å¦‚ä½•å½¢å¼åŒ–çš„ï¼Ÿ\nä»ç³»ç»Ÿè§’åº¦çœ‹ï¼Œä½œè€…å…³å¿ƒçš„æ ¸å¿ƒä¼˜åŒ–ç›®æ ‡æ˜¯ï¼š\n\nåœ¨ç»™å®šçš„ GPU æ•°é‡ã€äº’è¿æ‹“æ‰‘å’Œæ¨¡å‹å‚æ•°è§„æ¨¡ä¸‹ï¼Œæœ€å°åŒ–è®­ç»ƒæ—¶é—´ / æœ€å¤§åŒ–å®é™… FLOPs åˆ©ç”¨ç‡ï¼ŒåŒæ—¶æ»¡è¶³æ˜¾å­˜çº¦æŸå’Œä¸¥æ ¼åŒæ­¥è¯­ä¹‰ã€‚(people.eecs.berkeley.edu)\n\nå¯ä»¥ç”¨ä¸¤ä¸ªå±‚æ¬¡æ¥ç†è§£å»ºæ¨¡æ–¹å¼ï¼š\n\nç®—åŠ›å±‚é¢ï¼š\n\nå¯¹äº GPT ç±»æ¨¡å‹ï¼Œä¸€æ¬¡å‰å‘+åå‘çš„ FLOPs å¤§çº¦å’Œ â€œå‚æ•°é‡ Ã— åºåˆ—é•¿åº¦ Ã— batch å¤§å°â€ æˆæ­£æ¯”ã€‚\nè‹¥å•å¡ååä¸º \\(X\\) TFLOP/sï¼Œæ€» FLOPs ä¸º \\(8TP\\)ï¼ˆå‰é¢å…¬å¼ä¸­çš„è¿‘ä¼¼ï¼‰ï¼Œç›®æ ‡å°±æ˜¯è®©å®é™…æµæ°´çº¿è°ƒåº¦ + é€šä¿¡å¼€é”€ä¸‹çš„æœ‰æ•ˆ \\(X\\) å°½å¯èƒ½æ¥è¿‘ç¡¬ä»¶å³°å€¼ã€‚(NVIDIA Developer)\n\nå¹¶è¡Œç­–ç•¥å±‚é¢ï¼š\n\nç»™å®š TP/PP/DP ä¸‰ä¸ªå¹¶è¡Œåº¦ \\((t, p, d)\\)ï¼Œä»¥åŠ micro-batch æ•° \\(m\\)ï¼Œå¯ä»¥åˆ†æå¯¹åº”çš„ bubble æ¯”ä¾‹ã€æ¿€æ´»æ˜¾å­˜å ç”¨å’Œé€šä¿¡é‡ï¼Œå¹¶é€šè¿‡å®éªŒæµ‹é‡å®é™…ååã€‚\nè®ºæ–‡æ²¡æœ‰æ„é€ ä¸€ä¸ªå®Œæ•´çš„å½¢å¼åŒ–æœ€ä¼˜åŒ–æ¨¡å‹ï¼Œè€Œæ˜¯æä¾›ä¸€ç³»åˆ—ç»éªŒè§„åˆ™æ¥é€‰å– â€œè¿‘ä¼¼æœ€ä¼˜â€ çš„ \\((t, p, d, m)\\) ç»„åˆã€‚(people.eecs.berkeley.edu)\n\n\nä¸»è¦ç®€åŒ–åŒ…æ‹¬ï¼š\n\næŠŠå¤§éƒ¨åˆ† kernel çœ‹æˆ compute-boundï¼Œå¿½ç•¥ç»†ç²’åº¦ cache è¡Œä¸ºç­‰å¤æ‚å› ç´ ï¼›\næŠŠ pipeline è°ƒåº¦çš„ä»£ä»·æŠ½è±¡ä¸º bubble + é€šä¿¡ï¼Œä¸¤è€…ä»¥ç®€å•å‚æ•°ï¼ˆå¦‚ \\(p, v, m\\)ï¼‰æ¥åˆ»ç”»ï¼›\nå‡è®¾ç›¸åŒ stage å†…çš„å±‚è®¡ç®—é‡åŸºæœ¬å‡åŒ€ï¼Œå¯å¿½ç•¥ load imbalanceã€‚\n\n4.2 æ ¸å¿ƒè¯„ä¼°æŒ‡æ ‡\nè®ºæ–‡åœ¨ç³»ç»Ÿè¯„ä¼°ä¸­ä½¿ç”¨äº†ä»¥ä¸‹å‡ ä¸ªå…³é”®æŒ‡æ ‡ï¼ˆæˆ‘ç”¨å·¥ç¨‹è§†è§’åšäº†é‡æ–°ç»„ç»‡ï¼‰ï¼š\n\nå•å¡å®é™…ååï¼ˆTFLOP/sï¼‰ä¸å³°å€¼å æ¯”\n\nç»Ÿè®¡åŒ…å«è®¡ç®—å’Œé€šä¿¡åœ¨å†…çš„ end-to-end FLOPs åˆ©ç”¨ç‡ï¼Œä¾‹å¦‚ 1T æ¨¡å‹åœ¨ 3072 A100 ä¸Šè¾¾åˆ°äº† 163 TFLOP/s / GPU â‰ˆ 52% å³°å€¼ã€‚(people.eecs.berkeley.edu)\nè¿™æ˜¯ç›´æ¥è¡¡é‡â€œè¿™å¥—å¹¶è¡Œ+è°ƒåº¦æŠŠç¡¬ä»¶å‹æ¦¨å¾—æ€ä¹ˆæ ·â€çš„æ ¸å¿ƒæŒ‡æ ‡ã€‚\n\nèšåˆååï¼ˆPetaFLOP/sï¼‰ä¸å¼±æ‰©å±•æ•ˆç‡\n\néšç€ GPU æ•°ä»å‡ åæ‰©å±•åˆ°å‡ åƒï¼Œæµ‹é‡æ€» petaFLOP/s ä¸ç†æƒ³çº¿æ€§æ‰©å±•çš„åå·®ã€‚(NVIDIA Developer)\nç”¨äºåˆ¤æ–­è¿™å¥—æ–¹æ¡ˆåœ¨å¤§è§„æ¨¡é›†ç¾¤ä¸Šçš„å¯æ‰©å±•æ€§ï¼Œç›´æ¥å¯¹åº”â€œèƒ½ä¸èƒ½è®­ 1T ç”šè‡³æ›´å¤§æ¨¡å‹â€ã€‚\n\npipeline bubble å æ¯”\n\nä½¿ç”¨å‰é¢æ¨å¯¼çš„ \\(\\frac{p-1}{m}\\) ä¸ \\(\\frac{1}{v}\\frac{p-1}{m}\\) ç­‰å…¬å¼æ¥ä¼°ç®—ä¸åŒè°ƒåº¦ä¸‹çš„ç†è®º bubbleï¼Œå¹¶é€šè¿‡æ—¶åºå›¾ï¼ˆæ—¶é—´è½´ï¼‰éªŒè¯ã€‚(people.eecs.berkeley.edu)\nä¸æµæ°´æ·±åº¦ã€micro-batch æ•°å’Œ interleaved åº¦æ•°ç›´æ¥å¯¹åº”ï¼Œæ˜¯ç†è§£ä¸ºä»€ä¹ˆ interleaved 1F1B æœ‰æ”¶ç›Šçš„å…³é”®ã€‚\n\næ˜¾å­˜å ç”¨ï¼ˆå‚æ•°ã€æ¿€æ´»ã€ä¼˜åŒ–å™¨çŠ¶æ€ï¼‰\n\nå¯¹æ¯” GPipe vs 1F1B vs interleaved ç­‰ä¸åŒæµæ°´è°ƒåº¦ä¸‹çš„æ¿€æ´»æ˜¾å­˜å³°å€¼ï¼›åŒæ—¶ä¸ ZeRO-3 ç­‰â€œåˆ‡å‚æ•°+ä¼˜åŒ–å™¨â€çš„æ–¹æ¡ˆç›¸æ¯”ã€‚(people.eecs.berkeley.edu)\nå¸®åŠ©è¯»è€…ç†è§£â€œæ˜¾å­˜æ˜¯è¢«å‚æ•°åƒæ‰äº†è¿˜æ˜¯è¢«æ¿€æ´»åƒæ‰äº†â€ï¼Œå¯¹å®é™…å·¥ç¨‹é‡Œè°ƒ activation recomputeã€checkpoint éå¸¸æœ‰æŒ‡å¯¼æ„ä¹‰ã€‚\n\né€šä¿¡å¸¦å®½æ¶ˆè€—ï¼ˆpipeline / data parallel ä¸¤ç±»ï¼‰\n\nè®ºæ–‡ç»™å‡ºäº†è®­ç»ƒ 1T æ¨¡å‹æ—¶ pipeline é€šä¿¡å’Œ data-parallel é€šä¿¡çš„æœ‰æ•ˆ bisection å¸¦å®½ï¼ˆå¦‚æ•°ç™¾ GB/s vs æ•°å TB/s çº§åˆ«ï¼‰ï¼Œä»¥å±•ç¤ºé€šä¿¡å·²ç»æ˜¯ç¬¬ä¸€ç­‰å…¬æ°‘ã€‚(people.eecs.berkeley.edu)\nè¿™ä¸€æŒ‡æ ‡ä¸é›†ç¾¤ç½‘ç»œé…ç½®ï¼ˆç½‘å¡æ•°é‡ã€æ‹“æ‰‘ã€æ‹¥å¡æ§åˆ¶ï¼‰å¼ºç›¸å…³ï¼Œæ˜¯è¿ç§»åˆ°è‡ªå·±æœºæˆ¿æ—¶å¿…é¡»æ ¸å¯¹çš„æ•°å­—ã€‚\n\n\n\näº”ã€ä¸»è¦å®éªŒå‘ç°\n\nä¸‰ç»´å¹¶è¡Œï¼ˆPTD-Pï¼‰åœ¨å¤§è§„æ¨¡é›†ç¾¤ä¸Šå®ç°äº†æ¥è¿‘çº¿æ€§çš„æ‰©å±•ï¼šåœ¨ 3072 å— A100 ä¸Šï¼Œ1T å‚æ•° GPT æ¨¡å‹çš„æ€»ååè¾¾åˆ° 502 PFLOP/sï¼Œå•å¡çº¦ 163 TFLOP/sï¼Œæ˜¾ç¤ºåœ¨é«˜å¸¦å®½äº’è¿ä¸‹ TP+PP+DP çš„ç»„åˆå¯ä»¥å……åˆ†åƒæ»¡ç¡¬ä»¶ã€‚(people.eecs.berkeley.edu)\ninterleaved 1F1B è°ƒåº¦åœ¨å¤šç§é…ç½®ä¸‹å¸¦æ¥äº† 10% ä»¥ä¸Šçš„ååæå‡ï¼šåœ¨ä¿æŒæ˜¾å­˜å ç”¨æ¥è¿‘ä¸å˜çš„å‰æä¸‹ï¼Œé€šè¿‡æŠŠæ¯å— GPU åˆ‡æˆå¤šä¸ª model chunkï¼Œç¼©çŸ­äº† pipeline flush çš„æ—¶é—´ï¼Œä»è€Œå‡å°‘äº† idleã€‚(people.eecs.berkeley.edu)\nTP ä¸ PP çš„ç»„åˆæ–¹å¼å¯¹æ€§èƒ½å½±å“å·¨å¤§ï¼šè®ºæ–‡æ˜¾ç¤ºï¼Œä¸€äº›â€œçœ‹èµ·æ¥åˆç†â€çš„ TP/PP å› å­åœ¨ä¸Šåƒ GPU æ—¶ä¼šå¯¼è‡´æœ€å¤š 2Ã— çš„ååæŸå¤±ï¼Œä¸»è¦åŸå› æ˜¯è·¨èŠ‚ç‚¹çš„å¼ é‡å¹¶è¡Œ all-reduce æˆæœ¬è¿‡é«˜ã€‚å°† TP é™åˆ¶åœ¨å•æœºå†…ã€æŠŠè·¨æœºç»´åº¦ç•™ç»™ PP æ˜¯å®è·µä¸­éå¸¸å…³é”®çš„ç»éªŒã€‚(people.eecs.berkeley.edu)\nåˆé€‚çš„ micro-batch å¤§å°å¯ä»¥å†æŒ–å‡º 10%ï½15% çš„æ”¶ç›Šï¼šmicro-batch å¤ªå°ï¼Œkernel æ— æ³•è¢«å……åˆ†å¡«æ»¡ï¼›å¤ªå¤§åˆä¼šæ”¾å¤§ pipeline bubble æˆ–å‡»ç©¿æ˜¾å­˜ã€‚è®ºæ–‡çš„å®è¯è¡¨æ˜ï¼Œâ€œæœ€ä½³ micro-batchâ€ æ˜¯ä¸€ä¸ªå¼ºçƒˆä¾èµ–æ¨¡å‹è§„æ¨¡å’Œå¹¶è¡Œé…ç½®çš„è¶…å‚ã€‚(people.eecs.berkeley.edu)\nä¸ ZeRO-3 ç­‰çº¯ DP+å‚æ•°åˆ‡åˆ†æ–¹æ¡ˆç›¸æ¯”ï¼ŒPTD-P åœ¨ç™¾äº¿ï½åƒäº¿è§„æ¨¡ä¸Šæœ‰æ˜æ˜¾ä¼˜åŠ¿ï¼šåœ¨ 175B å’Œ 530B æ¨¡å‹ä¸Šï¼Œä¸ ZeRO-3 å¯¹æ¯”ï¼ŒPTD-P æ–¹æ¡ˆåœ¨ç›¸åŒè®¾å¤‡æ•°ä¸‹ååé«˜çº¦ 70%ï¼Œå…³é”®å·®å¼‚åœ¨äºå‡å°‘äº†è·¨èŠ‚ç‚¹å¤§è§„æ¨¡å‚æ•°åŒæ­¥ã€‚(people.eecs.berkeley.edu)\n\n5.1 å…³é”®å›¾è¡¨è§£è¯»\n\nä¸‹åˆ—å›¾è¡¨æè¿°åŸºäºè®ºæ–‡å’Œå®˜æ–¹åšå®¢ä¸­çš„å†…å®¹ï¼Œå…·ä½“æ•°å€¼ä»¥åŸæ–‡ä¸ºå‡†ã€‚\n\n\nå›¾ï¼šèšåˆåå vs GPU æ•°é‡ä¸æ¨¡å‹è§„æ¨¡\n\nç°è±¡ï¼šä»çº¦ 1.7B å‚æ•°æ¨¡å‹åœ¨ 32 GPUï¼Œä¸Šå‡åˆ° 1T æ¨¡å‹åœ¨ 3072 GPUï¼Œæ€»ååä»æ•° PFLOP/s æå‡åˆ° 502 PFLOP/sï¼Œæ•´ä½“æ‰©å±•æ•ˆç‡è¶…è¿‡ 100Ã—ã€‚(NVIDIA Developer)\næ”¯æ’‘çš„è§‚ç‚¹ï¼šè¯´æ˜ PTD-P æ¶æ„åœ¨ç°å®ç¡¬ä»¶ä¸ç½‘ç»œæ¡ä»¶ä¸‹å¯ä»¥ç¨³å½“æ‰©å±•åˆ°ä¸‡äº¿çº§æ¨¡å‹ï¼Œä¸ºåæ¥å„ç§ 500B / 1T æ¨¡å‹æä¾›äº†å¯è¡Œæ€§è¯æ˜ã€‚\n\nå›¾ï¼šGPipe vs 1F1B vs Interleaved 1F1B è°ƒåº¦æ—¶é—´çº¿\n\nç°è±¡ï¼š\n\nGPipeï¼šå…ˆæ‰§è¡Œæ‰€æœ‰ micro-batch çš„ forwardï¼Œå†æ‰§è¡Œæ‰€æœ‰ backwardï¼Œbubble å¤§ä¸”æ¿€æ´»æ˜¾å­˜å ç”¨é«˜ã€‚\n1F1Bï¼ˆPipeDream-Flushï¼‰ï¼šwarmup + steady äº¤æ›¿ F/Bï¼Œbubble ä¸ GPipe ç›¸åŒï¼Œä½†æ¿€æ´»æ˜¾å­˜å³°å€¼æ˜¾è‘—é™ä½ã€‚\ninterleaved 1F1Bï¼šæŠŠæ¯ä¸ª device ä¸Šçš„å±‚åˆ‡æˆå¤šä¸ª chunkï¼Œæ—¶é—´è½´ä¸Š flush ç‚¹æ˜æ˜¾æå‰ï¼Œbubble é•¿åº¦ç¼©çŸ­ã€‚(people.eecs.berkeley.edu)\n\næ”¯æ’‘çš„è§‚ç‚¹ï¼šè§£é‡Šäº†ä¸ºä»€ä¹ˆåœ¨ç›¸åŒæ˜¾å­˜é¢„ç®—ä¸‹ï¼Œinterleaved è°ƒåº¦å¯ä»¥é¢å¤–å†åƒæ‰ä¸€éƒ¨åˆ† bubbleï¼Œä»è€Œå¤šæ‹¿ä¸€æˆªååã€‚\n\nè¡¨ï¼šä¸åŒ TP/PP/DP é…ç½®ä¸‹çš„ååå¯¹æ¯”\n\nç°è±¡ï¼šä¾‹å¦‚åœ¨ 175B / 530B æ¨¡å‹ä¸Šï¼Œä½¿ç”¨æ›´é«˜çš„ TPï¼ˆè·¨èŠ‚ç‚¹ï¼‰ä¼šæ˜¾è‘—æ¶åŒ–ååï¼Œè€Œå¢åŠ  PP æ·±åº¦å¹¶é™åˆ¶ TP åœ¨å•æœºå†…åˆ™èƒ½æŒç»­é è¿‘çº¿æ€§æ‰©å±•ã€‚(people.eecs.berkeley.edu)\næ”¯æ’‘çš„è§‚ç‚¹ï¼šå®šé‡å±•ç¤ºäº†â€œTP å°½é‡å±€é™åœ¨å•æœºã€PP è´Ÿè´£è·¨æœºæ‰©å±•â€çš„å®è·µå‡†åˆ™ï¼Œåé©³äº†â€œTP è¶Šå¤§è¶Šå¥½â€çš„ç›´è§‰ã€‚\n\n\nç»“æœè§£è¯»ä¸è¾¹ç•Œ\næ€»ä½“æ¥çœ‹ï¼Œè¿™äº›å®éªŒéå¸¸æœ‰åŠ›åœ°æ”¯æ’‘äº†è®ºæ–‡çš„ä¸¤ä¸ªæ ¸å¿ƒç»“è®ºï¼š 1ï¼‰ä¸‰ç»´å¹¶è¡Œ + interleaved è°ƒåº¦åœ¨ç°å®å¤§é›†ç¾¤ä¸Šæ˜¯å¯è½åœ°ä¸”é«˜æ•ˆçš„ï¼› 2ï¼‰TP/PP/DP å’Œ micro-batch çš„ç»„åˆæœ‰ä¸€å¥—å¯å¤ç”¨çš„ç»éªŒè§„åˆ™ã€‚\nä½†ä¹Ÿæœ‰ä¸€äº›æ˜æ˜¾çš„è¾¹ç•Œä¸æ½œåœ¨æ··æ·†å› ç´ ï¼š\n\nå®éªŒä¸»è¦åŸºäº A100 + NVLink + é«˜é€Ÿ InfiniBand çš„â€œè±ªåé…ç½®â€ï¼Œåœ¨æ™®é€šä»¥å¤ªç½‘ç¯å¢ƒä¸‹çš„å¯è¿ç§»æ€§éœ€è¦é¢å¤–å®éªŒã€‚\nç›®æ ‡ä»»åŠ¡åå‘ GPT ç±»è‡ªå›å½’ LLMï¼Œå°šæœªç³»ç»Ÿè¦†ç›– MoEã€encoder-decoderã€å¤šæ¨¡æ€ç­‰æ¶æ„ã€‚\nå¯¹æ”¶æ•›è´¨é‡ä¸ç¨³å®šæ€§çš„åˆ†æç›¸å¯¹ç®€ç•¥ï¼ˆå°¤å…¶æ˜¯å¯¹äºæå¤§ batchã€æ¿€è¿› pipeline æ·±åº¦çš„è®¾ç½®ï¼‰ï¼Œåœ¨â€œåªçœ‹ throughput ä¸çœ‹ lossâ€çš„åœºæ™¯é‡Œå¯èƒ½ä¼šè¢«è¯¯ç”¨ã€‚\n\n\nå…­ã€ä¼˜ç‚¹ä¸å±€é™\näº®ç‚¹ï¼ˆStrengthsï¼‰\n\né—®é¢˜å®šä¹‰æ¸…æ™°ä¸”è´´è¿‘å·¥ä¸šå®è·µï¼šç›´æ¥ç„å‡†â€œå¦‚ä½•é«˜æ•ˆè®­ç»ƒ 1T æ¨¡å‹â€çš„ç³»ç»Ÿé—®é¢˜ï¼Œè€Œä¸æ˜¯æŠ½è±¡çš„ç†è®ºæ¨¡å‹ï¼Œéå¸¸å¥‘åˆå½“ä¸‹å¤§æ¨¡å‹è®­ç»ƒéœ€æ±‚ã€‚(arXiv)\næ–¹æ³•è®¾è®¡ç³»ç»Ÿä¸”ç»„åˆæ€§å¼ºï¼šé€šè¿‡ PTD-P æŠŠ TP / PP / DP æœ‰æœºåœ°æ‹¼åœ¨ä¸€èµ·ï¼Œå¹¶ç»™å‡º interleaved 1F1B è¿™æ ·å¯ç›´æ¥åœ¨ç°æœ‰æ¡†æ¶ä¸­å®ç°çš„è°ƒåº¦æ”¹è¿›ã€‚\nåˆ†æä¸å·¥ç¨‹ç»†èŠ‚å…¼é¡¾ï¼šæ—¢æœ‰ bubble å…¬å¼ã€é€šä¿¡é‡ç­‰ç†è®ºåˆ†æï¼Œåˆç»™å‡ºäº† network bandwidth ä½¿ç”¨ã€kernel bound/ memory bound åˆ¤å®šç­‰éå¸¸â€œå·¥ç¨‹å‘³â€çš„æŒ‡æ ‡ã€‚(people.eecs.berkeley.edu)\nå®éªŒè§„æ¨¡ä¸è¯´æœåŠ›ï¼šåœ¨ 3072 A100 ä¸Šè®­ç»ƒ 1T æ¨¡å‹çš„ç»“æœæœ¬èº«å°±å…·æœ‰å¾ˆå¼ºçš„â€œç¤ºèŒƒæ•ˆåº”â€ï¼Œä¹Ÿä¸ºåç»­å·¥ä½œæä¾›äº†å¯¹æ ‡åŸºçº¿ã€‚(people.eecs.berkeley.edu)\nå¼€æºå®ç°å¯ç›´æ¥å‚è€ƒï¼šåŸºäº Megatron-LM çš„å…¬å¼€ä»£ç è®©è¯»è€…å¯ä»¥ç›´æ¥å¯¹ç…§å®ç°ç»†èŠ‚ã€å¤ç°å®éªŒç”šè‡³æ‰©å±•è‡ªå·±çš„å¹¶è¡Œç­–ç•¥ã€‚(GitHub)\n\nå±€é™ï¼ˆLimitationsï¼‰\n\nä¾èµ–é«˜ç«¯ç¡¬ä»¶ä¸ç½‘ç»œç¯å¢ƒï¼šå‡ ä¹æ‰€æœ‰å…³é”®ç»“è®ºéƒ½æ˜¯åœ¨ NVLink + é«˜é€Ÿ InfiniBand çš„å‰æä¸‹ç»™å‡ºçš„ï¼Œå¯¹â€œæ™®é€šæœºæˆ¿é…ç½®â€çš„é€‚ç”¨æ€§éœ€è¦è°¨æ…è§£è¯»ã€‚\næ¨¡å‹ç±»å‹ç›¸å¯¹å•ä¸€ï¼šä¸»è¦èšç„¦ GPT ç±» dense Transformerï¼Œå¯¹ MoEã€sparse attentionã€encoder-decoder ç­‰ç»“æ„ç¼ºä¹ç³»ç»Ÿå®éªŒã€‚\nç¼ºå°‘è‡ªåŠ¨å¹¶è¡Œæœç´¢æœºåˆ¶ï¼šè™½ç„¶ç»™å‡ºäº† heuristicsï¼Œä½†å¹¶æ²¡æœ‰ç±»ä¼¼ FlexFlow / Alpa é‚£æ ·çš„è‡ªåŠ¨æ¢ç´¢æœºåˆ¶ï¼Œå®é™…ä½¿ç”¨ä»éœ€è¦å¤§é‡ç»éªŒå’Œäººå·¥è°ƒå‚ã€‚(people.eecs.berkeley.edu)\nè®­ç»ƒè´¨é‡åˆ†æä¸å¤Ÿæ·±å…¥ï¼šæ›´åé‡ç³»ç»ŸæŒ‡æ ‡ï¼ˆthroughputã€åˆ©ç”¨ç‡ç­‰ï¼‰ï¼Œå¯¹ä¸åŒå¹¶è¡Œç­–ç•¥ / batch é…ç½®ä¸‹æ”¶æ•›é€Ÿåº¦ä¸æœ€ç»ˆç²¾åº¦çš„å½±å“è®¨è®ºæœ‰é™ã€‚\nä¸ ZeRO / FSDP ç­‰å‚æ•°åˆ‡åˆ†æŠ€æœ¯çš„ç»„åˆç©ºé—´æœªå®Œå…¨å±•å¼€ï¼šåªç»™å‡ºäº†ä¸€äº›å¯¹æ¯”ç»“æœï¼Œä½†æ²¡æœ‰æ·±å…¥æ¢è®¨â€œPTD-P + ZeRO-likeâ€çš„å¯èƒ½ç»„åˆã€‚(people.eecs.berkeley.edu)\n\n\nä¸ƒã€ä¸šå†…ç›¸å…³å·¥ä½œå¯¹æ¯”\nè¿™é‡Œé€‰ä¸‰ç±»å…¸å‹å·¥ä½œåšæ¨ªå‘å¯¹æ¯”ï¼šMegatron-LMï¼ˆåŸå§‹å¼ é‡å¹¶è¡Œï¼‰ã€GPipeï¼ˆæµæ°´å¹¶è¡Œï¼‰å’Œ ZeRO ç³»åˆ—ï¼ˆæ•°æ®å¹¶è¡Œ + å‚æ•°åˆ‡åˆ†ï¼‰ã€‚\n\n\n\n\n\n\n\n\n\nå·¥ä½œ\né—®é¢˜èšç„¦\næ–¹æ³•è·¯çº¿\nä¸æœ¬æ–‡å…³ç³»ä¸è¯„ä»·\n\n\n\n\nMegatron-LM (2019) (arXiv)\nå•æœºå¤šå¡ã€æ˜¾å­˜ä¸è¶³æ—¶å¦‚ä½•é€šè¿‡ intra-layer å¼ é‡å¹¶è¡Œè®­ç»ƒ 10B çº§ Transformer\nä¸»è¦é€šè¿‡åˆ—å¹¶è¡Œ / è¡Œå¹¶è¡Œçº¿æ€§å±‚ + all-reduce/all-gatherï¼Œåœ¨ 8 GPU å†…å®ç°æ•°åäº¿å‚æ•°æ¨¡å‹\næœ¬æ–‡åœ¨æ­¤åŸºç¡€ä¸Šæ‰©å±•åˆ°â€œå¤šæœº+æ›´å¤š GPUâ€ï¼Œå¹¶é¦–æ¬¡ç³»ç»Ÿæ€§æ¢ç´¢ TP ä¸ PPã€DP çš„ç»„åˆï¼Œæ˜¯ä»â€œå•æœºå¼ é‡å¹¶è¡Œâ€åˆ°â€œä¸‰ç»´å¹¶è¡Œâ€çš„è‡ªç„¶æ¼”è¿›\n\n\nGPipe (2019) (fid3024.github.io)\nå¦‚ä½•é€šè¿‡æµæ°´å¹¶è¡Œè®­ç»ƒè¶…å¤§æ¨¡å‹å¹¶ä¿æŒåŒæ­¥è¯­ä¹‰\nå°†æ¨¡å‹åˆ‡ä¸ºå¤šä¸ª stageï¼Œé€šè¿‡ micro-batch æµæ°´ + activation recompute å®ç°é«˜æ•ˆ pipeline\næœ¬æ–‡ç»§æ‰¿ GPipe çš„åŒæ­¥è¯­ä¹‰ä¸ batch splitting æ€è·¯ï¼Œä½†åœ¨è°ƒåº¦ä¸Šæ”¹ç”¨ PipeDream-Flush / interleaved 1F1Bï¼Œä»¥é™ä½æ¿€æ´»æ˜¾å­˜å’Œ bubbleï¼Œæ˜¯æ›´å·¥ç¨‹åŒ–çš„â€œç¬¬äºŒä»£æµæ°´æ–¹æ¡ˆâ€\n\n\nZeRO / ZeRO-Offload / ZeRO-3 (arXiv)\né€šè¿‡å‚æ•° / æ¢¯åº¦ / ä¼˜åŒ–å™¨çŠ¶æ€åˆ‡åˆ† + offload åœ¨ DP æ¡†æ¶ä¸‹æ”¯æ’‘è¶…å¤§æ¨¡å‹\nåœ¨æ•°æ®å¹¶è¡Œç»´åº¦ä¸Šå¯¹å‚æ•°ä¸ä¼˜åŒ–å™¨è¿›è¡Œç»†ç²’åº¦åˆ†ç‰‡ï¼Œå¹¶å¯å°†éƒ¨åˆ†çŠ¶æ€ offload åˆ° CPU/NVMe\nZeRO ç³»åˆ—å¼ºè°ƒâ€œDP+å‚æ•°åˆ‡åˆ†â€è·¯çº¿ï¼Œæœ¬å·¥ä½œå±•ç¤ºäº†åœ¨ 175B/530B è§„æ¨¡ä¸Š PTD-P å¯¹ ZeRO-3 çš„æ€§èƒ½ä¼˜åŠ¿ï¼›ä¸¤è€…åœ¨ç†å¿µä¸Šæ˜¯äº’è¡¥çš„ï¼Œåç»­ä¹Ÿå¯ä»¥æ¢ç´¢ PTD-P ä¸ ZeRO/FSDP çš„ç»„åˆ\n\n\n\næ€»ä½“æ¥è¯´ï¼Œè¿™ç¯‡ SCâ€™21 è®ºæ–‡æ›´åƒæ˜¯â€œå¼ é‡å¹¶è¡Œ + æµæ°´å¹¶è¡Œ + æ•°æ®å¹¶è¡Œâ€è¿™æ¡è·¯çº¿çš„é˜¶æ®µæ€§é›†å¤§æˆè€…ï¼Œä¸ ZeRO/FSDP ç­‰â€œå‚æ•°åˆ‡åˆ†â€è·¯çº¿å±äºå¯äº’è¡¥ã€å¯å¯¹æ¯”çš„ä¸¤æ¡ä¸»çº¿ã€‚\n7.1 ä¸ªäººè§‚ç‚¹\nä» reviewer çš„è§†è§’çœ‹ï¼Œè¿™ç¯‡å·¥ä½œåœ¨ baseline é€‰æ‹©ä¸å®éªŒè®¾ç½®ä¸Šè¿˜æ˜¯æ¯”è¾ƒè°¨æ…çš„ï¼šå¯¹æ¯”äº† ZeRO-3 ç­‰å½“æ—¶ä¸»æµæ–¹æ¡ˆï¼Œä¹Ÿç»™å‡ºäº†è¾ƒå®Œæ•´çš„ç¼©æ”¾æ›²çº¿ã€‚ä½†å¦‚æœè¿›ä¸€æ­¥æŠ ç»†èŠ‚ï¼Œæˆ‘ä¼šå¸Œæœ›çœ‹åˆ°ï¼š\n\næ›´å¤šå…³äºâ€œåŒç­‰æ˜¾å­˜é¢„ç®—â€çš„å¯¹æ¯”ï¼Œä¾‹å¦‚åœ¨ç›¸åŒæ˜¾å­˜å³°å€¼è€Œéç›¸åŒè®¾å¤‡æ•°é‡ä¸‹ PTD-P vs ZeRO/FSDP çš„ååå·®å¼‚ï¼›\nå¯¹è®­ç»ƒç¨³å®šæ€§å’Œ sample efficiency çš„æ›´ç»†ç²’åº¦åˆ†æï¼Œå°¤å…¶æ˜¯æå¤§ batchã€ææ·± pipeline æ—¶æ˜¯å¦éœ€è¦é¢å¤–æŠ€å·§ï¼ˆLR scheduleã€optimizer scaling ç­‰ï¼‰ã€‚\n\nå¦‚æœç”±æˆ‘æ¥è®¾è®¡ä¸€ç‰ˆâ€œå‡çº§ç‰ˆâ€å®éªŒï¼Œæˆ‘å¯èƒ½ä¼šï¼š\n\nåŠ å…¥ä¸åŒç½‘ç»œæ‹“æ‰‘ï¼ˆä¾‹å¦‚åªç”¨ 100GbEã€RoCEï¼‰çš„å®éªŒï¼Œå¯¹ PTD-P çš„å¯è¿ç§»æ€§åšæ›´å…¨é¢çš„è¯„ä¼°ï¼›\nç³»ç»Ÿæ¢ç´¢ â€œPTD-P + å‚æ•°åˆ‡åˆ†ï¼ˆZeRO/FSDPï¼‰â€ çš„ç»„åˆç©ºé—´ï¼Œçœ‹æ˜¯å¦å­˜åœ¨æ›´ä¼˜çš„ Pareto å‰æ²¿ç‚¹ï¼›\nåœ¨åŒä¸€å¥—ä»£ç æ¡†æ¶ä¸‹å…¬å¼€ä¸€ç»„â€œæ ‡å‡†é…ç½®â€ï¼ˆYAML/JSONï¼‰ï¼Œæ–¹ä¾¿ç¤¾åŒºç›´æ¥å¯¹æ ‡å’Œå¤ç°ã€‚\n\n\nå…«ã€åœ¨å®é™…è®­ç»ƒæ ˆä¸­å¦‚ä½•è½åœ°ï¼Ÿ\nå¦‚æœä½ å·²ç»æœ‰ä¸€å¥—è‡ªå·±çš„å¤§è§„æ¨¡è®­ç»ƒæ ˆï¼ˆä¾‹å¦‚åŸºäº Megatron / DeepSpeed / vLLM ç­‰ï¼‰ï¼Œè¦å¼•å…¥æœ¬æ–‡æ–¹æ³•ï¼Œå¤§è‡´å¯ä»¥ä»ä»¥ä¸‹å‡ ä¸ªæ–¹é¢æ”¹é€ ï¼š\n\nDataLoader / æ•°æ®æ‰“åŒ…ä¸é¢„å¤„ç†\n\nç¡®ä¿æ•°æ®å¯ä»¥è¢«ç¨³å®šåœ°åˆ’åˆ†ä¸ºå¤§çš„ global batch å’Œè¶³å¤Ÿå¤šçš„ micro-batchï¼Œä»¥æ»¡è¶³ \\(m \\gg p\\) çš„æ¡ä»¶ã€‚\nå¯¹ packed dataset åšå¥½â€œæ ·æœ¬åˆ° micro-batchâ€çš„æ˜ å°„å’Œé‡å¤åº¦æ§åˆ¶ï¼Œé¿å… pipeline æ·±åº¦å¼•å…¥éšå¼çš„ data skewã€‚\n\nå¹¶è¡Œè°ƒåº¦ï¼ˆTP/PP/DP ç»„åˆï¼‰\n\nåœ¨ launcher ç«¯æ˜¾å¼å¼•å…¥ä¸‰ç»´å¹¶è¡Œé…ç½®ï¼štensor_parallel_size, pipeline_model_parallel_size, data_parallel_sizeã€‚\nrank æ˜ å°„ä¸Šï¼Œä¼˜å…ˆä¿è¯ï¼šTP ç»´åº¦å®Œå…¨è½åœ¨å•æœºå†…ï¼ŒPP ç»´åº¦è·¨æœºï¼ŒDP å†è·¨æ›´å¤§èŒƒå›´ï¼›å¿…è¦æ—¶æ ¹æ®ç‰©ç†æ‹“æ‰‘ç¼–å†™è‡ªå®šä¹‰ rank -&gt; (dp,tp,pp) æ˜ å°„å‡½æ•°ã€‚(people.eecs.berkeley.edu)\nå·¥ç¨‹é£é™©ï¼šæ˜ å°„é”™è¯¯ä¼šç›´æ¥å¯¼è‡´â€œè·¨èŠ‚ç‚¹å¤§ all-reduceâ€ï¼Œæ€§èƒ½å¤§è·³æ°´ã€‚\n\nå¼ é‡å¹¶è¡Œç­–ç•¥ä¸ç®—å­å®ç°\n\næŠŠæ ¸å¿ƒæ¨¡å—ï¼ˆQKV projectionã€FFNã€embeddingã€LM head ç­‰ï¼‰æ”¹å†™ä¸ºå¼ é‡å¹¶è¡Œç‰ˆæœ¬ï¼Œåœ¨ TP ç»´åº¦ä¸Šæ’å…¥å¿…è¦çš„ all-reduce / all-gatherã€‚\nå¯¹äºâ€œéå¯¹ç§°æ¨¡å—â€ï¼ˆä¾‹å¦‚è¶…å¤§è¯è¡¨ embeddingã€MoE expertsï¼‰ï¼Œéœ€è¦å•ç‹¬ç­–ç•¥ï¼ˆå¦‚ vocabulary parallel embeddingã€expert parallel ç­‰ï¼‰ã€‚\né£é™©ï¼šå‚æ•°åˆå§‹åŒ–ã€checkpoint load/save éƒ½å¿…é¡»éµå¾ªç›¸åŒåˆ†ç‰‡è§„åˆ™ï¼Œå¦åˆ™ææ˜“åœ¨æ¢å¤è®­ç»ƒæ—¶è¸©é›·ã€‚\n\næµæ°´å¹¶è¡Œè°ƒåº¦ä¸é€šä¿¡\n\nåœ¨ pipeline ç»´åº¦å¼•å…¥ stage åˆ’åˆ†é€»è¾‘ï¼ŒæŠŠæ¨¡å‹åˆ†ä¸º num_layers / pipeline_size å·¦å³çš„å‡åŒ€å—ï¼›å†åŸºäº interleaved æ–¹æ¡ˆè¿›ä¸€æ­¥æŠŠæ¯å—æ‹†æˆå¤šä¸ª chunkã€‚\nå®ç° 1F1B å’Œ interleaved 1F1B è°ƒåº¦å™¨ï¼Œç¡®ä¿ï¼š\n\nflush ç‚¹ä¸€è‡´ï¼›\nä¸åŒ stage çš„ weight ç‰ˆæœ¬åœ¨ä¸€ä¸ª batch å†…ä¿æŒä¸¥æ ¼åŒæ­¥ã€‚\n\né£é™©ï¼šä¸€æ—¦è°ƒåº¦å™¨å®ç°æœ‰ bugï¼ˆä¾‹å¦‚æŸäº› micro-batch çš„ F/B é¡ºåºé”™ä½ï¼‰ï¼Œéå¸¸éš¾ä»¥æ’æŸ¥ï¼Œä¸”è¡¨è±¡å¾€å¾€åªæ˜¯â€œloss ä¸ç¨³å®šâ€ã€‚(people.eecs.berkeley.edu)\n\né€šä¿¡ backend ä¸ overlap\n\nåœ¨ NCCL åç«¯æ˜¾å¼åŒºåˆ†å‡ ç±»é€šä¿¡ï¼šTP all-reduceã€DP all-reduceã€PP P2Pï¼ˆsend/recvï¼‰ï¼Œå¹¶ç»™æ¯ç±»åˆ†é…ç‹¬ç«‹çš„ stream ä¸ä¼˜å…ˆçº§ã€‚\nå°è¯•æŠŠ DP all-reduce æ”¾åœ¨ backward tail éƒ¨åˆ†ä¸éƒ¨åˆ†è®¡ç®—é‡å ï¼ŒæŠŠ PP P2P ä¸ä¸‹ä¸€ä¸ª micro-batch çš„ F/B é‡å ã€‚\né£é™©ï¼šstream ä¾èµ–ä¸äº‹ä»¶ï¼ˆeventï¼‰åŒæ­¥å…³ç³»å¤æ‚ï¼Œå®¹æ˜“åŸ‹ race condition æˆ–æ­»é”ã€‚\n\næ˜¾å­˜ç®¡ç†ä¸ activation recompute\n\næ ¹æ®è®ºæ–‡å»ºè®®ï¼Œåœ¨è¾ƒæ·± pipeline è®¾ç½®ä¸‹ä¼˜å…ˆå¼€å¯ activation recomputeï¼ŒæŠŠæ¿€æ´»æ˜¾å­˜å³°å€¼ä» \\(O(mL)\\) å‹ç¼©åˆ° \\(O(p)\\) çº§åˆ«ã€‚(fid3024.github.io)\nå¯¹ä¸åŒ moduleï¼ˆattention / FFN / embeddingï¼‰è®¾ç½®ä¸åŒçš„ recompute ç­–ç•¥ï¼Œé¿å…æŠŠæ‰€æœ‰å±‚éƒ½é‡ç®—åˆ°å¯¼è‡´ç®—åŠ›æµªè´¹ã€‚\né£é™©ï¼šæ˜¾å­˜ç¢ç‰‡å’Œ allocator è¡Œä¸ºåœ¨å¤§è§„æ¨¡å¹¶è¡Œä¸‹ä¼šæ”¾å¤§ï¼Œéœ€è¦ä»”ç»†è§‚æµ‹ allocated / reserved / active ç­‰æŒ‡æ ‡ã€‚\n\né…ç½®æœç´¢ / è‡ªåŠ¨è°ƒå‚\n\næŠŠè®ºæ–‡ä¸­çš„ heuristics å°è£…ä¸ºä¸€ä¸ªâ€œå¹¶è¡Œé…ç½®å»ºè®®å™¨â€ï¼šç»™å®šæ¨¡å‹è§„æ¨¡ã€ç›®æ ‡åºåˆ—é•¿åº¦ã€è®¾å¤‡æ•°é‡ï¼Œè¾“å‡ºå€™é€‰ (tp, pp, dp, microbatch) ç»„åˆã€‚\nåœ¨ä¸Šçº¿å‰å¯¹è‹¥å¹²å€™é€‰é…ç½®è·‘çŸ­ç¨‹ benchmarkï¼ˆå‡ ååˆ°å‡ ç™¾ stepï¼‰ï¼Œæ ¹æ®å®é™…ååã€é€šä¿¡å æ¯”ã€æ˜¾å­˜å³°å€¼é€‰æ‹©æœ€ç»ˆé…ç½®ã€‚\n\n\n\nä¹ã€å€¼å¾—è¿›ä¸€æ­¥æ¢ç´¢çš„ç ”ç©¶æ–¹å‘\n\nè‡ªåŠ¨åŒ–ä¸‰ç»´å¹¶è¡Œæœç´¢ä¸ä»£ä»·æ¨¡å‹\n\né—®é¢˜ï¼šç›®å‰ PTD-P çš„é…ç½®ä¸»è¦åŸºäºç»éªŒå’Œå°‘é‡è¯•éªŒï¼Œç¼ºå°‘ç³»ç»ŸåŒ–çš„è‡ªåŠ¨æœç´¢ã€‚\nä»·å€¼ï¼šæ„å»ºä¸€ä¸ªé’ˆå¯¹ TP/PP/DP + micro-batch çš„ä»£ä»·æ¨¡å‹ï¼Œå†ç»“åˆå›¾æœç´¢æˆ–å¼ºåŒ–å­¦ä¹ ï¼Œåœ¨ç»™å®šé›†ç¾¤æ‹“æ‰‘å’Œæ¨¡å‹ç»“æ„ä¸‹è‡ªåŠ¨ç»™å‡ºè¿‘ä¼¼æœ€ä¼˜é…ç½®ï¼Œå¯ä»¥æ˜¾è‘—é™ä½å·¥ç¨‹äººå‘˜çš„è¯•é”™æˆæœ¬ã€‚(Deepak Narayanan)\n\nä¸å‚æ•°åˆ‡åˆ† / FSDP çš„æ·±åº¦èåˆ\n\né—®é¢˜ï¼šå½“å‰ PTD-P å’Œ ZeRO/FSDP å¤šä»¥â€œè°æ›´å¿«â€æ¥å¯¹æ¯”ï¼Œç¼ºä¹å¯¹ä¸¤è€…äº’è¡¥æ€§çš„ç³»ç»Ÿæ¢ç´¢ã€‚\nä»·å€¼ï¼šæ¢ç´¢åœ¨ PTD-P å¤–åˆå ä¸€å±‚å‚æ•°åˆ‡åˆ†ï¼ˆä¾‹å¦‚å¯¹åµŒå…¥å±‚æˆ–ä¼˜åŒ–å™¨çŠ¶æ€åš FSDP/ZeROï¼‰çš„æ··åˆæ–¹æ¡ˆï¼Œæœ‰æœ›åœ¨ä¿æŒé«˜ååçš„åŒæ—¶è¿›ä¸€æ­¥é™ä½æ˜¾å­˜å³°å€¼ï¼Œä½¿å¾—æ›´å¤§æ¨¡å‹åœ¨æ›´å°é›†ç¾¤ä¸Šå¯è¡Œã€‚(DeepSpeed)\n\né¢å‘éå‡åŒ€æ¨¡å‹ç»“æ„çš„è´Ÿè½½å‡è¡¡æµæ°´å¹¶è¡Œ\n\né—®é¢˜ï¼šç°å®å¤§æ¨¡å‹è¶Šæ¥è¶Šâ€œéå‡åŒ€â€ï¼Œä¾‹å¦‚ embedding ç‰¹åˆ«å¤§ã€éƒ¨åˆ† block å¸¦ MoEã€decoder head ç‰¹åˆ«é‡ï¼Œç®€å•çš„â€œå‡åˆ†å±‚æ•°â€ä¸å†åˆç†ã€‚\nä»·å€¼ï¼šåœ¨ PTD-P æ¡†æ¶ä¸‹å¼•å…¥è‡ªåŠ¨ partitionï¼ˆå¦‚åŸºäº profile çš„å›¾åˆ’åˆ†ï¼‰ï¼Œå¯¹ pipeline stage åšè´Ÿè½½å‡è¡¡ï¼Œå¯ä»¥æ˜¾è‘—é™ä½å• stage æˆä¸ºç“¶é¢ˆçš„æ¦‚ç‡ã€‚(pacman.cs.tsinghua.edu.cn)\n\né’ˆå¯¹å¼±äº’è¿é›†ç¾¤çš„é²æ£’å¹¶è¡Œç­–ç•¥\n\né—®é¢˜ï¼šå¾ˆå¤šå®é™…é›†ç¾¤å¹¶æ²¡æœ‰ NVLink + å¤šè·¯ InfiniBand è¿™ç§é…ç½®ï¼Œå¦‚ä½•åœ¨ 100GbE æˆ–å•è·¯ IB ä¸Šè·å¾—æœ‰æ„ä¹‰çš„æ‰©å±•ä»ä¸æ¸…æ¥šã€‚\nä»·å€¼ï¼šç ”ç©¶åœ¨å¼±äº’è¿åœºæ™¯ä¸‹ï¼Œå¦‚ä½•è°ƒæ•´ TP/PP/DP çš„åˆ†é…ã€åŠ å…¥é€šä¿¡å‹ç¼©/ç¨€ç– all-reduceã€å»¶è¿Ÿæ›´æ–°ç­‰æ‰‹æ®µï¼Œä½¿ PTD-P èƒ½åœ¨â€œå¹³ä»·é›†ç¾¤â€ä¸Šä¾ç„¶å®ç”¨ã€‚\n\nç«¯åˆ°ç«¯è®­ç»ƒç¨³å®šæ€§ä¸å¤§ batch æ”¶æ•›æ€§ç ”ç©¶\n\né—®é¢˜ï¼špipeline æ·±åº¦ã€interleaved åº¦æ•°ã€micro-batch å¤§å°éƒ½ä¼šå½±å“æœ‰æ•ˆ batch å’Œæ¢¯åº¦å™ªå£°ï¼Œä½†ç›®å‰åˆ†ææœ‰é™ã€‚\nä»·å€¼ï¼šç³»ç»Ÿåœ°ç ”ç©¶ä¸åŒå¹¶è¡Œé…ç½®å¯¹ loss æ›²çº¿ã€æ³›åŒ–æ€§èƒ½çš„å½±å“ï¼Œå¯ä»¥æŒ‡å¯¼åœ¨ä¸ç‰ºç‰²æ”¶æ•›è´¨é‡çš„å‰æä¸‹æ›´æ¿€è¿›åœ°æ¨å¤§ batch å’Œæ¨é«˜ååã€‚\n\n\n\nåã€çŸ¥è¯†å›¾è°±æ€ç»´é“¾\nä»â€œè„‘å†…çŸ¥è¯†å›¾è°±â€çš„è§’åº¦ï¼Œè¿™ç¯‡è®ºæ–‡åœ¨å¤šä¸ªæ–¹å‘ä¸Šéƒ½èµ·åˆ°äº†â€œè¿æ¥èŠ‚ç‚¹â€çš„ä½œç”¨ï¼š\n\nå¹¶è¡Œä¸è°ƒåº¦\n\næä¾›äº†ä¸€ä¸ªç»å…¸çš„ä¸‰ç»´å¹¶è¡Œ PTD-P æ¨¡å¼ï¼ŒæŠŠ TP/PP/DP ä¸‰ç§æ€è·¯ç»Ÿä¸€åœ¨ä¸€ä¸ªæ¡†æ¶ä¸‹ã€‚(people.eecs.berkeley.edu)\né€šè¿‡ GPipe â†’ PipeDream-Flush â†’ interleaved 1F1B çš„æ¼”è¿›ï¼Œç»™å‡ºäº†å¦‚ä½•åœ¨ä¿æŒåŒæ­¥è¯­ä¹‰çš„å‰æä¸‹æé™å‹ç¼© pipeline bubble çš„ç»“æ„åŒ–æ–¹æ³•ã€‚(people.eecs.berkeley.edu)\n\nå†…å­˜ç®¡ç†ä¸æ˜¾å­˜ä¼˜åŒ–\n\nç”¨ activation recompute + æ·± pipeline æ§åˆ¶æ¿€æ´»æ˜¾å­˜ï¼ŒæŠŠå¤§éƒ¨åˆ†æ˜¾å­˜é¢„ç®—ç•™ç»™å‚æ•°å’Œ optimizerã€‚(fid3024.github.io)\nä¸ ZeRO/FSDP ç³»åˆ—å½¢æˆäº†â€œæ¿€æ´» vs å‚æ•°ä¼˜åŒ–â€çš„ä¸¤æ¡äº’è¡¥è·¯çº¿ã€‚(arXiv)\n\né€šä¿¡ä¸é›†ä½“æ“ä½œ\n\næ˜ç¡®åŒºåˆ†äº† TP all-reduce / DP all-reduce / PP P2P ä¸‰ç±»é€šä¿¡ï¼Œå¹¶å¼ºè°ƒæ‹“æ‰‘æ„ŸçŸ¥æ˜ å°„å¯¹æ€§èƒ½çš„é‡è¦æ€§ã€‚(people.eecs.berkeley.edu)\né€šè¿‡å¯¹ bisection bandwidth ä½¿ç”¨çš„åˆ†æï¼ŒæŠŠâ€œç½‘ç»œâ€ä»è¾…åŠ©å› ç´ æå‡ä¸ºä¸€ç­‰å…¬æ°‘ã€‚\n\nkernel ä¸ç®—å­ä¼˜åŒ–\n\nè™½ç„¶ä¸æ˜¯æœ¬æ–‡é‡ç‚¹ï¼Œä½†ä½œè€…å¼ºè°ƒä¸ºäº†è®©è®­ç»ƒ compute-boundï¼Œéœ€è¦é«˜æ•ˆå®ç° GEMMã€Attentionã€LayerNorm ç­‰æ ¸å¿ƒç®—å­ï¼Œè¿™ä¸åç»­å„ç§ FlashAttentionã€fused-kernel å·¥ä½œæœ‰å¤©ç„¶è¿æ¥ã€‚(people.eecs.berkeley.edu)\n\næ¨¡å‹ç»“æ„ä¸æ¶æ„è®¾è®¡\n\né»˜è®¤åœºæ™¯æ˜¯å¤šå±‚å‡åŒ€çš„ GPT Transformerï¼Œè¿™å¯¹åæ¥çš„äººåœ¨è®¾è®¡â€œå¤§æ¨¡å‹ç»“æ„â€æ—¶æä¾›äº†ä¸€ä¸ªâ€œå¯¹ pipeline å‹å¥½â€çš„å‚è€ƒèŒƒå¼ã€‚\nä¹Ÿä¸ºåç»­ MoE / encoder-decoder ç­‰éå‡åŒ€æ¶æ„å¦‚ä½•åµŒå…¥ PTD-P æä¾›äº†å‡ºå‘ç‚¹ã€‚\n\næ•°æ®ã€é¢„å¤„ç†ä¸æ‰“åŒ…ç­–ç•¥\n\nå¼ºè°ƒ large batch + å¤š micro-batch å¯¹æµæ°´å¹¶è¡Œçš„å¿…è¦æ€§ï¼Œé—´æ¥æ¨åŠ¨äº†å¤§å®¶åœ¨æ•°æ®ç®¡çº¿ä¸­æ›´æ—©åœ°åš packed datasetã€åˆ†å¸ƒå¼ sampler ç­‰å·¥ç¨‹ä¼˜åŒ–ã€‚\n\n\n10.1 ä¸ªäººæ”¶è·ä¸åæ€\nå¯¹æˆ‘ä¸ªäººè€Œè¨€ï¼Œè¿™ç¯‡è®ºæ–‡æœ€å¤§çš„å¯å‘æœ‰ä¸¤ç‚¹ï¼š\n\næŠŠâ€œå¹¶è¡Œç­–ç•¥â€å’Œâ€œé›†ç¾¤æ‹“æ‰‘â€è§†ä½œä¸€ä¸ªæ•´ä½“æ¥ä¼˜åŒ– å¾ˆå¤šæ—¶å€™æˆ‘ä»¬åœ¨è®¨è®º TP/PP/DP æ—¶ä¼šâ€œå…ˆè®¾å®šé€»è¾‘å¹¶è¡Œåº¦ï¼Œå†å»é€‚é…ç¡¬ä»¶â€ï¼Œè€Œè¿™ç¯‡å·¥ä½œåè¿‡æ¥ï¼šå®ƒå…ˆçœ‹æ¸…æ¥š A100 + NVSwitch + InfiniBand çš„ç‰©ç†ç»“æ„ï¼Œå†è®¾è®¡ PTD-P çš„ rank æ˜ å°„å’Œé€šä¿¡è°ƒåº¦ã€‚è¿™ç§â€œç¡¬ä»¶é©±åŠ¨çš„è½¯ä»¶è®¾è®¡â€æ€è·¯ï¼Œå¯¹ä»»ä½•åšå¤§è§„æ¨¡ç³»ç»Ÿçš„äººéƒ½å¾ˆå€¼å¾—å€Ÿé‰´ã€‚\nç³»ç»Ÿå·¥ä½œä¹Ÿå¯ä»¥åšå¾—éå¸¸â€œå·¥ç¨‹å¯å¤ç”¨â€ è®ºæ–‡ä¸ä»…ä»…ç»™å‡ºç»“æœï¼Œè¿˜ç»™äº†æ¸…æ™°çš„ç»éªŒå‡†åˆ™å’Œå…¬å¼€å®ç°ï¼ˆMegatron-LMï¼‰ã€‚è¿™ä½¿å¾—å®ƒä¸ä»…æ˜¯ä¸€ä¸ªç ”ç©¶æˆæœï¼Œä¹Ÿæ˜¯ä¸€ä¸ªå¯ä»¥ç›´æ¥ç…§æ¬åˆ°è‡ªå·±è®­ç»ƒæ ˆçš„â€œæ“ä½œæ‰‹å†Œâ€ã€‚å¯¹æˆ‘åç»­è®¾è®¡è‡ªå·±è®­ç»ƒç³»ç»Ÿï¼ˆæ— è®ºæ˜¯åŸºäº Megatronã€è¿˜æ˜¯æ›´è½»é‡çš„æ ˆï¼‰éƒ½æä¾›äº†ä¸€ä¸ªéå¸¸å¥½çš„æ¨¡æ¿ï¼šä»»ä½•è®¾è®¡ï¼Œéƒ½å°½é‡æ²‰æ·€ä¸ºå¯å¤ç”¨çš„ä»£ç ä¸ heuristicsã€‚\n\nåœ¨å®è·µå±‚é¢ï¼Œæˆ‘ä¼šè€ƒè™‘ï¼š\n\nåœ¨è‡ªå·±çš„è®­ç»ƒæ ˆä¸­ï¼ŒæŠŠ pipeline è°ƒåº¦æŠ½è±¡æˆä¸€ä¸ªå¯æ’æ‹”æ¨¡å—ï¼Œå°è¯•ä»æœ€åŸºç¡€çš„ 1F1B å‡çº§åˆ° interleaved 1F1Bï¼Œè§‚å¯Ÿå¯¹æ˜¾å­˜å’Œååçš„å…·ä½“å½±å“ï¼›\nç³»ç»Ÿæ•´ç†ä¸€å¥—é’ˆå¯¹è‡ªå·±é›†ç¾¤çš„ â€œTP/PP/DP + micro-batch æ¨èè¡¨â€ï¼Œå¹¶åŠ å…¥ç®€å•çš„ profile é©±åŠ¨æœºåˆ¶ï¼Œé€æ­¥å‘â€œè‡ªåŠ¨é…ç½®â€æ¼”è¿›ã€‚\n\n\næ€»ä½“è¯„ä»·ï¼šè¿™ç¯‡ SCâ€™21 è®ºæ–‡åœ¨â€œå¦‚ä½•æŠŠ GPT ç±»å¤§æ¨¡å‹å¯é åœ°è®­åˆ° 1T å‚æ•°â€è¿™ä¸ªé—®é¢˜ä¸Šç»™å‡ºäº†éå¸¸ç³»ç»Ÿä¸”å¯è½åœ°çš„ç­”æ¡ˆï¼Œæ˜¯ç†è§£å½“ä»Šä¸»æµä¸‰ç»´å¹¶è¡Œè®­ç»ƒæ ˆï¼ˆå°¤å…¶æ˜¯ Megatron ç³»ï¼‰çš„å¿…è¯»æ–‡çŒ®ï¼Œæ›´åå·¥ç¨‹ä¸ç³»ç»Ÿä¼˜åŒ–ï¼Œå¯¹åšå¤§è§„æ¨¡è®­ç»ƒåŸºç¡€è®¾æ–½çš„è¯»è€…å°¤å…¶æœ‰é•¿æœŸå‚è€ƒä»·å€¼ã€‚\n\n","categories":["è®ºæ–‡é˜…è¯»"],"tags":["paper"]},{"title":"Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism","url":"/2025/11/22/paper/megatron_lm/","content":"\n\nåŸæ–‡ï¼šMegatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism Â· arXiv\n\nä¸€ã€è®ºæ–‡é€Ÿè§ˆ\nMegatron-LMè®ºæ–‡æå‡ºäº†ä¸€ç§åœ¨ç°æœ‰æ·±åº¦å­¦ä¹ æ¡†æ¶ä¸‹è®­ç»ƒè¶…å¤§è§„æ¨¡Transformerè¯­è¨€æ¨¡å‹çš„å®ç”¨æ–¹æ³•ã€‚ä½œè€…é€šè¿‡å±‚å†…æ¨¡å‹å¹¶è¡Œï¼ˆIntra-layer Model Parallelismï¼‰å°†å•ä¸ªTransformerå±‚çš„è®¡ç®—æ‹†åˆ†åˆ°å¤šä¸ªGPUä¸Šæ‰§è¡Œï¼Œä»¥çªç ´å•GPUå†…å­˜é™åˆ¶ã€‚è¿™ä¸€æ–¹æ³•ä»…éœ€åœ¨æ ‡å‡†PyTorchå®ç°ä¸­æ’å…¥å°‘é‡é€šä¿¡æ“ä½œï¼Œæ— éœ€å®šåˆ¶ç¼–è¯‘å™¨æˆ–åº•å±‚åº“ä¿®æ”¹ï¼Œä¾¿å®ç°äº†å¯¹æ•°åäº¿å‚æ•°æ¨¡å‹çš„é«˜æ•ˆè®­ç»ƒã€‚è®ºæ–‡ä»¥GPT-2å’ŒBERTä¸¤ç±»æ¨¡å‹ä¸ºä¾‹ï¼ŒæˆåŠŸåœ¨512å¼ GPUä¸Šè®­ç»ƒäº†çº¦83äº¿å‚æ•°çš„GPT-2æ¨¡å‹å’Œ39äº¿å‚æ•°çš„BERTæ¨¡å‹ï¼Œè¾¾åˆ°äº†å½“æ—¶æœ€å…ˆè¿›çš„æ€§èƒ½å’Œæ•ˆæœã€‚\nåœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œå·¥ç¨‹å®è·µæ˜¯æ ¸å¿ƒï¼šé€šè¿‡å·§å¦™åˆ©ç”¨å¼ é‡å¹¶è¡ŒæŠ€æœ¯ï¼ŒMegatron-LMå……åˆ†å‘æŒ¥äº†GPUé›†ç¾¤ç®—åŠ›ã€‚åœ¨ä¸ç‰ºç‰²è®¡ç®—ç²¾åº¦å’Œæ¨¡å‹æ”¶æ•›çš„å‰æä¸‹ï¼Œä½œè€…å®ç°äº†æ¥è¿‘çº¿æ€§çš„åŠ é€Ÿæ¯”å’Œé«˜è¾¾15.1 PetaFLOPsçš„æŒç»­è®¡ç®—ååã€‚æ›´é‡è¦çš„æ˜¯ï¼Œè®ºæ–‡å±•ç¤ºäº†æ¨¡å‹è§„æ¨¡ä¸æ€§èƒ½çš„è‰¯æ€§å…³ç³»ï¼šéšç€å‚æ•°å¢å¤šï¼Œè¯­è¨€æ¨¡å‹çš„å›°æƒ‘åº¦ï¼ˆperplexityï¼‰æ˜¾è‘—ä¸‹é™ï¼Œä¸‹æ¸¸ä»»åŠ¡å‡†ç¡®ç‡ç¨³æ­¥æå‡ã€‚æ­¤å¤–ï¼Œä½œè€…è¿˜å‘ç°å¯¹äºBERTè¿™ç±»åŒå‘Transformeræ¨¡å‹ï¼Œéœ€è¦å¯¹Layer Normalizationå±‚çš„æ’å…¥ä½ç½®è¿›è¡Œè°ƒæ•´ï¼Œä»¥ç¡®ä¿å¤§æ¨¡å‹è®­ç»ƒè¿‡ç¨‹çš„ç¨³å®šå’Œç²¾åº¦æå‡ã€‚\näºŒã€è®ºæ–‡ç»“æ„\nè®ºæ–‡é¦–å…ˆä»‹ç»äº†ç ”ç©¶èƒŒæ™¯å’ŒæŒ‘æˆ˜ï¼ŒåŒ…æ‹¬å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒçš„è¶‹åŠ¿ä»¥åŠè®­ç»ƒæ­¤ç±»æ¨¡å‹é¢ä¸´çš„å†…å­˜ç“¶é¢ˆï¼ˆç¬¬2èŠ‚ï¼‰ã€‚æ¥ä¸‹æ¥ï¼Œåœ¨æ–¹æ³•éƒ¨åˆ†ï¼ˆç¬¬3èŠ‚ï¼‰ï¼Œä½œè€…è¯¦ç»†æè¿°äº†Transformeræ¶æ„ä¸­çš„æ¨¡å‹å¹¶è¡Œå®ç°æ–¹æ¡ˆï¼Œè§£é‡Šå¦‚ä½•åœ¨ä¸æ”¹å˜æ¨¡å‹åŸºæœ¬ç»“æ„çš„æƒ…å†µä¸‹ï¼Œå°†æ¯ä¸€å±‚çš„è®¡ç®—åˆ†æ‘Šåˆ°å¤šä¸ªè®¾å¤‡ï¼Œå¹¶å®šä¹‰äº†ç›¸åº”çš„é€šä¿¡åŸè¯­ï¼ˆå¦‚All-Reduceï¼‰çš„ä½¿ç”¨ç­–ç•¥ã€‚ç„¶åï¼Œè®ºæ–‡è¿›å…¥å®éªŒè®¾ç½®å’Œç»“æœåˆ†æï¼ˆç¬¬4~5èŠ‚ï¼‰ï¼šä½œè€…ç»™å‡ºäº†æ¨¡å‹ä¸è®­ç»ƒé…ç½®ã€è¯„ä¼°æŒ‡æ ‡ï¼Œå¹¶é€šè¿‡ä¸€ç³»åˆ—å®éªŒå±•ç¤ºäº†æ‰€ææ–¹æ³•çš„æ‰©å±•æ€§å’Œæœ‰æ•ˆæ€§ã€‚å…¶ä¸­ï¼Œç¬¬5èŠ‚åˆ†åˆ«æŠ¥å‘Šäº†é’ˆå¯¹GPT-2ï¼ˆå•å‘è¯­è¨€æ¨¡å‹ï¼‰å’ŒBERTï¼ˆåŒå‘è¯­è¨€æ¨¡å‹ï¼‰çš„é¢„è®­ç»ƒç»“æœï¼Œä»¥åŠåœ¨WikiText103ã€LAMBADAã€RACEç­‰åŸºå‡†ä¸Šçš„æ€§èƒ½å¯¹æ¯”ã€‚æœ€åï¼Œç¬¬6èŠ‚æ€»ç»“äº†ä¸»è¦ç»“è®ºå¹¶è®¨è®ºäº†æœªæ¥å·¥ä½œã€‚\n\næ ¸å¿ƒæ€æƒ³ï¼šé€šè¿‡åœ¨Transformerå±‚å†…å¼•å…¥ç®€æ´é«˜æ•ˆçš„æ¨¡å‹å¹¶è¡Œå’Œé€šä¿¡æœºåˆ¶ï¼ŒMegatron-LMå®ç°äº†è¶…å¤§æ¨¡å‹çš„åˆ†å¸ƒå¼è®­ç»ƒï¼Œåœ¨ç°æœ‰è½¯ç¡¬ä»¶æ ˆä¸Šè¾¾æˆäº†å‰æ‰€æœªæœ‰çš„æ¨¡å‹è§„æ¨¡ä¸æ€§èƒ½æå‡ã€‚\n\nä¸‰ã€æ–¹æ³•ä¸ç³»ç»Ÿè®¾è®¡\næœ¬æ–‡æ–¹æ³•çš„æ ¸å¿ƒæ˜¯åœ¨ä¸æ”¹å˜æ¨¡å‹æ•´ä½“ç»“æ„çš„å‰æä¸‹ï¼Œå°†å•ä¸ªTransformerå±‚çš„è®¡ç®—åˆ’åˆ†åˆ°å¤šä¸ªGPUä¸Šå¹¶è¡Œæ‰§è¡Œã€‚å›´ç»•è¿™ä¸€ç›®æ ‡ï¼Œä½œè€…è§£å†³äº†è‹¥å¹²å­é—®é¢˜ï¼š\n\nå¦‚ä½•å¯¹Transformerçš„å…³é”®ç»„æˆï¼ˆè‡ªæ³¨æ„åŠ›å’Œå‰é¦ˆç½‘ç»œï¼‰è¿›è¡Œåˆ’åˆ†ï¼Œä»¥æœ€å°åŒ–è·¨GPUé€šä¿¡ï¼Ÿ\n\nå¦‚ä½•åœ¨PyTorchä¸­ç”¨å°‘é‡åŸç”Ÿæ“ä½œå®ç°ä¸Šè¿°å¹¶è¡Œè®¡ç®—ï¼Œå¹¶ç¡®ä¿è‡ªåŠ¨æ±‚å¯¼æ­£ç¡®å·¥ä½œï¼Ÿ\n\nå¦‚ä½•ä¸æ•°æ®å¹¶è¡Œã€æµæ°´å¹¶è¡Œç­‰å…¶ä»–å¹¶è¡ŒèŒƒå¼å…¼å®¹ï¼Œå……åˆ†åˆ©ç”¨å¤§å‹é›†ç¾¤çš„è®¡ç®—èƒ½åŠ›ï¼Ÿ\n\nå¦‚ä½•åœ¨ä¿æŒæ¨¡å‹ç²¾åº¦å’Œç¨³å®šæ€§çš„åŒæ—¶ï¼Œå®ç°è®¡ç®—ä¸é€šä¿¡çš„é«˜æ•ˆé‡å ï¼Ÿ\n\n3.1 æ ¸å¿ƒæ¨¡å—ä¸€è§ˆ\n\nå¼ é‡å¹¶è¡ŒTransformerå±‚ï¼šå°†Transformerå±‚å†…éƒ¨çš„å¤§çŸ©é˜µä¹˜æ³•æ‹†åˆ†åˆ°å¤šGPUæ‰§è¡Œã€‚ä¾‹å¦‚ï¼Œå°†è‡ªæ³¨æ„åŠ›å’Œå‰é¦ˆå±‚ä¸­çš„æƒé‡çŸ©é˜µæŒ‰åˆ—æˆ–è¡Œåˆ†å—ï¼Œæ¯ä¸ªGPUè´Ÿè´£ä¸€éƒ¨åˆ†è®¡ç®—ã€‚æ­¤æ¨¡å—çš„ä½œç”¨æ˜¯åœ¨ä¿è¯è®¡ç®—æ­£ç¡®æ€§çš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½å•GPUæ˜¾å­˜å ç”¨ï¼Œå­é—®é¢˜æ¶‰åŠå¦‚ä½•åˆ’åˆ†æƒé‡åŠé‡ç»„è¾“å‡ºã€‚\né€šä¿¡æ“ä½œæ¨¡å—ï¼šæä¾›å¿…è¦çš„GPUé—´é€šä¿¡åŸè¯­ï¼Œå¦‚All-Reduceï¼ˆå…¨å½’çº¦æ±‚å’Œï¼‰å’ŒAll-Gatherï¼ˆå…¨æ±‡é›†ï¼‰ã€‚è¿™äº›é€šä¿¡åœ¨å‰å‘æˆ–åå‘è¿‡ç¨‹ä¸­æ’å…¥ï¼Œç”¨äºæ±‡æ€»è·¨GPUçš„éƒ¨åˆ†ç»“æœæˆ–æ¢¯åº¦ã€‚æ¨¡å—ä½œç”¨æ˜¯åœ¨å¹¶è¡Œè®¡ç®—çš„å„å­éƒ¨åˆ†ä¹‹é—´ä¼ é€’ä¿¡æ¯ï¼Œå¯¹åº”çš„å­é—®é¢˜æ˜¯å¦‚ä½•å°†é€šä¿¡å¼€é”€é™åˆ°æœ€ä½å¹¶é¿å…é˜»å¡è®­ç»ƒæµç¨‹ã€‚\nå¹¶è¡Œè°ƒåº¦æ§åˆ¶ï¼šè´Ÿè´£åè°ƒå¤šGPUçš„æ‰§è¡Œé¡ºåºå’ŒåŒæ­¥ï¼ŒåŒ…æ‹¬åˆ’åˆ†æ•°æ®å¹¶è¡Œç»„ä¸æ¨¡å‹å¹¶è¡Œç»„ã€åœ¨ä¸åŒå¹¶è¡Œç»´åº¦é—´åˆ†é…è®¡ç®—ä»»åŠ¡ç­‰ã€‚å…¶ä½œç”¨æ˜¯ä¿éšœå„GPUæŒ‰è®¡åˆ’ååŒå·¥ä½œï¼Œå­é—®é¢˜åŒ…æ‹¬å¦‚ä½•è®¾è®¡åŒæ­¥ç‚¹ä»¥åŠé¿å…æ­»é”ã€‚\næ··åˆç²¾åº¦ä¸å†…å­˜ä¼˜åŒ–ï¼šåœ¨ä¿è¯è®­ç»ƒç¨³å®šçš„æƒ…å†µä¸‹ä½¿ç”¨åŠç²¾åº¦æµ®ç‚¹ï¼ˆFP16/BF16ï¼‰å’Œæ¢¯åº¦æ£€æŸ¥ç‚¹ç­‰æŠ€æœ¯æ¥è¿›ä¸€æ­¥é™ä½æ˜¾å­˜å ç”¨ã€æé«˜è¿ç®—æ•ˆç‡ã€‚è¯¥æ¨¡å—è¾…åŠ©å¤§è§„æ¨¡å¹¶è¡Œè®­ç»ƒé¡ºåˆ©è¿›è¡Œï¼Œæ¶‰åŠçš„å­é—®é¢˜æ˜¯å¦‚ä½•åœ¨å‡å°å†…å­˜çš„åŒæ—¶ä¸å¼•å…¥æ•°å€¼ä¸ç¨³å®šã€‚\n\n3.2 æ•°æ®æµä¸æ§åˆ¶æµ\næ•´ä¸ªæ¨¡å‹å¹¶è¡Œè®­ç»ƒæµç¨‹å¯ä»¥åˆ†ä¸ºä»¥ä¸‹ä¸»è¦æ­¥éª¤ï¼š\n\næ•°æ®åˆ†å‘ï¼šè®­ç»ƒå¼€å§‹æ—¶ï¼Œæ•°æ®åŠ è½½å™¨å°†æ¯ä¸ªmini-batchåˆ’åˆ†ç»™å„ä¸ªæ•°æ®å¹¶è¡Œç»„ï¼›åœ¨åŒä¸€æ•°æ®å¹¶è¡Œç»„å†…ï¼Œå±äºæ¨¡å‹å¹¶è¡Œç»„çš„å¤šä¸ªGPUæ¥æ”¶ç›¸åŒçš„è¾“å…¥å­æ‰¹ã€‚è¿™ä¿è¯äº†å¹¶è¡ŒGPUåœ¨å¤„ç†åŒä¸€ç»„æ ·æœ¬æ—¶æ‰€éœ€çš„ä¸€è‡´è¾“å…¥ã€‚\nå‰å‘ä¼ æ’­ï¼ˆæ¨¡å‹å¹¶è¡Œéƒ¨åˆ†ï¼‰ï¼šå¯¹äºTransformerçš„æ¯ä¸€å±‚ï¼Œæ‰§è¡Œä»¥ä¸‹å­æ­¥éª¤ï¼š\n\næ¯ä¸ªGPUæŒæœ‰è¯¥å±‚æƒé‡çš„ä¸€éƒ¨åˆ†ï¼ˆä¾‹å¦‚ï¼Œå°†æƒé‡çŸ©é˜µæ²¿åˆ—åˆ’åˆ†ä¸º\\(P\\)å—ï¼Œåˆ†é…ç»™\\(P\\)ä¸ªGPUï¼‰ã€‚å„GPUåŸºäºå®Œæ•´çš„è¾“å…¥æ¿€æ´»\\(X\\)ï¼Œå„è‡ªè®¡ç®—éƒ¨åˆ†çº¿æ€§å˜æ¢ï¼š\\(Y_i = X \\times A_i\\)ï¼ˆå…¶ä¸­\\(A_i\\)è¡¨ç¤ºGPU \\(i\\)ä¸Šçš„æƒé‡å­çŸ©é˜µï¼‰ã€‚å¯¹\\(Y_i\\)åº”ç”¨éçº¿æ€§æ¿€æ´»ï¼ˆå¦‚GeLUï¼‰å¾—åˆ°éƒ¨åˆ†è¾“å‡ºã€‚\nå°†ä¸Šè¿°éƒ¨åˆ†è¾“å‡º\\(Y_i\\)åœ¨GPUé—´è¿›è¡Œé€šä¿¡ç»„åˆã€‚å…·ä½“è€Œè¨€ï¼Œå¯¹å‰é¦ˆå±‚ç¬¬äºŒéƒ¨åˆ†çš„è®¡ç®—ï¼Œå„GPUè®¡ç®—è‡ªå·±çš„éƒ¨åˆ†è¾“å‡º\\(Z_i = Y_i \\times B_i\\)ï¼ˆè¿™é‡Œ\\(B_i\\)æ˜¯è¯¥GPUæŒæœ‰çš„ç¬¬äºŒä¸ªæƒé‡å­çŸ©é˜µï¼‰ã€‚éšåæ‰§è¡Œä¸€æ¬¡All-Reduceé€šä¿¡ï¼šå„GPUå°†\\(Z_i\\)ç›¸åŠ å¹¶åŒæ­¥å¾—åˆ°å®Œæ•´è¾“å‡º\\(Z = \\sum_{i=1}^{P} Z_i\\)ï¼Œå†è¿›å…¥åç»­å±‚ã€‚å¯¹äºè‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œé‡‡ç”¨ç±»ä¼¼ç­–ç•¥ï¼šå„GPUåˆ†åˆ«è®¡ç®—ä¸€éƒ¨åˆ†æ³¨æ„åŠ›å¤´çš„è¾“å‡ºï¼Œæœ€åé€šè¿‡é€šä¿¡æ•´åˆå¾—åˆ°å®Œæ•´çš„å¤šå¤´æ³¨æ„åŠ›ç»“æœã€‚\nï¼ˆå¯é€‰ï¼‰æ‰§è¡Œå…¶ä»–å¿…è¦æ“ä½œï¼ˆå¦‚Dropoutã€æ®‹å·®è¿æ¥å’ŒLayerNormï¼‰ï¼Œè¿™äº›æ“ä½œå¤§å¤šä¸éœ€è¦è·¨GPUé€šä¿¡æˆ–è€…é€šä¿¡å¼€é”€å¾ˆå°ã€‚è‡³æ­¤å®Œæˆå½“å‰å±‚çš„å‰å‘è®¡ç®—ï¼Œå†å°†ç»“æœä¼ é€’ç»™ä¸‹ä¸€å±‚é‡å¤ä¸Šè¿°è¿‡ç¨‹ã€‚\n\næŸå¤±è®¡ç®—ï¼šæ¨¡å‹æœ€åä¸€å±‚è¾“å‡ºç»è¿‡å¿…è¦çš„æ‹¼æ¥æˆ–èšåˆåï¼Œç”¨äºè®¡ç®—è¯­è¨€æ¨¡å‹çš„è®­ç»ƒç›®æ ‡ï¼ˆä¾‹å¦‚ï¼ŒGPT-2çš„è‡ªå›å½’ä¸‹ä¸€ä¸ªè¯é¢„æµ‹çš„äº¤å‰ç†µæŸå¤±æˆ–BERTçš„æ©ç è¯­è¨€æ¨¡å‹æŸå¤±ï¼‰ã€‚æŸå¤±æ ‡é‡åœ¨æ•°æ®å¹¶è¡Œç»´åº¦ä¸Šè¿›ä¸€æ­¥åšä¸€æ¬¡All-Reduceï¼Œä»¥ç¡®ä¿å„GPUä½¿ç”¨å…¨å±€ä¸€è‡´çš„æŸå¤±å€¼è¿›è¡Œæ¢¯åº¦è®¡ç®—ã€‚\nåå‘ä¼ æ’­ï¼šæŒ‰ç…§å±‚é¡ºåºåå‘ä¼ æ’­æ¢¯åº¦ã€‚åœ¨æ¯ä¸ªå¹¶è¡Œå±‚åä¼ æ—¶æ‰§è¡Œä¸å‰å‘å¯¹å¶çš„é€šä¿¡ï¼š\n\nå¯¹äºå‰å‘ä¸­é€šè¿‡All-Reduceèšåˆçš„è¾“å‡ºï¼Œåœ¨åå‘ä¸­å„GPUä¼šæ”¶åˆ°ç›¸åŒçš„æ¢¯åº¦\\(\\partial Z\\)ï¼Œå› æ­¤ä¸éœ€è¦å†é€šä¿¡ï¼ˆç›¸å½“äºå‰å‘é€šä¿¡çš„â€œä¼´éšâ€æ“ä½œåœ¨åå‘æ˜¯æ’ç­‰ä¼ é€’ï¼‰ã€‚\nå¯¹äºå‰å‘ä¸­æœªé€šä¿¡è€Œå¤åˆ¶å­˜åœ¨çš„è¾“å…¥ï¼ˆä¾‹å¦‚æ¯ä¸ªGPUéƒ½ç”¨åˆ°äº†å®Œæ•´çš„\\(X\\)ï¼‰ï¼Œåå‘æ¢¯åº¦éœ€è¦æ±‡æ€»ï¼šå„GPUæ ¹æ®æœ¬åœ°è®¡ç®—å¾—åˆ°\\(\\partial X_i\\)åï¼Œæ‰§è¡Œä¸€æ¬¡All-Reduceå°†æ¢¯åº¦æ±‚å’Œ\\(\\partial X = \\sum_{i=1}^{P} \\partial X_i\\)ï¼Œå†ä¼ å›ä¸Šä¸€å±‚ã€‚è¿™å¯¹åº”äºå‰å‘å¤åˆ¶æ“ä½œçš„åå‘é€šä¿¡ã€‚\nå„GPUè®¡ç®—è‡ªå·±æŒæœ‰æƒé‡çš„æ¢¯åº¦\\(\\partial A_i, \\partial B_i\\)ï¼Œè¿™äº›æ¢¯åº¦ä¼šåœ¨æ¨¡å‹å¹¶è¡Œç»„å†…ä¿æŒåˆ†å¸ƒçŠ¶æ€ï¼ˆæ¯ä¸ªGPUåªæ›´æ–°è‡ªå·±é‚£éƒ¨åˆ†æƒé‡ï¼‰ã€‚åœ¨æ•°æ®å¹¶è¡Œç»„èŒƒå›´ï¼Œåˆ™éœ€å¯¹æ¢¯åº¦åšAll-Reduceä»¥èšåˆæ¥è‡ªä¸åŒæ•°æ®åˆ†ç‰‡çš„æ›´æ–°ã€‚\n\nå‚æ•°æ›´æ–°ï¼šåœ¨ä¼˜åŒ–å™¨é˜¶æ®µï¼Œå„GPUä½¿ç”¨èšåˆåçš„å…¨å±€æ¢¯åº¦æ›´æ–°å¯¹åº”çš„æƒé‡å­çŸ©é˜µå‚æ•°ã€‚ç”±äºä½¿ç”¨äº†å¦‚Adamä¹‹ç±»çš„ä¼˜åŒ–å™¨ï¼Œæ¯ä¸ªGPUä¹Ÿç»´æŠ¤å¹¶æ›´æ–°ä¸å…¶å‚æ•°å¯¹åº”çš„ä¼˜åŒ–å™¨çŠ¶æ€ï¼ˆå¦‚ä¸€é˜¶ã€äºŒé˜¶åŠ¨é‡ï¼‰ï¼Œä¿è¯å„è‡ªå‚æ•°çš„æ›´æ–°åŒæ­¥ä¸€è‡´ã€‚\nè¿­ä»£ä¸åŒæ­¥ï¼šä¸€ä¸ªè®­ç»ƒiterationå®Œæˆåï¼Œè¿›å…¥ä¸‹ä¸€æ‰¹æ•°æ®é‡å¤ä¸Šè¿°è¿‡ç¨‹ã€‚è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå„GPUé€šè¿‡åŒæ­¥é€šè®¯ä¿è¯åœ¨å…³é”®ç‚¹ï¼ˆå¦‚All-Reduceï¼‰ä¸Šä¸€è‡´ï¼Œé¿å…å‡ºç°è®¡ç®—ç«æ€ã€‚åŒæ—¶åˆ©ç”¨æµæ°´çº¿å¹¶è¡Œï¼ˆå¦‚æœ‰ï¼‰å¯ä»¥åœ¨ç­‰å¾…é€šä¿¡æ—¶å¼€å§‹ä¸‹ä¸€å±‚çš„è®¡ç®—ï¼Œä»¥æé«˜è®¡ç®—é€šä¿¡é‡å åº¦ã€‚\n\né€šè¿‡ä¸Šè¿°æ•°æ®æµä¸æ§åˆ¶æµè®¾è®¡ï¼ŒMegatron-LMå®ç°äº†åœ¨å¤šGPUé—´é«˜å¹¶è¡Œåº¦ä¸”åè°ƒä¸€è‡´çš„è®­ç»ƒè¿‡ç¨‹ã€‚åœ¨å…¸å‹å®ç°ä¸­ï¼Œæ¯å¼ GPUè¿›ç¨‹ä¸¥æ ¼æŒ‰ç…§æ—¢å®šé¡ºåºæ‰§è¡Œï¼Œæ—¢å‘æŒ¥GPUå¹¶è¡Œç®—åŠ›åˆå°†é€šä¿¡å¼€é”€é™è‡³å¿…è¦çš„æœ€å°ã€‚\n3.3 å…³é”®å‡è®¾ä¸é€‚ç”¨èŒƒå›´\nè®­ç»ƒæ¡†æ¶åœ¨è®¾è®¡æ—¶åšå‡ºäº†ä¸€äº›é»˜è®¤å‡è®¾ï¼Œè¿™äº›å‡è®¾ç•Œå®šäº†æ–¹æ³•é€‚ç”¨çš„èŒƒå›´ï¼Œä¹ŸæŒ‡æ˜åœ¨ä½•ç§æƒ…å†µä¸‹æ•ˆæœå¯èƒ½ä¸ä½³ï¼š\n\né«˜å¸¦å®½ä½å»¶è¿Ÿçš„é€šä¿¡ç½‘ç»œï¼šå‡è®¾GPUä¹‹é—´æ‹¥æœ‰é«˜é€Ÿäº’è”ï¼ˆå¦‚NVLinkæˆ–InfiniBandï¼‰ï¼Œä»¥æ”¯æ’‘é¢‘ç¹çš„All-Reduceæ“ä½œã€‚å¦‚æœé€šä¿¡ç½‘ç»œè¾ƒæ…¢æˆ–è€…èŠ‚ç‚¹é—´å»¶è¿Ÿè¿‡é«˜ï¼Œæ¨¡å‹å¹¶è¡Œçš„åŒæ­¥å¼€é”€å°†æ˜¾è‘—å¢é•¿ï¼Œæ•´ä½“åŠ é€Ÿæ¯”ä¼šé™ä½ç”šè‡³å¤±å»ä¼˜åŠ¿ã€‚\næ¨¡å‹ç»“æ„æ˜“äºåˆ†å—ï¼šæ–¹æ³•å‡è®¾Transformerå±‚ç­‰ç»“æ„å¯ä»¥æŒ‰ç»´åº¦è§„åˆ™åˆ’åˆ†ï¼ˆä¾‹å¦‚å°†çŸ©é˜µå‡åŒ€åˆ‡åˆ†ï¼‰ã€‚å¦‚æœæ¨¡å‹ä¸­å­˜åœ¨éš¾ä»¥åˆ‡åˆ†çš„ç®—å­æˆ–å¼ºè€¦åˆçš„è·¨é€šé“è¿ç®—ï¼ˆå¦‚æŸäº›è‡ªå®šä¹‰å±‚æˆ–åŠ¨æ€è®¡ç®—å›¾ï¼‰ï¼Œæ¨¡å‹å¹¶è¡Œéš¾ä»¥ç›´æ¥åº”ç”¨ï¼Œéœ€ä¿®æ”¹æ¨¡å‹ç»“æ„æˆ–æ”¾å¼ƒå¹¶è¡Œï¼Œå¦åˆ™ä¼šå¯¼è‡´ä¸æ­£ç¡®æˆ–æ•ˆç‡ä½ä¸‹ã€‚\nè¶³å¤Ÿå¤§çš„batchå’Œè®¡ç®—è´Ÿè½½ï¼šä¸ºæ‘Šè–„é€šä¿¡æˆæœ¬ï¼Œé»˜è®¤è®­ç»ƒä½¿ç”¨è¾ƒå¤§çš„mini-batchå’Œé•¿åºåˆ—ã€‚è‹¥åœºæ™¯ä¸­batchå°ºå¯¸å—é™æˆ–æ¨¡å‹è§„æ¨¡ä¸å¤Ÿå¤§ï¼Œé€šä¿¡å¼€é”€ç›¸å¯¹è®¡ç®—å¯èƒ½å æ¯”è¿‡é«˜ï¼Œä½¿å¹¶è¡Œæ”¶æ•ˆç”šå¾®ã€‚è¿™ç§æƒ…å†µä¸‹ï¼Œç®€å•çš„æ•°æ®å¹¶è¡Œå¯èƒ½æ›´é«˜æ•ˆã€‚\nGPUèµ„æºè§„æ¨¡åŒ¹é…æ¨¡å‹å¤§å°ï¼šå‡å®šæœ‰å……è¶³çš„GPUæ¥åˆ†æ‹…æ¨¡å‹ï¼ˆä¾‹å¦‚83äº¿å‚æ•°æ¨¡å‹éœ€è¦8è·¯æ¨¡å‹å¹¶è¡Œä»¥ä¸Šï¼‰ã€‚å¦‚æœGPUæ•°é‡ä¸è¶³ä»¥åˆ‡åˆ†æ¨¡å‹è‡³å„è‡ªå†…å­˜å®¹é‡å¯å®¹çº³ï¼Œä»ç„¶ä¼šå‡ºç°å†…å­˜ä¸è¶³çš„é—®é¢˜ã€‚æ­¤å¤–ï¼Œæ–¹æ³•æš‚æœªè€ƒè™‘å¼‚æ„å†…å­˜ï¼ˆå¦‚CPUå†…å­˜ã€NVMeï¼‰çš„è°ƒåº¦åˆ©ç”¨ã€‚\nä¸€è‡´çš„è®¡ç®—ç¯å¢ƒï¼šè¦æ±‚å‚ä¸è®­ç»ƒçš„æ‰€æœ‰GPUç®—åŠ›å‡è¡¡ã€ç¯å¢ƒä¸€è‡´ã€‚è‹¥éƒ¨åˆ†è®¾å¤‡æ€§èƒ½ä¸ä¸€æˆ–å‡ºç°ä¸­æ–­ï¼ŒåŒæ­¥è®­ç»ƒä¼šæ‹–æ…¢è‡³æœ€æ…¢èŠ‚ç‚¹ã€‚è¿™æ„å‘³ç€åœ¨ä¸å…·å¤‡æ•…éšœå®¹é”™æœºåˆ¶æ—¶ï¼Œé›†ç¾¤ä¸­ä»»ä¸€èŠ‚ç‚¹çš„å¤±è´¥éƒ½ä¼šä¸­æ–­æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ã€‚\n\nä¸Šè¿°å‡è®¾ç¡®ä¿äº†Megatron-LMæ–¹æ³•åœ¨å¤§å‹GPUé›†ç¾¤ã€æ ‡å‡†Transformeræ¨¡å‹åœºæ™¯ä¸‹è¡¨ç°è‰¯å¥½ã€‚å½“è¿™äº›æ¡ä»¶ä¸æ»¡è¶³æ—¶ï¼Œéœ€å¯¹è®­ç»ƒé…ç½®è¿›è¡Œè°ƒæ•´ï¼ˆä¾‹å¦‚å‡å°‘å¹¶è¡Œåº¦ã€é‡‡ç”¨æ¿€æ´»é‡è®¡ç®—æˆ–ZeROä¼˜åŒ–ç­‰ï¼‰æ¥å¼¥è¡¥æˆ–é€‚é…ï¼Œå¦åˆ™è®­ç»ƒæ•ˆç‡å’Œæ•ˆæœå¯èƒ½å—å½±å“ã€‚\n3.4 æ•°å­¦å…¬å¼ä¸ç®—æ³•è§£è¯»\nç”±äºæœ¬æ–‡åé‡ç³»ç»Ÿå®ç°ï¼Œè®ºæ–‡ä¸­å¹¶æœªå¤§é‡ä½¿ç”¨å¤æ‚å…¬å¼æ¨å¯¼ï¼Œä½†å…¶ä¸­å…³é”®è¿‡ç¨‹å¯ç”¨ç®€æ˜çš„æ•°å­¦è¡¨ç¤ºæè¿°å…¶æ­£ç¡®æ€§å’Œé«˜æ•ˆæ€§ã€‚ä¾‹å¦‚ï¼Œå¯¹äºTransformerå‰é¦ˆå±‚ï¼ˆä¸¤ä¸ªçº¿æ€§å±‚çš„ç»„åˆï¼‰åœ¨ä¸¤è·¯æ¨¡å‹å¹¶è¡Œ(\\(P=2\\))ä¸‹çš„åˆ’åˆ†ï¼Œå¯ä»¥è¡¨ç¤ºå¦‚ä¸‹ï¼š\n\nåˆ’åˆ†è®¡ç®—ï¼šè®¾è¾“å…¥å¼ é‡ä¸º\\(X \\in \\mathbb{R}^{B\\times H}\\)ï¼ˆæ‰¹å¤§å°\\(B\\)ï¼Œéšå±‚ç»´åº¦\\(H\\)ï¼‰ï¼Œç¬¬ä¸€å±‚æƒé‡\\(A \\in \\mathbb{R}^{H\\times I}\\)ï¼Œç¬¬äºŒå±‚æƒé‡\\(B \\in \\mathbb{R}^{I\\times H}\\)ï¼Œå…¶ä¸­\\(I\\)ä¸ºå‰é¦ˆå±‚éšç»´åº¦ã€‚å°†\\(A\\)æŒ‰åˆ—å‡åˆ†ä¸ºä¸¤éƒ¨åˆ†\\([A_1,\\ A_2]\\)ï¼Œå°†\\(B\\)æŒ‰è¡Œå‡åˆ†ä¸ºä¸¤éƒ¨åˆ†\\(\\begin{pmatrix}B_1;\\\\ B_2\\end{pmatrix}\\)ï¼ˆè¿™æ ·\\(A_1, A_2 \\in \\mathbb{R}^{H\\times (I/2)}\\)ï¼Œ \\(B_1, B_2 \\in \\mathbb{R}^{(I/2)\\times H}\\)ï¼‰ã€‚\nå±€éƒ¨å‰å‘ï¼šGPUâ‚å’ŒGPUâ‚‚åˆ†åˆ«è®¡ç®—ï¼š\\(Y_1 = \\mathrm{GeLU}(X A_1)\\)ï¼Œ\\(Y_2 = \\mathrm{GeLU}(X A_2)\\)ã€‚ç”±äºå¯¹éçº¿æ€§\\(\\mathrm{GeLU}(Â·)\\)çš„åˆ’åˆ†è¾“å‡ºäº’ä¸ä¾èµ–ï¼Œè¿™ä¸€æ­¥ä¸éœ€è¦é€šä¿¡ã€‚\nå±€éƒ¨åˆå¹¶ï¼šæ¥ç€ï¼Œå„GPUç»§ç»­è®¡ç®—ç¬¬äºŒå±‚å±€éƒ¨è¾“å‡ºï¼š\\(Z_1 = Y_1 B_1\\), \\(Z_2 = Y_2 B_2\\)ã€‚æ­¤æ—¶æ¯ä¸ª\\(Z_i\\)éƒ½æ˜¯æœ€ç»ˆè¾“å‡º\\(Z\\)çš„ä¸€éƒ¨åˆ†è´¡çŒ®ã€‚å®Œæ•´è¾“å‡ºå¯è¡¨ç¤ºä¸º\\(Z = Z_1 + Z_2 = X (A_1 B_1 + A_2 B_2)\\)ã€‚ä¸ºäº†å¾—åˆ°\\(Z\\)ï¼Œç³»ç»Ÿæ‰§è¡Œä¸€æ¬¡All-Reduceå°†\\(Z_1, Z_2\\)åœ¨ä¸¤GPUé—´æ±‚å’ŒåŒæ­¥ï¼Œä½¿æ¯ä¸ªGPUéƒ½è·å¾—å®Œæ•´çš„\\(Z\\)ç”¨äºåç»­è®¡ç®—ã€‚\næ¢¯åº¦å›ä¼ ï¼šåœ¨åå‘ä¼ æ’­ä¸­ï¼Œè®¾æœ€ç»ˆè¾“å‡ºçš„æ¢¯åº¦ä¸º\\(\\partial Z\\)ï¼ˆå„GPUåœ¨All-Reduceåæ‹¥æœ‰ç›¸åŒçš„\\(\\partial Z\\)ï¼‰ã€‚åˆ™æ¯ä¸ªGPUå¯ä»¥å±€éƒ¨è®¡ç®—è‡ªå·±çš„æ¢¯åº¦åˆ†é‡ï¼š\\(\\partial Y_1 = \\partial Z B_1^T\\), \\(\\partial Y_2 = \\partial Z B_2^T\\)ï¼Œä»¥åŠ\\(\\partial X_1 = \\partial Y_1 A_1^T\\), \\(\\partial X_2 = \\partial Y_2 A_2^T\\)ï¼Œè¿˜æœ‰å±€éƒ¨æƒé‡æ¢¯åº¦\\(\\partial B_1 = Y_1^T \\partial Z\\), \\(\\partial B_2 = Y_2^T \\partial Z\\)ï¼Œ\\(\\partial A_1 = X^T (\\partial Y_1)\\), \\(\\partial A_2 = X^T (\\partial Y_2)\\)ã€‚\n\nå¯¹äº\\(\\partial Z\\)ï¼Œå‰å‘å·²é€šè¿‡All-Reduceå¾—åˆ°å®Œæ•´\\(Z\\)ï¼Œåå‘ä¸éœ€é€šä¿¡ï¼Œå„GPUç›´æ¥ä½¿ç”¨\\(\\partial Z\\)è®¡ç®—å³å¯ï¼ˆå³æ¢¯åº¦åœ¨è¿™ä¸€å±‚çš„å‰å‘é€šä¿¡å¯¹åº”åå‘æ’ç­‰ï¼‰ã€‚\nå¯¹äº\\(\\partial X\\)ï¼Œç”±äºå‰å‘æ—¶\\(X\\)çš„è®¡ç®—è¢«å„GPUå¤ç”¨ï¼Œåå‘éœ€å°†å„GPUç®—å¾—çš„\\(\\partial X_i\\)æ±‚å’Œã€‚é€šè¿‡ä¸€æ¬¡All-Reduceï¼Œå¾—åˆ°\\(\\partial X = \\partial X_1 + \\partial X_2\\)å¹¶å°†ç»“æœå¹¿æ’­è‡³ä¸¤GPUï¼ˆè¿™å¯¹åº”å‰å‘å¤åˆ¶çš„åå‘é€šä¿¡æ­¥éª¤ï¼‰ã€‚\næƒé‡æ¢¯åº¦\\(\\partial A_i, \\partial B_i\\)å¤©ç„¶æ˜¯åˆ†å¸ƒå¼çš„ï¼Œå„GPUå„è‡ªè´Ÿè´£è‡ªå·±åˆ†å—çš„æ›´æ–°ï¼›ä¸åŒæ•°æ®å¹¶è¡Œå®ä¾‹çš„æƒé‡æ¢¯åº¦ç¨åè¿˜éœ€è·¨èŠ‚ç‚¹æ±‚å’Œå¹³å‡ï¼Œä½†åœ¨æ¨¡å‹å¹¶è¡Œç»„å†…éƒ¨ä¸éœ€è¦é¢å¤–åŒæ­¥ã€‚\n\n\nä¸Šè¿°è¿‡ç¨‹ä½“ç°äº†ä½œè€…å¼•å…¥çš„ä¸¤ä¸ªå…³é”®é€šä¿¡ç®—å­\\(f\\)å’Œ\\(g\\)çš„ä½œç”¨:\n\nè¿ç®—\\(g\\)åœ¨å‰å‘æ˜¯All-Reduceï¼ˆå¦‚å°†\\(Z_i\\)æ±‚å’Œå¾—åˆ°\\(Z\\)ï¼‰ï¼Œåœ¨åå‘åˆ™æ˜¯æ’ç­‰ä¼ é€’æ¢¯åº¦ï¼›\nè¿ç®—\\(f\\)åœ¨å‰å‘æ˜¯æ’ç­‰ï¼ˆå¦‚å°†\\(X\\)å¤åˆ¶ä½¿ç”¨ï¼‰ï¼Œåœ¨åå‘åˆ™æ˜¯All-Reduceï¼ˆæ±‡æ€»\\(\\partial X\\)ï¼‰ã€‚\n\né€šè¿‡è¿™å¯¹å…±è½­ç®—å­\\(f/g\\)ï¼Œä½œè€…ä»…ç”¨å¯¥å¯¥æ•°è¡Œä»£ç å®ç°äº†æ¨¡å‹å¹¶è¡Œæ‰€éœ€çš„åŒæ­¥ã€‚æ•´ä½“è€Œè¨€ï¼Œè™½ç„¶è®ºæ–‡å…¬å¼ä¸å¤šï¼Œä½†ç®—æ³•æœ¬èº«åŸºäºä»¥ä¸Šç®€å•æ­£ç¡®çš„çº¿æ€§ä»£æ•°å…³ç³»ï¼Œç¡®ä¿å¹¶è¡Œè®¡ç®—å®Œå…¨ç­‰ä»·äºåŸå§‹å…¨æ¨¡å‹è®¡ç®—ã€‚æ­¤å¤–ï¼Œè®­ç»ƒæ—¶è¿˜æ­é…äº†æ ‡å‡†çš„äº¤å‰ç†µæŸå¤±\\(\\mathcal{L}(\\theta) = -\\frac{1}{N}\\sum_{i=1}^{N}\\log P_\\theta(w_i \\mid \\text{context}_i)\\)æ¥å½¢å¼åŒ–è¯­è¨€æ¨¡å‹ç›®æ ‡ï¼Œå…¶ä¸­\\(P_\\theta\\)æ˜¯æ¨¡å‹å¯¹è¯\\(w_i\\)çš„é¢„æµ‹æ¦‚ç‡ã€‚æ¨¡å‹é€šè¿‡æœ€å°åŒ–æ­¤æŸå¤±è®­ç»ƒï¼ŒåŒæ—¶ä»¥å›°æƒ‘åº¦ï¼ˆPerplexityï¼‰\\(\\mathrm{PPL} = \\exp(\\mathcal{L})\\)è¡¡é‡æ¨¡å‹å¯¹è¯­è¨€çš„æ‹Ÿåˆç¨‹åº¦ã€‚\nä¸å¸¸è§è®­ç»ƒæ ˆçš„å¯¹åº”å…³ç³»ï¼šä¸Šè¿°Megatron-LMçš„å®ç°ä¸å…¸å‹æ·±åº¦å­¦ä¹ è®­ç»ƒæ ˆå„ç»„ä»¶ä¸€ä¸€å¯¹åº”ï¼š\n\næ•°æ®åŠ è½½ï¼šåˆ©ç”¨å¸¸è§„çš„æ•°æ®è¯»å–ç®¡é“ï¼Œç»“åˆDistributedSamplerç­‰æœºåˆ¶ï¼Œåœ¨æ•°æ®å¹¶è¡Œç»´åº¦ä¸Šåˆ’åˆ†æ•°æ®é›†ã€‚å¯¹äºæ¨¡å‹å¹¶è¡Œç»„å†…çš„GPUï¼Œç¡®ä¿å®ƒä»¬æ”¶åˆ°ç›¸åŒçš„æ ·æœ¬æ‰¹ï¼ˆä¾‹å¦‚é€šè¿‡å›ºå®šéšæœºç§å­æˆ–å¹¿æ’­æ•°æ®ï¼‰æ¥å…±åŒè®¡ç®—ä¸€ä¸ªå­æ‰¹æ¬¡ã€‚è¿™ä¸æ ‡å‡†DataLoaderæµç¨‹å…¼å®¹ï¼Œåªæ˜¯éœ€è¦è€ƒè™‘ç»„å†…æ•°æ®ä¸€è‡´æ€§ã€‚\nå¹¶è¡Œè°ƒåº¦ï¼šé€šè¿‡PyTorchåˆ†å¸ƒå¼é€šä¿¡ç»„ç­‰æ‰‹æ®µï¼Œå°†GPUåˆ’åˆ†ä¸ºå¤šå±‚æ¬¡å¹¶è¡Œç»„ï¼ˆå¦‚æ¯8å—GPUä¸ºä¸€ç»„è¿›è¡Œå¼ é‡æ¨¡å‹å¹¶è¡ŒTPï¼Œå¤šç»„ä¹‹é—´å†åšæ•°æ®å¹¶è¡ŒDPï¼‰ã€‚æ¡†æ¶åˆ©ç”¨PyTorch DDPï¼ˆDistributed Data Parallelï¼‰å’Œè‡ªå®šä¹‰çš„å¹¶è¡Œåº“åè°ƒå„ç»´åº¦ä¸Šçš„åŒæ­¥ã€‚Megatron-LMçš„æ–¹æ³•ä¹Ÿå¯ä¸æµæ°´å¹¶è¡Œ(PP)ç»“åˆä½¿ç”¨ï¼Œå°†æ¨¡å‹å±‚æ‹†åˆ†åˆ°ä¸åŒè®¾å¤‡ä»¥è·å¾—è¿›ä¸€æ­¥æ‰©å±•ã€‚æ­¤å¤–ï¼Œæ–°è¿‘å‡ºç°çš„ä¸Šä¸‹æ–‡å¹¶è¡Œ(CP)ï¼ˆåœ¨åºåˆ—é•¿åº¦ç»´åº¦è¿›è¡Œå¹¶è¡Œï¼‰ä¹Ÿå±äºå¯é€‰æ–¹æ¡ˆï¼Œå°½ç®¡åŸè®ºæ–‡æœªæ¶‰åŠï¼Œä½†æ¦‚å¿µä¸Šå¯ä¸TP/PPäº’è¡¥ï¼Œç”¨äºå¤„ç†è¶…é•¿åºåˆ—ã€‚æ€»ä½“æ¥è¯´ï¼Œå¹¶è¡Œè°ƒåº¦ç”±é«˜å±‚è„šæœ¬æˆ–Launcherè´Ÿè´£ï¼Œæ— éœ€äººå·¥å¹²é¢„æ¯æ­¥é€šä¿¡ï¼Œè®­ç»ƒè¿‡ç¨‹äº•ç„¶æœ‰åºåœ°åœ¨å„è®¾å¤‡ä¸Šå¹¶è¡Œå±•å¼€ã€‚\nå†…æ ¸ç®—å­ï¼šæ¨¡å‹çš„å¤§éƒ¨åˆ†è®¡ç®—ä»é€šè¿‡æ ‡å‡†æ·±åº¦å­¦ä¹ ç®—å­ï¼ˆçŸ©é˜µä¹˜ã€LayerNormã€æ¿€æ´»å‡½æ•°ç­‰ï¼‰å®ç°ã€‚Megatron-LMå……åˆ†åˆ©ç”¨äº†NVIDIA GPUä¸Šçš„cuBLASå’ŒNCCLåº“ï¼Œä¿è¯çŸ©é˜µä¹˜æ³•ã€All-Reduceç­‰å…³é”®è·¯å¾„é«˜åº¦ä¼˜åŒ–ã€‚æ•´ä¸ªå®ç°æœªå¼•å…¥æ–°çš„åº•å±‚å†…æ ¸ï¼Œä»…åœ¨Pythonå±‚å°†å·²æœ‰ç®—å­ç»„åˆä»¥å®ç°æ¨¡å‹å¹¶è¡Œã€‚ç„¶è€Œï¼Œå·¥ç¨‹ä¸Šå›¢é˜Ÿä¹Ÿæ•´åˆäº†ä¸€äº›Kernelä¼˜åŒ–ï¼ˆå¦‚èåˆQKVçº¿æ€§å˜æ¢ã€èåˆDropout+Biasç­‰ï¼‰æ¥å‡å°‘æ¡†æ¶å¼€é”€ï¼Œæé«˜å•æ­¥æ‰§è¡Œæ•ˆç‡ã€‚è¿™å¯¹åº”è®­ç»ƒæ ˆä¸­å¯¹ç®—å­çš„é«˜æ•ˆå®ç°éƒ¨åˆ†ï¼Œä¸å¸¸è§æ¡†æ¶ï¼ˆPyTorchã€DeepSpeedç­‰ï¼‰çš„ä¼˜åŒ–æ€è·¯ä¸€è‡´ã€‚\né€šä¿¡åç«¯ï¼šä½¿ç”¨NCCLç­‰é«˜æ€§èƒ½é€šä¿¡åº“å®ç°All-Reduceã€All-Gatherç­‰æ“ä½œï¼Œç¡®ä¿åœ¨å¤šGPUå¤šèŠ‚ç‚¹ç¯å¢ƒä¸‹é€šä¿¡é«˜æ•ˆå¯é ã€‚NCCLè´Ÿè´£åº•å±‚ä¼ è¾“ï¼Œåˆ©ç”¨ç¯å½¢ç®—æ³•ç­‰åœ¨GPUé—´ä¼ è¾“å¼ é‡ï¼Œå¹¶è‡ªåŠ¨ä½¿ç”¨NVLinkæˆ–InfiniBandç­‰äº’è”åŠ é€Ÿã€‚Megatron-LMçš„é€šä¿¡éœ€æ±‚ä¸å…¸å‹Collectiveé€šä¿¡åœºæ™¯åŒ¹é…ï¼Œå¦‚åŒæ­¥SGDä¸­çš„æ¢¯åº¦All-Reduceï¼Œåªæ˜¯è¿™é‡Œåœ¨æ¨¡å‹å†…éƒ¨æ›´é¢‘ç¹ã€‚ç”±äºé‡‡ç”¨æˆç†Ÿåç«¯ï¼Œå¼€å‘è€…ä¸éœ€å…³å¿ƒé€šä¿¡ç»†èŠ‚ï¼Œä½†éœ€è¦æ­£ç¡®è®¾ç½®ç¯å¢ƒï¼ˆå¦‚MPIå¯åŠ¨ã€GPUæ‹“æ‰‘ï¼‰ä»¥å‘æŒ¥å¸¦å®½æ½œåŠ›ã€‚\nè®­ç»ƒè¿‡ç¨‹é›†æˆï¼šä¸Šè¿°å„æ¨¡å—èå…¥è®­ç»ƒä¸»å¾ªç¯ï¼Œä¸å¸¸è§è®­ç»ƒæ ˆä¸­çš„DataLoaderã€Optimizerã€Schedulerå…±åŒæ„æˆå®Œæ•´æµç¨‹ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒMegatron-LMä¸ä¸»æµè®­ç»ƒæ¡†æ¶ï¼ˆä¾‹å¦‚NVIDIAçš„Megatron-LMä»£ç åº“ã€Microsoft DeepSpeedç­‰ï¼‰è‰¯å¥½ç»“åˆï¼Œè¿™äº›æ¡†æ¶æä¾›äº†é…ç½®æ¥å£æ¥æ‰“å¼€å¼ é‡å¹¶è¡Œã€æµæ°´å¹¶è¡Œç­‰ç‰¹æ€§ï¼Œä½¿å¾—å®é™…è½åœ°æ—¶åªéœ€åœ¨é…ç½®æ–‡ä»¶ä¸­æŒ‡å®šå¹¶è¡Œç¨‹åº¦å³å¯ï¼Œå¤§å¤§é™ä½äº†å·¥ç¨‹å®æ–½éš¾åº¦ã€‚\n\né€šè¿‡ä¸Šè¿°å¯¹åº”å…³ç³»å¯ä»¥çœ‹å‡ºï¼ŒMegatron-LMçš„æ–¹æ³•è¢«è®¾è®¡ä¸ºå¯ç§»æ¤ã€å¯ç»„åˆçš„ï¼Œå¼€å‘è€…æ— éœ€é‡æ„æ•´ä¸ªè®­ç»ƒæ ˆï¼Œåªéœ€åœ¨å¸¸è§„çš„è®­ç»ƒæµç¨‹ä¸­å¼€å¯ç›¸åº”å¹¶è¡Œç­–ç•¥ï¼Œä¾¿èƒ½åœ¨ç°æœ‰ç¡¬ä»¶ä¸Šè®­ç»ƒè¶…å¤§è§„æ¨¡æ¨¡å‹ã€‚\nå››ã€å»ºæ¨¡æ–¹å¼ä¸è¯„ä¼°æŒ‡æ ‡\n4.1 é—®é¢˜æ˜¯å¦‚ä½•å½¢å¼åŒ–çš„ï¼Ÿ\nä½œè€…å°†è¶…å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹è®­ç»ƒé—®é¢˜å½¢å¼åŒ–ä¸ºç»å…¸çš„æ— ç›‘ç£è¯­è¨€å»ºæ¨¡ä»»åŠ¡ã€‚å¯¹äºGPT-2è¿™ç±»è‡ªå›å½’è¯­è¨€æ¨¡å‹ï¼Œç›®æ ‡æ˜¯åœ¨ç»™å®šå‰æ–‡çš„æ¡ä»¶ä¸‹æœ€å¤§åŒ–ä¸‹ä¸€ä¸ªå•è¯å‡ºç°çš„æ¦‚ç‡ï¼›å¯¹äºBERTè¿™ç±»åŒå‘æ¨¡å‹ï¼Œåˆ™é€šè¿‡æ©ç è¯­è¨€æ¨¡å‹é¢„æµ‹è¢«é®è”½çš„å•è¯ã€‚åŒæ—¶ï¼ŒBERTçš„é¢„è®­ç»ƒè¿˜åŒ…å«ä¸‹ä¸€å¥é¢„æµ‹ç­‰ä»»åŠ¡ã€‚ä½†æ€»ä½“è€Œè¨€ï¼Œè®­ç»ƒå¯å½’ç»“ä¸ºåœ¨å¤§è§„æ¨¡è¯­æ–™ä¸Šæœ€å°åŒ–é¢„æµ‹è¯¯å·®çš„é—®é¢˜ã€‚\nå½¢å¼åŒ–æ¥è¯´ï¼Œç»™å®šè®­ç»ƒè¯­æ–™åºåˆ—\\(\\{w_1, w_2, ..., w_N\\}\\)ï¼Œæ¨¡å‹éœ€å­¦ä¹ å‚æ•°\\(\\theta\\)ä»¥æœ€å¤§åŒ–åºåˆ—æ¦‚ç‡\\(P_\\theta(w_1, ..., w_N)\\)ã€‚è¿™é€šå¸¸è½¬åŒ–ä¸ºæœ€å°åŒ–äº¤å‰ç†µæŸå¤±ï¼š \\[L(\\theta) = -\\frac{1}{N}\\sum_{t=1}^{N} \\log P_\\theta(w_t \\mid w_{&lt;t})\\] å¯¹äºGPT-2ï¼Œ\\(P_\\theta(w_t \\mid w_{&lt;t})\\)æ˜¯åŸºäºå…ˆå‰æ‰€æœ‰è¯é¢„æµ‹ä¸‹ä¸€è¯çš„æ¦‚ç‡ï¼›å¯¹äºBERTï¼Œè®­ç»ƒæ—¶å¯¹éšæœºé®è”½çš„è¯\\(w_k\\)é¢„æµ‹å…¶åŸè¯ã€‚è¯¥æŸå¤±è¡¡é‡æ¨¡å‹å¯¹è®­ç»ƒåˆ†å¸ƒçš„æ‹Ÿåˆç¨‹åº¦ï¼Œè¶Šå°è¡¨ç¤ºæ¨¡å‹å¯¹ä¸Šä¸‹æ–‡çš„é¢„æµ‹è¶Šå‡†ç¡®ã€‚ä¸ºä¾¿äºè§£é‡Šè®­ç»ƒéš¾åº¦ï¼Œè®ºæ–‡è¿˜ä½¿ç”¨å›°æƒ‘åº¦ï¼ˆPerplexity, PPLï¼‰æŒ‡æ ‡ï¼Œå°†å¹³å‡æŸå¤±æŒ‡æ•°åŒ–ï¼š\\(\\mathrm{PPL} = \\exp(L)\\)ï¼Œå®ƒè¡¨ç¤ºæ¨¡å‹åœ¨ä¸ç¡®å®šåº¦ä¸Šçš„ç­‰æ•ˆè¯æ±‡è¡¨è§„æ¨¡ï¼Œå›°æƒ‘åº¦è¶Šä½æ„å‘³ç€è¯­è¨€æ¨¡å‹è¶Šå¥½ã€‚\nåœ¨æ¨¡å‹å¹¶è¡Œçš„èƒŒæ™¯ä¸‹ï¼Œä½œè€…æ²¡æœ‰å¯¹ç›®æ ‡å‡½æ•°è¿›è¡Œä¿®æ”¹ï¼Œæ¨¡å‹å¹¶è¡Œä»…æ”¹å˜äº†è®¡ç®—åˆ†å¸ƒæ–¹å¼ï¼Œä¸å½±å“ä¸Šè¿°å½¢å¼åŒ–å®šä¹‰ã€‚å› æ­¤ï¼Œé—®é¢˜ä»ç„¶æ˜¯é€šè¿‡æ¢¯åº¦ä¸‹é™æ±‚è§£\\(\\min_\\theta L(\\theta)\\)ã€‚ä¸åŒçš„æ˜¯ï¼Œä»–ä»¬æ„å»ºäº†ä¸€ä¸ªå¯æ‰©å±•çš„è®¡ç®—ç»“æ„ä½¿è¿™ä¸ªä¼˜åŒ–è¿‡ç¨‹åœ¨æ•°ç™¾GPUä¸Šå¹¶è¡Œå®Œæˆã€‚æ¢è¨€ä¹‹ï¼Œå½¢å¼åŒ–çš„ç›®æ ‡ä¿æŒä¸å˜ï¼Œå˜åŒ–çš„æ˜¯å®ç°è¿™ä¸€ç›®æ ‡çš„è®¡ç®—ç­–ç•¥ã€‚\n4.2 æ ¸å¿ƒè¯„ä¼°æŒ‡æ ‡\nä¸ºè¯„ä¼°æ–¹æ³•æ•ˆæœï¼Œè®ºæ–‡é‡‡ç”¨äº†å¤šæ–¹é¢çš„æŒ‡æ ‡ï¼ŒåŒ…æ‹¬æ¨¡å‹æ€§èƒ½å’Œç³»ç»Ÿæ•ˆç‡ï¼š\n\nå›°æƒ‘åº¦ (Perplexity)ï¼šè¯­è¨€æ¨¡å‹å¸¸ç”¨æŒ‡æ ‡ï¼Œå®šä¹‰ä¸ºæµ‹è¯•é›†ä¸Š\\(2^{\\text{äº¤å‰ç†µ}}\\)ã€‚å›°æƒ‘åº¦åæ˜ æ¨¡å‹é¢„æµ‹ä¸‹ä¸€ä¸ªè¯çš„ä¸ç¡®å®šæ€§ï¼Œå€¼è¶Šä½è¡¨ç¤ºæ¨¡å‹é¢„æµ‹è¶Šå‡†ç¡®ã€‚ä½œè€…æŠ¥å‘Šäº†WikiText-103æ•°æ®é›†çš„å›°æƒ‘åº¦ï¼Œç”¨äºè¡¡é‡ä¸åŒå‚æ•°è§„æ¨¡GPT-2æ¨¡å‹çš„è¯­è¨€å»ºæ¨¡èƒ½åŠ›ã€‚\nå‡†ç¡®ç‡ (Accuracy)ï¼šé’ˆå¯¹ä¸‹æ¸¸ä»»åŠ¡çš„è¯„ä»·æŒ‡æ ‡ã€‚ä¾‹å¦‚LAMBADAæ•°æ®é›†çš„å®Œå½¢å¡«ç©ºä»»åŠ¡é‡‡ç”¨å®Œå¥é¢„æµ‹å‡†ç¡®ç‡ï¼ŒRACEé˜…è¯»ç†è§£ä»»åŠ¡é‡‡ç”¨é€‰æ‹©é¢˜å‡†ç¡®ç‡ã€‚è¿™äº›æŒ‡æ ‡è¡¡é‡æ¨¡å‹åœ¨ç‰¹å®šNLPä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼Œæ•°å€¼è¶Šé«˜è¶Šå¥½ã€‚è®ºæ–‡ä¸­ç‰¹åˆ«å…³æ³¨LAMBADAçš„å•è¯é¢„æµ‹å‡†ç¡®ç‡å’ŒRACEè€ƒè¯•é¢˜çš„å‡†ç¡®ç‡æå‡ã€‚\nä¸‹æ¸¸ä»»åŠ¡ç»¼åˆæŒ‡æ ‡ï¼šå¯¹äºBERTæ¨¡å‹ï¼Œä½œè€…è¯„ä¼°äº†åœ¨GLUEåŸºå‡†ä¸Šçš„å¤šé¡¹ä»»åŠ¡ï¼ˆMNLIã€QQPç­‰ï¼‰çš„å‡†ç¡®ç‡å’Œåœ¨SQuADé—®ç­”ä¸Šçš„F1/Exact Matchç­‰ã€‚è¿™äº›æŒ‡æ ‡ç»¼åˆä½“ç°å¤§æ¨¡å‹åœ¨è¿ç§»å­¦ä¹ åœºæ™¯çš„æ•ˆæœã€‚è®ºæ–‡å°†ä¸åŒè§„æ¨¡BERTæ¨¡å‹åœ¨è¿™äº›ä»»åŠ¡ä¸Šçš„åˆ†æ•°è¿›è¡Œå¯¹æ¯”ï¼Œè¯æ˜æ¨¡å‹è§„æ¨¡æå‡å¸¦æ¥çš„æ€§èƒ½å¢é•¿ã€‚\nè®¡ç®—ååé‡ï¼šä»¥æ¯ç§’å¤„ç†çš„æµ®ç‚¹è¿ç®—æ•°æ¥è¡¡é‡è®­ç»ƒæ•ˆç‡ã€‚ä½œè€…æŠ¥å‘Šäº†åœ¨512 GPUä¸Šè¾¾åˆ°çš„15.1 PetaFLOPsæŒç»­æ€§èƒ½ï¼Œä»¥åŠå•GPUçš„39 TeraFLOPsä¸ºåŸºå‡†ã€‚è¿™ä¸€æŒ‡æ ‡å±•ç¤ºå¹¶è¡Œä¼˜åŒ–çš„ç¡¬ä»¶æ•ˆç‡ï¼Œæ¥è¿‘ç†è®ºå³°å€¼çš„æ¯”ä¾‹è¶Šé«˜è¡¨ç¤ºå¹¶è¡Œæ–¹æ³•è¶Šé«˜æ•ˆã€‚è®ºæ–‡ä¸­æåˆ°è¾¾åˆ°å•å¡å³°å€¼30%ï¼ˆé‡‡ç”¨FP16è®­ç»ƒï¼‰ï¼Œå¤šå¡æ‰©å±•æ•ˆç‡çº¦76%ã€‚\næ‰©å±•æ•ˆç‡ (Scaling Efficiency)ï¼šå®šä¹‰ä¸ºå®é™…åŠ é€Ÿæ¯”ä¸ç†æƒ³çº¿æ€§åŠ é€Ÿæ¯”çš„æ¯”å€¼ã€‚ä¾‹å¦‚512å¡è¾¾åˆ°76%æ„å‘³ç€å®é™…é€Ÿåº¦çº¦ä¸ºçº¿æ€§512å€åŠ é€Ÿçš„0.76å€ã€‚ä½œè€…é€šè¿‡å¼±æ‰©å±•ï¼ˆå¢åŠ GPUåŒæ—¶å¢å¤§æ¨¡å‹å‚æ•°ï¼‰å’Œå¼ºæ‰©å±•ï¼ˆå›ºå®šæ¨¡å‹è§„æ¨¡å¢åŠ GPUï¼‰å®éªŒè¯„ä¼°äº†è¯¥å€¼ã€‚é«˜æ‰©å±•æ•ˆç‡è¡¨æ˜å¹¶è¡Œç®—æ³•åœ¨å¢åŠ è®¡ç®—èµ„æºæ—¶èƒ½æœ‰æ•ˆåˆ©ç”¨è€Œéæµªè´¹ç®—åŠ›ã€‚\nè®­ç»ƒç¨³å®šæ€§ï¼šè¿™ä¸æ˜¯æ˜ç¡®çš„æ•°å€¼æŒ‡æ ‡ï¼Œä½†é€šè¿‡lossæ›²çº¿å’Œå¹³ç¨³è®­ç»ƒè¿‡ç¨‹æ¥è¡¡é‡ã€‚ç‰¹åˆ«æ˜¯BERTæ¨¡å‹åœ¨ä¸åŒLayerNormæ”¾ç½®æ–¹å¼ä¸‹çš„å¤§æ¨¡å‹è®­ç»ƒæ˜¯å¦å‘æ•£ï¼Œè¢«ä½œä¸ºæ¯”è¾ƒå†…å®¹ã€‚è®ºæ–‡é€šè¿‡æ›²çº¿å›¾å±•ç¤ºäº†åŸå§‹æ¶æ„ä¸‹å¤§æ¨¡å‹è®­ç»ƒçš„ä¸ç¨³å®šï¼Œä»¥åŠè°ƒæ•´æ¶æ„åçš„ç¨³å®šä¸‹é™ï¼Œä»è€Œä¾§é¢åæ˜ äº†è®­ç»ƒç¨³å®šæ€§æ”¹è¿›ã€‚\n\nç»¼ä¸Šï¼Œè¿™äº›æŒ‡æ ‡æ¶µç›–æ¨¡å‹æ•ˆæœï¼ˆå›°æƒ‘åº¦ã€å‡†ç¡®ç‡ï¼‰å’Œç³»ç»Ÿæ•ˆç‡ï¼ˆFLOPsã€æ‰©å±•æ¯”ï¼‰ä¸¤ä¸ªæ–¹é¢ã€‚é€šè¿‡åŒæ—¶å…³æ³¨NLPä»»åŠ¡è¡¨ç°å’Œèµ„æºåˆ©ç”¨ç‡ï¼Œä½œè€…å…¨é¢è¯„ä¼°äº†Megatron-LMçš„ä¼˜è¶Šæ€§ã€‚\näº”ã€ä¸»è¦å®éªŒå‘ç°\n\næ¨¡å‹å¹¶è¡Œæœ‰æ•ˆæå‡äº†å¯è®­ç»ƒæ¨¡å‹è§„æ¨¡ä¸æ€§èƒ½ï¼šä½œè€…æˆåŠŸè®­ç»ƒäº†å‚æ•°é‡é«˜è¾¾8.3äº¿ï¼ˆGPT-2ï¼‰å’Œ3.9äº¿ï¼ˆBERTï¼‰çš„è¶…å¤§æ¨¡å‹:ï¼ˆæ³¨ï¼šåŸæ–‡å•ä½ä¸º billionï¼Œå³10äº¿ï¼Œè¿™é‡Œç®€åŒ–æè¿°ï¼‰ï¼Œæ˜¾è‘—è¶…å‡ºå½“æ—¶å¹¿æ³›ä½¿ç”¨çš„æ¨¡å‹è§„æ¨¡ï¼ˆä¾‹å¦‚BERT-Largeçš„3.36äº¿ï¼‰ã€‚éšç€è§„æ¨¡æ‰©å¤§ï¼Œæ¨¡å‹åœ¨è¯­è¨€å»ºæ¨¡å’Œä¸‹æ¸¸ä»»åŠ¡ä¸Šçš„è¡¨ç°å•è°ƒæå‡ã€‚è¿™éªŒè¯äº†â€œå¤§æ¨¡å‹å¸¦æ¥æ›´å¥½æ•ˆæœâ€çš„è¶‹åŠ¿ï¼Œå¹¶è¯æ˜äº†åªè¦é…å¥—çš„å¹¶è¡Œè®­ç»ƒå¾—å½“ï¼Œæå‡å‚æ•°è§„æ¨¡ä¾ç„¶èƒ½å¸¦æ¥æ”¶ç›Šã€‚\næé«˜çš„ç¡¬ä»¶ååä¸å¯æ‰©å±•æ€§ï¼šåœ¨512 GPUçš„GPUé›†ç¾¤ä¸Šï¼ŒMegatron-LMå®ç°äº†15.1 PFLOPsçš„æŒç»­è®­ç»ƒååï¼Œè¾¾åˆ°å•å¡æ€§èƒ½çš„76%æ‰©å±•æ•ˆç‡ã€‚è€ƒè™‘åˆ°é€šä¿¡å’ŒåŒæ­¥å¼€é”€ï¼Œè¿™ä¸€æ•ˆç‡éå¸¸æ¥è¿‘çº¿æ€§æ‰©å±•çš„ç†æƒ³å€¼ï¼Œè¯´æ˜ä½œè€…çš„æ–¹æ³•å……åˆ†åˆ©ç”¨äº†é›†ç¾¤è®¡ç®—èƒ½åŠ›ã€‚å¼±æ‰©å±•å®éªŒæ˜¾ç¤ºï¼Œæ¨¡å‹å‚æ•°ä¸GPUæ•°é‡åŒæ¯”å¢é•¿æ—¶ï¼ŒåååŸºæœ¬éšGPUçº¿æ€§å¢åŠ ï¼›å¼ºæ‰©å±•å®éªŒä¹Ÿå±•ç¤ºäº†è‰¯å¥½çš„åŠ é€Ÿæ¯”ã€‚è¿™æ„å‘³ç€é€šè¿‡æœ¬æ–¹æ³•ï¼Œå¢åŠ ç®—åŠ›å‡ ä¹å¯ä»¥ç›´æ¥ç”¨äºè®­ç»ƒæ›´å¤§æ¨¡å‹æˆ–åŠ é€Ÿè®­ç»ƒè¿‡ç¨‹ï¼Œå¹¶è¡Œæ”¶ç›Šæ¥è¿‘ç†æƒ³ã€‚\nSOTAæ°´å¹³çš„ä»»åŠ¡æ•ˆæœï¼šè®­ç»ƒå¾—åˆ°çš„8.3B GPT-2æ¨¡å‹åœ¨WikiText103æ•°æ®é›†ä¸Šè¾¾åˆ°10.8çš„å›°æƒ‘åº¦ï¼ˆæ­¤å‰æœ€ä½³ä¸º15.8ï¼‰ï¼Œåœ¨LAMBADAå®Œå½¢å¡«ç©ºæµ‹è¯•ä¸­å‡†ç¡®ç‡66.5%ï¼ˆæ­¤å‰æœ€ä½³63.2%ï¼‰ã€‚åŒæ ·ï¼Œ3.9Bçš„Megatron-BERTåœ¨RACEé˜…è¯»ç†è§£ä»»åŠ¡ä¸Šè¾¾åˆ°90.9%å‡†ç¡®ç‡ï¼ˆè¶…è¿‡æ­¤å‰SOTAçš„89.4%ï¼‰ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œé€šè¿‡å¢åŠ æ¨¡å‹å®¹é‡å’Œä½¿ç”¨æ›´é•¿æ—¶é—´é¢„è®­ç»ƒï¼Œè¯­è¨€æ¨¡å‹å¯ä»¥å¤§å¹…æå‡å¯¹æ–‡æœ¬çš„ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ï¼Œåˆ·æ–°å¤šä¸ªåŸºå‡†ä»»åŠ¡çš„è®°å½•ã€‚\næ¶æ„å¾®è°ƒå¯¹å¤§æ¨¡å‹è‡³å…³é‡è¦ï¼šå®éªŒä¸­ä¸€ä¸ªçªå‡ºçš„å‘ç°æ˜¯ï¼ŒLayerNormçš„ä½ç½®ä¼šå½±å“BERTå¤§å‹æ¨¡å‹çš„è®­ç»ƒå¯è¡Œæ€§ã€‚åŸå§‹BERTæ¶æ„åœ¨æ®‹å·®è¿æ¥ä¹‹åä½¿ç”¨LayerNormï¼ˆPost-LNï¼‰ï¼Œä½œè€…å‘ç°å½“å‚æ•°æ‰©å±•åˆ°æ•°äº¿è§„æ¨¡æ—¶è®­ç»ƒå‡ºç°ä¸ç¨³å®šç”šè‡³æ€§èƒ½é€€åŒ–ã€‚é€šè¿‡æ”¹ç”¨Pre-LNæ¶æ„ï¼ˆåœ¨æ¯ä¸ªå­å±‚è®¡ç®—å‰åº”ç”¨LayerNormï¼‰ï¼Œæ¨¡å‹è®­ç»ƒå˜å¾—ç¨³å®šï¼Œå¹¶éšç€è§„æ¨¡å¢åŠ å‡†ç¡®ç‡æŒç»­æå‡ã€‚è¿™ä¸€ç°è±¡å¼ºè°ƒäº†åœ¨æ”¾å¤§æ¨¡å‹å°ºå¯¸æ—¶ï¼Œè®­ç»ƒç¨³å®šæ€§å¯èƒ½æˆä¸ºç“¶é¢ˆï¼Œéœ€è¦é€šè¿‡æ¶æ„è°ƒæ•´ï¼ˆæˆ–ä¼˜åŒ–å™¨è¶…å‚è°ƒæ•´ï¼‰æ¥è§£å†³ã€‚\nå·¥ç¨‹å®ç°å¼€æ”¾ä¸”å¯å¤ç”¨ï¼šä½œè€…å°†å®Œæ•´çš„è®­ç»ƒä»£ç å’Œæµæ°´çº¿å®ç°å¼€æºåœ¨NVIDIA/Megatron-LMä»“åº“ã€‚è¿™æ„å‘³ç€ç ”ç©¶ç¤¾åŒºå’Œå·¥ä¸šç•Œå¯ä»¥ç›´æ¥ä½¿ç”¨è¿™ä¸€æˆæœæ¥è®­ç»ƒè‡ªå·±çš„å¤§æ¨¡å‹ã€‚è¿™åœ¨å½“æ—¶å…·æœ‰é‡è¦æ„ä¹‰ï¼šä¸ä»…è¯æ˜äº†æ–¹æ³•çš„å¯è¡Œæ€§ï¼Œä¹Ÿé™ä½äº†æŠ€æœ¯ä¼ æ’­é—¨æ§›ã€‚è®¸å¤šåç»­å·¥ä½œï¼ˆä¾‹å¦‚å¾®è½¯çš„Turing-NLG 170äº¿å‚æ•°æ¨¡å‹ï¼‰éƒ½å»ºç«‹åœ¨Megatron-LMçš„æ–¹æ³•ä¹‹ä¸Šï¼Œä½“ç°äº†è¯¥å·¥ä½œçš„å½±å“åŠ›å’Œå®ç”¨ä»·å€¼ã€‚\n\n5.1 å…³é”®å›¾è¡¨è§£è¯»\nå®éªŒéƒ¨åˆ†åŒ…å«å¤šå¹…å›¾è¡¨ï¼Œå½¢è±¡åœ°æ”¯æŒäº†ä¸Šè¿°å‘ç°ï¼š\n\næ‰©å±•æ•ˆç‡æ›²çº¿ï¼šè®ºæ–‡çš„Figure 1å±•ç¤ºäº†ä¸åŒå¹¶è¡Œé…ç½®ä¸‹çš„è®¡ç®—æ•ˆç‡å¯¹æ¯”ã€‚å…¶ä¸­æ¨¡å‹å¹¶è¡Œï¼ˆå¼ é‡å¹¶è¡Œï¼‰éšGPUæ•°é‡å¢é•¿çš„åååŸºæœ¬æ¥è¿‘ç†æƒ³ç›´çº¿ï¼Œè€Œä»…æ•°æ®å¹¶è¡Œåœ¨é«˜GPUæ•°æ—¶æ•ˆç‡å¼€å§‹ä¸‹é™ã€‚å›¾ä¸­æ ‡æ³¨çš„76%æ‰©å±•æ•ˆç‡è¯æ˜äº†8è·¯æ¨¡å‹å¹¶è¡Œåœ¨512å¡ä¸Šä»ä¿æŒé«˜æ•ˆã€‚è¿™ä¸€å›¾è¡¨ç›´è§‚è¯æ˜äº†Megatron-LMæ–¹æ¡ˆçš„é«˜å¯æ‰©å±•æ€§ï¼Œæ”¯æŒç¬¬ä¸€æ¡ä¸»è¦å‘ç°ã€‚\néªŒè¯å›°æƒ‘åº¦éšè¿­ä»£æ”¶æ•›å›¾ï¼šFigure 6ç»˜åˆ¶äº†ä¸åŒè§„æ¨¡GPT-2æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„å›°æƒ‘åº¦éšè®­ç»ƒè¿›ç¨‹ï¼ˆè¿­ä»£æ•°ï¼‰çš„ä¸‹é™è¶‹åŠ¿ã€‚ä»å›¾ä¸­å¯ä»¥çœ‹åˆ°ï¼Œè¾ƒå¤§çš„æ¨¡å‹ä¸ä»…æœ€ç»ˆå›°æƒ‘åº¦æ›´ä½ï¼ˆä¾‹å¦‚8.3Bæ¨¡å‹æœ€ç»ˆéªŒè¯PPLçº¦9.27ï¼Œå°æ¨¡å‹æ˜æ˜¾æ›´é«˜ï¼‰ï¼Œè€Œä¸”æ”¶æ•›æ›´å¿«ï¼ˆåœ¨ç›¸åŒè¿­ä»£å†…å¤§æ¨¡å‹è¾¾åˆ°æ›´ä½PPLï¼‰ã€‚è¿™è¯´æ˜å¢åŠ æ¨¡å‹å®¹é‡å¸¦æ¥çš„æ”¶ç›Šæ˜¯åŒé‡çš„ï¼šæ€§èƒ½æå‡å’Œæ”¶æ•›åŠ é€Ÿï¼Œæ”¯æŒäº†â€œå¤§æ¨¡å‹æ›´æœ‰æ•ˆâ€çš„è®ºæ–­ã€‚\nBERTæ¶æ„å¯¹æ¯”è®­ç»ƒæ›²çº¿ï¼šFigure 7æ¯”è¾ƒäº†åŸå§‹BERTæ¶æ„å’Œè°ƒæ•´LayerNormåæ¶æ„åœ¨è®­ç»ƒå¤§æ¨¡å‹æ—¶çš„lossæ›²çº¿ã€‚æ›²çº¿(a)ï¼ˆåŸå§‹ï¼‰å‡ºç°éœ‡è¡ç”šè‡³æ— æ³•é™ä½ï¼Œè€Œæ›²çº¿(b)ï¼ˆè°ƒæ•´åï¼‰å¹³æ»‘æ”¶æ•›åˆ°æ›´ä½lossã€‚è¿™å¼ å›¾å½¢è±¡åœ°æ”¯æ’‘äº†ç¬¬å››æ¡å‘ç°ï¼šæ­£ç¡®çš„LayerNormä½ç½®æ¶ˆé™¤äº†è®­ç»ƒä¸ç¨³å®šï¼Œä½¿å¾—3.9Bå‚æ•°BERTæˆåŠŸæ”¶æ•›å¹¶å–å¾—æ›´é«˜ç²¾åº¦ã€‚å®ƒæé†’æˆ‘ä»¬åœ¨å¤§æ¨¡å‹è®­ç»ƒä¸­ï¼Œå°çš„æ¶æ„æ”¹åŠ¨ä¼šå¸¦æ¥å·¨å¤§å½±å“ã€‚\nä¸‹æ¸¸ä»»åŠ¡ç»“æœè¡¨æ ¼ï¼šè®ºæ–‡çš„Table 3å’ŒTable 5æ±‡æ€»äº†æ¨¡å‹åœ¨WikiText103ã€LAMBADAç­‰æ— ç›‘ç£ä»»åŠ¡ä»¥åŠRACEã€MNLIç­‰ä¸‹æ¸¸ä»»åŠ¡çš„å…·ä½“æ•°å€¼ã€‚ä¾‹å¦‚Table 3æ¸…æ™°åˆ—å‡ºäº†355Mã€2.5Bã€8.3Bå„æ¨¡å‹çš„WikiTextå›°æƒ‘åº¦å’ŒLAMBADAå‡†ç¡®ç‡ï¼Œä»¥åŠè¿‡å»SOTAå¯¹æ¯”ã€‚è¿™äº›è¡¨æ ¼æ•°æ®ä¸€ç›®äº†ç„¶åœ°è¯æ˜äº†æ¨¡å‹è§„æ¨¡æå‡å¸¦æ¥çš„æ€§èƒ½å¢ç›Šå’ŒSOTAè¶…è¶Šï¼Œä¸ºç¬¬äºŒå’Œç¬¬ä¸‰æ¡å‘ç°æä¾›äº†å®šé‡ä¾æ®ã€‚\n\né€šè¿‡ä»¥ä¸Šå…³é”®å›¾è¡¨ï¼Œè¯»è€…å¯ä»¥ç›´è§‚ç†è§£Megatron-LMæ–¹æ³•çš„æ•ˆæœï¼šè®¡ç®—æ•ˆç‡é«˜ã€æ¨¡å‹è¡¨ç°ä¼˜å¼‚ä¸”æ¶æ„è°ƒæ•´å‘æŒ¥å…³é”®ä½œç”¨ã€‚æ¯ä¸ªå›¾è¡¨å’Œè¡¨æ ¼éƒ½å¯¹åº”åœ°æ”¯æ’‘äº†å‰æ–‡çš„å®éªŒç»“è®ºã€‚\nç»“æœè§£è¯»ä¸è¾¹ç•Œï¼šæ€»ä½“è€Œè¨€ï¼ŒMegatron-LMçš„å®éªŒç»“æœå±•ç°äº†ä»¤äººä¿¡æœçš„æ€§èƒ½æå‡å’Œæ‰©å±•èƒ½åŠ›ï¼Œè¯æ˜åªè¦è®­ç»ƒèµ„æºå……è¶³ï¼Œå¤§è§„æ¨¡æ¨¡å‹çš„æ½œåŠ›å¯ä»¥è¢«å……åˆ†æŒ–æ˜ã€‚è¿™ä¸€ç»“è®ºå¯¹NLPé¢†åŸŸå½±å“æ·±è¿œâ€”â€”å®ƒä¸ºæ­¤åå‡ºç°çš„æ›´å¤§æ¨¡å‹ï¼ˆå¦‚GPT-3ç­‰ï¼‰å¥ å®šäº†æ–¹æ³•åŸºç¡€ï¼Œè¡¨æ˜é‡‡ç”¨æ¨¡å‹å¹¶è¡Œç­‰æŠ€æœ¯èƒ½å¤Ÿæœ‰æ•ˆåœ°è®­ç»ƒç™¾äº¿çº§å‚æ•°æ¨¡å‹ã€‚ç„¶è€Œï¼Œä¹Ÿéœ€è¦ç†æ€§çœ‹å¾…è¿™äº›ç»“æœçš„é€‚ç”¨èŒƒå›´å’Œå±€é™ï¼š\n\né¦–å…ˆï¼Œæˆæœ¬ä¸èƒ½è€—è¾¹ç•Œï¼šè¾¾åˆ°è®ºæ–‡ä¸­çš„SOTAç»“æœä¾èµ–æ•°ç™¾GPUæ—¥ä»¥ç»§å¤œçš„è®¡ç®—ï¼ˆè®ºæ–‡æåŠ8.3Bæ¨¡å‹å•è½®epochè®­ç»ƒéœ€çº¦ä¸¤å¤©ã€‚è¿™ç§è§„æ¨¡çš„è®¡ç®—ä»£ä»·ä½¿å¾—å¤§æ¨¡å‹è®­ç»ƒä¸»è¦å±€é™äºé¡¶å°–å®éªŒå®¤å’Œå…¬å¸ã€‚æ¢è¨€ä¹‹ï¼Œæ–¹æ³•è™½ç„¶è¯æ˜å¯è¡Œï¼Œä½†åœ¨èµ„æºå—é™ç¯å¢ƒä¸‹éš¾ä»¥å¤ç°ï¼Œæˆæœ¬å’Œèƒ½è€—æ˜¯ç°å®è¾¹ç•Œä¹‹ä¸€ã€‚\næ¨¡å‹è§„æ¨¡çš„æ”¶ç›Šé€’å‡ï¼šå°½ç®¡è®ºæ–‡ä¸­æ€§èƒ½éšè§„æ¨¡å¢é•¿è€Œæå‡ï¼Œä½†å¹¶æœªç³»ç»Ÿæ¢è®¨å¢é•¿åˆ°æ›´é«˜å‚æ•°é‡æ—¶æ˜¯å¦å­˜åœ¨æ‹ç‚¹æˆ–ç“¶é¢ˆã€‚åç»­ç ”ç©¶æå‡ºäº†Scaling Lawï¼ˆæ‰©å±•è§„å¾‹ï¼‰ï¼ŒæŒ‡å‡ºæ€§èƒ½æå‡å¯¹æ•°é€’å‡ã€‚Megatron-LMçš„ç»“æœä¸»è¦è¦†ç›–åˆ°8Bé‡çº§ï¼Œå¯¹äºç™¾äº¿ç”šæˆ–åƒäº¿å‚æ•°æ˜¯å¦çº¿æ€§é€‚ç”¨ï¼Œä»å­˜åœ¨ä¸ç¡®å®šæ€§ï¼ˆå¾…æ ¸å®ï¼‰ã€‚\né€šç”¨æ€§ä¸å…¶å®ƒå› ç´ ï¼šè®ºæ–‡é›†ä¸­åœ¨Transformerè¯­è¨€æ¨¡å‹ï¼Œå¯¹å…¶å®ƒæ¶æ„ï¼ˆCNNã€RNNï¼‰æˆ–å…¶å®ƒä»»åŠ¡çš„å¯æ¨å¹¿æ€§æœªåšå®éªŒã€‚ä¾‹å¦‚è§†è§‰æ¨¡å‹çš„å¤§è§„æ¨¡è®­ç»ƒæ˜¯å¦ä¹Ÿèƒ½ç›´æ¥å¥—ç”¨ç±»ä¼¼æ–¹æ³•å°šå¾…éªŒè¯ã€‚æ­¤å¤–ï¼Œè®ºæ–‡å…³æ³¨è§„æ¨¡å’Œå¹¶è¡Œï¼Œæœ¬èº«å¹¶æœªè¯¦ç»†è®¨è®ºä¼˜åŒ–ç®—æ³•ã€æ­£åˆ™åŒ–ç­‰å¯¹æœ€ç»ˆæ€§èƒ½çš„å½±å“ï¼Œè¿™äº›åœ¨æ›´å¤§è§„æ¨¡è®­ç»ƒæ—¶å¯èƒ½å˜å¾—æ˜¾è‘—ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œç»“æœçš„ä¼˜ç§€éƒ¨åˆ†å½’å› äºæ›´å¤§æ¨¡å‹å®¹é‡ï¼Œä½†ä¼˜åŒ–ç»†èŠ‚æˆ–è®­ç»ƒæ•°æ®ç­‰å› ç´ å¯¹ç»“æœçš„è´¡çŒ®æ²¡æœ‰åˆ†åˆ«é‡åŒ–ã€‚\nè¯„æµ‹ç»´åº¦æœ‰é™ï¼šä½œè€…ä¸»è¦ä»¥æ ‡å‡†åŸºå‡†ä»»åŠ¡è¡¡é‡æ¨¡å‹ï¼Œä¾§é‡äºå‡†ç¡®ç‡å’Œå›°æƒ‘åº¦ç­‰æŒ‡æ ‡ã€‚è€Œå¯¹äºå¤§æ¨¡å‹æ½œåœ¨çš„å…¶å®ƒè¯„æµ‹ç»´åº¦ï¼ˆå¦‚æ³›åŒ–èƒ½åŠ›ã€åè§å’Œå…¬å¹³æ€§ã€é²æ£’æ€§ç­‰ï¼‰ï¼Œè®ºæ–‡æ²¡æœ‰æ¶‰çŒã€‚è¿™äº›æ„æˆäº†ç»“æœè§£è¯»çš„è¾¹ç•Œï¼šæ€§èƒ½å“è¶Šä¸ç­‰äºå®Œç¾ï¼Œå¤§æ¨¡å‹åœ¨å®ç”¨ä¸­è¿˜éœ€è¦è€ƒè™‘æ›´å¤šå…¨é¢çš„æŒ‡æ ‡ã€‚\n\næ€»ä¹‹ï¼ŒMegatron-LMçš„å®éªŒæˆæœåœ¨å¤§æ¨¡å‹è®­ç»ƒé¢†åŸŸæ ‘ç«‹äº†æ ‡æ†ï¼Œä½†åŒæ—¶ä¹Ÿæç¤ºæˆ‘ä»¬æ³¨æ„èƒŒåçš„ä»£ä»·å’Œæœªè§£å†³çš„é—®é¢˜ã€‚åœ¨ç»§ç»­è¿½æ±‚æ›´å¤§æ›´å¼ºæ¨¡å‹çš„é“è·¯ä¸Šï¼Œè¿™äº›è¾¹ç•Œæ¡ä»¶å°†æ˜¯éœ€è¦å…‹æœçš„æŒ‘æˆ˜ã€‚\nå…­ã€ä¼˜ç‚¹ä¸å±€é™\nStrengths â€“ äº®ç‚¹ï¼š\n\nå¤§å¹…æå‡å¯è®­ç»ƒæ¨¡å‹è§„æ¨¡ï¼šMegatron-LMæ–¹æ¡ˆæ˜¾è‘—çªç ´å•æœºæ˜¾å­˜é™åˆ¶ï¼Œä½¿å¾—å½“æ—¶æ¨¡å‹å‚æ•°è§„æ¨¡ä»æ•°äº¿æå‡åˆ°æ•°åäº¿çº§åˆ«æˆä¸ºå¯èƒ½ã€‚è¿™ç§èƒ½åŠ›ç›´æ¥æ¨åŠ¨äº†æ›´é«˜æ€§èƒ½çš„è¯­è¨€æ¨¡å‹å‡ºç°ï¼Œä¸ºä¹‹åçš„è¶…å¤§è§„æ¨¡æ¨¡å‹ï¼ˆå¦‚GPT-3ç­‰ï¼‰é“ºå¹³é“è·¯ã€‚\nå·¥ç¨‹å®ç°ç®€å•é«˜æ•ˆï¼šæ–¹æ³•ä¸ä¾èµ–ç‰¹æ®Šç¼–è¯‘å™¨æˆ–æ¡†æ¶æ”¹åŠ¨ï¼Œä»…é€šè¿‡æ’å…¥All-Reduceç­‰é€šä¿¡æ“ä½œå®ç°ã€‚å€ŸåŠ©PyTorchå·²æœ‰æœºåˆ¶ï¼Œå°±èƒ½è¾¾åˆ°æ¥è¿‘ç†æƒ³çš„æ‰©å±•æ•ˆç‡ã€‚è¿™æ„å‘³ç€ç°æœ‰ä»£ç åº“æ˜“äºé›†æˆï¼Œé™ä½äº†å¹¶è¡Œè®­ç»ƒçš„å®ç°å¤æ‚åº¦ï¼Œå…·æœ‰å¾ˆé«˜çš„å·¥ç¨‹å®ç”¨ä»·å€¼ã€‚\nSOTAæ€§èƒ½è¯æ˜æœ‰æ•ˆæ€§ï¼šè®ºæ–‡ä¸ä»…åœ¨ç†è®ºä¸Šæå‡ºæ–¹æ³•ï¼Œè¿˜é€šè¿‡å®é™…è®­ç»ƒéªŒè¯äº†å¤§æ¨¡å‹å¸¦æ¥çš„æ€§èƒ½æå‡ï¼ŒåŒ…æ‹¬åˆ·æ–°å¤šé¡¹NLPä»»åŠ¡çš„SOTAã€‚è¿™ä¸ºâ€œå¤§æ¨¡å‹æ›´å¥½â€æä¾›äº†ç›´æ¥è¯æ®ï¼Œå¢å¼ºäº†å­¦ç•Œä¸šç•Œå¯¹æŠ•å…¥èµ„æºè®­ç»ƒæ›´å¤§æ¨¡å‹çš„ä¿¡å¿ƒã€‚\nçµæ´»å…¼å®¹å…¶ä»–å¹¶è¡Œç­–ç•¥ï¼šä½œè€…å¼ºè°ƒå…¶å¼ é‡æ¨¡å‹å¹¶è¡Œä¸æ•°æ®å¹¶è¡Œå’Œæµæ°´çº¿å¹¶è¡Œæ˜¯æ­£äº¤ä¸”å¯ç»“åˆçš„ã€‚è¿™ä¸€ç‰¹æ€§è®©æ–¹æ³•å¯åº”ç”¨äºå„ç§é›†ç¾¤è§„æ¨¡å’Œå†…å­˜éœ€æ±‚ä¸‹ï¼Œé€šè¿‡å¤šé‡å¹¶è¡Œçš„ç»„åˆè¿›ä¸€æ­¥æ‰©å±•ã€‚ä¾‹å¦‚8è·¯æ¨¡å‹å¹¶è¡Œé…åˆ64è·¯æ•°æ®å¹¶è¡Œçš„æ··åˆæ–¹æ¡ˆåœ¨è®ºæ–‡ä¸­è·å¾—æˆåŠŸã€‚\næ¶æ„æ´å¯Ÿä¸æ”¹è¿›ï¼šå·¥ä½œä¸­å‘ç°çš„LayerNormè°ƒæ•´å¯¹BERTæ€§èƒ½çš„å½±å“ï¼Œæ˜¯ä¸€ä¸ªå®è´µçš„ç»éªŒæ•™è®­ã€‚è¿™å±•ç¤ºäº†ä½œè€…å¯¹æ¨¡å‹è®­ç»ƒåŠ¨æ€çš„æ·±å…¥æ´å¯Ÿï¼Œå¹¶æä¾›äº†æ”¹è¿›å¤§æ¨¡å‹ç¨³å®šæ€§çš„ä¸€ä¸ªé€šç”¨æŠ€å·§ï¼ˆåæ¥è¢«å¹¿æ³›é‡‡ç”¨ä¸ºPre-LN Transformeræ¶æ„ï¼‰ã€‚\nå¼€æºä¸å½±å“ï¼šä½œè€…å¼€æºäº†Megatron-LMè®­ç»ƒä»£ç å’Œé…ç½®ï¼Œä¸ºç¤¾åŒºæä¾›äº†ç›´æ¥ä½¿ç”¨å¤§è§„æ¨¡è®­ç»ƒæ–¹æ¡ˆçš„æœºä¼šã€‚è¿™æå¤§åœ°åŠ é€Ÿäº†ç›¸å…³ç ”ç©¶çš„å‘å±•ã€‚éšåè®¸å¤šå¤§å‹æ¨¡å‹è®­ç»ƒï¼ˆMicrosoft Turing-NLG, EleutherAI GPTç­‰ï¼‰éƒ½å€Ÿé‰´æˆ–ç›´æ¥ä½¿ç”¨äº†Megatron-LMçš„å®ç°ï¼Œå……åˆ†ä½“ç°äº†æœ¬å·¥ä½œçš„å½±å“åŠ›ã€‚\n\nLimitations â€“ å±€é™ï¼š\n\nèµ„æºè¦æ±‚æé«˜ï¼šè¯¥æ–¹æ³•éœ€è¦å¤§é‡GPUååŒè®­ç»ƒæ‰èƒ½å‘æŒ¥ä¼˜åŠ¿ã€‚è®ºæ–‡å®éªŒç”¨åˆ°512å—V100 GPUï¼Œè¿™ç§è§„æ¨¡çš„èµ„æºæä¸ºæ˜‚è´µä¸”æ™®é€šå›¢é˜Ÿéš¾ä»¥è·å¾—ã€‚å³ä½¿æ–¹æ³•æœ¬èº«é«˜æ•ˆï¼Œä½†ç®—åŠ›å’Œå†…å­˜é—¨æ§›ä¾ç„¶é™åˆ¶äº†å®ƒçš„æ™®åŠé¢ï¼Œè¿™å±äºæ— æ³•å¿½è§†çš„ç°å®å±€é™ã€‚\né€šä¿¡ç“¶é¢ˆä»å­˜åœ¨ï¼šå°½ç®¡å·²å°†é€šä¿¡å‹ç¼©åˆ°æ¯å±‚ä»…2æ¬¡All-Reduceï¼Œä½†å¯¹äºæ›´å¤§è§„æ¨¡å¹¶è¡Œï¼ˆå¦‚æˆåƒä¸Šä¸‡GPUï¼‰ï¼Œé€šä¿¡å¼€é”€å¯èƒ½å¢é•¿å¹¶æˆä¸ºç“¶é¢ˆã€‚ç½‘ç»œæ‹“æ‰‘ä¸ä½³æˆ–å¸¦å®½ä¸è¶³æ—¶æ•ˆç‡ä¼šæ€¥å‰§ä¸‹é™ã€‚å› æ­¤è¯¥æ–¹æ³•åœ¨è¶…å¤§è§„æ¨¡é›†ç¾¤ä¸‹çš„æ•ˆç‡å¯ä¼¸ç¼©æ€§éœ€è¦è¿›ä¸€æ­¥éªŒè¯ï¼Œé€šä¿¡å»¶å±•æ€§æ˜¯æ½œåœ¨çš„çŸ­æ¿ã€‚\nä¾èµ–ç‰¹å®šæ¨¡å‹ç»“æ„ï¼šæ–¹æ¡ˆåˆ©ç”¨Transformerå±‚çš„å‡åŒ€ç»“æ„å’Œç‹¬ç«‹æ€§å®ç°å¹¶è¡Œï¼Œå¯¹Transformerä»¥å¤–çš„æ¨¡å‹ï¼ˆå¦‚RNNã€CNNï¼‰å¹¶ä¸ä¸€å®šç›´æ¥é€‚ç”¨ã€‚è‹¥æ¨¡å‹å±‚ä¹‹é—´å­˜åœ¨ä¾èµ–é¡ºåºæˆ–å…¨å±€æ“ä½œï¼Œåˆ™æ— æ³•å¥—ç”¨ç®€å•çš„å¼ é‡å¹¶è¡Œåˆ’åˆ†ã€‚æ­¤å¤–ï¼Œå¯¹äºæŸäº›éœ€è¦è·¨å±‚é€šä¿¡çš„ç½‘ç»œï¼Œæ–¹æ³•éœ€è°ƒæ•´æˆ–æ— æ³•ä½¿ç”¨ã€‚\nå†…å­˜ç“¶é¢ˆè½¬ç§»ï¼šæ¨¡å‹å¹¶è¡Œé™ä½äº†æ¯ä¸ªGPUçš„æ¨¡å‹å‚æ•°å†…å­˜ï¼Œä½†å¹¶æœªè§£å†³ä¼˜åŒ–å™¨çŠ¶æ€å’Œæ¿€æ´»çš„å†…å­˜æ¶ˆè€—ã€‚ä»¥Adamä¼˜åŒ–ä¸ºä¾‹ï¼Œä»éœ€è¦ä¸ºæ¯ä¸ªå‚æ•°ç»´æŠ¤é¢å¤–2å€çš„çŠ¶æ€ã€‚è¿™äº›åœ¨å¤§æ¨¡å‹ä¸‹å æ®å¤§é‡å†…å­˜ã€‚è™½ç„¶å¯ä»¥å€ŸåŠ©æ¢¯åº¦æ£€æŸ¥ç‚¹ç­‰ç¼“è§£æ¿€æ´»å†…å­˜ï¼Œä½†ä¼˜åŒ–å™¨çŠ¶æ€å’Œæ¢¯åº¦çš„å†…å­˜é—®é¢˜åœ¨è®ºæ–‡ä¸­æœªè§£å†³ï¼Œåç»­ZeROç­‰æŠ€æœ¯æ­£æ˜¯ä¸ºæ­¤æå‡ºã€‚\nè®­ç»ƒç¨³å®šæ€§å…¶ä»–é—®é¢˜ï¼šé™¤äº†LayerNormä½ç½®è°ƒæ•´ï¼Œè¶…å¤§æ¨¡å‹è®­ç»ƒå¯èƒ½é¢ä¸´å…¶ä»–æ•°å€¼ç¨³å®šæŒ‘æˆ˜ï¼Œå¦‚æ¢¯åº¦çˆ†ç‚¸/æ¶ˆå¤±ã€å­¦ä¹ ç‡è§„åˆ’ç­‰ã€‚è®ºæ–‡ä»…æ¢è®¨äº†LayerNormä¸€ç§å› ç´ ã€‚å¯¹äºä¸åŒæ¨¡å‹å’Œæ›´é•¿è®­ç»ƒè¿‡ç¨‹ï¼Œè¿˜å¯èƒ½å‡ºç°æœªé¢„è§çš„ä¸ç¨³å®šï¼Œéœ€è¦é¢å¤–è°ƒä¼˜ã€‚æ–¹æ³•æœ¬èº«æ²¡æœ‰æä¾›å…³äºè¿™äº›æ–¹é¢çš„ä¿è¯ã€‚\nè¯„ä¼°èŒƒå›´æœ‰é™ï¼šä½œè€…ä¸»è¦å…³æ³¨æ¨¡å‹ç²¾åº¦å’Œé€Ÿåº¦ï¼Œå¯¹æ¨¡å‹äº§ç”Ÿçš„å…¶ä»–å½±å“å¦‚æ³›åŒ–ã€é²æ£’æ€§ã€åè§ç­‰æœªåšè®¨è®ºã€‚å¤§æ¨¡å‹å¾€å¾€å¸¦æ¥å‚æ•°å¤šã€è¡¨è¾¾èƒ½åŠ›å¼ºçš„åŒæ—¶ï¼Œä¹Ÿå¯èƒ½è®°å¿†è®­ç»ƒæ•°æ®æˆ–æ”¾å¤§åè§ã€‚Megatron-LMè®­ç»ƒå‡ºçš„æ¨¡å‹åœ¨è¿™äº›æ–¹é¢çš„è¡Œä¸ºæ²¡æœ‰åœ¨è®ºæ–‡ä¸­æ¢è®¨ï¼Œè¿™å±äºæ–¹æ³•åœ¨å®é™…åº”ç”¨ä¸­çš„å±€é™å’Œé£é™©ã€‚\n\nä¸ƒã€ä¸šå†…ç›¸å…³å·¥ä½œå¯¹æ¯”\nå¤§è§„æ¨¡æ¨¡å‹è®­ç»ƒæ˜¯è¿‘å¹´AIç ”ç©¶çš„çƒ­ç‚¹ï¼ŒMegatron-LMä¸å…¶ä»–ä¸€äº›å¹¶è¡ŒåŒ–æˆ–æ¨¡å‹å‹ç¼©æ€è·¯æœ‰æ‰€åŒºåˆ«å’Œå…³è”ã€‚ä¸‹é¢é€‰å–å‡ é¡¹åŒæœŸæˆ–ç›¸å…³å·¥ä½œè¿›è¡Œå¯¹æ¯”ï¼š\n\nGPipe (2018) â€“ æµæ°´çº¿å¹¶è¡Œï¼šGoogleæå‡ºçš„GPipeå°†æ¨¡å‹ä¸åŒå±‚åˆ‡åˆ†åˆ°ä¸²è¡Œçš„è®¾å¤‡ä¸Šï¼Œé‡‡ç”¨å¾®æ‰¹æ¬¡æµæ°´çº¿æ–¹å¼æ¥å¹¶è¡Œè®­ç»ƒã€‚å…¶é—®é¢˜å®šä¹‰åŒä¸ºçªç ´å•å¡å†…å­˜é™åˆ¶ï¼Œä½†æ–¹æ³•è·¯çº¿ä¸åŒï¼šGPipeä¸»æ‰“è·¨å±‚å¹¶è¡Œï¼Œå°†æ¨¡å‹åˆ†æ®µè€ŒMegatron-LMä¸»æ‰“å±‚å†…å¹¶è¡Œï¼Œåœ¨æ¯å±‚å†…éƒ¨åˆ‡åˆ†çŸ©é˜µã€‚GPipeéœ€è¦å°†æ¨¡å‹é‡æ„ä¸ºpipelineå¹¶ç®¡ç†â€œbubbleâ€å»¶è¿Ÿï¼Œè€ŒMegatron-LMåªéœ€åœ¨å±‚å†…æ’å…¥é€šä¿¡ã€‚ä¸¤è€…å¯ç»„åˆï¼ˆæ­£å¦‚Megatronä½œè€…æ‰€è¨€æ¨¡å‹å¹¶è¡Œä¸æµæ°´çº¿å¹¶è¡Œæ­£äº¤ï¼‰ï¼ŒGPipeä¾§é‡å‡å°‘å³°å€¼å†…å­˜ï¼ŒMegatronè¿½æ±‚å……åˆ†åˆ©ç”¨ç®—åŠ›ã€‚ä¸»è§‚è¯„ä»·æ¥çœ‹ï¼ŒGPipeå®ç°å¤æ‚åº¦è¾ƒé«˜ï¼Œéœ€è¦ç‰¹æ®Šæ¡†æ¶æ”¯æŒï¼ˆå¦‚TensorFlow XLAï¼‰ï¼Œè®­ç»ƒæ—¶éœ€è¦å‡è¡¡å„åˆ†æ®µè®¡ç®—è´Ÿè½½ï¼Œå¦åˆ™ä¼šæœ‰æµæ°´ç­‰å¾…ã€‚è€ŒMegatron-LMå®ç°æ›´ç®€æ´ç›´æ¥ï¼Œåœ¨PyTorché‡Œå‡ ä¹å³æ’å³ç”¨ã€‚ä½†GPipeå¯¹é€šä¿¡çš„éœ€æ±‚è¾ƒä½ï¼ˆæ¯é˜¶æ®µä»…éœ€ä¼ é€’æ¿€æ´»ç»™ä¸‹æ¸¸ï¼‰ï¼Œåœ¨è¶…é•¿åºåˆ—æˆ–ææ·±ç½‘ç»œæ—¶å¯èƒ½æ›´é«˜æ•ˆã€‚æ€»ä½“è€Œè¨€ï¼ŒäºŒè€…å„æ“…æ‰€é•¿ï¼Œå¯ç»“åˆç”¨äºæ›´å¤§æ¨¡å‹ï¼šä¸šç•Œå®è·µå¸¸å°†Megatronçš„å¼ é‡å¹¶è¡Œä¸GPipeçš„åˆ†å±‚å¹¶è¡Œä¸€åŒä½¿ç”¨ï¼Œå®ç°2Då¹¶è¡Œæ‰©å±•ã€‚\nMesh-TensorFlow (2018) â€“ å¼ é‡åˆ’åˆ†æ¡†æ¶ï¼šShazeerç­‰æå‡ºçš„Mesh-TensorFlowæä¾›äº†ä¸€ç§åœ¨ä»»æ„åˆ†å¸ƒå¼è®¾å¤‡ç½‘æ ¼ï¼ˆmeshï¼‰ä¸Šåˆ’åˆ†å¼ é‡çš„æ–¹æ³•ã€‚å®ƒçš„é—®é¢˜å®šä¹‰ä¹Ÿæ˜¯åœ¨ä¸åŒè®¾å¤‡é—´åˆ’åˆ†æ¨¡å‹å¼ é‡ï¼Œæ–¹æ³•ä¸Šé€šè¿‡åœ¨TensorFlowä¸­å£°æ˜å¼ é‡çš„åˆ†å¸ƒç»´åº¦ï¼Œç”±XLAç¼–è¯‘å™¨è‡ªåŠ¨ç”Ÿæˆå¹¶è¡Œæ‰§è¡Œè®¡åˆ’ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒMegatron-LMæ˜¯æ‰‹å·¥åœ¨PyTorchä¸­æ’å…¥é€šä¿¡å®ç°å¹¶è¡Œï¼ŒMesh-TFåˆ™é«˜åº¦ä¾èµ–ç¼–è¯‘å™¨ä¼˜åŒ–ã€‚Mesh-TFçš„å¯ç»„åˆæ€§å¼ºï¼Œå¯ä»¥æ”¯æŒå¤šç§å¹¶è¡Œæ¨¡å¼æ··åˆï¼Œä½†éœ€è¦ä½¿ç”¨å…¶DSLé‡æ–°å®šä¹‰æ¨¡å‹ï¼Œå®šåˆ¶æˆæœ¬é«˜ã€‚Megatron-LMæ³¨é‡æ˜“ç”¨ï¼Œåœ¨PyTorchåŸç”Ÿæ¨¡å‹ä¸Šç¨åŠ ä¿®æ”¹å³å¯ã€‚ä¸»è§‚è¯„ä»·ï¼ŒMesh-TFä½œä¸ºé€šç”¨æ¡†æ¶çµæ´»å¼ºå¤§ï¼Œæ”¯æŒä¾‹å¦‚TPUä¸Šçš„å¹¶è¡Œå¹¶æ›¾ç”¨äºè°·æ­Œçš„T5ç­‰æ¨¡å‹è®­ç»ƒï¼›ä½†è°ƒè¯•å’Œå®ç°éš¾åº¦è¾ƒå¤§ï¼Œæ¨¡å‹å¼€å‘è€…éœ€è¦ç†è§£å¹¶è¡Œå¸ƒå±€æ¦‚å¿µã€‚è€ŒMegatron-LMèƒœåœ¨å®ç”¨æ•ˆç‡ï¼Œé’ˆå¯¹Transformerè¿™ç§è§„åˆ™æ¨¡å‹ç»™å‡ºäº†ç°æˆä¼˜åŒ–æ–¹æ¡ˆã€‚Mesh-TFä¾é XLAï¼ŒæŸç§ç¨‹åº¦ä¸Šé¢„ç¤ºäº†æœªæ¥æ·±åº¦å­¦ä¹ ç¼–è¯‘å™¨çš„æ–¹å‘ï¼›Megatron-LMåˆ™åœ¨å½“æ—¶ç¡¬ä»¶è½¯ä»¶æ¡ä»¶ä¸‹åŠæ—¶æä¾›äº†å¯è½åœ°çš„æ–¹æ¡ˆã€‚\nDeepSpeed ZeRO (2020) â€“ ä¼˜åŒ–å™¨çŠ¶æ€å¹¶è¡Œï¼šå¾®è½¯æå‡ºçš„ZeROä¼˜åŒ–å™¨å±äºæ•°æ®å¹¶è¡Œå†…å­˜ä¼˜åŒ–èŒƒç•´ã€‚å®ƒä¸Megatron-LMé—®é¢˜å®šä¹‰çš„å…±åŒç‚¹åœ¨äºéƒ½è§£å†³GPUæ˜¾å­˜ä¸è¶³é™åˆ¶å¤§æ¨¡å‹è®­ç»ƒï¼Œä½†è·¯çº¿æˆªç„¶ä¸åŒï¼šZeROé€šè¿‡åˆ’åˆ†ä¼˜åŒ–å™¨çŠ¶æ€å’Œæ¢¯åº¦æ¥é™ä½æ¯å¼ å¡çš„å†…å­˜å ç”¨ï¼Œä¸æ”¹å˜æ¨¡å‹æœ¬èº«çš„å¹¶è¡Œè®¡ç®—é¡ºåºã€‚ç®€è¨€ä¹‹ï¼ŒZeROä»æ˜¯æ•°æ®å¹¶è¡Œè®­ç»ƒï¼Œåªæ˜¯åœ¨æ¯æ­¥åå°†å„å¡çš„æ¢¯åº¦å’Œä¼˜åŒ–å™¨ç´¯ç§¯ä¿¡æ¯åˆ†æ‘Šå­˜å‚¨ã€‚è¿™æ ·æ¯å¼ å¡åªéœ€ç»´æŠ¤å…¨å±€1/æµ·é‡çš„æ•°æ®å‰¯æœ¬ï¼Œä»è€Œæ”¯æŒæ›´å¤§æ¨¡å‹ã€‚ZeROä¸Megatronå…·å¤‡å¾ˆå¼ºçš„å¯ç»„åˆæ€§ï¼šäº‹å®ä¸Šè®¸å¤šè®­ç»ƒæ ˆåŒæ—¶é‡‡ç”¨Megatronçš„æ¨¡å‹å¹¶è¡Œå’ŒZeROçš„ä¼˜åŒ–å™¨ç¢ç‰‡åŒ–ï¼Œä½¿å¾—æ¨¡å‹å‚æ•°ã€æ¢¯åº¦ã€ä¼˜åŒ–å™¨éƒ½å¾—åˆ°å……åˆ†å¹¶è¡Œã€‚ä¸»è§‚ä¸Šçœ‹ï¼ŒZeROå¯¹ç°æœ‰è®­ç»ƒä»£ç æ”¹åŠ¨è¾ƒå°‘ï¼ˆåˆ©ç”¨DeepSpeedåº“å°è£…å®ç°ï¼‰ï¼Œä½†å®ƒéœ€è¦é¢‘ç¹é€šä¿¡åŒæ­¥ç¢ç‰‡åŒ–çš„æ¢¯åº¦ï¼Œé€šä¿¡é‡éšå‚æ•°å¢é•¿çº¿æ€§ä¸Šå‡ï¼Œå¯¹ç½‘ç»œä¾èµ–å¤§ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒMegatronåœ¨é™ä½é€šä¿¡é¢‘æ¬¡æ–¹é¢åšäº†ä¼˜åŒ–ï¼ˆæ¯å±‚2æ¬¡All-Reduceå›ºå®šï¼‰ã€‚ä¸¤è€…çš„æ€æƒ³å¯ä»¥ç»“åˆï¼šMegatronè§£å†³è®¡ç®—å’Œå‰å‘å†…å­˜ï¼ŒZeROè§£å†³æ¢¯åº¦å’Œä¼˜åŒ–å™¨å†…å­˜ï¼Œå…±åŒçªç ´å¤šæ–¹é¢ç“¶é¢ˆã€‚æœªæ¥ä¸Šç™¾äº¿å‚æ•°æ¨¡å‹è®­ç»ƒä¸­ï¼Œæ··åˆå¼ é‡å¹¶è¡Œ+ZeROå·²æˆä¸ºäº‹å®æ ‡å‡†é…ç½®ã€‚\nALBERT (2019) â€“ å‚æ•°å…±äº«å‹ç¼©ï¼šLanç­‰æå‡ºçš„ALBERTé’ˆå¯¹BERTæ¨¡å‹è§„æ¨¡ç“¶é¢ˆï¼Œé‡‡ç”¨è·¨å±‚å‚æ•°å…±äº«å’Œå‘é‡åˆ†è§£åµŒå…¥ç­‰æ–¹æ³•å‡å°‘å‚æ•°æ€»é‡ï¼Œä»¥æå‡æ¨¡å‹è®­ç»ƒå¯è¡Œæ€§ã€‚å®ƒè§£å†³çš„æ˜¯ç±»ä¼¼é—®é¢˜ï¼ˆBERTè¶…è¿‡BERT-Largeåæ•ˆæœä¸‹é™å’Œèµ„æºä¸è¶³ï¼‰ï¼Œä½†æ–¹æ³•ä¸æ˜¯å¹¶è¡Œè®­ç»ƒï¼Œè€Œæ˜¯æ”¹å˜æ¨¡å‹ç»“æ„ä½¿å‚æ•°æ›´å°‘ã€æ›´é«˜æ•ˆã€‚ä¾‹å¦‚å°†æ¯å±‚Transformeræƒé‡å…±äº«ï¼Œä»è€Œå¤§å¹…å‡å°‘å‚æ•°é‡ã€‚Megatron-LMå’ŒALBERTå¯ä»¥è¯´å–å¾„ç›¸åï¼šä¸€ä¸ªæ˜¯é€šè¿‡å¢åŠ ç¡¬ä»¶èµ„æºå¹¶è¡Œä»¥å®¹çº³æ›´å¤šå‚æ•°ï¼Œä¸€ä¸ªæ˜¯é€šè¿‡ä¼˜åŒ–ç½‘ç»œè®¾è®¡åœ¨åŒæ ·èµ„æºä¸‹å‡å°‘å‚æ•°ã€‚è¿™ä¸¤ç§å¯ä¸€å®šç¨‹åº¦ç»„åˆï¼ˆæ¯”å¦‚ä½¿ç”¨æ¨¡å‹å¹¶è¡Œè®­ç»ƒALBERTä¹Ÿå¯è¿›ä¸€æ­¥æé«˜æ•ˆç‡ï¼‰ï¼Œä½†å› ä¸ºALBERTå‡å°‘å‚æ•°ä¹Ÿæ„å‘³ç€å®¹é‡ä¸‹é™ï¼Œåæ¥çš„å®è·µè¯æ˜ä¸å…±äº«å‚æ•°çš„å¤§æ¨¡å‹å¾€å¾€æ•ˆæœæ›´å¥½ã€‚å› æ­¤Megatronçš„æ–¹æ³•æ›´åå‘â€œç”¨ç¡¬ä»¶ brute force å®ç°æ•ˆæœæå‡â€ï¼Œè€ŒALBERTå±äºâ€œå·§å¦™è®¾è®¡æ¨¡å‹å‹ç¼©â€ã€‚ä¸»è§‚è¯„ä»·ï¼ŒALBERTå¯¹å­¦æœ¯ç ”ç©¶æœ‰æ„ä¹‰ï¼Œå¯å‘äº†å‚æ•°é«˜æ•ˆåˆ©ç”¨çš„æ€è·¯ï¼Œä½†åœ¨çœŸæ­£è¿½æ±‚SOTAæ—¶è¿˜æ˜¯æ›´å¤§çš„éå…±äº«æ¨¡å‹èƒœå‡ºã€‚Megatron-LMä»£è¡¨çš„è·¯çº¿è·¯å¾„åœ¨åæ¥å±…ä¸Šï¼Œè¯æ˜äº†åªè¦èƒ½è®­ç»ƒï¼Œå¤§æ¨¡å‹çš„æ•ˆæœç»ˆå°†ä¼˜äºå°æ¨¡å‹+å‚æ•°å…±äº«ã€‚\n\n7.1 ä¸ªäººè§‚ç‚¹\nç»¼è§‚è¿™äº›å·¥ä½œï¼ŒMegatron-LMä»¥å…¶å®ç”¨æ€§å’Œé«˜æ•ˆæ€§èƒ½è„±é¢–è€Œå‡ºã€‚ä½œä¸ºè¯»è€…ï¼Œæˆ‘è®¤ä¸ºå…¶æˆåŠŸåœ¨äºæ´æ‚‰å¹¶å¹³è¡¡äº†è®¡ç®—ä¸é€šä¿¡ï¼šä¸åƒæ—©æœŸæ¡†æ¶é‚£æ ·å¼ºä¾èµ–æ–°ç¼–è¯‘æŠ€æœ¯ï¼Œè€Œæ˜¯é¡ºåº”å½“ä¸‹PyTorchç”Ÿæ€ï¼Œç”¨æœ€å°æ”¹åŠ¨æ¢å–å·¨å¤§æ”¶ç›Šã€‚è¿™ç§â€œä»¥å·¥ç¨‹æ¢æ€§èƒ½â€çš„åšæ³•éå¸¸ç°å®ï¼Œä½“ç°äº†å·¥ä¸šç•ŒèƒŒæ™¯ç ”ç©¶äººå‘˜çš„æ€è·¯ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒGPipeå’ŒMesh-TFæ›´å…·å‰ç»æ€§ä½†å®ç°é—¨æ§›é«˜ã€æ³›ç”¨æ€§æœ‰é™ã€‚Megatron-LMçš„æ–¹æ¡ˆåˆ™å¿«äººä¸€æ­¥æ»¡è¶³äº†è®­ç»ƒGTçº§æ¨¡å‹çš„ç‡ƒçœ‰ä¹‹æ€¥ï¼Œè¿™ä¹Ÿæ˜¯åæ¥è®¸å¤šå¤§å‹æ¨¡å‹ç›´æ¥é‡‡ç”¨å®ƒçš„åŸå› ã€‚\nå¦‚æœä»æ”¹è¿›ç©ºé—´æ¥çœ‹ï¼Œæˆ‘ä¸ªäººè§‰å¾—Megatron-LMè¿˜æœ‰ä»¥ä¸‹å¯ä»¥è¿›ä¸€æ­¥å®Œå–„ä¹‹å¤„ï¼š\n\nè‡ªåŠ¨åŒ–ç¨‹åº¦ï¼šç›®å‰å¹¶è¡Œåˆ’åˆ†éœ€è¦äººå…ˆéªŒæŒ‡å®šï¼ˆå¦‚æ¨¡å‹å¹¶è¡Œåº¦ã€åˆ†ç»„å¤§å°ï¼‰ã€‚æœªæ¥æˆ‘ä¼šè€ƒè™‘è®¾è®¡è‡ªåŠ¨å¹¶è¡Œè§„åˆ’ç®—æ³•ï¼Œæ ¹æ®é›†ç¾¤æ‹“æ‰‘å’Œæ¨¡å‹ç»“æ„è‡ªåŠ¨å†³å®šåˆ‡åˆ†ç­–ç•¥ï¼Œå‡å°‘äººå·¥è¯•é”™ã€‚ä¾‹å¦‚å¯ä»¥å€Ÿé‰´å¯å‘å¼æœç´¢æˆ–ä½¿ç”¨profilingæ•°æ®æ¥åˆ†é…æœ€ä¼˜å¹¶è¡Œç»´åº¦ç»„åˆã€‚\nå†…å­˜ä¼˜åŒ–é›†æˆï¼šæ­£å¦‚ZeROæ‰€è§£å†³çš„ï¼Œæ¨¡å‹å¹¶è¡Œå°šæœªå¤„ç†ä¼˜åŒ–å™¨å’Œæ¢¯åº¦çš„å†…å­˜ã€‚æˆ‘ä¼šåœ¨MegatronåŸºç¡€ä¸Šé›†æˆZeROæˆ–ç±»ä¼¼æŠ€æœ¯ï¼Œç”šè‡³åœ¨æ¨¡å‹å¹¶è¡Œä¸­å¼•å…¥æ¢¯åº¦ç‰‡æ®µAll-Gatherï¼Œä½¿å¾—æ— è®ºæ­£å‘è¿˜æ˜¯åå‘ï¼Œå„éƒ¨åˆ†å†…å­˜éƒ½èƒ½è¢«ä¸åŒGPUåˆ†æ‹…ã€‚è¿™æ ·èƒ½å¤Ÿè¿›ä¸€æ­¥æå‡å•æœºèƒ½æ”¯æŒçš„å‚æ•°ä¸Šé™ï¼Œä¹Ÿå‡å°‘æ¯å¼ å¡çš„å†…å­˜å‹åŠ›ï¼Œé™ä½OOMé£é™©ã€‚\né€šä¿¡ä¸è®¡ç®—é‡å ï¼šè™½ç„¶è®ºæ–‡å·²æœ‰éƒ¨åˆ†é‡å ï¼ˆä¾‹å¦‚ä¸‹ä¸€å±‚è®¡ç®—å¯åœ¨ç­‰å¾…All-Reduceæ—¶æå‰ï¼‰ï¼Œä½†æˆ‘è®¤ä¸ºä»æœ‰ç©ºé—´é€šè¿‡å¼‚æ­¥é€šä¿¡ã€å‹ç¼©é€šä¿¡ç­‰æ–¹å¼å‰Šå‡åŒæ­¥å¼€é”€ã€‚æ¯”å¦‚å¯¹æ¢¯åº¦All-Reduceä½¿ç”¨ä½ç²¾åº¦å‹ç¼©ã€åˆ†æ®µé€šä¿¡ï¼Œä»è€Œåœ¨ä¸æŸå¤±å¤šå°‘ç²¾åº¦ä¸‹è¿›ä¸€æ­¥æé«˜æ‰©å±•æ•ˆç‡ã€‚å¦‚æœç½‘ç»œå¸¦å®½æˆä¸ºç“¶é¢ˆï¼Œä¹Ÿå¯è€ƒè™‘æ‹“æ‰‘æ„ŸçŸ¥çš„é€šä¿¡è®¡åˆ’ï¼Œè®©é€šä¿¡åˆ©ç”¨åˆ†å¸ƒå¼ç¼“å­˜æˆ–NVSwitchæ›´é«˜æ•ˆã€‚\nè®­ç»ƒç¨³å®šæ€§ç ”ç©¶ï¼šLayerNormçš„ä½ç½®åªæ˜¯ä¸€ä¸ªå› ç´ ï¼Œæˆ‘å€¾å‘äºç³»ç»Ÿæ€§åœ°ç ”ç©¶è¶…å¤§æ¨¡å‹è®­ç»ƒä¸­çš„ä¸ç¨³å®šæ¥æºï¼Œå¦‚ä¼˜åŒ–å™¨è¶…å‚æ•°ã€åˆå§‹åŒ–æ–¹æ¡ˆã€æ¢¯åº¦è£å‰ªé˜ˆå€¼ç­‰ï¼Œå¹¶é’ˆå¯¹æ€§æå‡ºæ”¹è¿›ã€‚Megatron-LMä¸­å¯ä»¥åŠ å…¥è‡ªé€‚åº”ä¼˜åŒ–è°ƒæ•´æ¨¡å—ï¼Œç›‘æ§æ¢¯åº¦èŒƒæ•°å’Œlossæ›²çº¿ï¼Œä¸€æ—¦æ£€æµ‹åˆ°ä¸ç¨³å®šå¾å…†è‡ªåŠ¨è°ƒæ•´å­¦ä¹ ç‡æˆ–grad clippingï¼Œä»¥æå‡å¤§è§„æ¨¡è®­ç»ƒçš„é²æ£’æ€§ã€‚\nè·¨ç¡¬ä»¶æ”¯æŒï¼šç›®å‰Megatron-LMä¸»è¦é’ˆå¯¹NVIDIA GPUã€‚æˆ‘ä¼šè€ƒè™‘å¦‚ä½•è®©ç±»ä¼¼æ€æƒ³æ‹“å±•åˆ°TPUã€ä»¥åŠæ–°çš„AIåŠ é€Ÿå™¨ä¸Šï¼ŒåŒ…æ‹¬åº”å¯¹ä¸åŒç¡¬ä»¶çš„é€šä¿¡æœºåˆ¶å’Œå†…å­˜æ¶æ„ã€‚è®©å¹¶è¡Œæ–¹æ¡ˆå…·æœ‰ç¡¬ä»¶æ— å…³æ€§ï¼Œå°†ä½¿å…¶å¯¹æ›´å¹¿æ³›çš„è®­ç»ƒç¯å¢ƒé€‚ç”¨ï¼Œä¹Ÿæœ‰åˆ©äºå­¦æœ¯ç•Œç”¨TPU podç­‰èµ„æºå¤ç°ã€‚\n\næ€»çš„æ¥è¯´ï¼ŒMegatron-LMçš„æ€è·¯éå¸¸å€¼å¾—å€Ÿé‰´ã€‚æˆ‘åœ¨é˜…è¯»å’Œæ€è€ƒè¿‡ç¨‹ä¸­æ„Ÿå—åˆ°ï¼Œåœ¨AIæ¨¡å‹è§„æ¨¡æ¼”è¿›ä¸­ï¼Œç³»ç»Ÿä¼˜åŒ–å’Œæ¨¡å‹è®¾è®¡å¿…é¡»ååŒæ¨è¿›ã€‚æœ‰æ—¶ç¡¬ä»¶èµ„æºçš„æŠ•å…¥å’Œå·§å¦™çš„å¹¶è¡Œè®¡ç®—è®¾è®¡æœ¬èº«å°±æ˜¯æ¨åŠ¨ç®—æ³•èƒ½åŠ›çš„å…³é”®å› ç´ ã€‚ä½œä¸ºç ”ç©¶è€…ï¼Œæˆ‘ä¹Ÿä¼šè€ƒè™‘åœ¨è‡ªå·±å®éªŒä¸­åˆ©ç”¨ç±»ä¼¼æ¨¡å‹å¹¶è¡ŒæŠ€å·§æ¥å°è¯•è®­ç»ƒæ›´å¤§çš„æ¨¡å‹ï¼Œå¹¶ç•™æ„å¯èƒ½å‡ºç°çš„æ•°å€¼å’Œå·¥ç¨‹é—®é¢˜ï¼ŒåŠæ—¶åº”ç”¨è®ºæ–‡ä¸­çš„ç»éªŒæ¥è§£å†³ã€‚\nå…«ã€åœ¨å®é™…è®­ç»ƒæ ˆä¸­å¦‚ä½•è½åœ°ï¼Ÿ\nå°†Megatron-LMçš„æ–¹æ³•åº”ç”¨åˆ°å®é™…è®­ç»ƒæ ˆï¼Œéœ€è¦ç»¼åˆè€ƒè™‘æ•°æ®å¤„ç†ã€å¹¶è¡Œè°ƒåº¦ã€åº•å±‚ç®—å­å’Œç³»ç»Ÿå·¥ç¨‹ç­‰å¤šæ–¹é¢ã€‚ä»¥ä¸‹æŒ‰ç…§å…³é”®ç¯èŠ‚åˆ†ç±»è¯´æ˜å…¶è½åœ°æ–¹å¼ã€æ‰€éœ€çš„å·¥ç¨‹å·¥ä½œé‡ä»¥åŠæ½œåœ¨é£é™©ç‚¹ï¼š\n\næ•°æ®è½½å…¥ä¸æ ·æœ¬æ‰“åŒ…ï¼šå®é™…è®­ç»ƒæ—¶ï¼Œæ•°æ®ç®¡çº¿éœ€è¦ç¡®ä¿åœ¨å¤šæœºå¤šå¡ç¯å¢ƒä¸‹é«˜æ•ˆä¾›ç»™æ ·æœ¬ã€‚ä¸€æ–¹é¢ï¼Œéœ€è¦ä½¿ç”¨åˆ†å¸ƒå¼æ•°æ®åŠ è½½ï¼ˆä¾‹å¦‚PyTorchçš„DistributedSamplerï¼‰è®©æ¯ä¸ªæ•°æ®å¹¶è¡Œç»„è¯»å–ä¸åŒåˆ†ç‰‡çš„æ•°æ®ï¼Œä»è€Œæ•´ä½“æ¶µç›–å¤§æ•°æ®é›†ï¼›å¦ä¸€æ–¹é¢ï¼Œåœ¨æ¨¡å‹å¹¶è¡Œç»„å†…éƒ¨ï¼ŒåŒç»„GPUåº”æ¥æ”¶å®Œå…¨ç›¸åŒçš„è¾“å…¥æ‰¹æ¬¡ã€‚è¿™é€šå¸¸é€šè¿‡åœ¨ä¸€ä¸ªç»„çš„ä¸»è¿›ç¨‹ä¸ŠåŠ è½½æ•°æ®ï¼Œç„¶åå°†è¯¥batchå¹¿æ’­åˆ°ç»„å†…å…¶ä»–è¿›ç¨‹å®ç°ã€‚å·¥ç¨‹ä¸Šéœ€è¦ä»”ç»†å¤„ç†éšæœºæ•°ç§å­ã€æ•°æ®shuffleä¸€è‡´æ€§ç­‰ï¼Œä»¥å…ä¸åŒGPUçœ‹åˆ°ä¸åŒé¡ºåºçš„æ•°æ®å¯¼è‡´æ¢¯åº¦ä¸å¯¹é½ã€‚æ­¤å¤–ï¼Œå¯¹äºè‡ªå›å½’è¯­è¨€æ¨¡å‹ï¼Œå¸¸ç”¨æ•°æ®æ‰“åŒ…ï¼ˆPackingï¼‰æŠ€å·§å°†å¤šæ®µæ–‡æœ¬æ‹¼æ¥æˆé•¿åºåˆ—ä»¥å……åˆ†åˆ©ç”¨ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œæé«˜æ•ˆç‡ã€‚è¿™éœ€è¦DataLoaderæ”¯æŒæŒ‰epoché¢„å¤„ç†æˆ–åŠ¨æ€æ‰“åŒ…ã€‚é£é™©åœ¨äºï¼šæ•°æ®I/Oå¯èƒ½æˆä¸ºç“¶é¢ˆï¼Œå¦‚æœä¸èƒ½æä¾›ç¨³å®šçš„é«˜ååè¯»å–ï¼ˆä¾‹å¦‚NVMe SSDæˆ–é«˜é€Ÿç½‘ç»œæ–‡ä»¶ç³»ç»Ÿï¼‰ï¼ŒGPUä¼šå› ç­‰å¾…æ•°æ®è€Œç©ºè½¬ã€‚è§£å†³æ–¹æ³•åŒ…æ‹¬é¢„å…ˆå¤„ç†æ•°æ®ä¸ºå†…å­˜æ˜ å°„æ ¼å¼ã€å¯ç”¨å¤šçº¿ç¨‹/å¤šè¿›ç¨‹è¯»å–ç”šè‡³é‡‡ç”¨Streamingæ–¹å¼æŒ‰éœ€æ‹‰å–æ•°æ®ã€‚æ€»ä½“æ¥è¯´ï¼Œè¿™ä¸€é˜¶æ®µéœ€è¦å·¥ç¨‹å›¢é˜Ÿç¡®ä¿æ•°æ®æµæ°´çº¿è¶³å¤Ÿå¼ºå£®ï¼Œå¯æŒç»­åœ°å–‚é¥±æ•°ç™¾GPUã€‚\nå¹¶è¡Œè°ƒåº¦ (DP/TP/PP/CP)ï¼šåœ¨å¤šå¹¶è¡ŒèŒƒå¼ç»“åˆä¸‹ï¼Œè°ƒåº¦å’Œåè°ƒå˜å¾—å¤æ‚ã€‚å®é™…è½åœ°æ—¶ï¼Œé€šå¸¸ä½¿ç”¨å¼€æºè®­ç»ƒæ¡†æ¶ï¼ˆå¦‚NVIDIA Megatron-LMåº“ã€DeepSpeedã€Horovodç­‰ï¼‰æ¥éšè—ç»†èŠ‚ã€‚ç”¨æˆ·é€šè¿‡é…ç½®å¹¶è¡Œåº¦å‚æ•°ï¼ˆå¦‚å¼ é‡å¹¶è¡Œå¤§å°ã€æµæ°´å¹¶è¡Œé˜¶æ®µæ•°ã€æ•°æ®å¹¶è¡Œè¿›ç¨‹æ•°ã€ä¸Šä¸‹æ–‡å¹¶è¡Œå¤§å°ï¼‰å³å¯å¯åŠ¨è®­ç»ƒã€‚èƒŒåæ¡†æ¶ä¼šåˆ’åˆ†MPIé€šä¿¡ç»„æˆ–è¿›ç¨‹ç»„ï¼šä¾‹å¦‚512 GPUå¯ä»¥æŒ‰8GPUä¸€ç»„æ„æˆ64ç»„è¿›è¡Œå¼ é‡å¹¶è¡Œï¼Œå†å°†è¿™64ç»„åˆ†åˆ«ç»„åˆæˆè‹¥å¹²æµæ°´çº¿é˜¶æ®µï¼Œç­‰ç­‰ã€‚è¿™æ ·æ¯ä¸ªGPUæœ‰å¤šä¸ªèº«ä»½ï¼ˆæ‰€åœ¨çš„DPç»„ã€TPç»„ã€PPç»„ç­‰ï¼‰ï¼Œæ¡†æ¶è´Ÿè´£åœ¨æ°å½“çš„é˜¶æ®µè°ƒç”¨NCCLé€šä¿¡ã€‚å·¥ç¨‹ä¸Šéœ€è¦éªŒè¯è¿™äº›ç»„çš„åˆ’åˆ†æ˜¯å¦æ­£ç¡®åŒ¹é…ç¡¬ä»¶æ‹“æ‰‘ï¼Œä¾‹å¦‚å°½é‡è®©åŒä¸€æ¨¡å‹å¹¶è¡Œç»„çš„GPUåœ¨åŒä¸€æœåŠ¡å™¨æˆ–åŒä¸€InfiniBandäº¤æ¢æœºä¸‹ï¼Œä»¥é™ä½è·¨èŠ‚ç‚¹é€šä¿¡å»¶è¿Ÿã€‚å¹¶è¡Œè°ƒåº¦éƒ¨åˆ†è¿˜æœ‰ä¸€ä¸ªéš¾ç‚¹æ˜¯é”™è¯¯å¤„ç†ï¼šåœ¨è¶…å¤§è§„æ¨¡è¿è¡Œä¸­ï¼Œä»»ä¸€èŠ‚ç‚¹æ•…éšœéƒ½å¯èƒ½å¯¼è‡´æ•´ä½“å´©æºƒï¼Œéœ€è¦æœ‰æ£€æŸ¥ç‚¹æ¢å¤ï¼ˆè§åï¼‰ä»¥åŠå¼¹æ€§è®­ç»ƒçš„è€ƒè™‘ã€‚å¦‚æœä½¿ç”¨è¯¸å¦‚PyTorch DDPï¼Œè‡ªèº«æœ‰åŸºæœ¬çš„å®¹é”™ä½†è¿˜ä¸å®Œå–„ï¼Œå·¥ç¨‹ä¸Šå¯èƒ½éœ€è¦è„šæœ¬ç›‘æ§è®­ç»ƒè¿›ç¨‹ã€å‡ºç°å®•æœºè‡ªåŠ¨é‡å¯å¹¶åŠ è½½æœ€è¿‘checkpointï¼Œä»¥å‡å°‘é•¿æ—¶é—´è®­ç»ƒä¸­æ–­çš„æŸå¤±ã€‚å¹¶è¡Œè°ƒåº¦çš„æ­£ç¡®æ€§ä¸æ•ˆç‡ç›´æ¥å†³å®šäº†è®­ç»ƒèƒ½å¦é¡ºåˆ©è¿è¡Œå’Œè¾¾åˆ°è®ºæ–‡ä¸­çš„æ‰©å±•æ•ˆç‡æŒ‡æ ‡ï¼Œè¿™æ˜¯è½åœ°ä¸­çš„å…³é”®ç¯èŠ‚ä¹‹ä¸€ã€‚\nç®—å­å®ç°ä¸Kernelä¼˜åŒ–ï¼šMegatron-LMä¾èµ–çš„ä¸€äº›å…³é”®ç®—å­å¦‚GEMMã€LayerNormåœ¨æ·±åº¦å­¦ä¹ æ¡†æ¶ä¸­å·²æœ‰é«˜æ•ˆå®ç°ã€‚ä½†ä¸ºäº†è¿›ä¸€æ­¥æå‡æ€§èƒ½ï¼Œå·¥ç¨‹å®è·µä¸­å¾€å¾€ä¼šå¼•å…¥è‡ªå®šä¹‰Kernelæˆ–èåˆå†…æ ¸ã€‚ä¾‹å¦‚ï¼Œé‡‡ç”¨CUDAå†…æ ¸å®ç°QKVæŠ•å½±çš„èåˆï¼Œå°†åŸæœ¬ä¸‰ä¸ªçŸ©é˜µä¹˜åˆå¹¶ä¸ºä¸€ä¸ªä»¥å‡å°‘å†…å­˜è¯»å†™ï¼›åˆå¦‚å°†BiasåŠ å’ŒDropoutèåˆè¿›GEMMè¾“å‡ºï¼Œä»¥å‡å°‘ä¸­é—´ç»“æœå­˜å–ã€‚è¿™äº›ä¼˜åŒ–åœ¨NVIDIAçš„APExåº“ã€FlashAttentionç­‰é¡¹ç›®ä¸­å·²æœ‰ç¤ºä¾‹ã€‚å°†å…¶åº”ç”¨åœ¨è®­ç»ƒæ ˆä¸­éœ€è¦ç†Ÿæ‚‰CUDAç¼–ç¨‹å¹¶æ·±åˆ»ç†è§£æ¨¡å‹è®¡ç®—æµç¨‹ã€‚åœ¨æ²¡æœ‰è¿™äº›ä¼˜åŒ–æ—¶ï¼ŒMegatron-LMä¹Ÿèƒ½è¿è¡Œï¼Œä½†å…¶FLOPsåˆ©ç”¨ç‡å¯èƒ½è¾¾ä¸åˆ°æœ€ä¼˜ã€‚é€‰æ‹©æ ¸å¿ƒç®—å­åšå®šåˆ¶ä¼˜åŒ–å¾€å¾€å¸¦æ¥5-20%çš„æ€§èƒ½æå‡ã€‚ç›¸åº”çš„é£é™©æ˜¯å¼•å…¥è‡ªå®šä¹‰ç®—å­å¯èƒ½å¼•å‘æ•°å€¼è¯¯å·®ç§¯ç´¯æˆ–è°ƒè¯•å›°éš¾ï¼Œéœ€è¦ç¡®ä¿å…¶ä¸æ ‡å‡†å®ç°ç»“æœä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œä¸åŒGPUæ¶æ„ï¼ˆå¦‚A100, H100ï¼‰å¯èƒ½éœ€è¦é‡æ–°è°ƒä¼˜å†…æ ¸å‚æ•°æ‰èƒ½å‘æŒ¥æœ€ä½³æ€§èƒ½ã€‚å› æ­¤å·¥ç¨‹å›¢é˜Ÿéœ€è¦è¯„ä¼°æ”¶ç›Šå’Œç»´æŠ¤æˆæœ¬ï¼Œåœ¨è¿½æ±‚æè‡´æ€§èƒ½æ—¶æŠ•å…¥Kernelä¼˜åŒ–èµ„æºã€‚åœ¨ç®—å­æ–¹é¢å¦ä¸€ä¸ªè€ƒè™‘æ˜¯æ··åˆç²¾åº¦ï¼šæ¡†æ¶åº”ä½¿ç”¨FP16/BF16è¿›è¡ŒçŸ©é˜µè¿ç®—ï¼ŒåŒæ—¶ä¿è¯LayerNormã€æ®‹å·®ç´¯åŠ åœ¨FP32ç´¯ç§¯é¿å…ç²¾åº¦æŸå¤±ã€‚è¿™äº›ç»†èŠ‚é€šå¸¸ç”±æ¡†æ¶çš„AMP (Automatic Mixed Precision)æ¨¡å—å¤„ç†ï¼Œä½†åœ¨å¤§è§„æ¨¡å¹¶è¡Œæƒ…å†µä¸‹ï¼Œéœ€è¦ç¡®ä¿æ‰€æœ‰rankä¸€è‡´è¿›è¡Œloss scalingç­‰æ“ä½œï¼Œé¿å…ä¸ªåˆ«GPUä¸Šæº¢æˆ–ä¸‹æº¢å¯¼è‡´æ¢¯åº¦å¼‚å¸¸ã€‚\né€šä¿¡æ¨¡å¼ä¸Collectiveæ“ä½œï¼šå¤§è§„æ¨¡è®­ç»ƒä¸­é€šä¿¡å¾€å¾€æˆä¸ºæ€§èƒ½ç“¶é¢ˆï¼Œå› æ­¤åœ¨å·¥ç¨‹ä¸Šéœ€è¦ç²¾å¿ƒè®¾è®¡å’Œé…ç½®é€šä¿¡backendã€‚NCCLæ˜¯äº‹å®æ ‡å‡†ï¼Œå®ƒä¼šä¾æ®æ‹“æ‰‘è‡ªåŠ¨é€‰æ‹©All-Reduceç®—æ³•ï¼ˆç¯å½¢ã€æ ‘å½¢ã€æ··åˆæ‹“æ‰‘ç­‰ï¼‰ã€‚å¯¹äº512å¡è¿™ç§è§„æ¨¡ï¼Œå¤šæœºå¤šå±‚äº¤æ¢æœºæ‹“æ‰‘ä¸‹ï¼ŒNCCLå¯èƒ½ä½¿ç”¨åˆ†çº§All-Reduceï¼ˆå…ˆæœºæ¶å†…ã€å†æœºæ¶é—´ï¼‰ã€‚å·¥ç¨‹å®è·µä¸­ï¼Œåº”ç»‘å®šCPUäº²å’Œã€åˆ’åˆ†é€šä¿¡è½¨é“ï¼šä¾‹å¦‚åœ¨NVSwitch/InfiniBandåŒæ—¶å­˜åœ¨æ—¶ï¼Œè®©äº¤å‰èŠ‚ç‚¹é€šä¿¡ç”¨PCIe+InfiniBandï¼Œæœºå†…ç”¨NVLinkï¼Œé¿å…èµ„æºäº‰ç”¨ã€‚å¦å¤–å¯ä»¥ä½¿ç”¨åˆ†ç»„All-Reduceï¼ˆHierarchical Reductionï¼‰ä¼˜åŒ–å»¶è¿Ÿã€‚é…ç½®æ–¹é¢ï¼Œéœ€è¦ç¡®ä¿MPIæˆ–torch.distributedåˆå§‹åŒ–é€šä¿¡æ—¶ï¼Œç¯å¢ƒå˜é‡å¦‚NCCL_TREE_THRESHOLDç­‰è°ƒä¼˜å¾—å½“ã€‚å¾ˆå¤šè®­ç»ƒæ¡†æ¶ï¼ˆMegatron-LM, DeepSpeedï¼‰ä¼šç»™å‡ºæ¨èNCCLå‚æ•°å’Œlaunchè„šæœ¬ã€‚é€šä¿¡é‡å ä¹Ÿæ˜¯å·¥ç¨‹å…³æ³¨ç‚¹ï¼Œå³åœ¨GPUæ‰§è¡Œè®¡ç®—çš„åŒæ—¶ï¼Œé€šä¿¡åœ¨åå°æµå¼è¿›è¡Œã€‚PyTorchçš„å¼‚æ­¥é€šä¿¡ä»¥åŠCUDAæµçš„æ­£ç¡®ä½¿ç”¨å¯ä»¥å®ç°è®¡ç®—-é€šä¿¡å¹¶è¡Œã€‚é£é™©æ–¹é¢ï¼Œé€šä¿¡æœ€æ€•é‡åˆ°æ­»é”æˆ–hangï¼šä»»ä½•ä¸€æ¬¡All-Reduceç­‰å¾…ä¸åˆ°å¯¹ç«¯éƒ½ä¼šå…¨ä½“å¡ä½ã€‚è¿™é€šå¸¸ç”±å¹¶è¡Œä»£ç é€»è¾‘é”™è¯¯æˆ–ç½‘ç»œä¸ç¨³å®šå¼•èµ·ã€‚å·¥ç¨‹ä¸Šéœ€è¦å…·å¤‡é€šä¿¡debugèƒ½åŠ›ï¼Œä¾‹å¦‚ä½¿ç”¨NCCL_DEBUG=INFOè·Ÿè¸ªæ¯æ¬¡é€šä¿¡è°ƒåº¦ï¼Œæˆ–è€…ä½¿ç”¨å·¥å…·æ£€æŸ¥ç½‘ç»œå¥åº·åº¦ã€‚é›†ç¾¤ç¯å¢ƒçš„å¤æ‚æ€§ä¹Ÿæ„å‘³ç€å¯èƒ½å‡ºç°å¸¦å®½è·‘ä¸æ»¡çš„æƒ…å†µï¼Œå¦‚PCIeæ‹“æ‰‘æ¬¡ä¼˜å¯¼è‡´NCCLæ•ˆç‡ä½ï¼Œè¿™éœ€è¦åœ¨éƒ¨ç½²å‰é€šè¿‡é€šä¿¡benchmarksæµ‹è¯•åŠ ä»¥è°ƒæ•´ã€‚æ€»ä¹‹ï¼Œåœ¨è½åœ°é˜¶æ®µï¼Œå¯¹é€šä¿¡éƒ¨åˆ†è¦æŠ•å…¥ä¸“é—¨å·¥ç¨‹ç²¾åŠ›ä¼˜åŒ–ï¼Œæ¯æé«˜ç™¾åˆ†ä¹‹ä¸€çš„é“¾è·¯åˆ©ç”¨ç‡ï¼Œå¯¹åº”æ•´ä½“ååæå‡å¯èƒ½å°±æ˜¯æ•°å°æ—¶è®­ç»ƒæ—¶é—´çš„èŠ‚çœã€‚\né…ç½®æœç´¢ä¸è‡ªåŠ¨è°ƒå‚ï¼šè¶…å¤§è§„æ¨¡è®­ç»ƒæ¶‰åŠä¼—å¤šå¯è°ƒå‚æ•°ï¼ŒåŒ…æ‹¬å¹¶è¡Œå‚æ•°ï¼ˆDP/TP/PPåˆ’åˆ†æ–¹æ¡ˆã€micro-batchå¤§å°ç­‰ï¼‰ã€ä¼˜åŒ–å™¨å‚æ•°ï¼ˆå­¦ä¹ ç‡ã€betaã€weight decayï¼‰ã€è°ƒåº¦ç­–ç•¥ï¼ˆå­¦ä¹ ç‡warmupã€æ¢¯åº¦è£å‰ªé˜ˆå€¼ï¼‰ç­‰ã€‚è¿™äº›å‚æ•°åœ¨å¤§æ¨¡å‹æƒ…å¢ƒä¸‹å½¼æ­¤å½±å“å¤æ‚ã€‚ä¾‹å¦‚ï¼Œæ€»æ‰¹æ¬¡å¤§å°=å¾®æ‰¹å¤§å°Ã—æ•°æ®å¹¶è¡Œåº¦ï¼Œè¿‡å¤§å¯èƒ½å¯¼è‡´æ³›åŒ–å˜å·®ï¼Œè¿‡å°åˆæ— æ³•å……åˆ†åˆ©ç”¨ç®—åŠ›ã€‚è½åœ°æ—¶ï¼Œå¾€å¾€éœ€è¦è¿›è¡Œä¸€äº›è¶…å‚æœç´¢æˆ–å€Ÿé‰´ç»éªŒå€¼ã€‚è®¸å¤šå›¢é˜Ÿä¼šåŸºäºè®ºæ–‡æä¾›çš„è®¾ç½®ä½œä¸ºèµ·ç‚¹ï¼ˆå¦‚Megatron-LMä½œè€…ç»™å‡ºçš„3.9B BERTåœ¨512GPUä¸Šçš„å­¦ä¹ ç‡å’Œæ‰¹é‡é…ç½®ï¼‰ï¼Œç„¶ååœ¨æœ¬ä»»åŠ¡ä¸Šå¾®è°ƒã€‚è‡ªåŠ¨è°ƒå‚æ–¹é¢ï¼Œå¯ä»¥è€ƒè™‘ä½¿ç”¨å·¥å…·ï¼ˆå¦‚Optunaæˆ–è‡ªå®šä¹‰è„šæœ¬ï¼‰å¯¹å…³é”®å‚æ•°åšç½‘æ ¼æˆ–è´å¶æ–¯ä¼˜åŒ–ï¼Œä½†ç”±äºæ¯æ¬¡è¯•éªŒæˆæœ¬æé«˜ï¼ˆè®­ç»ƒä¸€ä¸ªæ¨¡å‹éœ€æ•°å¤©ï¼‰ï¼Œè°ƒå‚åŸºæœ¬ä¸Šä¾èµ–ç»éªŒå’Œå±€éƒ¨è¯•æ¢ã€‚ä¸ºäº†å‡å°‘åå¤å°è¯•ï¼Œå®è·µä¸­å¸¸æ¸è¿›æ‰©å±•ï¼šå…ˆç”¨è¾ƒå°‘GPUæˆ–å°æ¨¡å‹è¯•è¿è¡ŒéªŒè¯ï¼Œå†æŒ‰æ¯”ä¾‹æ”¾å¤§é…ç½®ã€‚è¿™éœ€è¦æ³¨æ„ä¸€äº›éçº¿æ€§å˜åŒ–ï¼šæ¯”å¦‚æ›´å¤šGPUæ—¶é€‚å½“æé«˜å­¦ä¹ ç‡ï¼Œä½†ä¸èƒ½çº¿æ€§æé«˜ï¼Œå¦åˆ™æŸå¤±å¯èƒ½éœ‡è¡ã€‚é£é™©æ˜¯ï¼Œå¦‚æœé…ç½®ä¸å½“ï¼Œå¤§è§„æ¨¡è®­ç»ƒå¯èƒ½ä¸­é€”å‘æ•£ï¼Œå¯¼è‡´è®¡ç®—èµ„æºæµªè´¹ã€‚å› æ­¤åœ¨å‘èµ·å¤§Jobä¹‹å‰ï¼Œå·¥ç¨‹å›¢é˜Ÿä¼šå……åˆ†éªŒè¯é…ç½®çš„ç¨³å®šæ€§ï¼Œç›‘æ§åˆæœŸlossæ›²çº¿ï¼Œå¿…è¦æ—¶ä¸­æ­¢è°ƒæ•´ã€‚å¼•å…¥è‡ªåŠ¨åŒ–è°ƒå‚å¯ä»¥åœ¨ä¸€å®šç¨‹åº¦ä¸Šç¼“è§£äººå·¥è´Ÿæ‹…ï¼Œä½†ä»éœ€äººå·¥æ™ºæ…§ä»‹å…¥å…³é”®å†³ç­–ã€‚å¯¹å®é™…è®­ç»ƒæ ˆè€Œè¨€ï¼Œå»ºç«‹ä¸€å¥—é…ç½®åŸºçº¿å’Œç›‘æ§æŠ¥è­¦ç³»ç»Ÿå°¤ä¸ºé‡è¦ï¼Œä¸€æ—¦æ£€æµ‹åˆ°è®­ç»ƒæŒ‡æ ‡å¼‚å¸¸ï¼ˆå¦‚lossçˆ†ç‚¸ï¼‰ï¼Œèƒ½åŠæ—¶ä»‹å…¥è°ƒæ•´ï¼Œé¿å…é•¿æ—¶é—´è®¡ç®—æµªè´¹åœ¨é”™è¯¯çš„å‚æ•°ä¸Šã€‚\nCheckpoint ä¸å®¹é”™æ¢å¤ï¼šå¤§æ¨¡å‹è®­ç»ƒé€šå¸¸æŒç»­æ•°å‘¨ï¼ŒæœŸé—´å¯èƒ½å› ä¸ºä½œä¸šè°ƒåº¦ã€ç¡¬ä»¶æ•…éšœç­‰åŸå› ä¸­æ–­ã€‚å› æ­¤å®ç°å¯é çš„æ–­ç‚¹ç»­è®­(checkpointing)æœºåˆ¶æ˜¯è½åœ°å¿…å¤‡ã€‚Megatron-LMçš„è®­ç»ƒæ ˆä¼šå®šæœŸä¿å­˜æ¨¡å‹checkpointï¼ŒåŒ…æ‹¬æ¨¡å‹å„åˆ†ç‰‡æƒé‡ã€ä¼˜åŒ–å™¨çŠ¶æ€ã€éšæœºæ•°ç§å­ç­‰ã€‚å·¥ç¨‹ä¸Šè¦ç¡®ä¿æ¯ä¸ªæ¨¡å‹å¹¶è¡ŒGPUå°†è‡ªå·±çš„æƒé‡å¿«ç…§ä¿å­˜åˆ°å­˜å‚¨ï¼ˆé€šå¸¸æ¯ä¸ªrankä¸€ä¸ªæ–‡ä»¶ï¼‰ï¼Œæ–‡ä»¶å‘½åå’Œç›®å½•ç»“æ„è¦æ¸…æ™°ï¼ˆä¾‹å¦‚åŒ…å«è¿­ä»£å·å’Œrank idï¼‰ã€‚ç”±äºå•ä¸ªæ¨¡å‹æƒé‡å°±å¯èƒ½æ•°åGBï¼Œ512 GPUå†™checkpointéœ€è¦å¹¶è¡ŒIOï¼Œè¿™å¯¹æ–‡ä»¶ç³»ç»Ÿæ˜¯å·¨å¤§å‹åŠ›ã€‚ç»éªŒä¸Šéœ€è¦é…ç½®é«˜æ€§èƒ½å¹¶è¡Œå­˜å‚¨ï¼ˆå¦‚Lustreã€BeeGFSï¼‰æˆ–è€…åˆ†æ•£æ¯èŠ‚ç‚¹æœ¬åœ°å­˜å‚¨ç„¶åå†æ±‡æ€»ã€‚Checkpointé¢‘ç‡éœ€è¦æƒè¡¡ï¼šè¿‡äºé¢‘ç¹ä¼šä¸¥é‡æ‹–æ…¢è®­ç»ƒï¼ˆæ¯æ¬¡å¯èƒ½è€—æ—¶æ•°åˆ†é’Ÿï¼‰ï¼Œå¤ªå°‘åˆ™ä¸€æ—¦ä¸­æ–­æŸå¤±è¿›åº¦è¿‡å¤šã€‚å¸¸è§ç­–ç•¥æ˜¯åœ¨è®­ç»ƒæ—©æœŸé¢‘ç¹checkpointï¼ˆæ¨¡å‹ä¸ç¨³å®šå®¹æ˜“å‘æ•£æ—¶å¯ä»¥å›é€€ï¼‰ï¼ŒåæœŸæ”¶æ•›å¥½äº†é€‚å½“æ‹‰é•¿é—´éš”ã€‚æ¢å¤æ—¶ï¼Œè®­ç»ƒæ¡†æ¶åº”èƒ½æ–¹ä¾¿åœ°åŠ è½½å…ˆå‰ä¿å­˜çš„åˆ‡ç‰‡æ¨¡å‹ã€‚Megatron-LMæä¾›äº†åˆ†å¸ƒå¼åŠ è½½åŠŸèƒ½ï¼Œå³æ¯ä¸ªGPUåªè¯»å–å±äºè‡ªå·±çš„å‚æ•°æ–‡ä»¶ä»¥é‡å»ºä¼˜åŒ–å™¨å’Œæ¨¡å‹çŠ¶æ€ã€‚å·¥ç¨‹è½åœ°éœ€è¦æµ‹è¯•è¿™ä¸€è¿‡ç¨‹ï¼Œç¡®ä¿è·¨ç‰ˆæœ¬å…¼å®¹ã€æ–­ç‚¹æ–‡ä»¶å¯é æ€§ã€‚å¦ä¸€ä¸ªå®¹é”™ç‚¹æ˜¯ç¬æ—¶é€šä¿¡é”™è¯¯æˆ–å•æœºæ‰çº¿ï¼Œå¦‚ä½•è‡ªåŠ¨æ¢å¤ã€‚é€šå¸¸é…åˆä¸Šå±‚ä½œä¸šè°ƒåº¦å™¨å®ç°ï¼šæ¯”å¦‚æ£€æµ‹åˆ°æŸGPUå¤±è”ï¼Œåˆ™é‡å¯æ•´ä¸ªMPIä½œä¸šä»ä¸Šä¸€ä¸ªcheckpointç»§ç»­ã€‚ç†æƒ³æƒ…å†µä¸‹ï¼Œå¯è¡Œçš„æ”¹è¿›æ˜¯å®ç°å±€éƒ¨æ•…éšœéš”ç¦»ï¼Œä¾‹å¦‚æŸèŠ‚ç‚¹æ‰çº¿èƒ½å¦ç”¨å†—ä½™èŠ‚ç‚¹æ¥æ›¿å¹¶åŠ è½½å¯¹åº”checkpointç»§ç»­è®­ç»ƒï¼Œè€Œä¸å¿…æ•´ä¸ªjobé‡å¯ã€‚ä½†å½“å‰è®­ç»ƒæ ˆæ”¯æŒæœ‰é™ï¼Œå¤§å¤šé‡‡ç”¨å…¨ä½œä¸šé‡å¯ç­–ç•¥ï¼Œè¿™ä¼šé€ æˆæ•°åˆ†é’Ÿåˆ°æ•°å°æ—¶çš„æŸè€—ï¼ˆé‡å¯åŠ é‡æ–°åˆ†é…èµ„æºæ—¶é—´ï¼‰ã€‚å› æ­¤ï¼Œæé«˜å®¹é”™æ€§çš„å…³é”®åœ¨äºåŠ å¿«checkpointå’Œæ¢å¤é€Ÿåº¦ï¼Œä»¥åŠæé«˜é›†ç¾¤ç¨³å®šæ€§ã€‚å·¥ç¨‹ä¸Šä¼šåœ¨è®­ç»ƒå‰åšå‹åŠ›æµ‹è¯•ç¡®ä¿ç¡¬ä»¶å¯é ï¼Œå¹¶åœ¨è®­ç»ƒä¸­å®æ—¶ç›‘æ§èµ„æºçŠ¶å†µï¼Œå°½é‡æå‰é¢„é˜²æ•…éšœã€‚æ€»è€Œè¨€ä¹‹ï¼Œåœ¨å®é™…è½åœ°æ—¶ï¼Œéœ€è¦å°†checkpointæœºåˆ¶èå…¥è®­ç»ƒLoopï¼Œä½œä¸ºå’Œå‰å‘åå‘åŒç­‰é‡è¦çš„ä¸€éƒ¨åˆ†æ¥å¯¹å¾…ï¼Œæ‰èƒ½ä¿è¯é•¿æ—¶é—´çš„å¤§è§„æ¨¡è®­ç»ƒé¡ºåˆ©å®Œæˆã€‚\n\nä»¥ä¸Šå„æ–¹é¢æ„æˆäº†ä¸€ä¸ªå¤§å‹æ¨¡å‹è®­ç»ƒæ ˆè½åœ°Megatron-LMæ–¹æ³•æ‰€éœ€çš„å·¥ç¨‹å·¥ä½œã€‚å¯ä»¥çœ‹åˆ°ï¼Œè½åœ°å¹¶éæ˜“äº‹ï¼šæ—¢è¦å†™ä»£ç å±‚é¢çš„å®ç°ï¼Œåˆè¦è€ƒè™‘åˆ†å¸ƒå¼ç³»ç»Ÿè°ƒä¼˜ï¼Œè¿˜è¦å‡†å¤‡æ•…éšœé¢„æ¡ˆã€‚è¿™ä¹Ÿè§£é‡Šäº†ä¸ºä½•æœ‰äº†è®ºæ–‡æ–¹æ³•åï¼Œä¸šå†…ä»èŠ±è´¹å¤§é‡ç²¾åŠ›æ‰“é€ å®Œå–„çš„è®­ç»ƒæ¡†æ¶ï¼ˆå¦‚Megatron-LMåº“ã€DeepSpeedã€Horovodç­‰ï¼‰æ¥æ”¯æ’‘è¿™äº›éœ€æ±‚ã€‚å¯¹äºä¸€ä¸ªå…¸å‹çš„è®­ç»ƒå›¢é˜Ÿæ¥è¯´ï¼Œå……åˆ†åˆ©ç”¨å·²æœ‰å¼€æºå·¥å…·å¹¶æ ¹æ®è‡ªå·±é›†ç¾¤ç‰¹ç‚¹åšé’ˆå¯¹æ€§ä¼˜åŒ–ï¼Œæ˜¯å®è·µä¸­è¡Œä¹‹æœ‰æ•ˆçš„ç­–ç•¥ã€‚\nä¹ã€å€¼å¾—è¿›ä¸€æ­¥æ¢ç´¢çš„ç ”ç©¶æ–¹å‘\né¢å‘æœªæ¥çš„å¤§æ¨¡å‹è®­ç»ƒï¼ŒMegatron-LMæ‰“å¼€äº†ä¸€ä¸ªèµ·ç‚¹ï¼Œä½†ä»æœ‰è®¸å¤šæ–¹å‘å€¼å¾—æ·±å…¥ï¼Œä»¥æå‡æ€§èƒ½ã€é™ä½æˆæœ¬å¹¶æ‰©å±•é€‚ç”¨æ€§ï¼š\n\nè‡ªåŠ¨å¹¶è¡Œåˆ’åˆ†ä¸ç¼–è¯‘ä¼˜åŒ–ï¼šå‘å±•æ™ºèƒ½çš„å¹¶è¡Œåˆ’åˆ†ç®—æ³•ï¼Œå°†æ‰‹å·¥æŒ‡å®šå¹¶è¡Œåº¦è½¬å˜ä¸ºç¼–è¯‘å™¨è‡ªåŠ¨æ¢ç´¢ã€‚è¿™æ–¹é¢å¯ä»¥å€Ÿé‰´DeepMindçš„GSPMDã€OpenAIçš„FTXç¼–è¯‘ç­‰ï¼Œè®©ç³»ç»Ÿæ ¹æ®æ¨¡å‹è®¡ç®—å›¾è‡ªåŠ¨å†³å®šåœ¨å“ªäº›ç»´åº¦åˆ‡åˆ†ã€ä½•æ—¶æ’å…¥All-Reduceï¼Œç”šè‡³å¼•å…¥å¼ é‡åˆ‡ç‰‡è¯­è¨€ä½¿å¼€å‘è€…å£°æ˜å¹¶è¡Œç­–ç•¥ã€‚è‡ªåŠ¨åŒ–å¹¶è¡Œèƒ½æå‡æ˜“ç”¨æ€§ï¼Œå‡å°‘äººä¸ºè°ƒå‚ï¼Œå¹¶å¯èƒ½æ‰¾åˆ°éç›´è§‰çš„æ€§èƒ½æœ€ä¼˜åˆ’åˆ†æ–¹æ¡ˆï¼Œæé«˜ç¡¬ä»¶åˆ©ç”¨ç‡ã€‚\næ›´å¤§è§„æ¨¡ä¸æ··åˆå¹¶è¡Œç­–ç•¥ï¼šæŒç»­æ¢ç´¢ç™¾äº¿åˆ°åƒäº¿å‚æ•°æ¨¡å‹çš„é«˜æ•ˆè®­ç»ƒæ–¹æ¡ˆã€‚ç›®å‰æ™®éé‡‡ç”¨çš„æ•°æ®+å¼ é‡+æµæ°´çº¿ä¸‰é‡å¹¶è¡Œå¯ä»¥è¿›ä¸€æ­¥æ‰©å±•ï¼Œæ¯”å¦‚å¼•å…¥MoEä¸“å®¶å¹¶è¡Œï¼ˆå°†æ¨¡å‹ä¸åŒéƒ¨åˆ†è·¯ç”±åˆ°ä¸åŒä¸“å®¶æ¨¡å—ï¼‰æˆ–Sequence Parallelï¼ˆåºåˆ—å¹¶è¡Œï¼‰ï¼ˆåœ¨åºåˆ—é•¿åº¦ç»´åº¦æ‹†åˆ†è®¡ç®—ï¼‰ç­‰æ–°å¹¶è¡Œç»´åº¦ã€‚è¿™äº›æ··åˆç­–ç•¥æœ‰æœ›çªç ´å•ä¸€å¹¶è¡ŒèŒƒå¼çš„ç“¶é¢ˆï¼Œä½¿å¾—è®­ç»ƒæ›²çº¿åœ¨å¢åŠ è®¡ç®—èµ„æºåä¿æŒæ¥è¿‘çº¿æ€§ã€‚ç‰¹åˆ«æ˜¯å¯¹äºè¶…è¿‡GPUæ˜¾å­˜å¤šä¸ªæ•°é‡çº§çš„å¤§æ¨¡å‹ï¼Œç»“åˆåˆ†å¸ƒå¼å­˜å‚¨ã€CPUå†…å­˜æ¢å…¥æ¢å‡ºç­‰æŠ€æœ¯ï¼Œä¹Ÿæ˜¯é‡è¦æ–¹å‘ã€‚ç›®æ ‡æ˜¯åœ¨ä¸ç‰ºç‰²è®­ç»ƒé€Ÿåº¦çš„æƒ…å†µä¸‹ï¼Œå®ç°å‚æ•°è§„æ¨¡å†æå‡ä¸€ä¸ªæ•°é‡çº§ï¼ŒåŒæ—¶å°½é‡å‡å°‘é€šä¿¡å¼€é”€çš„è¶…çº¿æ€§å¢é•¿ã€‚\né€šä¿¡ä¼˜åŒ–ä¸ç½‘ç»œæ¶æ„å…±è®¾ï¼šéšç€å¹¶è¡Œè§„æ¨¡æ‰©å¤§ï¼Œé€šä¿¡æˆæœ¬å¯èƒ½è·ƒå‡ä¸ºä¸»è¦çŸ›ç›¾ã€‚å› æ­¤ï¼Œä¸€ä¸ªæ–¹å‘æ˜¯åœ¨è½¯ç¡¬ä»¶ä¸¤ç«¯ä¼˜åŒ–é€šä¿¡æ•ˆç‡ã€‚åœ¨è½¯ä»¶ä¸Šï¼Œå¯ä»¥ç ”ç©¶æ–°çš„é€šä¿¡ç®—æ³•ï¼ˆä¾‹å¦‚åˆ†ç»„All-Reduceã€æ··åˆæ‹“æ‰‘è°ƒåº¦ï¼‰ä»¥åŠé€šä¿¡å‹ç¼©æŠ€æœ¯ï¼ˆå¦‚8-bitæˆ–æ¢¯åº¦æˆªæ–­å‹ç¼©ï¼‰æ¥é™ä½å¸¦å®½éœ€æ±‚ã€‚åœ¨ç¡¬ä»¶ä¸Šï¼Œæ¨åŠ¨æ›´é«˜é€Ÿä½å»¶è¿Ÿçš„äº’è”ï¼ˆå¦‚NVLinkæ›´æ–°ã€æ›´å¼ºå¤§çš„äº¤æ¢æœºæ¶æ„ï¼‰å’Œç½‘ç»œæ‹“æ‰‘æ„ŸçŸ¥çš„è°ƒåº¦ï¼Œå‡å°‘è¿œè·ç¦»é€šä¿¡å æ¯”ã€‚è¿™éœ€è¦æœºå™¨å­¦ä¹ å’Œç³»ç»Ÿæ¶æ„ç¤¾åŒºååŒåˆ›æ–°ã€‚ä¾‹å¦‚ï¼ŒNVIDIAè¿‘æœŸæå‡ºçš„NVLink Switchå’Œåˆ†å¸ƒå¼Shard TraderæŠ€æœ¯ï¼Œå°±æ˜¯æœç€é™ä½å¤§è§„æ¨¡é€šä¿¡å¼€é”€è¿ˆè¿›ã€‚é€šä¿¡ä¼˜åŒ–ç›´æ¥å…³ç³»åˆ°æ€§èƒ½å’Œæˆæœ¬æ¯”ï¼šæå‡5-10%é€šä¿¡æ•ˆç‡ï¼Œåœ¨æ•°æœˆçš„è®­ç»ƒä½œä¸šä¸­å°†èŠ‚çœå¯è§‚çš„æ—¶é—´ä¸ç»è´¹ã€‚\nè®­ç»ƒé²æ£’æ€§ä¸å®¹é”™ï¼šå½“è®­ç»ƒè·¨è¶Šæˆç™¾ä¸ŠåƒGPUã€å†æ—¶æ•°å‘¨ï¼Œå¦‚ä½•ä¿è¯è®­ç»ƒè¿‡ç¨‹ä¸å› é”™è¯¯ä¸­æ–­ä¸”æ¨¡å‹æ”¶æ•›ç¨³å¥æ˜¯é‡å¤§è¯¾é¢˜ã€‚ä¸€æ–¹é¢ï¼Œå¯ä»¥æ¢ç´¢åˆ†å¸ƒå¼è®­ç»ƒçš„å®¹é”™ç®—æ³•ï¼Œä¾‹å¦‚å±€éƒ¨checkpointã€å†—ä½™è®¡ç®—ã€æŒ‰éœ€é‡æ–°åŒæ­¥ç­‰ï¼Œä½¿å¾—å¶å‘çš„èŠ‚ç‚¹æ•…éšœä¸ä¼šå¯¼è‡´æ•´ä¸ªè®­ç»ƒåœæ‘†ã€‚è°·æ­Œçš„Checkpointingå¾®è°ƒå’Œè®ºæ–‡å·²ç»æœ‰åˆæ­¥æ¢è®¨ï¼Œä½†ä»æœ‰æ”¹è¿›ç©ºé—´ã€‚å¦ä¸€æ–¹é¢ï¼Œè¶…é•¿æ—¶é—´è®­ç»ƒä¸‹æ¨¡å‹å¯èƒ½å‡ºç°æ„å¤–çš„ä¸ç¨³å®šï¼ˆå¦‚çªç„¶lossçˆ†ç‚¸ï¼‰ã€‚å¼€å‘åœ¨çº¿ç›‘æ§å’Œè‡ªé€‚åº”è°ƒæ•´ç³»ç»Ÿï¼ŒåŸºäºæ£€æµ‹åˆ°çš„å‘æ•£å¾å…†è‡ªåŠ¨é‡‡å–æªæ–½ï¼ˆé™ä½å­¦ä¹ ç‡ã€é‡ç½®æ¢¯åº¦ç­‰ï¼‰æå‡é²æ£’æ€§ã€‚å¢å¼ºå®¹é”™å’Œé²æ£’æ€§æ„å‘³ç€æ›´é«˜çš„è®­ç»ƒæˆåŠŸç‡å’Œèµ„æºåˆ©ç”¨ç‡ï¼Œå¯¹äºå·¥ä¸šç•Œçš„å¤§æ¨¡å‹è®­ç»ƒä»»åŠ¡æœ‰å·¨å¤§çš„å®é™…ä»·å€¼ã€‚\nèƒ½æ•ˆå’Œæˆæœ¬ä¼˜åŒ–ï¼šå¤§æ¨¡å‹è®­ç»ƒæˆæœ¬é«˜æ˜‚ï¼Œå› æ­¤æœªæ¥ä¸€ä¸ªé‡è¦æ–¹å‘æ˜¯æå‡èƒ½æ•ˆå’Œé™ä½æˆæœ¬ã€‚è¿™åŒ…æ‹¬ç®—æ³•å±‚é¢çš„æ”¹è¿›ï¼Œå¦‚åˆ©ç”¨ä½ç²¾åº¦è®¡ç®—ï¼ˆFP8ã€INT8æ··åˆè®­ç»ƒï¼‰ã€ç¨€ç–æ¿€æ´»æˆ–ç½‘ç»œå‰ªæåœ¨è®­ç»ƒä¸­åŠ¨æ€é™ä½è®¡ç®—é‡ï¼Œä»¥åŠä¼˜åŒ–å™¨å±‚é¢çš„é©æ–°ï¼ˆå¦‚æ›´å¿«é€Ÿæ”¶æ•›çš„æ–°ä¼˜åŒ–ç®—æ³•å‡å°‘è¿­ä»£æ¬¡æ•°ï¼‰ã€‚ä¹ŸåŒ…å«å·¥ç¨‹å±‚é¢ï¼Œå¦‚æ›´å¥½åœ°åˆ©ç”¨äº‘é—²ç½®ç®—åŠ›ã€æŒ‰éœ€å¼¹æ€§æ‰©å±•/æ”¶ç¼©GPUæ•°ä»¥ä¼˜åŒ–èµ„æºã€‚åœ¨èƒ½è€—æ–¹é¢ï¼Œå¯ä»¥ç ”ç©¶å°†éƒ¨åˆ†è®¡ç®—ç§»åˆ°æ›´èƒ½æ•ˆæ¯”é«˜çš„ç¡¬ä»¶ï¼ˆå¦‚TPUï¼‰æˆ–åœ¨å†·å´ã€ä¾›ç”µä¸Šåšç³»ç»Ÿä¼˜åŒ–ã€‚ç»ˆæç›®æ ‡æ˜¯åœ¨ä¿è¯æ¨¡å‹æ€§èƒ½çš„åŒæ—¶ï¼Œè®©æ¯æå‡1ç‚¹å‡†ç¡®ç‡æ‰€èŠ±çš„ç¾å…ƒå’Œç¢³æ’æ”¾å°½å¯èƒ½å‡å°‘ã€‚è¿™ä¸ä»…å¯¹ä¼ä¸šæˆæœ¬é‡è¦ï¼Œä¹Ÿæ˜¯AIå¯æŒç»­å‘å±•çš„è¦æ±‚ã€‚\n\nä»¥ä¸Šç ”ç©¶æ–¹å‘å„æœ‰ä¾§é‡ï¼šæœ‰çš„ç€çœ¼äºæ€§èƒ½æé™ï¼Œæœ‰çš„æŒ‡å‘è®­ç»ƒç¨³å®šå’Œæ˜“ç”¨ï¼Œä¹Ÿæœ‰çš„å…³æ³¨ç°å®æˆæœ¬ä¸å¯æŒç»­æ€§ã€‚å¯ä»¥é¢„è§ï¼Œå¯¹è¿™äº›æ–¹å‘çš„æ¢ç´¢å°†ç›¸äº’ä¿ƒè¿›ï¼Œæ„æˆæœªæ¥å‡ å¹´è¶…å¤§è§„æ¨¡æ¨¡å‹è®­ç»ƒæŠ€æœ¯çš„ä¸»æ—‹å¾‹ã€‚\nåã€çŸ¥è¯†å›¾è°±æ€ç»´é“¾\nåœ¨æœ¬è®ºæ–‡ä¸ç›¸å…³èƒŒæ™¯ä¸­ï¼Œå¯ä»¥æ„å»ºå¦‚ä¸‹çš„çŸ¥è¯†è„‰ç»œé“¾æ¡ï¼Œå°†é—®é¢˜ã€æ–¹æ³•ä¸æ•ˆæœä¸²è”èµ·æ¥ï¼š\n\næ¨¡å‹è§„æ¨¡å—é™ (å†…å­˜ç“¶é¢ˆ) â†’ å¼•å…¥å¹¶è¡ŒåŒ–ç­–ç•¥æ‰“ç ´é™åˆ¶ â†’ æ¨¡å‹å¹¶è¡Œ (å¼ é‡å¹¶è¡Œ) å°†å•å±‚è®¡ç®—åˆ†ç‰‡è‡³å¤šè®¾å¤‡ â†’ å•è®¾å¤‡å†…å­˜å‹åŠ›é™ä½ï¼Œè®­ç»ƒè¶…å¤§æ¨¡å‹æˆä¸ºå¯èƒ½\nTransformer ç»“æ„è§„åˆ™ â†’ è®¡ç®—å¯æ‹†è§£ä¸ºç‹¬ç«‹éƒ¨åˆ† + å°‘é‡åŒæ­¥ (All-Reduce) â†’ å±€éƒ¨è®¡ç®— + å…¨å±€é€šä¿¡ å¹¶è¡ŒèŒƒå¼æˆç«‹ â†’ å¹¶è¡Œè®¡ç®—ä¸é€šä¿¡åè°ƒå®ç°é«˜æ•ˆæ‰©å±•\nè®¡ç®—èµ„æºå¢åŠ  â†’ å¯è®­ç»ƒæ¨¡å‹å‚æ•°å¢å¤š â†’ æ¨¡å‹æ€§èƒ½æå‡ (å›°æƒ‘åº¦é™ä½ã€ä¸‹æ¸¸ç²¾åº¦æé«˜) â†’ å¤§æ¨¡å‹å±•ç°å‡ºæ›´ä¼˜NLPä»»åŠ¡è¡¨ç°ï¼Œè¯å®â€œè§„æ¨¡æœ‰å¥‡æ•ˆâ€\nBERTå¤§æ¨¡å‹ä¸ç¨³å®š â†’ åˆ†æç“¶é¢ˆ (LayerNormä½ç½®) â†’ æ¶æ„æ”¹è¿› (Pre-LN) æ¶ˆé™¤æ¢¯åº¦é˜»å¡ â†’ æˆåŠŸè®­ç»ƒæ›´å¤§BERTï¼Œæå‡ä¸‹æ¸¸ä»»åŠ¡å‡†ç¡®ç‡\nç³»ç»Ÿå®ç°ä¸ç®—æ³•ç»“åˆ â†’ å¼€æºæ¡†æ¶ (Megatron-LMä»£ç ) å¤ç°æ–¹æ¡ˆ â†’ ç¤¾åŒºè·Ÿè¿› (å„å¤§æ¨¡å‹é‡‡ç”¨ç±»ä¼¼å¹¶è¡Œ) â†’ è¶…å¤§æ¨¡å‹è®­ç»ƒæˆä¸ºæ–°å¸¸æ€ï¼Œæ¨åŠ¨NLP SOTAä¸æ–­åˆ·æ–°\n\nä¸Šè¿°æ€ç»´é“¾è¡¨æ˜ï¼Œä»é—®é¢˜å‡ºå‘ï¼ˆå†…å­˜ä¸è§„æ¨¡ç“¶é¢ˆï¼‰ï¼Œé€šè¿‡æ¨¡å‹å¹¶è¡Œçš„åˆ›æ–°æ‰‹æ®µï¼Œç»“åˆå¯¹Transformerç»“æ„çš„ç†è§£ä¸æ¶æ„è°ƒæ•´ï¼Œæœ€ç»ˆå®ç°äº†å¤§æ¨¡å‹çš„è®­ç»ƒä¸åº”ç”¨çªç ´ã€‚è¿™æ¡è·¯å¾„æ—¢æ¶‰åŠè®¡ç®—æœºä½“ç³»ç»“æ„å’Œå¹¶è¡Œè®¡ç®—çŸ¥è¯†ï¼Œä¹Ÿè´¯ç©¿ç€å¯¹æ·±åº¦å­¦ä¹ æ¨¡å‹è¡Œä¸ºçš„è§‚å¯Ÿå’Œæ”¹è¿›ï¼Œä½“ç°äº†è·¨é¢†åŸŸçš„èåˆåˆ›æ–°ã€‚\n10.1 ä¸ªäººæ”¶è·ä¸åæ€\né˜…è¯»å¹¶æ¶ˆåŒ–Megatron-LMè¿™ç¯‡è®ºæ–‡ï¼Œæˆ‘æ”¶è·è‰¯å¤šã€‚é¦–å…ˆï¼Œå®ƒè®©æˆ‘æ·±åˆ»ä½“ä¼šåˆ°å·¥ç¨‹å®è·µå¯¹AIå‰æ²¿çš„é‡è¦æ€§ï¼šè®¸å¤šçœ‹ä¼¼æ— æ³•çªç ´çš„ç“¶é¢ˆï¼ˆå¦‚æ˜¾å­˜é™åˆ¶ï¼‰å¾€å¾€å¯ä»¥é€šè¿‡å·§å¦™çš„ç³»ç»Ÿè®¾è®¡åŠ ä»¥è§£å†³ï¼Œä»è€ŒæŠŠå­¦æœ¯ä¸Šâ€œæ›´å¤§æ¨¡å‹=æ›´å¥½æ•ˆæœâ€çš„æƒ³æ³•çœŸæ­£è½åœ°æˆä¸ºç°å®ã€‚ä½œè€…åœ¨ä¸å¼•å…¥å…¨æ–°æ¡†æ¶çš„æƒ…å†µä¸‹ï¼Œç”¨å°‘é‡é€šä¿¡æ“ä½œæ”¹å˜äº†æ¸¸æˆè§„åˆ™ï¼Œå¯å‘æˆ‘åœ¨è‡ªå·±ç ”ç©¶ä¸­ä¹Ÿåº”å–„äºåˆ©ç”¨ç°æœ‰å·¥å…·ï¼Œé€šè¿‡å·§æ€æ•´åˆæ¥å®ç°åˆ›æ–°ã€‚\nå…¶æ¬¡ï¼Œæˆ‘åæ€åˆ°ï¼Œå¤§è§„æ¨¡åˆ†å¸ƒå¼è®­ç»ƒéœ€è¦å…¼é¡¾å…¨å±€ä¸å±€éƒ¨ã€‚ä¸€æ–¹é¢è¦ç«™åœ¨æ•´ä½“ç³»ç»Ÿè§’åº¦è€ƒè™‘é€šä¿¡å’Œè®¡ç®—åˆ†å·¥ï¼Œå¦ä¸€æ–¹é¢åˆè¦å¤„ç†åº•å±‚ç»†èŠ‚ï¼ˆå¦‚æ•°å€¼ç¨³å®šæ€§ã€é€šä¿¡æ­»é”ç­‰ï¼‰ã€‚è®ºæ–‡ä¸­é’ˆå¯¹BERT LayerNormçš„å°è°ƒæ•´ï¼Œå°±æ˜¯ä»æ¨¡å‹å†…éƒ¨ç»†èŠ‚å‡ºå‘è§£å†³å¤§é—®é¢˜çš„å…¸å‹ï¼Œè®©æˆ‘æ„è¯†åˆ°å®è§‚æ€§èƒ½æå‡å¾€å¾€ä¾èµ–å¾®è§‚æœºåˆ¶ä¿éšœã€‚è¿™ä¿ƒä½¿æˆ‘åœ¨ä»Šåç ”ç©¶ä¸­ï¼Œä¸ä»…å…³æ³¨ç®—æ³•å±‚åˆ›æ–°ï¼Œä¹Ÿå¤šè€ƒè™‘å®ç°å±‚æŒ‘æˆ˜ï¼Œæå‰è®¾è®¡åº”å¯¹æ–¹æ¡ˆã€‚\næœ€åï¼Œè¿™é¡¹å·¥ä½œä¹Ÿæ¿€å‘äº†æˆ‘å¯¹ååŒä¼˜åŒ–çš„å…´è¶£ã€‚AIæ¨¡å‹ã€è½¯ä»¶æ¡†æ¶ã€ç¡¬ä»¶èµ„æºä¸‰è€…ç›¸è¾…ç›¸æˆï¼Œå…±åŒå†³å®šäº†æœ€ç»ˆæ•ˆæœã€‚Megatron-LMçš„æˆåŠŸå½’åŠŸäºå¯¹Transformerç»“æ„çš„æ´å¯Ÿï¼ˆç®—æ³•ï¼‰å’Œå¯¹PyTorch/NCCLçš„æ·±å…¥æŠŠæ¡ï¼ˆè½¯ä»¶ï¼‰ï¼Œä»¥åŠå……åˆ†åˆ©ç”¨äº†512 GPUé›†ç¾¤ï¼ˆç¡¬ä»¶ï¼‰ã€‚è¿™è®©æˆ‘è®¤è¯†åˆ°ï¼Œåœ¨è¿½æ±‚æè‡´AIæ€§èƒ½æ—¶ï¼Œä»»ä½•å•ä¸€å±‚é¢çš„æ”¹è¿›éƒ½å¯èƒ½ä¸è¶³ï¼Œå”¯æœ‰è”åˆä¼˜åŒ–æ‰èƒ½å–å¾—é£è·ƒã€‚æˆ‘ä¼šå°†è¿™ç§æ€ç»´è¿ç”¨åˆ°è‡ªå·±çš„è¯¾é¢˜ä¸­ï¼Œä¾‹å¦‚è€ƒè™‘æ–°çš„æ¨¡å‹è®¾è®¡æ—¶åŒæ­¥è€ƒè™‘è®­ç»ƒå¹¶è¡Œç­–ç•¥ï¼Œä»ä¸€å¼€å§‹å°±ä¸ºå¤§è§„æ¨¡å®ç°åšå¥½å‡†å¤‡ã€‚\n\næ€»ä½“è€Œè¨€ï¼ŒMegatron-LMè®ºæ–‡åœ¨å·¥ç¨‹å®è·µä¸­æˆåŠŸæ‰©å±•äº†Transformeræ¨¡å‹çš„è§„æ¨¡ä¸Šé™ï¼Œä»¥ç®€æ´æœ‰æ•ˆçš„æ¨¡å‹å¹¶è¡Œç­–ç•¥è®©æ•°åäº¿å‚æ•°çº§çš„è®­ç»ƒæˆä¸ºç°å®ï¼Œä¸ä»…å–å¾—äº†å‡ºè‰²çš„æ€§èƒ½æå‡ï¼Œä¹Ÿä¸ºåæ¥è¶…å¤§æ¨¡å‹çš„è®­ç»ƒæ–¹æ³•å¥ å®šäº†åŸºç¡€ã€‚ç„¶è€Œï¼Œå®ƒä¹Ÿæé†’æˆ‘ä»¬å¤§æ¨¡å‹æ—¶ä»£ä¼´ç”Ÿçš„ç³»ç»Ÿå¤æ‚åº¦å’Œèµ„æºä»£ä»·ï¼Œéœ€è¦æŒç»­çš„æŠ€æœ¯åˆ›æ–°æ¥å¹³è¡¡è§£å†³ã€‚\n\n","categories":["è®ºæ–‡é˜…è¯»"],"tags":["paper"]},{"title":"lumos:Efficient Performance Modeling and Estimation for Large-scale LLM Training","url":"/2025/08/17/paper/lumos/","content":"\n\n\nä¸€å¥è¯æ€»ç»“ï¼šLumos æ˜¯ä¸€ä¸ªåŸºäºè¿è¡Œæ—¶ trace çš„å»ºæ¨¡/æ¨¡æ‹Ÿå·¥å…·ï¼Œä» PyTorch Kineto ç­‰é‡‡é›†åˆ°çš„äº‹ä»¶ä¸­è‡ªåŠ¨æ¢å¤ç²¾ç»†çš„æ‰§è¡Œå›¾ï¼ˆå«ç®—-é€šé‡å ä¸è·¨æµä¾èµ–ï¼‰ï¼Œå¹¶æ”¯æŒåœ¨ä¸é‡æ–°è·‘æ¨¡å‹çš„æƒ…å†µä¸‹ï¼Œå¯¹ DP/PP/æ¨¡å‹ç»“æ„ åš â€œwhat-ifâ€ ä¿®æ”¹ä¸å¿«é€Ÿä¼°ç®—ï¼›åœ¨ 512Ã—H100 é›†ç¾¤ä¸Šå›æ”¾å¹³å‡è¯¯å·®çº¦ 3.3%ã€‚(arXiv)\n\n\n1. æ ¸å¿ƒè´¡çŒ®ä¸å®šä½\n\nç²¾ç»†æ‰§è¡Œå›¾ï¼šä»…ç”¨æ¡†æ¶å†…ç½®çš„ profilerï¼ˆå¦‚ PyTorch Kinetoï¼‰å³å¯ä» CPU/GPU äº‹ä»¶æ¢å¤å››ç±»å…³é”®ä¾èµ–ï¼ˆCPUâ†’GPUã€GPUâ†’CPUã€åŒæµé¡ºåºã€è·¨æµäº‹ä»¶ï¼‰ï¼Œç²¾å‡†è¡¨è¾¾ç®—-é€šé‡å ä¸åŒæ­¥å…³ç³»ã€‚(arXiv)\nå›¾ç¼–è¾‘ &amp; å¿«é€Ÿå¤–æ¨ï¼šåœ¨ä¸æ”¹åŠ¨æ¨¡å‹/ç³»ç»Ÿçš„å‰æä¸‹ï¼Œä»åŸå§‹ trace-graph å‡ºå‘ï¼Œå¯¹ æ•°æ®å¹¶è¡Œï¼ˆDPï¼‰ã€æµæ°´å¹¶è¡Œï¼ˆPPï¼‰ ä¸æ¨¡å‹å±‚æ•°/éšè—ç»´åº¦åšå›¾çº§æ”¹å†™ï¼Œå†ç”¨æ¨¡æ‹Ÿå™¨é‡æ”¾ä¸€æ•´ä¸ªè¿­ä»£ä¼°ç®—æ€§èƒ½ã€‚(arXiv)\né«˜ç²¾åº¦å›æ”¾ï¼šåœ¨ç”Ÿäº§é›†ç¾¤ æœ€å¤š 512Ã—H100ã€å¤šç§ GPT-3 å˜ä½“ã€ä¸åŒå¹¶è¡Œç­–ç•¥ä¸‹ï¼Œè¿­ä»£æ—¶é—´å›æ”¾å¹³å‡è¯¯å·® 3.3%ï¼Œå¹¶èƒ½å†ç°å®æµ‹çš„æ‰§è¡Œç»†åˆ†å æ¯”ã€‚(arXiv)\n\n\n2. Lumos å¦‚ä½•ä» trace æ„å»ºæ‰§è¡Œå›¾\n\näº‹ä»¶æ¥æºï¼šç›´æ¥ä½¿ç”¨ PyTorch/TensorFlow çš„å†…ç½® profilerï¼ˆå¦‚ Kinetoï¼‰ï¼Œæ— éœ€å¯¹æ¨¡å‹æˆ–æ¡†æ¶åšä¾µå…¥å¼æ”¹é€ ã€‚(arXiv)\nä¾èµ–å»ºæ¨¡ï¼ˆå››ç±»ï¼‰ï¼š\n\nCPUâ†’GPUï¼ˆlaunchï¼‰ï¼šç”¨ correlation ID ç»‘å®š CPU ç«¯çš„ cudaLaunchKernel/cudaMemsetAsync ä¸å¯¹åº”çš„ GPU kernelã€‚\nGPUâ†’CPUï¼ˆåŒæ­¥ï¼‰ï¼šcudaDeviceSync/cudaStreamSync ç­‰éœ€è¦ç­‰åˆ°ç›¸å…³ GPU kernel å®Œæˆã€‚\nåŒæµé¡ºåºï¼šåŒä¸€ CUDA stream å†…æ ¸ä¸¥æ ¼é¡ºåºã€‚\nè·¨æµäº‹ä»¶ï¼šcudaEventRecord ä¸ cudaStreamWaitEvent å½¢æˆâ€œè®°å½•â†’ç­‰å¾…â€çš„è·¨æµä¾èµ–ï¼Œè¡¨è¾¾ä¸åŒæµé—´çš„æœ‰åºæ€§ã€‚(arXiv)\n\n\n\n3. å›¾ç¼–è¾‘ï¼šæ”¯æŒå“ªäº› â€œwhat-ifâ€ æ”¹åŠ¨\n\næ•°æ®å¹¶è¡Œï¼ˆDPï¼‰ï¼šåªéœ€è°ƒæ•´é€šä¿¡ä»»åŠ¡ï¼ˆå¦‚æ¢¯åº¦è§„çº¦ç±»ï¼‰çš„æ‰§è¡Œæ—¶é—´ï¼›æœ¬åœ°è®¡ç®—ä¸å˜ã€‚(arXiv)\næµæ°´å¹¶è¡Œï¼ˆPPï¼‰ï¼š\n\nå…ˆæŒ‰æ‰€é€‰è°ƒåº¦ï¼ˆå¦‚ 1F1Bï¼‰æ›´æ–°å„å¾®æ‰¹çš„å‰åå‘é¡ºåºï¼›\nå°†åŸå›¾ä¸­ä»»åŠ¡æŒ‰å±‚èšç±»åé‡åˆ†é…åˆ°æ–° stageï¼›\nåœ¨ stage è¾¹ç•Œæ’å…¥/é‡è¿æ¿€æ´»ä¸æ¢¯åº¦çš„ send/recvï¼›\nä¿ç•™åŸ trace ä¸­çš„ä¾èµ–æ¨¡å¼ä»¥ä¿è¯å¯é‡æ”¾æ­£ç¡®æ€§ã€‚(arXiv)\n\næ¨¡å‹ç»“æ„ï¼š\n\néšè—ç»´åº¦å˜æ›´ï¼šé‡å†™ç›¸å…³ç®—å­/å†…æ ¸çš„è¾“å…¥å¼ é‡ç»´åº¦å¹¶é‡ä¼°æ—¶é•¿ï¼›\nå±‚æ•°å˜æ›´ï¼šå¤åˆ¶/åˆ å‡å±‚å—å¹¶é‡è¿ä¾èµ–ä¸é€šä¿¡ã€‚(arXiv)\n\næš‚ä¸æ”¯æŒï¼šä¿®æ”¹ Tensor Parallelismï¼ˆTPï¼‰ï¼ˆé€šå¸¸å—é™äºå•æœºä¸”é€šä¿¡é‡ï¼Œç•™ä½œæœªæ¥å·¥ä½œï¼‰ã€‚(arXiv)\n\n\n4. æ¨¡æ‹Ÿå™¨ï¼šäº‹ä»¶é©±åŠ¨æµç¨‹ï¼ˆè®ºæ–‡ç®—æ³• 1 çš„è¦ç‚¹ï¼‰\n\nç»´æŠ¤ä¸¤ä¸ªé›†åˆï¼š\n\nå›ºå®šä¾èµ–ï¼ˆåˆå§‹åŒ–é˜¶æ®µä¸€æ¬¡æ€§ç¡®å®šï¼Œå¦‚åŒçº¿ç¨‹/åŒæµé¡ºåºã€CPUâ†’GPU çš„ launch è¾¹ï¼‰ï¼›\nè¿è¡ŒæœŸä¾èµ–ï¼ˆä¾‹å¦‚ cudaStreamSync éœ€è¦ç­‰å¾…**è¯¥æµä¸Šâ€œæœ€åä¸€ä¸ª kernelâ€**å®Œæˆï¼Œè¿™ä¸ªâ€œæœ€åâ€è¦åœ¨è°ƒåº¦æ—¶æ‰èƒ½ç¡®å®šï¼‰ã€‚\n\nä¸»å¾ªç¯ï¼šä»å°±ç»ªé›†åˆå–ä»»åŠ¡ â†’ åˆ†é…åˆ°å…¶â€œå¤„ç†å™¨â€ï¼ˆCPU çº¿ç¨‹/CUDA streamï¼‰ä¸Šè¿è¡Œ â†’ æ›´æ–°å¤„ç†å™¨å¯ç”¨æ—¶é—´ä¸åç»§ä»»åŠ¡çš„æœ€æ—©å¯å¯åŠ¨æ—¶é—´ï¼›è‹¥ä»æœ‰è¿è¡ŒæœŸä¾èµ–æœªæ»¡è¶³åˆ™å»¶åã€‚(arXiv)\n\n\n5. è¯„æµ‹è®¾ç½®ä¸å…³é”®æ•°å­—\n\nè§„æ¨¡ä¸ç¯å¢ƒï¼šæœ€å¤š 512Ã—H100ï¼ˆ32 å°ä¸»æœºï¼‰ï¼ŒRoCE æ•°æ®ä¸­å¿ƒç½‘ç»œï¼ˆæ¯ä¸»æœº 8Ã—400Gbpsï¼‰ï¼ŒCUDA 12.4ï¼ŒPyTorch 2.5ï¼ŒTransformer Engine 0.12.0ï¼ŒLightning 1.9.4ã€‚(arXiv)\nå¯¹æ¯”åŸºçº¿ï¼šä¸ dPROï¼ˆtrace-driven å›æ”¾ç³»ç»Ÿï¼‰ç›¸æ¯”ï¼ŒLumos åœ¨å¤æ‚å¹¶è¡Œé…ç½®ä¸‹èƒ½æ›´å¥½æ•æ‰è·¨æµä¾èµ–ä¸ç®—-é€šé‡å ï¼Œæ˜¾è‘—é™ä½å›æ”¾è¯¯å·®ã€‚(arXiv)\nç»“æœï¼šå›æ”¾å¹³å‡è¯¯å·® ~3.3%ï¼›å¹¶å±•ç¤ºåœ¨ DP/PP/ç»“æ„å¤–æ¨æ—¶çš„ä¼°ç®—å‡†ç¡®æ€§ä¸æ‰§è¡Œç»†åˆ†ï¼ˆæš´éœ²è®¡ç®—/æš´éœ²é€šä¿¡/é‡å /å…¶ä»–ï¼‰ã€‚(arXiv)\n\n\n6. å·¥ç¨‹å®ç°ä¸ä½¿ç”¨é—¨æ§›\n\nå®ç°è§„æ¨¡ï¼šçº¦ 5,200 è¡Œ Pythonã€‚(arXiv)\næ¥å…¥æˆæœ¬ï¼šåœ¨è®­ç»ƒä»£ç é‡Œæ’å…¥ ~10 è¡Œ profiler hook é‡‡é›† Kineto traceï¼Œéšåèµ°è‡ªåŠ¨åŒ–æµç¨‹ï¼šå»ºå›¾ â†’ å›¾ç¼–è¾‘ â†’ æ¨¡æ‹Ÿä¼°ç®—ã€‚(arXiv)\n\n\n7. é€‚ç”¨/ä¸é€‚ç”¨åœºæ™¯\n\né€‚ç”¨ï¼š\n\néœ€è¦åœ¨çœŸå®æœºç¾¤å¤–å¿«é€Ÿæ¯”è¾ƒå¹¶è¡Œ/ç»“æ„é…ç½®ï¼ˆDP/PP/å±‚æ•°/éšè—ç»´ï¼‰å¹¶ä¼°ç®—æ”¶ç›Šï¼›\néœ€è¦é«˜ä¿çœŸå›æ”¾æ¥å®šä½ç®—-é€šé‡å ä¸è·¨æµåŒæ­¥å¤„çš„æ€§èƒ½ç“¶é¢ˆã€‚\n\nå½“å‰ä¸é€‚ç”¨/æ³¨æ„ï¼š\n\nä¿®æ”¹ TP çš„å¤–æ¨ï¼ˆè®ºæ–‡æš‚æœªæ”¯æŒï¼‰ï¼›\nè¿½æ±‚ FLOPsã€å†…å­˜ã€å¸¦å®½ã€èƒ½è€—ç­‰ç³»ç»Ÿçº§æŒ‡æ ‡ï¼ˆè®ºæ–‡ç§°ä¸ºåç»­è®¡åˆ’ï¼‰ï¼›\nä¼°ç®—å‡è®¾æ–°é…ç½®å¯æ­£å¸¸è¿è¡Œï¼ˆä¸è€ƒè™‘ OOM ç­‰å¤±æ•ˆæƒ…å½¢ï¼‰ã€‚(arXiv)\n\n\n\n8. ä¸æ—¢æœ‰å·¥ä½œçš„å…³ç³»ï¼ˆç¤ºä¾‹ï¼šdPROï¼‰\n\ndPRO åŒæ ·æ˜¯ trace-driven çš„æ€§èƒ½è¯Šæ–­/å›æ”¾ç³»ç»Ÿï¼Œä½†åœ¨å¤æ‚ LLM å¹¶è¡Œä¸‹ï¼Œè·¨æµä¾èµ–ä¸é‡å çš„ç²¾ç»†å»ºæ¨¡æ›´å›°éš¾ï¼Œå®¹æ˜“å¯¼è‡´è¿‡åº¦ä¹è§‚çš„å¹¶è¡Œé¢„æµ‹ï¼›Lumos åœ¨è¿™äº›æ–¹é¢åšäº†ç³»ç»Ÿå¢å¼ºå¹¶æ˜¾è‘—é™ä½è¯¯å·®ã€‚(arXiv)\n\n\n9. è®ºæ–‡ä¸ä¼šè®®ä¿¡æ¯ï¼ˆå¯å¼•ç”¨ï¼‰\n\nè®ºæ–‡ï¼ˆarXivï¼‰ï¼šâ€œLumos: Efficient Performance Modeling and Estimation for Large-scale LLM Trainingâ€ï¼ˆ2025-04-12 é¦–æ¬¡æäº¤ï¼‰ã€‚(arXiv)\nPDFï¼ˆä½œè€…ä¸»é¡µé•œåƒ/MLSys è®ºæ–‡ï¼‰ï¼šå¯ä¸‹è½½å…¨æ–‡ã€‚(mingyu-liang.github.io)\nMLSys 2025 æ¥æ”¶ä¸æ—¥ç¨‹é¡µé¢ï¼ˆå«æŠ¥å‘Š/å½•æ’­å…¥å£ï¼‰ã€‚(mlsys.org)\n\n\n10. ä»£ç ä¸å¼€æºçŠ¶æ€ï¼ˆæˆªè‡³ 2025-08-15ï¼‰\n\næœªè§å®˜æ–¹ä»£ç åº“é“¾æ¥ï¼ˆarXiv/MLSys é¡µé¢ä¸ä½œè€… PDF ä¸­å‡æœªæä¾›ï¼‰ï¼Œç¤¾åŒºé‡Œå­˜åœ¨åŒåä½†æ— å…³çš„ â€œLumosâ€ é¡¹ç›®ï¼ˆå¦‚ Agent/è§†é¢‘ç”Ÿæˆ/è§†è§‰ç­‰ï¼‰ï¼Œæ³¨æ„åŒºåˆ†ã€‚(arXiv, mlsys.org, GitHub)\n\n\n11. å¿«é€Ÿä¸Šæ‰‹ï¼ˆç¤ºæ„ï¼‰\n\né‡‡é›† Kineto trace â†’ æ„å»ºæ‰§è¡Œå›¾ â†’ åœ¨å›¾ä¸Šç¼–è¾‘ï¼ˆDP/PP/ç»“æ„ï¼‰â†’ æ¨¡æ‹Ÿå›æ”¾/ä¼°ç®—ã€‚ è®ºæ–‡æ­£æ–‡ç»™å‡ºäº†å…¸å‹çš„ PyTorch profiler ç”¨æ³•ç¤ºæ„ä¸å…¨æµç¨‹ç¤ºæ„å›¾ã€‚(arXiv)\n\n\n12. ä½ å¯èƒ½å…³å¿ƒçš„ç»†èŠ‚ï¼ˆç²¾ç‚¼ç‰ˆï¼‰\n\nä¸ºä»€ä¹ˆæ›´å‡†ï¼Ÿ\n\nç”¨ correlation ID ä¸²èµ· CPU launch ä¸ GPU kernelï¼›\næ˜¾å¼æ¢å¤ è·¨æµäº‹ä»¶ï¼ˆRecord/Waitï¼‰ä¸åŒæ­¥ï¼ˆStream/Device Syncï¼‰ï¼›\nåœ¨æ¨¡æ‹Ÿå™¨ä¸­å°†ä¾èµ–åˆ†ä¸ºå›ºå®šä¸è¿è¡ŒæœŸï¼Œç¡®ä¿åƒ â€œç­‰å¾…è¯¥æµæœ€åä¸€ä¸ª kernelâ€ è¿™ç±»è¯­ä¹‰è¢«æ­£ç¡®è¡¨è¾¾ã€‚(arXiv)\n\næ”¹ DP/PP æ€ä¹ˆç®—ï¼Ÿ\n\nDPï¼šåªé‡èµ‹é€šä¿¡ä»»åŠ¡æ—¶é•¿ï¼›\nPPï¼šæ›´æ–°è°ƒåº¦ï¼ˆå¦‚ 1F1Bï¼‰â†’ ä»»åŠ¡æŒ‰å±‚åˆ†ç»„å¹¶é‡åˆ† stage â†’ åœ¨è¾¹ç•Œæ’å…¥ send/recv â†’ ä¿æŒä¾èµ–é—­åˆã€‚(arXiv)\n\n\n\nå‚è€ƒæ–‡çŒ® / é“¾æ¥\n\nLumos è®ºæ–‡ï¼ˆarXiv é¡µé¢ä¸ PDFï¼‰ï¼š(arXiv)\nLumosï¼ˆMLSys 2025 ä¼šè®®é¡µé¢/æ—¥ç¨‹/å½•æ’­ï¼‰ï¼š(mlsys.org)\ndPROï¼ˆtrace-driven å›æ”¾åŸºçº¿è®ºæ–‡ï¼‰ï¼š(arXiv)\n\n\n\næ³¨ï¼šæœ¬æ–‡æ¡£åªæ‘˜å–å¯¹å·¥ç¨‹è½åœ°æœ€å…³é”®çš„äº‹å®ä¸æ–¹æ³•ï¼Œæ›´å¤šå›¾ä¾‹ï¼ˆå¦‚ PPÃ—TP å¾®æ‰¹è°ƒåº¦ç¤ºä¾‹ï¼‰ä¸å®Œæ•´ç®—æ³•ç»†èŠ‚è¯·å‚é˜…åŸè®ºæ–‡æ­£æ–‡ä¸é™„å›¾ã€‚(arXiv)\n\n\n","categories":["è®ºæ–‡é˜…è¯»"],"tags":["paper"]},{"title":"Rail-only: A Low-Cost High-Performance Network for Training LLMs with Trillion Parameters","url":"/2025/12/28/paper/rail_only/","content":"\n\nåŸæ–‡ï¼šRail-only: A Low-Cost High-Performance Network for Training LLMs with Trillion Parameters Â· arXiv\n\nä¸€ã€è®ºæ–‡é€Ÿè§ˆ\nRail-only ç½‘ç»œæ¶æ„æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åˆ†å¸ƒå¼è®­ç»ƒä¸­ç½‘ç»œäº’è¿æˆæœ¬é«˜ã€æ‰©å±•å›°éš¾çš„æ ¸å¿ƒé—®é¢˜ã€‚è®ºæ–‡å‘ç°ï¼Œåœ¨ä¸‡äº¿çº§å‚æ•° LLM çš„å¹¶è¡Œè®­ç»ƒä¸­ï¼Œç»å¤§å¤šæ•° GPU å¯¹ä¹‹é—´å¹¶æ— å¤§é‡é€šä¿¡éœ€æ±‚ï¼Œä»…æœ‰å°‘æ•°å°è§„æ¨¡ GPU ç»„å†…éƒ¨éœ€è¦é«˜å¸¦å®½äº’è”ã€‚åŸºäºè¿™ä¸€é€šä¿¡ç¨€ç–æ€§ï¼Œä½œè€…æå‡ºä¸€ç§â€œRail-onlyâ€ ä¸“ç”¨é›†ç¾¤ç½‘ç»œæ‹“æ‰‘ï¼šå°† GPU é›†ç¾¤åˆ’åˆ†ä¸ºå¤šä¸ªé«˜å¸¦å®½äº’è”åŸŸï¼ˆHB åŸŸï¼‰ï¼ŒåŸŸå†…ä¿æŒå…¨è¿æ¥é«˜é€Ÿé€šä¿¡ï¼ŒåŸŸé—´åˆ™ä»…è¿æ¥å­˜åœ¨é€šä¿¡éœ€æ±‚çš„å¯¹åº” GPUï¼ˆç§°ä¸ºâ€œrailâ€è½¨é“ï¼‰ã€‚å®éªŒå’Œè§£ææ¨¡å‹è¡¨æ˜ï¼Œåœ¨ä¸é™ä½è®­ç»ƒæ€§èƒ½çš„å‰æä¸‹ï¼Œè¯¥æ¶æ„ç›¸æ¯”ä¼ ç»Ÿå…¨äº’è” Clos ç½‘ç»œé™ä½çº¦ 37â€“75% ç½‘ç»œè®¾å¤‡æˆæœ¬ï¼Œæ˜¾è‘—æå‡äº†å¤§è§„æ¨¡ LLM é›†ç¾¤å»ºè®¾çš„æ€§ä»·æ¯”ã€‚\näºŒã€è®ºæ–‡ç»“æ„\n\nèƒŒæ™¯ â€“ ä»‹ç»ç°ä»£ GPU é›†ç¾¤çš„å…¸å‹æ¶æ„ï¼ˆå¦‚åŒå±‚é«˜å¸¦å®½åŸŸ + Clos ä¸»å¹²ï¼‰ã€ç¬¬2ç« ã€‘ï¼›å›é¡¾ LLM å¸¸ç”¨çš„å¹¶è¡Œç­–ç•¥ï¼ˆæ•°æ®å¹¶è¡Œã€å¼ é‡å¹¶è¡Œã€æµæ°´å¹¶è¡Œç­‰ï¼‰åŠå…¶å¯¹é€šä¿¡çš„å½±å“ã€‚\nLLM é€šä¿¡æ¨¡å¼åˆ†æ â€“ ä½œè€…å¯¹ Megatron-LM é£æ ¼çš„ LLM è®­ç»ƒé€šä¿¡é‡è¿›è¡Œæµ‹é‡å’Œåˆ†æã€ç¬¬3ç« ã€‘ã€‚è¿™ä¸€éƒ¨åˆ†æ­ç¤ºäº†LLM è®­ç»ƒé€šä¿¡é«˜åº¦å±€éƒ¨åŒ–çš„äº‹å®ï¼Œä¾‹å¦‚ 99% çš„ GPU å¯¹ä¹‹é—´å‡ ä¹æ²¡æœ‰ç›´æ¥é€šä¿¡ï¼Œä¸»è¦é€šä¿¡é›†ä¸­åœ¨æå°‘æ•° GPU å¯¹ä¸Šã€‚\nRail-only ç½‘ç»œè®¾è®¡ â€“ æå‡ºäº†å…¨æ–°çš„ Rail-only ç½‘ç»œæ‹“æ‰‘ç»“æ„ã€ç¬¬4ç« ã€‘ã€‚ä½œè€…è¯¦ç»†æè¿°äº†å¦‚ä½•æŒ‰éœ€è¿æ¥ GPU æ¥åŒ¹é…é€šä¿¡æ¨¡å¼ï¼Œå¹¶è®¨è®ºäº†è¯¥è®¾è®¡åœ¨æ•…éšœå®¹é”™æ–¹é¢çš„è€ƒè™‘ã€‚\nè®­ç»ƒè¿­ä»£æ—¶é—´æ¨¡å‹ â€“ ä½œè€…æ¨å¯¼äº†ä¸€ä¸ªç²¾ç¡®çš„è¿­ä»£æ—¶é—´è§£ææ¨¡å‹ã€ç¬¬5ç« ã€‘ï¼Œå°†å¹¶è¡Œé…ç½®å’Œç½‘ç»œå¸¦å®½ç­‰å› ç´ çº³å…¥è®¡ç®—ï¼Œç”¨äºè¯„ä¼°ä¸åŒç½‘ç»œè®¾è®¡ä¸‹çš„æ€§èƒ½ã€‚æ­¤éƒ¨åˆ†ä¸ºæƒ³æ·±å…¥ç†è§£æ€§èƒ½å»ºæ¨¡ã€é€‰æ‹©æœ€ä¼˜å¹¶è¡Œç­–ç•¥çš„è¯»è€…æä¾›äº†å·¥å…·ï¼Œä¹ŸéªŒè¯äº† Rail-only è®¾è®¡ä¸ä¼šæŸå¤±æ€§èƒ½ã€‚\nå®éªŒè¯„ä¼° â€“ å¯¹æ¯” Rail-only ä¸ä¼ ç»Ÿ Clos ç½‘ç»œï¼Œåœ¨æ€§èƒ½ã€ç½‘ç»œè§„æ¨¡ã€æ‰¹å¤§å°ç­‰æ–¹é¢çš„å½±å“ã€ç¬¬6ç« ã€‘ã€‚åŒ…æ‹¬HB åŸŸæœ€ä½³è§„æ¨¡ã€å¸¦å®½æ•æ„Ÿæ€§ã€æ‰¹é‡å¤§å°å½±å“ä»¥åŠç½‘ç»œæˆæœ¬åˆ†æç­‰å®éªŒç»“è®ºã€‚æ­¤éƒ¨åˆ†é¢å‘ç³»ç»Ÿå·¥ç¨‹å¸ˆï¼Œå¸®åŠ©é‡åŒ–æ–°æ¶æ„çš„æ”¶ç›Šå’Œé€‚ç”¨èŒƒå›´ã€‚\nç›¸å…³å·¥ä½œä¸æ€»ç»“ â€“ åˆ—ä¸¾äº†å…¶å®ƒå¤§è§„æ¨¡è®­ç»ƒç½‘ç»œæ–¹æ¡ˆè¿›è¡Œå¯¹æ¯”ã€ç¬¬7-8ç« ã€‘ï¼Œå¹¶æ€»ç»“è®ºæ–‡è´¡çŒ®ã€‚è¯»è€…å¯ä»¥åœ¨æ­¤äº†è§£ Rail-only ç›¸å¯¹äºä¸šç•Œç°æœ‰æ–¹æ¡ˆçš„ä½ç½®å’Œä½œè€…å¯¹æœªæ¥çš„å±•æœ›ã€‚\n\n\næ ¸å¿ƒæ€æƒ³ï¼šLLM è®­ç»ƒçš„é€šä¿¡æ¨¡å¼å…·æœ‰é«˜åº¦çš„å±€éƒ¨æ€§å’Œç¨€ç–æ€§ï¼ŒRail-only åˆ©ç”¨è¿™ä¸€ç‰¹æ€§å‰ªè£ç½‘ç»œæ‹“æ‰‘ï¼Œé€šè¿‡ç§»é™¤ä¸å¿…è¦çš„è·¨åŸŸè¿æ¥åœ¨å¤§å¹…é™ä½é›†ç¾¤ç½‘ç»œæˆæœ¬çš„åŒæ—¶ï¼ŒåŸºæœ¬ä¸ç‰ºç‰²è®­ç»ƒæ€§èƒ½ã€‚\n\nä¸‰ã€æ–¹æ³•ä¸ç³»ç»Ÿè®¾è®¡\nRail-only æ–¹æ³•çš„æ•´ä½“æ€è·¯æ˜¯ï¼šé’ˆå¯¹ LLM å¹¶è¡Œè®­ç»ƒçš„ç‰¹æ®Šé€šä¿¡æ¨¡å¼é‡æ–°è®¾è®¡é›†ç¾¤ç½‘ç»œã€‚ä¸ºæ­¤ï¼Œä½œè€…éœ€è¦è§£å†³å‡ ä¸ªå­é—®é¢˜ï¼š\n\nå­é—®é¢˜ 1ï¼šLLM è®­ç»ƒçš„é€šä¿¡éœ€æ±‚å¦‚ä½•åˆ†å¸ƒï¼Ÿï¼ˆåˆ†æé€šä¿¡æ¨¡å¼ï¼Œä»¥ç¡®å®šæ˜¯å¦çœŸçš„æ— éœ€å…¨äº’è”ï¼‰\nå­é—®é¢˜ 2ï¼šå¦‚ä½•è®¾è®¡åŒ¹é…é€šä¿¡æ¨¡å¼çš„ç½‘ç»œæ‹“æ‰‘ï¼Ÿï¼ˆåœ¨æ»¡è¶³å¸¦å®½éœ€æ±‚çš„åŒæ—¶å°½é‡å‡å°‘ç½‘ç»œè®¾å¤‡ï¼‰\nå­é—®é¢˜ 3ï¼šå®šåˆ¶ç½‘ç»œæ¶æ„å¦‚ä½•ä¿è¯é²æ£’æ€§ï¼Ÿï¼ˆå¤„ç†å¤§è§„æ¨¡é›†ç¾¤ä¸­çš„æ•…éšœå®¹é”™å’Œç‰¹æ®Šé€šä¿¡ï¼Œå¦‚å…¨å±€ all-to-allï¼‰\nå­é—®é¢˜ 4ï¼šå¦‚ä½•è¯„ä¼°æ–°ç½‘ç»œå¯¹è®­ç»ƒæ€§èƒ½çš„å½±å“ï¼Ÿï¼ˆå»ºç«‹æ€§èƒ½æ¨¡å‹ï¼Œé€‰æ‹©å¹¶è¡Œå‚æ•°å¹¶éªŒè¯ Rail-only ä¸é™ä½æ•ˆç‡ï¼‰\n\n3.1 æ ¸å¿ƒæ¨¡å—ä¸€è§ˆ\n\nLLMé€šä¿¡åˆ†ææ¨¡å—ï¼šåˆ†ææ¨¡å‹å¹¶è¡Œè®­ç»ƒæ—¶çš„æ•°æ®æµï¼Œé‡åŒ–å„éƒ¨åˆ†é€šä¿¡é‡å’Œæ¨¡å¼ï¼Œé’ˆå¯¹å­é—®é¢˜1ã€‚è¯¥æ¨¡å—æ­ç¤ºé€šä¿¡ä¸»è¦é›†ä¸­åœ¨å°‘æ•° GPU ç»„å†…ï¼ˆå¦‚å¼ é‡å¹¶è¡Œç»„ï¼‰ï¼Œä¸ºç½‘ç»œè£å‰ªæä¾›ä¾æ®ï¼ˆä¾‹å¦‚å‘ç° 99% GPU å¯¹ä»æ— ç›´æ¥é€šä¿¡ çš„å¼ºå±€éƒ¨æ€§ï¼‰ã€‚\nRail-only ç½‘ç»œæ‹“æ‰‘è®¾è®¡ï¼šæ ¸å¿ƒæ–¹æ¡ˆæ¨¡å—ï¼Œé¢å‘å­é—®é¢˜2ã€‚å°†é›†ç¾¤åˆ’åˆ†ä¸ºå¤šä¸ªé«˜å¸¦å®½åŸŸï¼ˆHB åŸŸï¼‰ï¼ˆä¾‹å¦‚æ¯ 8 ä¸ª GPU ä¸€ç»„å…±ç”¨ NVLink/NVSwitchï¼‰ï¼ŒåŸŸå†…å®Œå…¨äº’è”ã€‚åŸŸä¸åŸŸä¹‹é—´ä¸å†æ„å»ºä¼ ç»Ÿ Clos ä¸»å¹²ï¼Œè€Œæ˜¯ä»…é€šè¿‡â€œrailâ€é“¾è·¯è¿æ¥ç›¸åŒå±€éƒ¨åºå·çš„ GPUï¼ˆå³å„ HB åŸŸä¸­å…·æœ‰ç›¸åŒ local rank çš„ GPUï¼‰ï¼Œå½¢æˆè‹¥å¹²ç‹¬ç«‹çš„é€šä¿¡è½¨é“ã€‚è¿™æ ·ä¿ç•™äº†å¿…è¦çš„è·¨åŸŸé€šä¿¡é€šé“ï¼ˆå¦‚æµæ°´å¹¶è¡Œçº§è”ï¼‰ï¼Œç§»é™¤äº†ä¸æ‰¿è½½æµé‡çš„å¤šä½™ç½‘ç»œè®¾å¤‡ã€‚\nå®¹é”™ä¸é‡æ„æœºåˆ¶ï¼šå¢å¼ºæ¨¡å—ï¼Œè§£å†³å­é—®é¢˜3ã€‚ä¸º Rail-only æ‹“æ‰‘å¼•å…¥æ•…éšœæ¢å¤ç­–ç•¥ï¼Œä¾‹å¦‚åœ¨æ¯ä¸ª GPU ä¸ rail äº¤æ¢æœºä¹‹é—´å¢åŠ å¯é‡æ„å…‰å¼€å…³ã€‚å½“æŸ GPU æ•…éšœæ—¶ï¼Œå…‰å¼€å…³å¯åŠ¨æ€é‡ç»„ railï¼Œå°†åŒåŸŸå†…çš„å¤‡ç”¨ GPU æ¥å…¥ä»¥é¡¶æ›¿ï¼Œç¡®ä¿ HB åŸŸå†…éƒ¨å®Œæ•´æ€§ä¸è¢«ç ´åã€‚å¯¹äºæ²¡æœ‰å¤‡ç”¨ GPU çš„æƒ…å†µï¼Œæå‡ºæ•´ä½“è¿ç§»æ•´ä¸ª HB åŸŸä»»åŠ¡æˆ–å±€éƒ¨å¼•å…¥å…‰äº¤æ¢çš„æ–¹æ¡ˆï¼Œæœ€å¤§ç¨‹åº¦é™ä½å•ç‚¹æ•…éšœå½±å“ã€‚\nè¿­ä»£æ€§èƒ½è§£ææ¨¡å‹ï¼šåˆ†æä¸è¯„ä¼°æ¨¡å—ï¼Œå¯¹åº”å­é—®é¢˜4ã€‚å»ºç«‹åŒ…å«è®¡ç®—ã€é€šä¿¡å„é˜¶æ®µçš„è¿­ä»£æ—¶é—´å…¬å¼ï¼Œæ ¹æ®å¹¶è¡Œé…ç½®å’Œç½‘ç»œå¸¦å®½å‚æ•°è®¡ç®—è®­ç»ƒæ¯æ­¥ç”¨æ—¶ã€‚è¯¥æ¨¡å‹ä½œä¸ºè¯„ä¼° Rail-only æ¶æ„æ€§èƒ½çš„åŸºç¡€ï¼Œå¯ç”¨äºæœç´¢æœ€ä¼˜å¹¶è¡Œç­–ç•¥ï¼Œå¹¶éªŒè¯ Rail-only ç›¸æ¯”å…¨äº’è”æƒ…å†µä¸‹ç¡¬ä»¶ç®—åŠ›åˆ©ç”¨ç‡æ— æ˜¾è‘—ä¸‹é™ã€‚\n\n3.2 æ•°æ®æµä¸æ§åˆ¶æµ\n\né›†ç¾¤åˆ’åˆ†ä¸å¹¶è¡Œè®¾ç½®ï¼šé¦–å…ˆï¼Œå°†æ•´ä¸ª GPU é›†ç¾¤åˆ’åˆ†ä¸ºè‹¥å¹² HB åŸŸï¼ˆä¾‹å¦‚æ¯å° DGX æœåŠ¡å™¨ä½œä¸ºä¸€ä¸ª HB åŸŸï¼ŒåŒ…å« 8 ä¸ª GPU é€šè¿‡ NVSwitch å…¨å¸¦å®½äº’è”ï¼‰ã€‚é€‰æ‹©åˆé€‚çš„ä¸‰ç»´å¹¶è¡Œå‚æ•°ï¼ˆæµæ°´å¹¶è¡Œé˜¶æ®µæ•° = HB åŸŸæ•°é‡ï¼Œå¼ é‡å¹¶è¡Œç»„å¤§å° = HB åŸŸå†… GPU æ•°ï¼Œæ•°æ®å¹¶è¡Œç»„æ•°ç­‰ï¼‰æ¥éƒ¨ç½²æ¨¡å‹ã€‚æ‰€æœ‰ GPU æ ¹æ®å¹¶è¡Œç­–ç•¥è¢«èµ‹äºˆä¸‰é‡èº«ä»½æ ‡ç­¾ï¼šæ‰€åœ¨çš„ HB åŸŸ ç¼–å·ï¼ˆå†³å®šç‰©ç†ä½ç½®ï¼‰ï¼Œæµæ°´å¹¶è¡Œé˜¶æ®µç¼–å·ï¼Œä»¥åŠåœ¨åŸŸå†…çš„æœ¬åœ°åºå·ï¼ˆå†³å®š rail è½¨é“ç¼–å·ï¼‰ã€‚\næ­£å‘ä¼ æ’­æµæ°´ï¼šè®­ç»ƒè¿­ä»£å¼€å§‹æ—¶ï¼Œå„æ•°æ®å¹¶è¡Œç»„åˆ†åˆ«åŠ è½½ä¸åŒè®­ç»ƒæ ·æœ¬çš„ micro-batchã€‚æ¯ä¸ª micro-batch åœ¨ç¬¬1ä¸ªæµæ°´å¹¶è¡Œé˜¶æ®µï¼ˆHB åŸŸ1ï¼‰æ‰§è¡Œå‰å‘è®¡ç®—ï¼Œå¾—åˆ°ä¸­é—´æ¿€æ´»åï¼Œé€šè¿‡rail é“¾è·¯å‘é€åˆ°ä¸‹ä¸€é˜¶æ®µå¯¹åº” rail ä¸Šçš„ GPUã€‚ä¾‹å¦‚ï¼Œä½äº HB åŸŸ1ã€local rank=3 çš„ GPU å°†å…¶æ¿€æ´»å‘é€åˆ° HB åŸŸ2ã€local rank=3 çš„ GPUã€‚ä¾æ¬¡æ²¿æµæ°´é¡ºåºä¼ é€’ï¼Œç›´åˆ°æœ€åä¸€ä¸ªé˜¶æ®µå®Œæˆæ­£å‘è®¡ç®—ã€‚ç”±äº rail-only ç½‘ç»œä»…è¿æ¥ç›¸åŒ local rankçš„ GPUï¼Œæ­£å‘çš„è·¨åŸŸé€šä¿¡å§‹ç»ˆæ²¿å„è‡ª rail åœ¨ç›¸é‚»æµæ°´é˜¶æ®µä¹‹é—´ä¼ æ’­ã€‚\nåå‘ä¼ æ’­ä¸æ¢¯åº¦æ±‡èšï¼šåå‘ä¼ æ’­ä»æœ€åé˜¶æ®µå¼€å§‹ï¼Œå°†æ¢¯åº¦é€æ­¥æ²¿ç›¸åæ–¹å‘ä¼ å›å„å‰åºé˜¶æ®µï¼ŒåŒæ ·é€šè¿‡å¯¹åº” rail é“¾è·¯å°†æ¢¯åº¦å¼ é‡å‘é€ç»™ä¸Šä¸€é˜¶æ®µçš„å¯¹åº” GPUã€‚åœ¨æ¯ä¸ª HB åŸŸå†…ï¼Œå‚ä¸å¼ é‡å¹¶è¡Œçš„ GPU é—´é€šè¿‡ NVLink è¿›è¡ŒAll-Gather/Reduce-Scatter ç­‰é›†åˆé€šä¿¡ï¼Œä»¥å®Œæˆæ¢¯åº¦äº¤æ¢å’Œå‚æ•°æ›´æ–°æ‰€éœ€çš„æ•°æ®æ•´åˆã€‚ç”±äº HB åŸŸå†…éƒ¨å…·å¤‡å…¨å¸¦å®½äº’è”ï¼Œè¿™äº›å¼ é‡å¹¶è¡Œé€šä¿¡ä»¥æœ€é«˜é€Ÿç‡è¿›è¡Œã€‚åå‘ä¼ æ’­è¿‡ç¨‹å„é˜¶æ®µè®¡ç®—å’Œé€šä¿¡å¤§éƒ¨åˆ†å¯æµæ°´çº¿é‡å ï¼Œé™ä½ç­‰å¾…å¼€é”€ã€‚\nå‚æ•°åŒæ­¥ä¸æ›´æ–°ï¼šå½“ä¸€æ¬¡æµæ°´è¿­ä»£ç»“æŸæ—¶ï¼ˆæ‰€æœ‰å¾®æ‰¹æ¬¡å®Œæˆåä¼ ï¼‰ï¼Œæ¯ä¸ªæ•°æ®å¹¶è¡Œç»„éœ€è¦åŒæ­¥æ¨¡å‹å‚æ•°æ¢¯åº¦ã€‚åœ¨ Rail-only æ¶æ„ä¸­ï¼Œæ•°æ®å¹¶è¡Œç»„è¢«è‡ªç„¶æ˜ å°„ä¸ºå„æ¡ railï¼šä¾‹å¦‚ local rank=3 çš„ rail åŒ…å«äº†æ¯ä¸ª HB åŸŸçš„ç¬¬3å· GPUï¼Œè¿™æ­£å¯¹åº”ä¸€ä¸ªæ•°æ®å¹¶è¡Œç»„ã€‚é€šè¿‡ rail å†…çš„é€šä¿¡å­ç½‘ï¼Œè·¨åŸŸæ‰§è¡Œ All-Reduce æ“ä½œï¼Œæ±‡æ€»ä¸åŒæ•°æ®å¹¶è¡Œå‰¯æœ¬çš„æ¢¯åº¦ã€‚All-Reduce ä½¿ç”¨åˆ†å±‚ç®—æ³•ï¼ˆå…ˆåœ¨åŸŸå†…å½’çº¦ï¼Œå†åœ¨ rail é—´å½’çº¦ï¼‰ï¼Œå……åˆ†åˆ©ç”¨ HB åŸŸå¸¦å®½ã€‚æ¢¯åº¦åŒæ­¥å®Œæˆåï¼Œå„ GPU æ›´æ–°æ¨¡å‹å‚æ•°ï¼Œè¿›å…¥ä¸‹ä¸€ä¸ªè¿­ä»£ã€‚\næ§åˆ¶æµä¸ä¾‹å¤–å¤„ç†ï¼šåœ¨ä¸Šè¿°ä¸»è¦æ•°æ®æµä¹‹å¤–ï¼Œä¸€äº›æ§åˆ¶é€šä¿¡ï¼ˆå¦‚å¹¿æ’­é…ç½®ã€èŠ‚ç‚¹å¿ƒè·³ï¼‰å¯èƒ½éœ€è¦ä»»æ„ GPU å¯¹é€šä¿¡ã€‚Rail-only é»˜è®¤ä¸ç›´æ¥è¿æ¥è·¨ rail çš„ GPUï¼Œå¯¹è¿™ç±»å°‘é‡æ§åˆ¶æ¶ˆæ¯ï¼Œå¯ä»¥é€šè¿‡ç»ç”± HB åŸŸä¸­è½¬çš„æ–¹å¼è·¯ç”±ï¼šä¾‹å¦‚ GPU1ï¼ˆåŸŸ1ï¼‰éœ€ä¸ GPU2ï¼ˆåŸŸ2ï¼‰é€šä¿¡ï¼Œåˆ™å°†æ¶ˆæ¯å…ˆé€å…¥åŸŸ1 å†… GPU2ï¼Œå†é€šè¿‡ rail 2 å‘è‡³åŸŸ2 çš„ GPU2ã€‚ç”±äºè®­ç»ƒè¿‡ç¨‹ä¸­æ­¤ç±»é€šä¿¡éå¸¸å°‘ä¸”éæ€§èƒ½å…³é”®ï¼Œç»•è¡Œä¸ä¼šæ˜æ˜¾å½±å“è®­ç»ƒè¿›ç¨‹ã€‚å¯¹äºç‰¹æ®Šçš„å…¨è¿æ¥é€šä¿¡æ¨¡å¼ï¼ˆå¦‚ç¨€ç– MoE ä¸“å®¶å±‚éœ€è¦ all-to-allï¼‰ï¼ŒRail-only æä¾›åœ¨å¤šä¸ªè¿­ä»£é˜¶æ®µåˆ†æ­¥å®Œæˆé€šä¿¡çš„æ–¹æ¡ˆï¼Œæˆ–åˆ©ç”¨åŠ¨æ€å¯é‡æ„è¿æ¥ä¸´æ—¶å»ºç«‹ç›´è¿ï¼Œä»¥ä¿è¯åŠŸèƒ½å®Œå¤‡ã€‚\n\n3.3 å…³é”®å‡è®¾ä¸é€‚ç”¨èŒƒå›´\n\nå‡è®¾ 1ï¼šé‡‡ç”¨æœ€ä¼˜çš„å¹¶è¡Œç­–ç•¥ï¼ˆPTD-Pï¼‰ â€“ è®ºæ–‡å‡è®¾æ¨¡å‹è®­ç»ƒä½¿ç”¨ç»è¿‡ç²¾å¿ƒé…ç½®çš„ä¸‰ç»´å¹¶è¡Œï¼ˆæµæ°´å¹¶è¡Œ+å¼ é‡å¹¶è¡Œ+æ•°æ®å¹¶è¡Œï¼‰ç»„åˆï¼Œä½¿å¾—é€šä¿¡æ¨¡å¼é«˜åº¦è§„åˆ™åŒ–ã€‚ä¾‹å¦‚å„ GPU é€šä¿¡ä¸»è¦å‘ç”Ÿåœ¨åŒä¸€æµæ°´é˜¶æ®µå†…ï¼ˆå¼ é‡å¹¶è¡Œï¼‰å’Œå¯¹åº”é˜¶æ®µä¹‹é—´ï¼ˆæµæ°´ä¸²æ¥ï¼‰ï¼Œè€Œéä»»æ„åˆ†å¸ƒã€‚è¿™ä¸€å‡è®¾åœ¨å¤§æ¨¡å‹è®­ç»ƒä¸­é€šå¸¸æˆç«‹ï¼Œä½†å¦‚æœå¹¶è¡Œç­–ç•¥ä¸åˆç†ï¼ˆå¦‚æœªå°†é«˜é€šä¿¡çš„ GPU æ”¾åœ¨åŒä¸€ HB åŸŸï¼‰ï¼Œåˆ™å¯èƒ½å‡ºç°è·¨ HB åŸŸçš„å¤§é‡é€šä¿¡ï¼ŒRail-only ç½‘ç»œåœ¨æ­¤æƒ…å†µä¸‹å¯èƒ½å¯¼è‡´æ€§èƒ½ç“¶é¢ˆæˆ–å¤æ‚çš„é€šä¿¡è·¯ç”±é—®é¢˜ã€‚\nå‡è®¾ 2ï¼šé›†ç¾¤ä¸»è¦ç”¨äºç±»ä¼¼ LLM è®­ç»ƒçš„å·¥ä½œè´Ÿè½½ â€“ Rail-only é’ˆå¯¹å¯†é›†å¤§å‹æ¨¡å‹è®­ç»ƒçš„é€šä¿¡ç‰¹å¾è¿›è¡Œäº†ä¼˜åŒ–ï¼Œå‡å®šé›†ç¾¤ä¸­è¿è¡Œçš„ä»»åŠ¡é€šä¿¡æ¨¡å¼ç›¸å¯¹å›ºå®šä¸”å±€é™ã€‚å¦‚è‹¥åœ¨åŒä¸€é›†ç¾¤ä¸­è·‘å¤§é‡é LLM å·¥ä½œè´Ÿè½½ï¼ˆä¾‹å¦‚éšæœºé€šä¿¡çš„å›¾ç®—æ³•æˆ–åˆ†å¸ƒå¼è®­ç»ƒå°æ¨¡å‹éœ€è¦é¢‘ç¹å…¨å±€åŒæ­¥ï¼‰ï¼ŒRail-only æ‹“æ‰‘å¯èƒ½æ— æ³•å……åˆ†æ”¯æŒï¼Œå¿…é¡»ä¾èµ–å‰è¿°ç»•è¡Œæœºåˆ¶ï¼Œæ€§èƒ½å’Œæ•ˆç‡ä¼šä¸‹é™ã€‚å› æ­¤è¯¥æ¶æ„é€‚ç”¨èŒƒå›´æ›´åå‘ä¸“ç”¨çš„å¤§æ¨¡å‹è®­ç»ƒé›†ç¾¤ï¼Œè€Œä¸æ˜¯é€šç”¨æ•°æ®ä¸­å¿ƒåœºæ™¯ã€‚\nå‡æµ‹ 3ï¼šHB åŸŸå†…é€šä¿¡è¶³å¤Ÿå¿«ä¸”è§„æ¨¡é€‚å®œ â€“ æ–¹æ¡ˆéšå«å‡è®¾å•ä¸ª HB åŸŸå†…çš„ GPU æ•°é‡ï¼ˆä¾‹å¦‚ 8 æˆ– 16ï¼‰è¶³ä»¥å®¹çº³ä¸»è¦çš„å¼ºé€šä¿¡ç»„ï¼ˆå¦‚ä¸€ä¸ªå¼ é‡å¹¶è¡Œç»„æˆ–è€…ä¸€ä¸ªå®Œæ•´çš„ Transformer å±‚è®¡ç®—ï¼‰ã€‚HB åŸŸå†…éƒ¨é€šè¿‡ NVLink/NVSwitch æä¾›é«˜è¾¾ TB/s çº§å¸¦å®½ï¼Œå¦‚æ­¤é«˜å¸¦å®½è¢«è§†ä¸ºæ— ç“¶é¢ˆã€‚è‹¥å®é™…ä¸­æ¨¡å‹å¹¶è¡Œéœ€è¦çš„ GPU è¶…è¿‡ HB åŸŸè§„æ¨¡ï¼ˆä¾‹å¦‚æ¨¡å‹éå¸¸å¤§ä»¥è‡´å•å±‚éœ€è¦ 64 å¡è€Œ NVSwitch åªèƒ½è¿8å¡ï¼‰ï¼Œé‚£ä¹ˆéƒ¨åˆ†å¼ é‡å¹¶è¡Œé€šä¿¡ä¸å¾—ä¸ç©¿è¶ŠåŸŸé—´ railï¼Œæ­¤æ—¶ Rail-only çš„å‡è®¾è¢«æ‰“ç ´ï¼Œå¯èƒ½å‡ºç°è·¨åŸŸé€šä¿¡å˜ä¸ºæ–°ç“¶é¢ˆã€‚è§£å†³æ–¹æ³•å¯èƒ½éœ€è¦å¢å¤§ HB åŸŸè§„æ¨¡æˆ–è°ƒæ•´å¹¶è¡Œåˆ’åˆ†ï¼Œä½†åœ¨ç»™å®šç¡¬ä»¶é™åˆ¶ä¸‹è¿™æ˜¯ Rail-only è®¾è®¡çš„è¾¹ç•Œä¹‹ä¸€ã€‚\nå‡è®¾ 4ï¼šç½‘ç»œé€šä¿¡ä»¥å¸¦å®½ä¸ºä¸»ï¼Œå»¶è¿Ÿå½±å“å¯å¿½ç•¥ â€“ ä½œè€…åœ¨æ¨¡å‹ä¸­ä¸»è¦è€ƒè™‘äº†é€šä¿¡çš„æ•°æ®ä¼ è¾“æ—¶é—´ï¼Œå‡å®šæ¯æ¬¡ collective æ“ä½œçš„å¯åŠ¨å»¶è¿Ÿå’ŒåŒæ­¥å¼€é”€ç›¸å¯¹è¾ƒå°ï¼Œä¸å½±å“æ€»ä½“è¿­ä»£æ—¶é—´ã€‚è¿™åœ¨å¤§è§„æ¨¡æ•°æ®ä¼ è¾“ï¼ˆå¦‚ AllReduce å‡ å GB æ¢¯åº¦ï¼‰æ—¶é€šå¸¸æˆç«‹ã€‚ç„¶è€Œåœ¨å°æ‰¹é‡æˆ–é¢‘ç¹å°é€šä¿¡çš„æƒ…å†µä¸‹ï¼Œå»¶è¿Ÿå¯èƒ½ç´¯ç§¯æˆæ˜æ˜¾å¼€é”€ã€‚è‹¥å®é™…è®­ç»ƒä½¿ç”¨æå°çš„ micro-batch æˆ–éå¸¸æ·±çš„æµæ°´å¹¶è¡Œï¼ˆå¯¼è‡´å¤§é‡é˜¶æ®µé—´å°æ¶ˆæ¯ï¼‰ï¼Œè¿™äº›å‡è®¾å¯èƒ½ä¸å†å‡†ç¡®ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–å»¶è¿Ÿï¼Œæ¯”å¦‚é€šè¿‡æ‰¹é‡é€šä¿¡æˆ–å¹¶å‘æµæ°´ç­‰æ‰‹æ®µã€‚\nå‡è®¾ 5ï¼šæ•…éšœç‡ä½ä¸”æœ‰å†·å¤‡èµ„æº â€“ Rail-only åœ¨è®¾è®¡ä¸Šå‡è®¾ GPU/é“¾è·¯æ•…éšœæ˜¯ç›¸å¯¹å°‘è§çš„ç‰¹æ®Šäº‹ä»¶ï¼Œå¹¶æä¾›æ–¹æ¡ˆåœ¨åŸŸå†…æœ‰ç©ºé—² GPU æ—¶è¿›è¡Œå¿«é€Ÿæ›¿æ¢ã€‚è¿™ä¸€å‡è®¾åœ¨ä¸“ç”¨é›†ç¾¤ä¸­å¸¸é€šè¿‡ä¿ç•™å°‘é‡å†—ä½™å®ç°ï¼Œä½†å¦‚æœæ²¡æœ‰å†—ä½™ GPUï¼Œæˆ–é¢‘ç¹å‘ç”ŸèŠ‚ç‚¹æ•…éšœï¼Œéœ€è¦è·¨åŸŸè¿ç§»ä»»åŠ¡ï¼Œå°†ç»™è®­ç»ƒè°ƒåº¦å’Œæ€§èƒ½å¸¦æ¥æŒ‘æˆ˜ã€‚åœ¨æç«¯æƒ…å†µä¸‹ï¼Œå¤§è§„æ¨¡ Rail-only é›†ç¾¤å¯èƒ½éœ€è¦æ¯”ä¼ ç»ŸClosæ›´å¤æ‚çš„é›†ç¾¤ç®¡ç†ç­–ç•¥ï¼Œè¿™è¶…å‡ºäº†è®ºæ–‡å‡å®šçš„ç®€åŒ–æ•…éšœæ¨¡å‹ã€‚\n\n3.4 æ•°å­¦å…¬å¼ä¸ç®—æ³•è§£è¯»\nè®ºæ–‡çš„æ–¹æ³•éƒ¨åˆ†åŒ…å«ä¸€å®šçš„æ•°å­¦åˆ†æï¼Œä¸»è¦ä½“ç°åœ¨è®­ç»ƒè¿­ä»£æ—¶é—´æ¨¡å‹å’Œåˆ†å±‚é€šä¿¡ç®—æ³•ä¸­ã€‚ä¸‹é¢é€‰å–å…¶ä¸­å…³é”®çš„å…¬å¼è¿›è¡Œè§£è¯»ï¼š\nåŸæ–‡ä¸­çš„å…¬å¼ï¼šåˆ†å±‚ All-Gather é€šä¿¡æ—¶é—´\n\\[\nT_{\\mathrm{AG}} \\;=\\; \\frac{(y-1)\\,D}{B_{\\mathrm{NIC}}}\\;+\\;\\frac{(x-1)\\,D}{B_{\\mathrm{HB}}}\\,.\n\\]\nè§£é‡Šï¼š è¯¥å…¬å¼æè¿°äº†åœ¨ Rail-only åœºæ™¯ä¸‹æ‰§è¡Œä¸€æ¬¡ All-Gather é›†åˆé€šä¿¡ï¼ˆå°†æ¯å— GPU ä¸Šçš„æ•°æ®å—åœ¨æ‰€æœ‰ GPU ä¸Šæ±‡èšï¼‰çš„æ€»æ—¶é—´ã€‚ä½œè€…é‡‡ç”¨äº†åˆ†å±‚ All-Gather ç®—æ³•ï¼šé›†ç¾¤ä¸­ \\(N=x \\times y\\) ä¸ª GPU è¢«è§†ä½œä¸€ä¸ª \\(x \\times y\\) çš„ç½‘æ ¼ï¼ˆå…¶ä¸­ \\(x\\) æ˜¯æ¯ä¸ª HB åŸŸå†…çš„ GPU æ•°ï¼Œ\\(y\\) æ˜¯ HB åŸŸçš„æ•°é‡ï¼‰ã€‚ç®—æ³•åˆ†ä¸¤æ­¥è¿›è¡Œæ•°æ®æ±‡èšï¼š\n\nè·¨åŸŸé˜¶æ®µï¼ˆç½‘ç»œåŸŸï¼‰ï¼šé¦–å…ˆï¼Œæ¯æ¡ railï¼ˆæ¨ªè·¨ \\(y\\) ä¸ª HB åŸŸã€åŒ…å« \\(y\\) å¼  GPUã€æ¯åŸŸå„1å¼ ï¼‰å†…éƒ¨å®Œæˆåˆæ­¥æ±‡èšâ€”â€”å„ GPU å°†è‡ªå·±çš„æ•°æ®å—å‘é€ç»™åŒè½¨é“çš„å…¶ä»– \\(y-1\\) å¼  GPUã€‚è¿™æ ·ç»è¿‡æ­¤é˜¶æ®µï¼Œæ¯æ¡ rail ä¸Šçš„ GPU éƒ½æ”¶é›†åˆ°äº†æ¥è‡ªä¸åŒ HB åŸŸçš„éƒ¨åˆ†æ•°æ®ã€‚å…¬å¼ä¸­ \\(\\frac{(y-1)\\,D}{B_{\\mathrm{NIC}}}\\) è¡¨ç¤ºæ‰€æœ‰ GPU é€šè¿‡ç½‘ç»œäº¤æ¢æ•°æ®æ‰€éœ€æ—¶é—´ï¼šæ¯å¼  GPU éœ€è¦å‘é€/æ¥æ”¶ \\((y-1)\\) ä»½æ•°æ®å—ï¼ˆæ¯å—å¤§å° \\(D\\)ï¼‰ï¼Œ\\(B_{\\mathrm{NIC}}\\) æ˜¯æ¯å¼  GPU å¯åˆ©ç”¨çš„ç½‘ç»œå¸¦å®½ï¼ˆNIC/äº¤æ¢æœºå¸¦å®½ï¼‰ã€‚è¿™ä¸€é¡¹éš \\(y\\) å¢å¤§è€Œçº¿æ€§å¢åŠ ï¼Œè¡¨ç¤ºå¦‚æœ HB åŸŸæ•°é‡å¾ˆå¤šï¼Œåˆ™è·¨åŸŸé€šä¿¡å¼€é”€å˜å¤§ã€‚\nåŸŸå†…é˜¶æ®µï¼ˆHB åŸŸï¼‰ï¼šæ¥ä¸‹æ¥ï¼Œåœ¨æ¯ä¸ª HB åŸŸå†…éƒ¨ï¼ˆåŒ…å«æ¥è‡ªä¸åŒ rails çš„ \\(x\\) å¼  GPUï¼‰è¿›è¡Œç¬¬äºŒæ­¥æ±‡èšâ€”â€”è¿™äº› GPU å½¼æ­¤äº¤æ¢å„è‡ªæŒæœ‰çš„ç‰‡æ®µã€‚ç”±äºä¸Šä¸€é˜¶æ®µæ¯å¼  GPU å·²æ‹¥æœ‰ä¸€éƒ¨åˆ†å®Œæ•´æ•°æ®ï¼ˆæ¥è‡ªåŒä¸€ rail çš„ \\(y\\) ä»½ï¼‰ï¼ŒåŸŸå†…äº¤æ¢åï¼Œæ¯å¼  GPU å°†è·å¾—æ‰€æœ‰ \\(N\\) å¼  GPUçš„æ•°æ®å‰¯æœ¬ã€‚å…¬å¼ä¸­çš„ \\(\\frac{(x-1)\\,D}{B_{\\mathrm{HB}}}\\) è¡¨ç¤ºè¿™ä¸€åŸŸå†… All-Gather æ‰€éœ€æ—¶é—´ï¼šåŸŸå†…æ¯å¼  GPU éœ€ä¸å…¶ä»– \\(x-1\\) å¼  GPU äº¤æ¢æ•°æ®å—ï¼Œ\\(B_{\\mathrm{HB}}\\) æ˜¯å•å¼  GPU åœ¨ HB åŸŸå†…çš„æœ‰æ•ˆå¸¦å®½ï¼ˆå¦‚ NVLink å¸¦å®½ï¼‰ã€‚\\(x\\) è¶Šå¤§ï¼Œè¿™éƒ¨åˆ†è€—æ—¶è¶Šé«˜ï¼Œä½†ç”±äº NVLink æé«˜é€Ÿï¼Œé€šå¸¸ \\(B_{\\mathrm{HB}} \\gg B_{\\mathrm{NIC}}\\)ï¼ŒåŸŸå†…é€šä¿¡æ›´å¿«ã€‚\n\nç›´è§‚æ“ä½œæè¿°ï¼š å¯ä»¥æŠŠä¸Šè¿°è¿‡ç¨‹ç±»æ¯”ä¸ºå¼€ä¼šåˆ†äº«èµ„æ–™ï¼šå…¨ä½“ \\(N\\) äººè¢«åˆ’åˆ†æˆ \\(y\\) ä¸ªå°ç»„ï¼ˆHB åŸŸï¼‰ï¼Œæ¯ç»„æœ‰ \\(x\\) äººã€‚æ¯äººæ‰‹é‡Œæœ‰ä¸€ä»½ç‹¬æœ‰èµ„æ–™ï¼ˆæ•°æ®å—ï¼‰ã€‚é¦–å…ˆï¼Œæ¯ç»„çš„ç¬¬1å·æˆå‘˜å‡ºç»„ï¼Œä¸å…¶ä»–ç»„çš„ç¬¬1å·æˆå‘˜äº¤æ¢èµ„æ–™ï¼›ç¬¬2å·æˆå‘˜ä¹‹é—´ä¹Ÿå¦‚æ­¤ â€¦ è¿™æ ·å…±æœ‰ \\(x\\) æ¡â€œè½¨é“â€ï¼ˆå¯¹åº”ä¸åŒæˆå‘˜åºå·ï¼‰åœ¨å„ç»„ä¹‹é—´å¹¶è¡Œäº¤æ¢èµ„æ–™ã€‚äº¤æ¢å®Œæˆåï¼ŒåŒè½¨é“çš„æ¯ä¸ªäººéƒ½æ”¶é›†åˆ°äº† \\(y\\) ä»½ä¸åŒèµ„æ–™ï¼ˆå„æ¥è‡ªä¸€ä¸ªç»„ï¼‰ã€‚æ¥ç€ï¼Œå›åˆ°ç»„å†…ï¼Œæ¯ç»„çš„æˆå‘˜å½¼æ­¤åˆ†äº«è‡ªå·±æ”¶é›†åˆ°çš„èµ„æ–™ï¼ˆå› ä¸ºç»„å†…æ¯ä¸ªäººå„è‡ªä»£è¡¨äº†ä¸€æ¡è½¨é“æ”¶é›†åˆ°ä¸åŒèµ„æ–™ï¼‰ã€‚è¿™ç¬¬äºŒè½®åˆ†äº«åï¼Œæ¯ç»„æ¯ä¸ªäººéƒ½æ‹¿åˆ°äº†æ‰€æœ‰ \\(N\\) ä»½èµ„æ–™ã€‚ä¸¤è½®ä¸‹æ¥ï¼Œå®ç°äº†å…¨ä½“æ±‡æ€»ã€‚è¯¥ç®—æ³•ç›¸æ¯”ä¸€å¼€å§‹å°±æ¯ä¸ªäººå‘å…¶ä»– \\(N-1\\) äººå‘é€èµ„æ–™ï¼Œæ˜¾è‘—å‡å°‘äº†è·¨ç»„ï¼ˆè·¨åŸŸï¼‰å‘é€çš„æ•°æ®é‡ã€‚å…¬å¼ä¸­ \\((y-1)D/x\\) å¯ä»¥çœ‹ä½œæ¯äººé€šè¿‡ç½‘ç»œå®é™…éœ€äº¤æ¢çš„æ€»èµ„æ–™é‡ï¼ˆç›¸å¯¹æ€»å¤§å° \\(N \\!D\\) å¤§å¤§é™ä½ï¼‰ï¼Œå› æ­¤æ€»é€šä¿¡æ—¶é—´ä¸»è¦ç”±è¿™ä¸¤éƒ¨åˆ†å åŠ æ„æˆã€‚\nç­‰ä»·é‡å†™ä¸å‡è®¾ï¼š ä¸Šè¿°å…¬å¼å‡è®¾è·¨åŸŸå’ŒåŸŸå†…é€šä¿¡ä¸²è¡Œè¿›è¡Œï¼Œä¸”å„é˜¶æ®µèƒ½å¤Ÿå……åˆ†åˆ©ç”¨å¸¦å®½ã€‚å¦‚æœè·¨åŸŸå’ŒåŸŸå†…é€šä¿¡å¯ä»¥éƒ¨åˆ†é‡å ï¼Œæ—¶é—´å¯ä»¥è¿›ä¸€æ­¥å‡å°‘ã€‚ä¸è¿‡åœ¨ä½œè€…çš„åˆ†æä¸­ï¼Œä¸ºç®€åŒ–å‡è®¾é€šä¿¡é˜¶æ®µå…ˆåè¿›è¡Œï¼ˆä¸é‡å ï¼‰ï¼Œç¡®ä¿å…¬å¼ç»™å‡ºä¿å®ˆä¸Šç•Œã€‚é€šè¿‡è¿™ä¸€æ¨¡å‹ï¼Œä½œè€…å®šé‡è¯æ˜äº†ç»å¤§éƒ¨åˆ†æ•°æ®ï¼ˆçº¦ \\((x-1)/x\\) æ¯”ä¾‹ï¼‰é€šè¿‡ NVLink ç­‰åŸŸå†…é«˜é€Ÿé“¾è·¯äº¤æ¢ï¼Œä»…æå°éƒ¨åˆ†ï¼ˆçº¦ \\((y-1)/x\\)ï¼‰éœ€è¦èµ°ç›¸å¯¹æ…¢çš„è·¨åŸŸç½‘ç»œã€‚ä¾‹å¦‚ä¸€å° DGX (8å¡) ç»„æˆ HB åŸŸï¼Œ4å°è¿™æ ·çš„æœåŠ¡å™¨è®­ç»ƒï¼Œ\\(x=8, y=4\\)ï¼Œåˆ™è·¨åŸŸç½‘ç»œä»…æ‰¿æ‹… \\((4-1)/8 = 37.5\\%\\) çš„ All-Gather æ•°æ®ï¼Œå…¶ä½™ 62.5% åœ¨åŸŸå†…å®Œæˆã€‚è¿™æ­£æ˜¯ Rail-only èƒ½å¤Ÿåˆ å»å¤§éƒ¨åˆ†è·¨åŸŸç½‘ç»œè®¾å¤‡ä»ä¸æŸå¤±æ€§èƒ½çš„æ•°å­¦ä¾æ®ä¹‹ä¸€ã€‚\nåŸæ–‡ä¸­çš„å…¬å¼ï¼šè®­ç»ƒè¿­ä»£æ—¶é—´åˆ†è§£\n(ç”±äºåŸè®ºæ–‡ä¸­è¿­ä»£æ—¶é—´å…¬å¼ç›¸å½“å¤æ‚ï¼Œè¿™é‡Œæ¦‚å¿µæ€§è¯´æ˜)\nä½œè€…å°†ä¸€æ¬¡å®Œæ•´è®­ç»ƒè¿­ä»£çš„æ—¶é—´åˆ’åˆ†ä¸ºä¸‰ä¸ªéƒ¨åˆ†ï¼šæµæ°´å¡«å……/æ¸…ç©ºçš„ç­‰å¾…å¼€é”€ (\\(T_{\\text{bubble}}\\))ã€æœ€åä¸€ä¸ªæµæ°´é˜¶æ®µçš„è®¡ç®—ä¸é€šä¿¡æ—¶é—´ (\\(T_{\\text{last}}\\))ï¼Œä»¥åŠå‚æ•°åŒæ­¥æ—¶é—´ (\\(T_{\\text{sync}}\\))ã€‚æ®æ­¤ç»™å‡ºäº†è¿­ä»£æ—¶é—´çš„è¿‘ä¼¼æ€»å’Œï¼š\n\\[\nT_{\\text{iter}} \\approx T_{\\text{bubble}} + T_{\\text{last}} + T_{\\text{sync}}\\,.\n\\]\n\nå…¶ä¸­ï¼Œ\\(T_{\\text{bubble}}\\) è¡¨ç¤ºæµæ°´å¹¶è¡Œåœ¨å¼€å§‹å’Œç»“æŸæ—¶ç”±äºæµæ°´å°šæœªâ€œçŒæ»¡â€æˆ–â€œæ’ç©ºâ€è€ŒæŸå¤±çš„æ—¶é—´ã€‚è¿™éƒ¨åˆ†å¼€é”€åŒ…æ‹¬äº†ä¸€å®šçš„è®¡ç®—å’Œé€šä¿¡ï¼Œä½†ä½œè€…ä¸ºç®€åŒ–å‡å®šè®¡ç®—å’Œé€šä¿¡ä¸é‡å ï¼Œå¹¶ç»“åˆ micro-batch æ•°é‡æ¨å¯¼äº† \\(T_{\\text{bubble}}\\) éšå¹¶è¡Œæ·±åº¦å’Œæ‰¹å¤§å°çš„å…¬å¼ã€‚\n\\(T_{\\text{last}}\\) ä»£è¡¨æœ€åä¸€ä¸ªæµæ°´é˜¶æ®µå¤„ç†æ‰€æœ‰å¾®æ‰¹çš„ç”¨æ—¶ã€‚å› ä¸ºæœ€åé˜¶æ®µæ— æ³•ä¸åç»­é˜¶æ®µé‡å ï¼Œå…¶è®¡ç®—å’Œé€šä¿¡ï¼ˆåŒ…æ‹¬å¼ é‡å¹¶è¡Œ All-Gatherã€Reduce-Scatter ä»¥åŠæµæ°´å¹¶è¡Œä¹‹é—´çš„æ¿€æ´»/æ¢¯åº¦ä¼ è¾“ï¼‰ä¼šå½±å“æ•´ä½“ä¸´ç•Œè·¯å¾„ã€‚ä½œè€…è¯¦ç»†åˆ†æäº†åœ¨æœ€åé˜¶æ®µä¸­ï¼Œå„å¾®æ‰¹çš„å¼ é‡å¹¶è¡Œé€šä¿¡æ¬¡æ•°ï¼ˆä¾‹å¦‚æ¯å±‚4æ¬¡ All-Gather å’Œ 4æ¬¡ Reduce-Scatterï¼‰ä»¥åŠè¿™äº›é€šä¿¡åœ¨ HB åŸŸå†…å’Œè·¨åŸŸåˆ†åˆ«æ¶ˆè€—çš„æ—¶é—´ï¼Œå¹¶ç”¨ç±»ä¼¼ All-Gather åˆ†å±‚æ¨¡å‹çš„æ–¹æ³•è®¡ç®— \\(T_{\\text{last}}\\)ã€‚\n\\(T_{\\text{sync}}\\) åˆ™æ˜¯å‚æ•°æ¢¯åº¦çš„å…¨å±€ All-Reduce æ—¶é—´ã€‚åœ¨PTDå¹¶è¡Œä¸­ï¼Œé€šå¸¸å°†æ•°æ®å¹¶è¡Œåº¦ä¸º \\(D_p\\) çš„å‚æ•°æ¢¯åº¦åšä¸€æ¬¡ All-Reduceã€‚ç”±äº All-Reduce æœ¬è´¨ä¸Šå¯çœ‹ä½œä¸€æ¬¡ All-Gather åŠ ä¸€æ¬¡ Reduce-Scatterï¼Œä½œè€…ç›´æ¥å°† All-Gather æ—¶é—´ä¹˜ä»¥ 2 å¾—åˆ°å…¶é€šä¿¡è€—æ—¶ä¼°è®¡ï¼Œå¹¶ä½¿ç”¨åˆ†å±‚ç®—æ³•ï¼ˆå…ˆåŸŸå†…åè·¨åŸŸï¼‰è®¡ç®—ã€‚\n\nä»¥ä¸Šå„éƒ¨åˆ†å…¬å¼ç»„åˆï¼Œä½œè€…è·å¾—äº†è®­ç»ƒè¿­ä»£æ—¶é—´çš„å°é—­è§£ã€‚è™½ç„¶è¿™é‡Œæœªåˆ—å‡ºå®Œæ•´å…¬å¼ç»†èŠ‚ï¼Œä½†å…³é”®ç»“è®ºæ˜¯ï¼šè¿­ä»£æ—¶é—´å—å¹¶è¡Œé…ç½®å’Œç½‘ç»œå¸¦å®½å½±å“ï¼Œå¯ä»¥é€šè¿‡è°ƒèŠ‚ HB åŸŸå¤§å°ã€ç½‘ç»œå¸¦å®½ã€æ‰¹å¤§å°ç­‰æ‰¾åˆ°æ€§èƒ½æ¥è¿‘ç†æƒ³çš„é…ç½®ã€‚è¿™ä¸€è§£ææ¨¡å‹ç»å¯¹æ¯”éªŒè¯ï¼Œåœ¨ GPT-1T ç­‰å¤§æ¨¡å‹ä¸Šé¢„æµ‹çš„ç¡¬ä»¶ FLOPs åˆ©ç”¨ç‡ä¸å®æµ‹å€¼ç›¸å·®ä¸åˆ° 1%ï¼Œè¯æ˜äº†å…¶å‡†ç¡®æ€§ã€‚æ¨¡å‹ä¹Ÿé¢„æµ‹äº†HB åŸŸè¶Šå¤§ã€æ‰¹è¶Šå¤§ï¼Œé€šä¿¡å æ¯”è¶Šä½ç­‰è¶‹åŠ¿ï¼Œä¸å®éªŒç»“æœå»åˆã€‚\nä¸å¸¸è§è®­ç»ƒæ ˆçš„å¯¹åº”å…³ç³»\n\nLLM è®­ç»ƒå¹¶è¡Œå±‚é¢ï¼šä¸Šè¿°æ¨¡å—å¯¹åº”è®­ç»ƒæ¡†æ¶ä¸­çš„ å¹¶è¡Œç­–ç•¥è§„åˆ’ å±‚ã€‚LLM é€šä¿¡åˆ†æç›¸å½“äºæ¡†æ¶çš„ Profiler/Plannerï¼Œå†³å®šæ•°æ®å¹¶è¡Œã€å¼ é‡å¹¶è¡Œå¦‚ä½•åˆ’åˆ†ï¼›Rail-only æ‹“æ‰‘è®¾è®¡å±äº é›†ç¾¤æ¶æ„ï¼Œéœ€è¦è®­ç»ƒæ¡†æ¶äº†è§£ç½‘ç»œæ‹“æ‰‘ä»¥ä¼˜åŒ–é€šä¿¡è°ƒåº¦ï¼›å®¹é”™æœºåˆ¶æ¶‰åŠ é›†ç¾¤ç®¡ç†ä¸è°ƒåº¦ï¼ˆå¦‚åˆ†å¸ƒå¼è®­ç»ƒä½œä¸šåœ¨æ•…éšœæ—¶çš„ é‡å¯/è¿ç§» ç­–ç•¥ï¼‰ï¼›è¿­ä»£æ€§èƒ½æ¨¡å‹å¯åµŒå…¥è‡ªåŠ¨å¹¶è¡Œé…ç½®å·¥å…·ï¼Œå¸®åŠ©ç±»ä¼¼ Megatron/DeepSpeed çš„å¼•æ“é€‰æ‹©æœ€ä½³å¹¶è¡Œåº¦ã€‚\né€šä¿¡å®ç°å±‚é¢ï¼šRail-only éœ€è¦å¯¹é€šä¿¡åº“ï¼ˆå¦‚ NCCLã€MPIï¼‰çš„é›†åˆé€šä¿¡ç®—æ³•è¿›è¡Œè°ƒæ•´ï¼Œä»¥å®ç°å‰è¿°åˆ†å±‚ All-Gatherã€All-Reduceã€‚è¿™å¯¹åº” é€šä¿¡ backend çš„æ”¹è¿›ï¼ˆä¾‹å¦‚ NCCL çš„åˆ†å±‚ Ringï¼‰ã€‚HB åŸŸå†…é€šä¿¡åˆ©ç”¨ NVLink ç›¸å½“äº èŠ‚ç‚¹å†…éƒ¨é€šä¿¡ä¼˜åŒ–ï¼ŒåŸŸé—´é€šè¿‡ä»¥å¤ªç½‘/Infiniband åˆ™å¯¹åº” è·¨èŠ‚ç‚¹é€šä¿¡ å±‚ã€‚Rail-only åœ¨å®ç°ä¸Šå¯ä»¥çœ‹ä½œå°†ä¼ ç»Ÿ Clos ç½‘ç»œçš„ æ ¸å¿ƒäº¤æ¢å±‚å»é™¤ï¼Œå› æ­¤ä¹Ÿå½±å“ æ‹“æ‰‘æ„ŸçŸ¥çš„é€šä¿¡è°ƒåº¦ï¼ˆä¾‹å¦‚ collective ç®—æ³•éœ€è¦è¯†åˆ« rail ç»“æ„ï¼‰ã€‚\nç³»ç»Ÿé›†æˆå±‚é¢ï¼šæ¨¡å—é—´é…åˆæ¶‰åŠ ä½œä¸šè°ƒåº¦ï¼ˆç¡®ä¿æ¯ä¸ªæµæ°´å¹¶è¡Œé˜¶æ®µæ˜ å°„åˆ°ä¸€ä¸ª HB åŸŸï¼Œè¿™é€šå¸¸ç”±è°ƒåº¦å™¨æˆ–æ¡†æ¶é€šè¿‡æ‹“æ‰‘æ„ŸçŸ¥çš„ GPU æ’å¸ƒå®ç°ï¼‰ï¼Œæ•°æ®åŠ è½½ åˆ™åŸºæœ¬ä¸å—å½±å“ï¼ˆä½†å¤§æ‰¹é‡ä¸‹å¯èƒ½éœ€è¦è°ƒæ•´ DataLoader ä½¿è®¡ç®—ä¸é€šä¿¡æ¯”ä¾‹åˆç†ï¼‰ã€‚æ•…éšœæ¢å¤éœ€è¦ é›†ç¾¤ç›‘æ§ é…åˆ æ§åˆ¶APIï¼ˆå¦‚è§¦å‘å…‰å¼€å…³é‡æ„ï¼‰ï¼Œè¿™å±äºé›†ç¾¤ç®¡ç†ç³»ç»Ÿè€Œéå¸¸è§è®­ç»ƒæ¡†æ¶èŒè´£ã€‚\n\nå››ã€å»ºæ¨¡æ–¹å¼ä¸è¯„ä¼°æŒ‡æ ‡\n4.1 é—®é¢˜æ˜¯å¦‚ä½•å½¢å¼åŒ–çš„ï¼Ÿ\nä½œè€…å°†è®­ç»ƒæ€§èƒ½ä¼˜åŒ–å½¢å¼åŒ–ä¸ºä¸€ä¸ªè¿­ä»£æ—¶é—´æœ€å°åŒ–é—®é¢˜ã€‚åœ¨ç»™å®šæ¨¡å‹è§„æ¨¡ã€ç¡¬ä»¶å‚æ•°çš„å‰æä¸‹ï¼Œç›®æ ‡æ˜¯æœ€å°åŒ–æ¯æ¬¡è®­ç»ƒè¿­ä»£æ‰€éœ€æ—¶é—´ \\(T_{\\text{iter}}\\)ã€‚è¿™ä¸€ä¼˜åŒ–æ¶‰åŠå†³ç­–è¯¸å¦‚ å¹¶è¡Œåˆ’åˆ†ç­–ç•¥ï¼ˆå¤šå°‘å±‚æµæ°´å¹¶è¡Œ \\(P\\)ã€å¼ é‡å¹¶è¡Œå¤§å° \\(T\\)ã€æ•°æ®å¹¶è¡Œå¤åˆ¶æ•° \\(D\\) ç­‰ï¼‰å’Œ ç½‘ç»œæ¶æ„ï¼ˆæ˜¯å¦é‡‡ç”¨ Rail-onlyï¼Œä»¥åŠ HB åŸŸå¤§å° \\(K\\) ç­‰ï¼‰ã€‚ä¸ºäº†è¯„ä¼°ä¸åŒå†³ç­–çš„æ•ˆæœï¼Œè®ºæ–‡å»ºç«‹äº†ä¸€ä¸ªè§£ææ¨¡å‹ï¼Œç”¨æ•°å­¦å…¬å¼å°† \\(T_{\\text{iter}}\\) è¡¨ç¤ºä¸ºå¹¶è¡Œé…ç½®å’Œç³»ç»Ÿå‚æ•°çš„å‡½æ•°ã€å…¬å¼ (2) ç­‰ã€‘ã€‚å…¶ä¸­åŒ…å«çš„ä¸»è¦é‡æœ‰ï¼šæ¯å±‚è®¡ç®—å¼€é”€ã€NVLink åŸŸå†…é€šä¿¡å¼€é”€ã€ä»¥å¤ªç½‘/InfiniBand åŸŸé—´é€šä¿¡å¼€é”€ã€å„éƒ¨åˆ†é‡å æƒ…å†µç­‰ã€‚\nåœ¨å½¢å¼åŒ–è¿‡ç¨‹ä¸­ï¼Œä½œè€…åšäº†ä¸€äº›ç®€åŒ–çº¦æŸï¼šå‡å®šTransformer å±‚ç»“æ„å‡åŒ€ï¼ˆæ¯å±‚è®¡ç®—ä¸é€šä¿¡æ¨¡å¼ç›¸åŒï¼Œå¯ç”¨åŒä¸€å…¬å¼è¡¨ç¤ºï¼‰ï¼Œé‡‡ç”¨mixed precisionï¼ˆ16-bit æ•°æ®ï¼‰ä½¿é€šä¿¡å­—èŠ‚é‡ä¸å‚æ•°é‡çº¿æ€§ç›¸å…³ï¼Œå¹¶å¿½ç•¥ CPU å‚ä¸ï¼ˆæ‰€æœ‰é€šä¿¡å‡ GPUç›´è¿ï¼‰ã€‚å¦å¤–ï¼Œä¸ºäº†å¯è§£æåœ°æ¯”è¾ƒä¸åŒç½‘ç»œæ‹“æ‰‘ï¼Œä»–ä»¬å‡è®¾é€šä¿¡è¿‡ç¨‹åˆ†é˜¶æ®µä¸²è¡Œï¼ˆå¦‚å‰è¿° All-Gather åˆ†ä¸¤æ­¥æ‰§è¡Œä¸”æ— é‡å ï¼‰ï¼Œå¹¶é€‰å–ä¿å®ˆçš„é‡å æ¨¡å‹ï¼ˆä¾‹å¦‚ä¸åŒå¾®æ‰¹ä¹‹é—´çš„é€šä¿¡ä¸é‡å è®¡ç®—ï¼‰ã€‚è¿™äº›çº¦æŸç¡®ä¿æ¨¡å‹å¯è§£ä¸”è´´è¿‘å®é™…ï¼Œä½†ä¹Ÿæ„å‘³ç€åœ¨æç«¯æƒ…å†µä¸‹ï¼ˆå¦‚é«˜åº¦é‡å é€šä¿¡åœºæ™¯ï¼‰æ¨¡å‹å¯èƒ½ç•¥æœ‰åå·®ã€‚æ€»ä½“è€Œè¨€ï¼Œè¿™ä¸€å½¢å¼åŒ–å°†ç¡¬ä»¶æ€§èƒ½ï¼ˆGPU FLOPsã€ç½‘ç»œå¸¦å®½ï¼‰å’Œå¹¶è¡Œç®—æ³•ç»Ÿä¸€åˆ°äº†ä¸€ä¸ªä¼˜åŒ–æ¡†æ¶ï¼Œå¯ç”¨ä½œæŒ‡å¯¼ç½‘ç»œè®¾è®¡å’Œå¹¶è¡Œç­–ç•¥é€‰æ‹©çš„å®šé‡å·¥å…·ã€‚\n4.2 æ ¸å¿ƒè¯„ä¼°æŒ‡æ ‡\nè®ºæ–‡ä¸ºäº†éªŒè¯ Rail-only ç½‘ç»œçš„æœ‰æ•ˆæ€§ä»¥åŠç†è®ºæ¨¡å‹çš„å‡†ç¡®æ€§ï¼Œé‡‡ç”¨äº†å¤šç»´åº¦çš„è¯„ä¼°æŒ‡æ ‡ï¼š\n\nç¡¬ä»¶ç®—åŠ›åˆ©ç”¨ç‡ (HFU)ï¼šè¡¡é‡ GPU é›†ç¾¤å®é™…æ‰§è¡Œçš„æµ®ç‚¹è¿ç®— vs.Â ç†è®ºå³°å€¼çš„æ¯”å€¼ã€‚è®¡ç®—æ–¹æ³•æ˜¯å–æ¨¡å‹è¿­ä»£è€—æ—¶æ¨ç®—å‡ºçš„æ¯ç§’ FLOPs ä¸ç¡¬ä»¶ç†è®º FLOPs æ¯”è¾ƒï¼Œå¾—åˆ°ä¸€ä¸ªç™¾åˆ†æ¯”ã€‚HFU æŒ‡æ ‡ç›´æ¥åæ˜ äº†å¹¶è¡Œç­–ç•¥å’Œç½‘ç»œæ¶æ„æ˜¯å¦å……åˆ†åˆ©ç”¨äº† GPU ç®—åŠ›ã€ç”¨äºéªŒè¯è§£ææ¨¡å‹å‡†ç¡®æ€§ï¼šæ¨¡å‹é¢„æµ‹ HFU vs.Â å®æµ‹ HFU æ¯”è¾ƒï¼ŒHFU è¶Šæ¥è¿‘100%è¡¨ç¤ºç“¶é¢ˆè¶Šå°ã€‘ã€‚\nå•æ­¥è¿­ä»£æ—¶é—´ï¼šå³æ¯ä¸€æ¬¡å‚æ•°æ›´æ–°æ‰€éœ€çš„å¢™é’Ÿæ—¶é—´ï¼ˆç§’ï¼‰ã€‚è¿™æ˜¯é€šè¿‡è§£ææ¨¡å‹æˆ–æ¨¡æ‹Ÿè®¡ç®—å¾—åˆ°çš„ï¼Œä¹Ÿæ˜¯å®éªŒæµ‹é‡çš„ç›´æ¥è¾“å‡ºã€‚è¿­ä»£æ—¶é—´æ˜¯æ€§èƒ½ä¼˜åŒ–çš„æ ¸å¿ƒæŒ‡æ ‡â€”â€”Rail-only è®¾è®¡çš„æˆè´¥æœ€ç»ˆä½“ç°ä¸ºèƒ½å¦ä¸å¢åŠ è¿­ä»£æ—¶é—´ç”šè‡³ç•¥æœ‰é™ä½ã€å› ä¸ºå»é™¤äº†éƒ¨åˆ†ç½‘ç»œè®¾å¤‡å¯èƒ½å‡å°‘å»¶è¿Ÿã€‘ã€‚ä½œè€…ç‰¹åˆ«å…³æ³¨ä¸åŒæ¡ä»¶ä¸‹è¿­ä»£æ—¶é—´çš„å˜åŒ–ï¼Œç”¨å®ƒæ¥æ¯”è¾ƒRail-only ä¸ Closç½‘ç»œåœ¨å„ç§åœºæ™¯ä¸‹çš„æ€§èƒ½å·®å¼‚ã€‚\nç›¸å¯¹æ€§èƒ½ (Relative Performance)ï¼šä¸ºäº†æ›´ç›´è§‚è¯„ä¼° Rail-only çš„å½±å“ï¼Œè®ºæ–‡å®šä¹‰äº†ç›¸å¯¹æ€§èƒ½ = Rail-only è¿­ä»£æ—¶é—´ / ç†æƒ³å…¨è¿æ¥ç½‘ç»œè¿­ä»£æ—¶é—´ï¼ˆæˆ–å–ç™¾åˆ†æ¯”ï¼‰ã€‚å°äº100%è¡¨ç¤ºæ›´å¿«ï¼ˆæ›´å¥½ï¼‰ï¼Œæ¥è¿‘100%è¡¨ç¤ºæ— æŸæ€§èƒ½ã€‚è¿™ä¸ªæŒ‡æ ‡ç”¨æ¥å±•ç¤ºåœ¨å„ç§ HB åŸŸå¤§å°ã€æ‰¹å¤§å°æƒ…å†µä¸‹ï¼ŒRail-only è¾¾åˆ°çš„æ€§èƒ½å ç†æƒ³æƒ…å†µçš„å¤šå°‘ã€‚ä¾‹å¦‚ GPT-1T æ¨¡å‹åœ¨ HB åŸŸ256æ—¶ç›¸å¯¹æ€§èƒ½è¾¾ 99%ä»¥ä¸Šï¼Œè¯´æ˜å‡ ä¹æ— æ€§èƒ½æŸè€—ã€‚ã€è¯¥æŒ‡æ ‡è¯æ˜ Rail-only æ²¡æœ‰ç‰ºç‰²æ€§èƒ½ï¼ŒåŒæ—¶ç”¨äºæ‰¾å‡ºåœ¨ä½•ç§æ¡ä»¶ä¸‹æ€§èƒ½å¼€å§‹æ˜¾è‘—ä¸‹é™ã€‘ã€‚\nç½‘ç»œæˆæœ¬ (Cost)ï¼šä»¥äº¤æ¢æœºå’Œé«˜é€Ÿé“¾è·¯çš„æ•°é‡æˆ–é€ ä»·è¡¡é‡æ•´ä¸ªç½‘ç»œçš„æˆæœ¬å¼€é”€ã€‚è®ºæ–‡é€šè¿‡åˆ—å‡ºä¸åŒç½‘ç»œè®¾è®¡ä¸‹æ‰€éœ€çš„äº¤æ¢èŠ¯ç‰‡æ•°é‡å’Œå…‰æ¨¡å—æ•°é‡ï¼Œä¼°ç®— Rail-only ç›¸å¯¹äº Clos èŠ‚çœçš„ç™¾åˆ†æ¯”ï¼ˆå¦‚ é™ä½ 38â€“77%ï¼‰ã€‚è¿™ä¸€æŒ‡æ ‡ç›´æ¥å¯¹åº”è®ºæ–‡è¦è§£å†³çš„é—®é¢˜â€”â€”é™ä½è¶…å¤§è§„æ¨¡é›†ç¾¤çš„ç½‘ç»œæŠ•å…¥ï¼Œå¯¹äºå·¥ç¨‹å†³ç­–è€…éå¸¸å…³é”®ã€‚\nç½‘ç»œåŠŸè€— (Power)ï¼šè¯„ä¼°ç½‘ç»œè®¾å¤‡åœ¨å³°å€¼è´Ÿè½½ä¸‹çš„ç”µåŠ›æ¶ˆè€—ï¼ˆç“¦æˆ–å…†ç“¦ï¼‰ã€‚ä½œè€…å¼•ç”¨å®é™…æ•°æ®ä¼°è®¡ä¼ ç»Ÿ Clos ç½‘ç»œ 30k GPU é›†ç¾¤éœ€ ~4.6 MW å³°å€¼åŠŸç‡ï¼Œè€Œ Rail-only å¯å‡å°‘ 37â€“75%ã€‚åŠŸè€—æŒ‡æ ‡å’Œæˆæœ¬ç±»ä¼¼ï¼Œä½“ç°è®¾è®¡çš„èƒ½æºæ•ˆç‡æå‡ï¼Œåœ¨å¤§è§„æ¨¡æ•°æ®ä¸­å¿ƒç¯å¢ƒä¸‹å…·æœ‰ç°å®æ„ä¹‰ï¼ˆåŠŸè€—é™ä½æ„å‘³ç€è¿è¥æˆæœ¬å’Œæ•£çƒ­å‹åŠ›çš„é™ä½ï¼‰ã€‚\né€šä¿¡å¼€é”€å æ¯”ï¼šé€šè¿‡è¿­ä»£æ—¶é—´ä¸­é€šä¿¡éƒ¨åˆ†æ‰€å æ¯”ä¾‹ï¼Œæˆ–All-to-all ç‰¹æ®Šé€šä¿¡çš„é¢å¤–å»¶è¿Ÿç™¾åˆ†æ¯”ç­‰æŒ‡æ ‡ï¼Œè¯„ä¼°ç½‘ç»œå¯¹è®­ç»ƒæ€§èƒ½çš„å½±å“ç¨‹åº¦ã€‚æ¯”å¦‚è®ºæ–‡æåˆ°åœ¨ MoE æ¨¡å‹åœºæ™¯ä¸‹ï¼ŒRail-only éœ€è¦é€šè¿‡è½¬å‘å®Œæˆ all-to-all å¯¼è‡´8.2â€“11.2% çš„è®­ç»ƒå»¶è¿Ÿå¢åŠ ï¼Œæ­¤æ•°å€¼å³æ˜¯ä¸€ä¸ªé€šä¿¡å¼€é”€å æ¯”æŒ‡æ ‡ã€‚å®ƒè¯´æ˜äº† Rail-only åœ¨å¤„ç†æç«¯å…¨è¿æ¥é€šä¿¡æ—¶çš„æ€§èƒ½ä»£ä»·ï¼Œç”¨äºè¯æ˜è¿™ç§ä»£ä»·åœ¨å¯æ¥å—èŒƒå›´ï¼ˆçº¦ä¸€æˆä»¥å†…ï¼‰ã€‚\n\näº”ã€ä¸»è¦å®éªŒå‘ç°\n\nLLM è®­ç»ƒé€šä¿¡æåº¦å±€éƒ¨åŒ–ï¼šå®éªŒé‡åŒ–æ˜¾ç¤ºï¼Œåœ¨åˆç†çš„ 3D å¹¶è¡Œç­–ç•¥ä¸‹ï¼Œ99% çš„ GPU å¯¹ä¹‹é—´ä»ä¸ç›´æ¥é€šä¿¡ï¼Œç»å¤§éƒ¨åˆ†é€šä¿¡é‡å‘ç”Ÿåœ¨å¾ˆå°çš„ GPU å­é›†å†…éƒ¨ã€ä¾‹å¦‚å¼ é‡å¹¶è¡Œç»„ã€‘ã€‚å¼ é‡å¹¶è¡Œç›¸å…³é€šä¿¡å æ®æ€»é€šä¿¡é‡çš„ 75%ä»¥ä¸Šï¼Œä¸”ä»…æ¶‰åŠä¸åˆ° 0.04% çš„å¯èƒ½ GPU å¯¹ã€‚è¿™è¯æ˜å…¨äº’è”ç½‘ç»œçš„å¤§éƒ¨åˆ†å¸¦å®½åœ¨ LLM è®­ç»ƒä¸­æ˜¯é—²ç½®çš„ã€‚\nå‰ªè£ç½‘ç»œæ‹“æ‰‘ä¸ä¼šé™ä½æ€§èƒ½ï¼šå°†é›†ç¾¤åˆ‡åˆ†ä¸ºé€‚å½“å¤§å°çš„ HB åŸŸå¹¶é‡‡ç”¨ Rail-only æ‹“æ‰‘åï¼Œè®­ç»ƒé€Ÿåº¦å‡ ä¹ä¸å˜ã€‚å¯¹äºä¸‡äº¿çº§å‚æ•°æ¨¡å‹ï¼ˆGPT-1Tï¼‰ï¼Œå½“ HB åŸŸè§„æ¨¡è¾¾åˆ° 32 æˆ– 256 æ—¶ï¼ŒRail-only ä¸ç†æƒ³ Clos ç½‘ç»œçš„æ¯æ­¥è¿­ä»£æ—¶é—´å·®å¼‚ä»… &lt;1%ã€‚æ¢è¨€ä¹‹ï¼Œå³ä½¿ç§»é™¤äº†å¤§é‡è·¨åŸŸè¿çº¿ï¼Œç¡¬ä»¶ç®—åŠ›åˆ©ç”¨ç‡ï¼ˆHFUï¼‰ä»ä¸å…¨è¿æ¥æ—¶æŒå¹³ï¼Œè¿™éªŒè¯äº†é€šä¿¡ç“¶é¢ˆå¹¶æœªæ¶åŒ–ã€‚\nHB åŸŸè§„æ¨¡å­˜åœ¨æœ€ä½³å€¼ï¼šå®éªŒå‘ç°ï¼Œå¢å¤§ HB åŸŸå†… GPU æ•°å¯ä»¥é™ä½è¿­ä»£æ—¶é—´ï¼Œä½†æ”¶ç›Šé€’å‡ã€‚å½“ HB åŸŸä»å¾ˆå°å¢åŠ æ—¶ï¼Œæ€§èƒ½æå‡æ˜¾è‘—ï¼ˆå› ä¸ºæ›´å¤šé€šä¿¡è½¬ç§»åˆ°åŸŸå†…é«˜é€Ÿé“¾è·¯ï¼‰ï¼›ä½†è¶…è¿‡ä¸€å®šè§„æ¨¡åï¼ˆå¦‚åŸŸå†… 32 å¡ä»¥ä¸Šï¼‰ï¼Œç»§ç»­æ‰©å¤§å¯¹æ•´ä½“è¿­ä»£æ—¶é—´çš„æ”¹å–„å˜å¾—å¾ˆå°ã€‚è¿™ä½“ç°äº†Amdahl å®šå¾‹æ•ˆåº”ï¼šé€šä¿¡ç“¶é¢ˆè¢«å‰Šå¼±åˆ°ä¸€å®šç¨‹åº¦åï¼Œå‰©ä½™çš„è®¡ç®—å ä¸»å¯¼ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–ç½‘ç»œæ”¶ç›Šæœ‰é™ã€‚\næå‡ NVLink å¸¦å®½æ¯”æå‡ä¸»å¹²å¸¦å®½æ›´æœ‰ä»·å€¼ï¼šé€šè¿‡å¯¹æ¯”ä¸åŒå¸¦å®½ç»„åˆï¼Œä½œè€…å‘ç°å¢åŠ  HB åŸŸå†…éƒ¨å¸¦å®½ï¼ˆå¦‚æ›´å¿«çš„ NVLink/NVSwitchï¼‰å¯¹é™ä½è¿­ä»£æ—¶é—´çš„æ•ˆæœå¤§äºç­‰é¢æé«˜è·¨åŸŸç½‘ç»œå¸¦å®½ã€‚è¿™æ˜¯å› ä¸ºå¤§éƒ¨åˆ†æ•°æ®ç»è¿‡åŸŸå†…äº¤æ¢ï¼ŒåŸŸå†…ç“¶é¢ˆæ”¹å–„èƒ½æ•´ä½“æé€Ÿï¼›è€Œè·¨åŸŸå¸¦å®½å³ä½¿ç•¥æ…¢ï¼Œå¯¹æ€»æ—¶é—´å½±å“ä¹Ÿå°ï¼ˆå‰ææ˜¯å·²ç»æŒ‰ Rail-only å‰Šå‡è·¨åŸŸé€šä¿¡é‡ï¼‰ã€‚\nå¤§ batch å¯ä»¥ç¼“è§£é€šä¿¡ç“¶é¢ˆï¼šéšç€å…¨å±€æ‰¹å¤§å°å¢å¤§ï¼ˆmicro-batch æ•°å¢åŠ ï¼‰ï¼Œé€šä¿¡å æ¯”ä¸‹é™ï¼Œä½¿ Rail-only ç›¸å¯¹äºç†æƒ³ç½‘ç»œçš„æ€§èƒ½å·®è·è¿›ä¸€æ­¥ç¼©å°ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨ HB åŸŸè¾ƒå°çš„ä¸åˆ©æƒ…å†µä¸‹ï¼ˆä¾‹å¦‚ä»…8å¡åŸŸï¼‰ï¼Œå°† batch ä» 256 å¢è‡³ 4096ï¼ŒRail-only æ€§èƒ½ä»ç›¸å½“äºç†æƒ³æƒ…å†µçš„ 65% æå‡åˆ° 85%ã€‚æ›´å¤§ batch æä¾›æ›´å¤šè®¡ç®—ä»¥éšè—é€šä¿¡ï¼Œä»å·¥ç¨‹å®è·µçœ‹ï¼Œå¦‚æœå—ç½‘ç»œé™åˆ¶ï¼Œå¯é€šè¿‡å¢å¤§ batch æˆ– gradient accumulation æ¥æé«˜ç¡¬ä»¶åˆ©ç”¨ç‡ã€‚\næˆæœ¬å’ŒåŠŸè€—å¤§å¹…ä¸‹é™ï¼šåœ¨ç›¸åŒè§„æ¨¡ï¼ˆä¾‹å¦‚ 30k GPUï¼‰çš„é›†ç¾¤ä¸‹ï¼ŒRail-only çœå»äº†æ‰€æœ‰ Spine/Core äº¤æ¢æœºï¼Œä»…ä¿ç•™æ¯æ¡ rail æ‰€éœ€çš„ ToRï¼ˆé¡¶å±‚æ±‡èšï¼‰äº¤æ¢æœºã€‚è®¡ç®—è¡¨æ˜ï¼Œè¿™å°†ç½‘ç»œæ‰€éœ€çš„äº¤æ¢èŠ¯ç‰‡æ•°é‡å‰Šå‡è¿‘ 50â€“70%ï¼Œå…‰æ¨¡å—ç­‰è¿çº¿é…ä»¶ä¹Ÿç›¸åº”å‡å°‘ï¼Œä¸€ä¸¾é™ä½çº¦ä¸‰åˆ†ä¹‹äºŒçš„ç½‘ç»œæ€»æˆæœ¬å’ŒåŠŸè€—ã€‚å¯¹äºå»ºè®¾è¶…å¤§ GPU é›†ç¾¤ï¼Œè¿™æ„å‘³ç€ä¸Šäº¿ç¾å…ƒçº§æˆæœ¬çš„èŠ‚çœå’Œæ•°å…†ç“¦çº§åŠŸè€—çš„é™ä½ï¼Œæ˜¯æå…¶æ˜¾è‘—çš„å·¥ç¨‹æ”¶ç›Šã€‚\n\n5.1 å…³é”®å›¾è¡¨è§£è¯»\n\nå›¾è¡¨1ï¼šè¿­ä»£æ—¶é—´ vs.Â HB åŸŸè§„æ¨¡ â€“ è®ºæ–‡é€šè¿‡æ›²çº¿å±•ç¤ºäº†ä¸åŒ HB åŸŸå¤§å°ä¸‹çš„è®­ç»ƒè¿­ä»£æ—¶é—´ï¼ˆæˆ–ç›¸å¯¹æ€§èƒ½ï¼‰ã€‚ç»“æœæ¸…æ™°è¡¨æ˜ï¼šéšç€ HB åŸŸä»å¾ˆå°å¢å¤§ï¼Œè¿­ä»£æ—¶é—´è¿…é€Ÿä¸‹é™æ¥è¿‘ç†æƒ³å€¼ï¼›å½“åŸŸå†… GPU æ•°è¾¾åˆ° 32 æˆ– 64 åï¼Œæ›²çº¿è¶‹äºå¹³ç¼“ï¼Œè¡¨ç¤ºå†æ‰©å¤§åŸŸè§„æ¨¡æ”¶ç›Šå˜å°ã€‚ä¾‹å¦‚ï¼Œå¯¹äº 1460äº¿å‚æ•°æ¨¡å‹ï¼ˆGPT-146Bï¼‰ï¼ŒHB åŸŸä»8å¢è‡³256ä½¿è¿­ä»£æ—¶é—´é™ä½çº¦ 43%ï¼Œæ¥è¿‘å…¨äº’è”æ€§èƒ½ï¼Œä»…æ¯”ç†æƒ³æƒ…å†µæ…¢ 4.1%ï¼›è€Œå¯¹æ›´å¤§çš„ GPT-1T æ¨¡å‹ï¼ŒåŒæ ·åŸŸè§„æ¨¡ä¸‹æ€§èƒ½å·®è·ä»… 0.9%ã€‚è¯¥å›¾ä½è¯äº†ä½œè€…çš„ä¸»å¼ ï¼šé€‰æ‹©é€‚å½“çš„ HB åŸŸå¤§å°å³å¯å®ç°æ¥è¿‘å…¨å¸¦å®½çš„æ€§èƒ½ï¼Œæ— éœ€æ•´ä¸ªé›†ç¾¤å…¨äº’è”ã€‚\nå›¾è¡¨2ï¼šHB åŸŸå¸¦å®½ vs.Â ä¸»å¹²å¸¦å®½çš„å½±å“ â€“ å¦ä¸€ç»„æ›²çº¿å¯¹æ¯”äº†åœ¨å°åŸŸï¼ˆå¦‚8å¡ï¼‰å’Œå¤§åŸŸï¼ˆ256å¡ï¼‰æƒ…å†µä¸‹ï¼Œæé«˜ NVLink å¸¦å®½æˆ–æé«˜ä»¥å¤ªç½‘å¸¦å®½å¯¹è¿­ä»£æ—¶é—´çš„ä½œç”¨ã€‚å¯ä»¥çœ‹åˆ°ï¼Œåœ¨å°åŸŸæƒ…å½¢ï¼ŒåŸŸå†…å¸¦å®½ç¿»å€å¸¦æ¥çš„åŠ é€Ÿæ˜æ˜¾ï¼ˆè¿­ä»£æ—¶é—´é™ä½ ~8%ï¼‰ï¼Œè€Œå¢åŠ ç½‘ç»œå¸¦å®½ä½œç”¨è¾ƒå°ï¼›åœ¨å¤§åŸŸæƒ…å½¢ä¸‹ï¼Œä¸¤è€…å½±å“éƒ½æ›´å°ï¼Œä½†æ€»ä½“ä¹Ÿæ˜¯åŸŸå†…å¸¦å®½æ•æ„Ÿæ€§æ›´é«˜ã€‚è¿™å¼ å›¾è¯æ˜äº†ä¼˜åŒ–åŸŸå†…é€šä¿¡ï¼ˆä¾‹å¦‚æœªæ¥ NVLink æé€Ÿï¼‰æ¯”æå‡æ•°æ®ä¸­å¿ƒç½‘ç»œæ›´é‡è¦â€”â€”å¯¹äº LLM è®­ç»ƒï¼ŒGPU å†…éƒ¨/æœºæ¶å†…é€šä¿¡æ‰æ˜¯ä¸»è¦ç“¶é¢ˆæ‰€åœ¨ã€‚\nå›¾è¡¨3ï¼šæ‰¹å¤§å°å¯¹æ€§èƒ½çš„å½±å“ â€“ ä½œè€…ç»˜åˆ¶äº†ä¸åŒå…¨å±€ batch å¤§å°ä¸‹ Rail-only ç½‘ç»œçš„è¿­ä»£æ—¶é—´å’Œç›¸å¯¹æ€§èƒ½å˜åŒ–è¶‹åŠ¿ã€‚å›¾ä¸­æ˜¾ç¤ºï¼šéš batch å¢å¤§ï¼Œè¿­ä»£æ€»æ—¶é—´ç•¥æœ‰å¢åŠ ï¼ˆå› ä¸ºéœ€è¦å¤„ç†æ›´å¤šæ ·æœ¬ï¼‰ï¼Œä½†ç›¸å¯¹æ€§èƒ½ç¨³æ­¥æå‡ï¼Œå°¤å…¶å¯¹å° HB åŸŸé…ç½®æå‡æ›´æ˜æ˜¾ã€‚ä¾‹å¦‚å½“ batch ä» 256 å¢è‡³ 4096 æ—¶ï¼ŒHB åŸŸä»…8å¡çš„é…ç½®ï¼Œå…¶ç›¸å¯¹æ€§èƒ½ä» 65% æé«˜åˆ° 85%ï¼Œè€Œå¤§å‹åŸŸé…ç½®æœ¬èº«å·²åœ¨90%ä»¥ä¸Šï¼Œæå‡å¹…åº¦è¾ƒå°ã€‚è¿™ä¸€å›¾è¡¨è¯´æ˜ï¼Œåœ¨é€šä¿¡å—é™çš„é…ç½®ä¸‹ï¼Œé€šè¿‡å¢å¤§æ‰¹æˆ–è€…ç´¯ç§¯æ¢¯åº¦å¯ä»¥å‡å°‘é€šä¿¡å¼€é”€å æ¯”ï¼Œä»è€Œç¼“è§£ç½‘ç»œç“¶é¢ˆã€‚\nè¡¨æ ¼ï¼šç½‘ç»œæ‹“æ‰‘æˆæœ¬æ¯”è¾ƒ â€“ è®ºæ–‡æä¾›äº†ä¸€å¼ è¡¨ï¼ˆæˆ–æ•°æ®ï¼‰ï¼Œåˆ—å‡ºåœ¨æ•°ä¸‡ GPU é›†ç¾¤ä¸­ï¼Œä¸åŒç½‘ç»œæ¶æ„éœ€è¦çš„äº¤æ¢æœºå’Œé«˜é€Ÿäº’è¿æ¨¡å—æ•°é‡ã€‚ä¾‹å¦‚ï¼Œå¯¹ 32768 GPU é›†ç¾¤ï¼šä¼ ç»Ÿå…¨éé˜»å¡ Clos ç½‘ç»œéœ€è¦ä¸Šåƒé¢—äº¤æ¢ ASICå’Œæˆç™¾ä¸Šåƒä¸ªå…‰æ¨¡å—ï¼Œè€Œ Rail-only ä»…éœ€ä¸ºæ¯æ¡ rail é…ç½®äº¤æ¢æœºï¼Œæ€»æ•°å¤§å‡ã€‚è¡¨ä¸­è®¡ç®—å‡º Rail-only åœ¨äº¤æ¢æœºæ•°é‡ä¸Šå‰Šå‡ 50%ä»¥ä¸Šï¼Œæ•´ä¸ªç½‘ç»œç¡¬ä»¶æˆæœ¬å‡å°‘çº¦ 38â€“76%ã€‚è¯¥è¡¨ç›´æ¥æ”¯æ’‘äº†æ ¸å¿ƒç»“è®ºä¹‹ä¸€ï¼šRail-only æå¤§é™ä½ç½‘ç»œåŸºç¡€è®¾æ–½æˆæœ¬ï¼Œå¹¶ä¸”è§„æ¨¡è¶Šå¤§ï¼ŒèŠ‚çœæ¯”ä¾‹è¶Šé«˜ã€‚\n\nç»“æœè§£è¯»ä¸è¾¹ç•Œ\nç»¼ä¸Šï¼Œè¿™äº›å®éªŒç»“æœæœ‰åŠ›åœ°æ”¯æ’‘äº†è®ºæ–‡çš„æ ¸å¿ƒç»“è®ºï¼šLLM è®­ç»ƒå¹¶ä¸éœ€è¦å…¨äº’è”ç½‘ç»œï¼Œé€šè¿‡ Rail-only ç»“æ„å¯ä»¥åœ¨æ€§èƒ½åŸºæœ¬ä¸å˜çš„æƒ…å†µä¸‹å‰Šå‡å¤§é‡ç½‘ç»œå¼€é”€ã€‚ç‰¹åˆ«æ˜¯é€šä¿¡æ¨¡å¼åˆ†æçš„ç»Ÿè®¡æ•°æ®å’Œè¿­ä»£æ—¶é—´æ¨¡å‹çš„éªŒè¯ï¼Œä½¿è®ºæ–­å…·æœ‰å®šé‡ä¾æ®ã€‚åœ¨å„ç§æ¨¡å‹å°ºå¯¸ã€æ‰¹å¤§å°ã€å¸¦å®½é…ç½®ä¸‹ï¼ŒRail-only éƒ½è¡¨ç°å‡ºæ¥è¿‘ç†æƒ³çš„æ€§èƒ½ï¼Œè¯´æ˜ä½œè€…çš„è®¾è®¡åœ¨ä¸»æµå¤§æ¨¡å‹è®­ç»ƒç¯å¢ƒä¸‹é€šç”¨ä¸”æœ‰æ•ˆã€‚\nç„¶è€Œï¼Œéœ€è¦æ³¨æ„çš„æ˜¯å®éªŒä»å­˜åœ¨ä¸€å®šè¾¹ç•Œå’Œå‡å®šï¼šé¦–å…ˆï¼Œå¤§éƒ¨åˆ†è¯„ä¼°æ˜¯åŸºäºæ¨¡å‹æ¨æ¼”å’Œæ¨¡æ‹Ÿï¼ˆä¾‹å¦‚æ ¹æ®å…¬å¼ç®— HFUã€è¿­ä»£æ—¶é—´ï¼‰ï¼Œå¹¶æ²¡æœ‰åœ¨çœŸå® 30k GPU é›†ç¾¤ä¸Šå…¨é¢å®æµ‹ï¼Œè¿™ç•™ä¸‹ä¸€å®šå®ç°ä¸Šçš„ä¸ç¡®å®šæ€§ã€‚å…¶æ¬¡ï¼Œå®éªŒä¸»è¦è¡¡é‡äº†å•ä¸€å¤§æ¨¡å‹ç‹¬å é›†ç¾¤çš„æƒ…å†µï¼Œæœªæ¶‰åŠå¤šä»»åŠ¡å¹¶å‘æˆ–é LLM ä»»åŠ¡çš„æ··è·‘åœºæ™¯ã€‚åœ¨å®é™…æ•°æ®ä¸­å¿ƒä¸­ï¼ŒåŒæ—¶è·‘ä¸åŒç±»å‹ä½œä¸šæ—¶ï¼ŒRail-only æ˜¯å¦çµæ´»ä¾ç„¶æœªçŸ¥ã€‚å¦å¤–ï¼Œä½œè€…å‡å®šçš„é”™è¯¯æ¢å¤æ–¹æ¡ˆï¼ˆå…‰å¼€å…³é‡æ„ï¼‰åœ¨å®éªŒä¸­ç¼ºä¹é‡åŒ–éªŒè¯ï¼Œå…¶å¤æ‚æ€§å’Œå¯é æ€§éœ€è¦è¿›ä¸€æ­¥ç ”ç©¶ã€‚ä¸‹é¢åˆ—å‡ºè‹¥å¹²æœªå®Œå…¨è¦†ç›–çš„å®éªŒç»´åº¦å’Œå¯èƒ½çš„å½±å“å› ç´ ï¼š\n\nä¸åŒå¹¶è¡Œç­–ç•¥ä¸‹çš„æ€§èƒ½ï¼šè®ºæ–‡é›†ä¸­äº PTD-P å¹¶è¡Œï¼Œå¦‚æœé‡‡ç”¨å…¶å®ƒå¹¶è¡Œç»„åˆï¼ˆå¦‚æ›´å¤šå±‚æ•°æ®å¹¶è¡Œã€æˆ–å¯ç”¨æ–°çš„ MoE å¹¶è¡Œæ¨¡å¼ï¼‰ï¼Œé€šä¿¡å½¢æ€å¯èƒ½å˜åŒ–ï¼›\nå·¥ä½œè´Ÿè½½å˜åŒ–ï¼šå¦‚æœè®­ç»ƒè¿‡ç¨‹ä¸­é€šä¿¡æ¨¡å¼å‘ç”Ÿå˜åŒ–ï¼ˆå¦‚æ··åˆæ¨¡å‹æˆ–é˜¶æ®µæ€§é€šä¿¡é«˜å³°ï¼‰ï¼ŒRail-only é™æ€æ‹“æ‰‘å¯èƒ½æ— æ³•è‡ªé€‚åº”ï¼›\nè°ƒåº¦ä¸å¤šç§Ÿæˆ·ï¼šå½“é›†ç¾¤è¢«å¤šä¸ªä½œä¸šå…±äº«æ—¶ï¼ŒRails å¯èƒ½åœ¨ä¸åŒä½œä¸šé—´æ‹†åˆ†ï¼Œè®ºæ–‡æœªæ¢è®¨æ­¤å¯¹ç½‘ç»œæ•ˆç‡çš„å½±å“ï¼›\nç½‘ç»œåè®®å¼€é”€ï¼šä¾‹å¦‚ RDMA çš„æ‹¥å¡æ§åˆ¶ã€PFC æµæ§åœ¨ Rail-only ç¯å¢ƒä¸‹æ˜¯å¦æ”¹å–„ï¼ˆä½œè€…å®£ç§°å¯é¿å… PFC stormï¼Œä½†æœªæä¾›è¯¦ç»†å®éªŒï¼‰ã€‚\n\nå…­ã€ä¼˜ç‚¹ä¸å±€é™\näº®ç‚¹ï¼ˆStrengthsï¼‰\n\né—®é¢˜åˆ‡ä¸­ç°å®ç—›ç‚¹ï¼šè®ºæ–‡èšç„¦äºä¸‡äº¿å‚æ•° LLM è®­ç»ƒçš„ç½‘ç»œæ‰©å±•ç“¶é¢ˆï¼Œè¿™æ˜¯å½“å‰è¶…å¤§è§„æ¨¡ AI åŸºç¡€è®¾æ–½ä¸­çš„å®é™…éš¾é¢˜ã€‚ä½œè€…é€šè¿‡æ•°æ®è¯æ˜äº†å…¨äº’è”æ¶æ„çš„æµªè´¹ï¼Œé€‰é¢˜éå¸¸æœ‰å·¥ç¨‹ä»·å€¼ã€‚\nå¤§èƒ†åˆ›æ–°çš„æ‹“æ‰‘è®¾è®¡ï¼šæå‡º Rail-only è¿™æ ·é¢ è¦†ä¼ ç»Ÿçš„ç½‘ç»œæ¶æ„ï¼Œæ‰“ç ´æ•°åå¹´æ¥â€œå¿…é¡»å…¨äº’è”â€çš„æ€ç»´å®šå¼ã€‚æ–¹æ³•ä¸Šåˆ©ç”¨é€šä¿¡å±€éƒ¨æ€§è£å‰ªç½‘ç»œï¼Œæ€è·¯æ–°é¢–ä¸”ç›´å‡»æˆæœ¬é—®é¢˜ï¼Œåœ¨åŒè¡Œå·¥ä½œä¸­å±è¾ƒå¤§èƒ†çš„æ¶æ„åˆ›æ–°ã€‚\nç†è®ºåˆ†æä¸å·¥ç¨‹å®è·µå¹¶é‡ï¼šä½œè€…æ—¢ç»™å‡ºäº†è§£ææ¨¡å‹æ¨å¯¼æ€§èƒ½ï¼Œåˆç»“åˆå®é™…å‚æ•°ç®—å‡ºäº†æˆæœ¬ã€åŠŸè€—ç­‰æŒ‡æ ‡ï¼Œå¹³è¡¡äº†ç†è®ºä¸¥è°¨æ€§å’Œå·¥ç¨‹å®ç”¨æ€§ã€‚è¿™ç§å®šé‡åˆ†æä½¿ç»“è®ºæ›´ä»¤äººä¿¡æœï¼Œä¸ºå®è·µéƒ¨ç½²æä¾›äº†æŒ‡å¯¼æ•°æ®ã€‚\nå®éªŒè®¾è®¡è¦†ç›–é¢å¹¿ï¼šè¯„ä¼°éƒ¨åˆ†è€ƒå¯Ÿäº†æ¨¡å‹è§„æ¨¡ã€HB åŸŸå¤§å°ã€å¸¦å®½ã€æ‰¹å¤§å°ç­‰å¤šä¸ªç»´åº¦ï¼Œå¯¹ Rail-only çš„æ€§èƒ½å½±å“è¿›è¡Œå…¨é¢æ‰«æã€‚å°¤å…¶æ˜¯æ¨¡æ‹Ÿäº†ä¸‡äº¿å‚æ•°æ¨¡å‹åœ¨3ä¸‡+ GPUä¸Šçš„è¡¨ç°ï¼Œå¹¶éªŒè¯äº†MoEç‰¹æ®Šåœºæ™¯ï¼Œè¯´æ˜æ–¹æ³•é€‚ç”¨èŒƒå›´å¹¿ä¸”ä½œè€…æœ‰æ„è¯†æ£€æŸ¥æç«¯æƒ…å†µã€‚\nå†™ä½œæ¸…æ™°ã€ç»“æ„åˆç†ï¼šè®ºæ–‡ç»“æ„å¾ªåºæ¸è¿›ï¼Œä»èƒŒæ™¯-&gt;æ¨¡å¼åˆ†æ-&gt;è®¾è®¡-&gt;æ¨¡å‹-&gt;å®éªŒ-&gt;å¯¹æ¯”ï¼Œé€»è¾‘æ¸…æ™°ã€‚è´¡çŒ®ç‚¹æ€»ç»“æ˜ç¡®ï¼ˆä¸‰å¤§è´¡çŒ®å±‚æ¬¡æ¸…æ¥šï¼‰ï¼Œå›¾è¡¨è¾…åŠ©åˆ°ä½ï¼Œä½¿è¯»è€…æ˜“äºç†è§£å¤æ‚çš„ç³»ç»Ÿè®¾è®¡ç†å¿µã€‚è¿™å¯¹äºç³»ç»Ÿæ¶æ„è®ºæ–‡æ¥è¯´æ˜¯éš¾å¾—çš„äº®ç‚¹ã€‚\n\nå±€é™ï¼ˆLimitationsï¼‰\n\nå¹¶è¡Œç­–ç•¥ä¾èµ–ï¼šæ–¹æ¡ˆå¼ºä¾èµ–é‡‡ç”¨â€œæœ€ä½³å¹¶è¡Œåˆ’åˆ†â€æ‰èƒ½å‘æŒ¥ä½œç”¨ï¼Œå‡å¦‚æ¨¡å‹æˆ–æ¡†æ¶ä½¿ç”¨äº†éå…¸å‹å¹¶è¡Œæ¨¡å¼ï¼ˆä¾‹å¦‚æŸäº›å¼‚æ„å¹¶è¡Œã€æˆ–æœªæ¥æ–°çš„å¹¶è¡Œç®—æ³•ï¼‰ï¼Œé€šä¿¡æ¨¡å¼å¯èƒ½ä¸ç¬¦åˆä½œè€…å‡è®¾ï¼ŒRail-only æ•ˆæœä¼šæ‰“æŠ˜ã€‚è¿™ä¸€ç‚¹åœ¨è®ºæ–‡ä¸­å‡è®¾PTD-Pæœ€ä½³ï¼Œä½†å¯¹åç¦»æƒ…å†µç¼ºå°‘è®¨è®ºã€‚\nå¯¹éè®­ç»ƒæµé‡æ”¯æŒæœ‰é™ï¼šRail-only ä¸“ä¸ºè®­ç»ƒä¼˜åŒ–ï¼Œç¼ºå°‘å¯¹é€šç”¨é€šä¿¡çš„çµæ´»æ”¯æŒã€‚æ•°æ®ä¸­å¿ƒç»å¸¸éœ€è¦å¤„ç†æ§åˆ¶æµæ¶ˆæ¯ã€å­˜å‚¨é€šä¿¡ç”šè‡³å¤šç§Ÿæˆ·ä½œä¸šæ··éƒ¨ï¼Œå®Œå…¨åˆ‡æ–­ rails é—´è¿æ¥å¯èƒ½å¯¼è‡´è¿ç»´å¤æ‚ï¼ˆéœ€è¦äººå·¥é…ç½®è½¬å‘è·¯å¾„ï¼‰æˆ–æ€§èƒ½éšæ‚£ã€‚è®ºæ–‡å¯¹è¿™ä¸€é€šç”¨æ€§é—®é¢˜ä»…ç®€è¦æåŠç»•è¡Œï¼Œç¼ºå°‘æ›´æ™®é€‚çš„è§£å†³æ–¹æ¡ˆã€‚\nç¼ºä¹å¤§è§„æ¨¡å®è¯ï¼šè™½ç„¶ä½œè€…é€šè¿‡è§£ææ¨¡å‹éªŒè¯äº†æƒ³æ³•ï¼Œä½†å¹¶æœªå±•ç¤ºå®é™…å¤§è§„æ¨¡é›†ç¾¤ä¸Šçš„æµ‹é‡æ•°æ®ï¼ˆå¯èƒ½ç”±äºå®¢è§‚æ¡ä»¶é™åˆ¶ï¼‰ã€‚æ•´ä¸ªè¯„ä¼°ä¸»è¦åŸºäºç†è®ºè®¡ç®—å’Œå¼•ç”¨ä»–äººå®éªŒæ•°æ®ï¼Œå¯¹å®é™…éƒ¨ç½²ä¸­çš„æœªçŸ¥é—®é¢˜ï¼ˆå¦‚ç½‘ç»œè·¯ç”±ç®—æ³•ã€æ‹¥å¡è¡Œä¸ºã€æ•…éšœç‡ï¼‰å¯èƒ½è€ƒè™‘ä¸å……åˆ†ã€‚è¿™è®©è¯»è€…å¯¹ Rail-only åœ¨çœŸå®ç¯å¢ƒä¸­çš„å¯æ“ä½œæ€§å’Œæ•ˆæœå¿ƒé‡Œæ²¡è°±ã€‚\nå®¹é”™æ–¹æ¡ˆå¤æ‚ä¸”ä»£ä»·æœªé‡åŒ–ï¼šè®ºæ–‡æå‡ºç”¨å…‰å¯é‡æ„å¼€å…³æ¥è§£å†³å• GPU æ•…éšœçš„é—®é¢˜ï¼Œä½†è¿™ç§æ–¹æ¡ˆåœ¨å®é™…å®ç°ä¸Šå¤æ‚ä¸”æ˜‚è´µï¼Œä¸”å¯èƒ½å¼•å…¥æ–°çš„å»¶è¿Ÿã€‚ä½œè€…æ²¡æœ‰é‡åŒ–å…‰åˆ‡æ¢å¯¹è®­ç»ƒçš„å½±å“ï¼Œä¹Ÿæ²¡æœ‰è®¨è®ºåœ¨æ›´é¢‘ç¹æ•…éšœæ—¶æ˜¯å¦å¯è¡Œã€‚å®¹é”™éƒ¨åˆ†è™½æœ‰æ€è·¯ä½†æ˜¾å¾—ä¸å¤Ÿå®ç”¨æˆ–ç¼ºå°‘å®è¯ï¼Œä½¿æ–¹æ¡ˆåœ¨å¯é æ€§æ–¹é¢ç•¥æ˜¾è–„å¼±ã€‚\nä¸ç°æœ‰ç”Ÿæ€é›†æˆçš„æŒ‘æˆ˜ï¼šRail-only éœ€è¦è®­ç»ƒæ¡†æ¶å’Œé›†ç¾¤è°ƒåº¦å¯¹æ‹“æ‰‘é«˜åº¦æ„ŸçŸ¥ã€‚è¿™æ„å‘³ç€å¯¹ Megatron-LMã€DeepSpeed ç­‰è½¯ç¡¬ä»¶æ ˆåšæ”¹åŠ¨ï¼Œè€Œè®ºæ–‡æ²¡æœ‰æ·±å…¥è®¨è®ºå®ç°ç»†èŠ‚ã€‚ä¾‹å¦‚ NCCL/RDMA å¦‚ä½•é€‚é…ã€é›†ç¾¤ç®¡ç†å¦‚ä½•åˆ†é… railï¼Œè¿™äº›å·¥ç¨‹é—®é¢˜æ½œåœ¨å·¥ä½œé‡å¤§ï¼Œæ˜¯æ–¹æ¡ˆè½åœ°çš„é£é™©ç‚¹ï¼Œä½†æ–‡ç« é‡Œç€å¢¨è¾ƒå°‘ã€‚\nç»“è®ºé€‚ç”¨èŒƒå›´çš„éšå«å‰æï¼šè®ºæ–‡å¼ºè°ƒä½æˆæœ¬å’Œæ— æ€§èƒ½æŸå¤±ï¼Œä½†è¿™ä¸€ç»“è®ºå»ºç«‹åœ¨ä¸€äº›éšå«å‰æä¸Šï¼ˆå¦‚è¶³å¤Ÿå¤§çš„ HB åŸŸã€æœ‰é—²ç½® GPU å¤‡ç”¨ã€LLM æ¨¡å‹ç»“æ„å‡åŒ€ç­‰ï¼‰ã€‚å¯¹äºä¸€äº›è¾¹ç¼˜æƒ…å†µï¼ˆæ¯”å¦‚é«˜åº¦éå‡åŒ€çš„æ¨¡å‹ã€éœ€è¦åŠ¨æ€æ‰©å±•çš„åœºæ™¯ï¼‰ï¼ŒRail-only æ˜¯å¦è¿˜èƒ½ä¿æŒä¼˜åŠ¿å­˜ç–‘ã€‚æ–‡ç« æœ¬èº«å¯¹è¿™äº›é™åˆ¶çš„æªè¾è¾ƒä¸ºä¹è§‚ï¼Œå¯èƒ½è®©è¯»è€…å¿½ç•¥å®é™…éƒ¨ç½²éœ€è°¨æ…æƒè¡¡çš„åœ°æ–¹ã€‚\n\nä¸ƒã€ä¸šå†…ç›¸å…³å·¥ä½œå¯¹æ¯”\n\nHammingMeshï¼ˆSC 2022ï¼‰ â€“ é—®é¢˜èšç„¦ï¼š é’ˆå¯¹å¤§è§„æ¨¡æ·±åº¦å­¦ä¹ é€šä¿¡ï¼Œç‰¹åˆ«æ˜¯All-Reduce ç­‰å…¨å±€é€šä¿¡çš„æˆæœ¬ï¼Œæå‡ºä¸€ç§æ–°çš„æ‹“æ‰‘ HammingMeshã€‚è¯¥æ‹“æ‰‘å°† GPU é›†ç¾¤è§†ä¸º2Dç½‘æ ¼ï¼Œæ¯ä¸ªæœ¬åœ°é«˜é€Ÿç½‘æ ¼é€šè¿‡è¡Œ/åˆ—äº¤æ¢æœºè¿æ¥å…¶å®ƒç½‘æ ¼ï¼Œç›¸å½“äºå±€éƒ¨å…¨è¿+å±€éƒ¨äº’è”çš„æ··åˆã€‚æ–¹æ³•è·¯çº¿ï¼š HammingMesh ä¸ Rail-only ç±»ä¼¼ï¼Œéƒ½åŸºäºâ€œå±€éƒ¨é«˜å¸¦å®½ + è·¨èŠ‚ç‚¹æœ‰é™è¿æ¥â€çš„æ€æƒ³ï¼Œä½† HammingMesh è®¾è®¡äº†è¡Œåˆ—äº¤ç»‡çš„ç½‘ç»œç»“æ„ï¼Œæä¾›æ¯”Rail-onlyæ›´æ™®éçš„è¿æ¥ï¼ˆå¯æ”¯æŒä¸€å®šèŒƒå›´çš„ä»»æ„é€šä¿¡ï¼‰ï¼ŒåŒæ—¶æˆæœ¬è¿œä½äºClosï¼ˆæ®ç§°å¯ä¾¿å®œ10å€ä»¥ä¸Šï¼‰ã€‚äº’è¡¥å…³ç³»ï¼š HammingMesh å¯ä»¥çœ‹ä½œ Rail-only çš„ç«äº‰æ–¹æ¡ˆï¼Œæä¾›äº†æ›´å¼ºçš„é€šä¿¡çµæ´»æ€§ä½†ä¹Ÿæ›´å¤æ‚ã€‚ä¸¤è€…åœ¨æ€æƒ³ä¸Šæœ‰å…±é€šç‚¹ï¼ˆåˆ©ç”¨è®­ç»ƒæµé‡æ¨¡å¼ï¼‰ï¼Œå¯ä»¥ç»„åˆçš„å¯èƒ½æ€§ä¸å¤§ï¼Œæ›´å¤šæ˜¯ä¸åŒæ‹“æ‰‘å–èˆçš„å¯¹æ¯”ã€‚è´¡çŒ®å®ç”¨ä»·å€¼ï¼š HammingMesh åœ¨éœ€è¦ä¸€å®šä»»æ„é€šä¿¡çš„ç¯å¢ƒä¸‹æ›´é€‚ç”¨ï¼Œè€Œ Rail-only é’ˆå¯¹å¼ºç¡®å®šæ¨¡å¼æ›´æè‡´çœæˆæœ¬ã€‚ä»å®ç”¨è§’åº¦ï¼ŒRail-only å®ç°æ›´ç®€å•ï¼ˆç§»é™¤ Spine å³å¯ï¼‰ï¼Œè€Œ HammingMesh éœ€è¦ä¸“é—¨çš„ç½‘ç»œå¸ƒçº¿ï¼Œä½†é•¿è¿œçœ‹ HammingMesh æä¾›è°ƒåº¦çµæ´»æ€§ï¼Œé€‚åˆå¤šä»»åŠ¡é›†ç¾¤ã€‚æ€»ä½“è€Œè¨€ï¼ŒHammingMesh çš„æ½œåœ¨ä»·å€¼åœ¨äºæˆæœ¬å’Œæ€§èƒ½æŠ˜ä¸­æ›´ä¼˜ï¼Œä½†å®ç°å¤æ‚åº¦ä¹Ÿæ›´é«˜ã€‚\nAlibaba HPNï¼ˆATC 2023ï¼‰ â€“ é—®é¢˜èšç„¦ï¼š é˜¿é‡Œäº‘ä¸ºå…¶ 15000+ GPU è®­ç»ƒé›†ç¾¤è®¾è®¡çš„ä¸“ç”¨ç½‘ç»œ HPNï¼Œå…³æ³¨å¤§è§„æ¨¡ LLM é›†ç¾¤çš„å»¶è¿Ÿä¸ç¨³å®šæ€§ç“¶é¢ˆã€‚æ–¹æ³•è·¯çº¿ï¼š HPN é‡‡ç”¨ä¸¤å±‚åŒå¹³é¢æ¶æ„ï¼šä»¥ Dual-ToRï¼ˆåŒé¡¶çº§äº¤æ¢æœºï¼‰+ äºŒçº§ spine å–ä»£ä¼ ç»Ÿä¸‰çº§ Closï¼Œæ¯ä¸ªæœºæ¶åŒå¹³é¢æ‹†åˆ†ä¸åŒæµé‡ï¼Œç­‰æ•ˆæä¾›éƒ¨åˆ†å†—ä½™å’Œéš”ç¦»ã€‚å®ƒæ²¡æœ‰å®Œå…¨ç æ‰ spineï¼Œè€Œæ˜¯é€šè¿‡åŒå¹³é¢å„è‡ªæœåŠ¡ä¸åŒé€šä¿¡æ¨¡å¼ï¼ˆä¾‹å¦‚ä¸€è·¯ä¾§é‡è®­ç»ƒæ•°æ®æµï¼Œä¸€è·¯ä¾§é‡å‚æ•°åŒæ­¥ï¼‰ï¼Œé™ä½æ‹¥å¡å’Œ PFC é£é™©ã€‚å¯¹æ¯”å…³ç³»ï¼š å’Œ Rail-only ç›¸æ¯”ï¼ŒHPN å±äºæ”¹è‰¯ Closï¼Œä»ä¿æŒä»»æ„é€šä¿¡èƒ½åŠ›ï¼Œä½†é€šè¿‡å·¥ç¨‹ä¼˜åŒ–å®ç°è¿‘ä¼¼ Rail ä¼˜åŒ–æ•ˆæœï¼ˆä¾‹å¦‚å…¸å‹é€šä¿¡å„èµ°å›ºå®šå¹³é¢ï¼‰ã€‚HPN å’Œ Rail-only å¯è°“æ€è·¯ä¸åŒï¼šå‰è€…å…¼é¡¾é€šç”¨æ€§ï¼Œåè€…æè‡´ä¸“ç”¨åŒ–ã€‚è´¡çŒ®å®ç”¨ä»·å€¼ï¼š HPN å·²åœ¨é˜¿é‡Œç”Ÿäº§ç¯å¢ƒè½åœ°ï¼Œè¯æ˜äº†éƒ¨åˆ†å‰Šå‡äº’è”çš„å¯è¡Œæ€§ï¼Œå…¶äº®ç‚¹æ˜¯å·¥ç¨‹ç¨³å¥ï¼ˆä¸æ”¹å˜åŸºæœ¬ Clos åŸåˆ™ï¼Œæ–¹ä¾¿éƒ¨ç½²ï¼‰ã€‚ä½†æˆæœ¬ä¸Š HPN ç›¸æ¯” Rail-only èŠ‚çœæœ‰é™ï¼ˆä»ä¿ç•™åŒå¹³é¢ï¼‰ï¼Œæ€§èƒ½éå¸¸ä¾èµ–ç»†è‡´è°ƒä¼˜ã€‚ç»¼åˆçœ‹æ¥ï¼Œå¯¹äºè¿½æ±‚ç¨³å¦¥éƒ¨ç½²çš„å¤§å‚é›†ç¾¤ï¼ŒHPN æ˜¯ç°å®æ–¹æ¡ˆï¼›è€Œ Rail-only åœ¨æ›´æç«¯è¿½æ±‚æˆæœ¬çš„åœºæ™¯ä¸‹ä»·å€¼çªå‡ºã€‚\nMegaScale (ByteDance, arXiv 2023) â€“ é—®é¢˜èšç„¦ï¼š æ¢ç´¢å°† LLM è®­ç»ƒæ‰©å±•åˆ°ä¸‡çº§ GPUçš„æ–¹æ³•ï¼Œå…¨æ–¹ä½è¦†ç›–æ•°æ®ã€å¹¶è¡Œã€å­˜å‚¨ç­‰æŒ‘æˆ˜ã€‚æ–¹æ³•è·¯çº¿ï¼š å¹¶æœªå¼•å…¥å…¨æ–°æ‹“æ‰‘ï¼Œè€Œæ˜¯é‡‡ç”¨ä¸‰å±‚åˆ†çº§ Closç½‘ç»œå¹¶ç»“åˆrail ä¼˜åŒ–æ€æƒ³ï¼ˆByteDance æ®æŠ¥é“ä½¿ç”¨äº†ä¸‰å±‚ fat-treeï¼Œéƒ¨åˆ† rail grouping ä»¥å‡å°æ¨ªå‘é€šä¿¡ï¼‰ã€‚MegaScale æ›´å¼ºè°ƒè½¯ç¡¬ä»¶ååŒï¼Œå¦‚ä¼˜åŒ–é€šä¿¡è°ƒåº¦ã€æ”¹è¿›æ¡†æ¶æ”¯æŒï¼Œé…åˆç¡¬ä»¶ä¸Šé€‚åº¦è¿‡è®¢é˜…ç½‘ç»œã€‚ä¸ Rail-only çš„å…³ç³»ï¼š MegaScale çš„ç½‘ç»œç­–ç•¥å¯è§†ä¸º Rail-only çš„å‰èº«æˆ–ä¿å®ˆç‰ˆæœ¬ï¼šä»–ä»¬è®¤è¯†åˆ°LLM é€šä¿¡å±€éƒ¨æ€§ï¼Œä½†é€‰æ‹©é€šè¿‡åˆ†å±‚è°ƒåº¦å’Œç°æœ‰ç½‘ç»œè°ƒæ•´æ¥åº”å¯¹ï¼Œæ²¡æœ‰å¤§åˆ€é˜”æ–§ç æ‰æ ¸å¿ƒäº¤æ¢æœºã€‚ä¸¤è€…å¯ç»„åˆâ€”â€”æœªæ¥ByteDanceè¿™ç±»é›†ç¾¤æˆ–å¯å°è¯•Rail-onlyè¿›ä¸€æ­¥é™æœ¬ã€‚è´¡çŒ®ä¸å®ç”¨ä»·å€¼ï¼š MegaScale ä½“ç°çš„ä»·å€¼åœ¨äºå®é™…ç»éªŒï¼šåœ¨çœŸå® 1 ä¸‡+ GPU ç³»ç»Ÿä¸Šè·‘é€šäº† GPT-ç±»æ¨¡å‹ï¼Œè¯æ˜äº†ä¸€äº›ä¼˜åŒ–çš„æœ‰æ•ˆæ€§ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒRail-only æ›´åƒä¸€ä¸ªå‰ç»æ€§ææ¡ˆã€‚æŒ‰å®ç”¨æ’åºï¼ŒMegaScale çš„æ–¹æ³•çŸ­æœŸæ˜“ç”¨ä½†èŠ‚çœæœ‰é™ï¼ŒRail-only åˆ™æ½œåŠ›å¤§ä½†éœ€æ›´å¤šéªŒè¯ã€‚\n\n7.1 ä¸ªäººè§‚ç‚¹\né€šè¯»è®ºæ–‡ï¼Œæˆ‘å¯¹å…¶è®ºè¯æ–¹å¼å’Œå®éªŒæœ‰ä»¥ä¸‹çœ‹æ³•ï¼š\né¦–å…ˆï¼Œåœ¨ baseline é€‰æ‹© ä¸Šï¼Œä½œè€…å°† Rail-only ä¸ç†æƒ³å…¨äº’è” Clos åšå¯¹æ¯”ï¼Œè¯æ˜æˆæœ¬å¤§é™ä¸”æ€§èƒ½æ— æŸã€‚ä½†æˆ‘è®¤ä¸ºç¨æ˜¾ä¸è¶³çš„æ˜¯ï¼Œæ²¡æœ‰æ¯”è¾ƒä¸­é—´æŠ˜è¡·æ–¹æ¡ˆã€‚ç°å®ä¸­å¾ˆå¤šé›†ç¾¤é‡‡ç”¨ 2:1 æˆ– 4:1 è¿‡è®¢é˜… Clos æ¥çœæˆæœ¬ï¼Œå¦‚æœèƒ½å¢åŠ ä¸€ç»„â€œè¿‡è®¢é˜…Closâ€çš„åŸºçº¿ï¼Œå±•ç¤º Rail-only åœ¨ç›¸åŒæ€§èƒ½ä¸‹æˆæœ¬ä¼˜åŠ¿æ›´æ˜æ˜¾ï¼Œè®ºè¯ä¼šæ›´å…¨é¢ã€‚æ­¤å¤–ï¼Œè¯„ä¼°ä¸­è™½ç„¶æåˆ°äº† MoE all-to-all çš„ overheadï¼Œä½†ç¼ºå°‘å®é™… MoE æ¨¡å‹è®­ç»ƒçš„æ•´ä½“æ€§èƒ½æ•°æ®ã€‚å¦‚æœèƒ½è¡¥å……ä¸€ä¸ª MoE æ¨¡å‹åœ¨ Rail-only vs Clos ä¸Šçš„ç«¯åˆ°ç«¯è®­ç»ƒå¯¹æ¯”ï¼ˆä¾‹å¦‚æ”¶æ•›æ—¶é—´éšç½‘ç»œçš„å˜åŒ–ï¼‰ï¼Œä¼šä½¿ä¸»å¼ æ›´å…·è¯´æœåŠ›ã€‚\nåœ¨ å®éªŒè®¾ç½® ä¸Šï¼Œä½œè€…ä¸»è¦ä¾èµ–è§£ææ¨¡å‹æ¨æ–­æ€§èƒ½ã€‚æˆ‘è§‰å¾—åº”å½“å°½å¯èƒ½å¼•å…¥å°è§„æ¨¡åŸå‹å®éªŒæ¥æ”¯æ’‘ã€‚ä¾‹å¦‚ï¼Œå¯ä»¥åœ¨ 2 ä¸ªæœºæ¶ä¸Šæ¨¡æ‹Ÿ Rail-onlyï¼ˆæ‰‹åŠ¨ç¦ç”¨è·¨æœºæ¶è¿æ¥ï¼Œä»…è®©å›ºå®šGPUå¯¹é€šä¿¡ï¼‰æ¥è§‚å¯Ÿ throughput å˜åŒ–ã€‚æœ‰ä¸€äº›å®é™…ç½‘ç»œå› ç´ ï¼ˆè·¯ç”±ç®—æ³•ã€åè®®å¼€é”€ï¼‰è§£ææ¨¡å‹å¯èƒ½æ²¡æ•æ‰ï¼Œå¦‚æœæ²¡æœ‰ç‰©ç†å®éªŒéªŒè¯ï¼Œç»“è®ºéš¾å…æœ‰ç†æƒ³åŒ–ä¹‹å«Œã€‚è‹¥ç”±æˆ‘è®¾è®¡ï¼Œæˆ‘ä¼šäº‰å–åœ¨ç°æœ‰é›†ç¾¤ä¸Šåšä¸ª 8æœº vs 8æœº å¯¹æ¯”å®éªŒï¼šä¸€ç§ç”¨å®Œæ•´ç½‘ç»œè®­ç»ƒï¼Œå¦ä¸€ç§é€šè¿‡ç½‘ç»œé…ç½®é™åˆ¶é€šä¿¡è·¯å¾„ï¼Œçœ‹çœ‹æ€§èƒ½å·®å¼‚æ˜¯å¦çœŸå¦‚æ¨¡å‹é¢„æµ‹çš„ ~0%ã€‚å“ªæ€•è§„æ¨¡å°ï¼Œä¹Ÿèƒ½å¢åŠ è®ºæ®çš„å¯ä¿¡åº¦ã€‚\næœ€åï¼Œåœ¨ ç»“è®ºè¡¨è¿° ä¸Šï¼Œè®ºæ–‡å€¾å‘å¼ºè°ƒ Rail-only â€œç«‹å³å¯éƒ¨ç½²â€â€œä¸ç‰ºç‰²æ€§èƒ½â€ã€‚ä½œä¸ºå·¥ç¨‹å¸ˆï¼Œæˆ‘è®¤å¯å…¶å·¨å¤§æ½œåŠ›ï¼Œä½†ä¹Ÿå¯Ÿè§‰åˆ°ä¸€äº›å®ç°ç»†èŠ‚æŒ‘æˆ˜ã€‚è‹¥è®©æˆ‘å®Œå–„ï¼Œæˆ‘ä¼šåœ¨ç»“è®ºé‡Œå¤šä¸€åˆ†ä¿å®ˆï¼Œä¾‹å¦‚æé†’è¯»è€…éƒ¨ç½²Rail-onlyéœ€ç¡®ä¿å¹¶è¡Œè½¯ä»¶æ ˆé…åˆã€å¯¹ç½‘ç»œæ•…éšœæœ‰é¢„æ¡ˆç­‰ã€‚è¿™ä¸æ˜¯è‹›æ±‚è®ºæ–‡ï¼Œè€Œæ˜¯ä¸ºäº†è®©ä¸šç•Œé‡‡ç”¨æ—¶æœ‰æ›´æ¸…æ™°çš„é¢„æœŸå’ŒæŒ‡å¯¼ã€‚æˆ‘éå¸¸èµèµä½œè€…å¼€åˆ›æ€§çš„æ€è·¯ï¼ŒåŒæ—¶è®¤ä¸ºåç»­å·¥ä½œå¯ä»¥è¡¥è¶³å®ç°å’Œå¤šæ ·åŒ–åœºæ™¯çš„éªŒè¯ï¼Œä½¿è¿™é¡¹æŠ€æœ¯çœŸæ­£æˆç†Ÿè½åœ°ã€‚\nå…«ã€åœ¨å®é™…è®­ç»ƒæ ˆä¸­å¦‚ä½•è½åœ°ï¼Ÿ\nè¦å°† Rail-only æ–¹æ³•å¼•å…¥ç°æœ‰å¤§è§„æ¨¡è®­ç»ƒæ ˆï¼ˆä¾‹å¦‚ Megatron-LMã€DeepSpeed ç­‰é€šç”¨æ¡†æ¶ï¼‰ï¼Œéœ€è¦åœ¨å¤šä¸ªå±‚é¢å¯¹æ¥æ”¹åŠ¨ï¼š\n\næ•°æ®åŠ è½½ä¸æ‰“åŒ…ï¼šDataLoader æœ¬èº«ä¸ç½‘ç»œæ¶æ„å…³ç³»ä¸å¤§ï¼Œé€šå¸¸æ— éœ€ä¿®æ”¹ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œä¸ºäº†å‘æŒ¥ Rail-only ä¼˜åŠ¿ï¼Œæˆ–è®¸å¯ä»¥è°ƒæ•´æ•°æ®å¹¶è¡Œæ‰¹æ¬¡çš„åˆ’åˆ†ç­–ç•¥â€”â€”æ¯”å¦‚ç¡®ä¿æ¯ä¸ªæ•°æ®å¹¶è¡Œç»„å†…çš„æ ·æœ¬æ•°å‡è¡¡ï¼Œä»¥å……åˆ†åˆ©ç”¨ rail çš„å¹¶è¡Œå¸¦å®½ã€‚å¦‚æœæ‰¹éå¸¸å°å¯¼è‡´é€šä¿¡é¢‘ç¹ï¼Œå æ¯”å˜é«˜ï¼Œè¿™æ—¶å¯èƒ½éœ€è¦å¢å¤§ batch æˆ–é‡‡ç”¨ gradient accumulation ç­–ç•¥ï¼ˆæ¡†æ¶å·²æœ‰æ”¯æŒï¼‰ã€‚æ€»ä½“è€Œè¨€ï¼Œæ•°æ®è¯»å–å’Œé¢„å¤„ç†é€»è¾‘å¯ä»¥ä¿æŒä¸å˜ï¼Œä½†å¤§æ‰¹è®­ç»ƒæ—¶è¦ç›‘æ§é€šä¿¡æ¯”é‡ï¼Œå¯èƒ½ä»æ•°æ®è§’åº¦è°ƒä¼˜æ‰¹å¤§å°æ¥é€‚é… Rail-only å¸¦æ¥çš„é€šä¿¡æ ¼å±€å˜åŒ–ã€‚\nå¹¶è¡Œè°ƒåº¦ä¸ä½œä¸šåˆ’åˆ†ï¼šè¿™æ˜¯è½åœ°çš„é‡å¤´ã€‚é›†ç¾¤è°ƒåº¦å™¨ï¼ˆå¦‚ Slurm æˆ– Kubernetesï¼‰å’Œè®­ç»ƒè„šæœ¬éœ€è¦æ‹“æ‰‘æ„ŸçŸ¥åœ°åˆ†é… GPUã€‚å…·ä½“æ¥è¯´ï¼Œè¦ç¡®ä¿åŒä¸€ä¸ªæµæ°´å¹¶è¡Œ stage çš„ GPU å…¨éƒ¨ä½äºåŒä¸€ HB åŸŸï¼Œä»¥åŠåŒä¸€ä¸ªæ•°æ®å¹¶è¡Œç»„çš„ GPU æ°å¥½åˆ†åˆ«æ¥è‡ªæ¯ä¸ª HB åŸŸã€‚è¿™å¯èƒ½éœ€è¦åœ¨ä½œä¸šæäº¤æ—¶æŒ‡å®šç‰¹æ®Šçš„æ‹“æ‰‘çº¦æŸï¼Œä¾‹å¦‚ä½¿ç”¨ HWLOC æ‹“æ‰‘ä¿¡æ¯æˆ–æ‰‹å·¥åˆ’åˆ† GPU åˆ—è¡¨ã€‚åœ¨Megatron/DeepSpeedä¸­ï¼Œä¸€èˆ¬å…è®¸ç”¨æˆ·æŒ‡å®š pipelineå¹¶è¡Œæ·±åº¦ã€å¼ é‡å¹¶è¡Œå¤§å°ç­‰â€”â€”ç»“åˆ Rail-onlyï¼Œæˆ‘ä»¬å¿…é¡»å°†è¿™äº›å‚æ•°ä¸ç‰©ç†æ‹“æ‰‘ç»‘å®šã€‚å¦‚8-GPUä¸€ç»„çš„ HB åŸŸå†…è·‘å¼ é‡å¹¶è¡Œï¼Œå°±è¦è®¾ç½®å¼ é‡å¹¶è¡Œ=8ï¼Œå¹¶ä¿è¯æ¯ç»„8å¡åœ¨åŒä¸€èŠ‚ç‚¹/æœºç®±ã€‚å¦‚æœè°ƒåº¦ç³»ç»Ÿä¸æ”¯æŒè¿™ä¹ˆç²¾ç»†çš„ç»‘å®šï¼Œåˆ™éœ€è¦æ‰©å±•å…¶åŠŸèƒ½ï¼Œè®©è°ƒåº¦ç­–ç•¥æ‡‚å¾—æŠŠ GPU ä»¥ â€œHBåŸŸå—â€ ä¸ºå•ä½åˆ†é…ç»™ä½œä¸šã€‚å¦å¤–ï¼Œå¤šä½œä¸šå¹¶è¡Œè¿è¡Œæ—¶ï¼Œæœ€å¥½é¿å…ä¸¤ä¸ªä½œä¸šæ··ç”¨åŒä¸€ HB åŸŸçš„ GPUï¼Œä»¥å…ç›¸äº’é€šä¿¡å†²çªã€‚è¿™æ¶‰åŠä½œä¸šç¼–æ’å±‚é¢çš„è§„åˆ™åˆ¶å®šå’Œè°ƒåº¦ç®—æ³•æ›´æ–°ã€‚\nå¼ é‡/æµæ°´å¹¶è¡Œç­–ç•¥è°ƒæ•´ï¼šåœ¨è®­ç»ƒæ¡†æ¶å†…éƒ¨ï¼Œéœ€è¦é…ç½®å¹¶è¡Œé€šä¿¡ç»„æ—¶è€ƒè™‘ rail æ‹“æ‰‘ã€‚Megatron-LM è¿™ç§æ¡†æ¶é€šå¸¸é€šè¿‡ MPI rank æˆ– GPU ID æ¥ç»„å»ºæ¨¡å‹å¹¶è¡Œç»„ã€æ•°æ®å¹¶è¡Œç»„ã€‚æˆ‘ä»¬è¦ç¡®ä¿å®ƒæŒ‰ç…§Rail-onlyæ˜ å°„æ¥å»ºç»„ã€‚ä¾‹å¦‚ï¼Œå¯ä»¥çº¦å®šï¼šGPU rank åˆ—è¡¨æŒ‰ HB åŸŸä¼˜å…ˆæ’åºï¼Œè¿™æ · rank ç›¸å·®å°çš„éƒ½åœ¨ä¸€åŸŸå†…ï¼Œä»è€Œ MPI åˆ’åˆ†å¼ é‡å¹¶è¡Œç»„æ—¶åˆšå¥½æŒ‘åˆ°è¿ç»­çš„8å¡ï¼ˆåŸŸå†…ï¼‰ï¼Œè€Œæ•°æ®å¹¶è¡Œç»„æŒ‘çš„æ˜¯éš”å¼€çš„ rankï¼ˆæ¯åŸŸå„1ï¼‰ã€‚å¦‚æœæ¡†æ¶ç°æœ‰é€»è¾‘ä¸èƒ½ä¿è¯ï¼Œéœ€è¦æ”¹å†™å¹¶è¡Œç»„åˆå§‹åŒ–é€»è¾‘ï¼Œæ˜¾å¼æŒ‡å®šæ¯ä¸ªç»„æˆå‘˜ GPU ç¼–å·ã€‚è¿™åœ¨ DeepSpeed çš„é…ç½®ä¸­å¯èƒ½æ¶‰åŠ pipeline_partition å’Œ tensor_parallel placementã€‚æ€»ä¹‹ï¼Œå¿…é¡»è®©å¹¶è¡Œåº“çŸ¥é“ rails çš„å­˜åœ¨ï¼Œä»¥åˆ›å»ºæ­£ç¡®çš„é€šä¿¡ peer åˆ—è¡¨ã€‚è¿™ä¸ªæ”¹åŠ¨æŠ€æœ¯ä¸Šä¸éš¾ï¼ˆä¸»è¦æ˜¯æ’åº/åˆ†ç»„é—®é¢˜ï¼‰ï¼Œä½†è¦ç»´æŠ¤åœ¨å„ç§ clusteré…ç½®ä¸‹çš„ä¸€è‡´æ€§ã€‚\né€šä¿¡åº“ä¸Collectiveå®ç°ï¼šNCCL ç­‰é€šä¿¡åº“å¯¹åº•å±‚æ‹“æ‰‘é€šå¸¸æ˜¯ä¸çŸ¥æƒ…çš„ï¼Œå®ƒå‡è®¾ä»»æ„ç‚¹å¯ç›´è¾¾ã€‚åœ¨ Rail-only å®ç°ä¸­ï¼Œå¦‚æœæˆ‘ä»¬ç‰©ç†ä¸Šæ‹†åˆ†äº†ç½‘ç»œï¼ˆæ¯æ¡ rail ä¸€ä¸ªå­ç½‘ï¼‰ï¼Œé‚£ä¹ˆ NCCL å±‚é¢éœ€è¦ç›¸åº”åœ°é‡‡ç”¨åˆ†å±‚é€šä¿¡ç®—æ³•ã€‚å¹¸è¿çš„æ˜¯ï¼ŒNCCL å·²æ”¯æŒåˆ†å±‚ AllReduce ç­‰ï¼ˆç”¨äº NVLink+PCIe åœºæ™¯ï¼‰ã€‚æˆ‘ä»¬å¯èƒ½éœ€è¦è‡ªå®šä¹‰ NCCL ç®—æ³•æ’ä»¶æˆ–è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œè®©å®ƒä¸º AllReduce/AllGather é‡‡ç”¨ â€œå…ˆåŸŸå†…NVLinkï¼Œå†è·¨åŸŸNICâ€ çš„æ¨¡å¼ï¼ˆè¿™æ­£æ˜¯è®ºæ–‡è¦æ±‚çš„ï¼‰ã€‚è¿™ä¸€éƒ¨åˆ†æ”¹åŠ¨é£é™©è¾ƒä½ï¼Œå› ä¸ºé€»è¾‘ä¸Šå·²ç»æœ‰äººåšè¿‡ç±»ä¼¼ä¼˜åŒ–ã€‚ä½†å¦‚æœ NCCL ä¸æ”¯æŒï¼Œæˆ‘ä»¬å¯èƒ½å¾—å¼€å‘é€šä¿¡è°ƒåº¦ä¸­é—´ä»¶ï¼Œè‡ªå·±æ‹†åˆ†é€šä¿¡ã€‚è¿™å·¥ç¨‹é‡è¾ƒå¤§ï¼Œæ¶‰åŠä¿®æ”¹æ¡†æ¶æˆ–æ›¿æ¢åº•å±‚é€šä¿¡åº“ã€‚å¦ä¸€ç‚¹æ˜¯ï¼ŒRail-onlyæ²¡æœ‰å…¨å±€è·¯ç”±ï¼Œæ„å‘³ç€MPI/SHARP ç­‰éœ€è¦é™å®šé€šä¿¡åŸŸã€‚ç®¡ç†ä¸Šéœ€è¦ç¡®ä¿ä¸åŒ rail é—´é»˜è®¤ä¸å‘ç”Ÿ MPIé€šä¿¡ï¼Œæˆ–é€šè¿‡è·¯ç”±è§„åˆ™ drop éæ³•åŒ…ï¼Œä»¥é˜²ä¸‡ä¸€ã€‚ç®€å•æ¥è¯´ï¼Œé€šä¿¡åº“å±‚é¢éœ€è¦æ‹“æ‰‘éš”ç¦»å’Œå±‚æ¬¡ç®—æ³•æ”¯æŒä¸¤æ‰‹å‡†å¤‡ã€‚\nKernel æˆ–ç®—å­å®ç°ï¼šæ¨¡å‹çš„è®¡ç®— kernel å¤§å¤šåœ¨ GPU å†…éƒ¨å®Œæˆï¼Œä¸å—ç½‘ç»œæ‹“æ‰‘ç›´æ¥å½±å“ã€‚å› æ­¤ç®—å­å±‚æ— éœ€ä¿®æ”¹ã€‚ä½†æ˜¯ï¼Œéœ€è¦å…³æ³¨é€šä¿¡ç›¸å…³ç®—å­ï¼ˆå¦‚ all_reduce(op=tensor) è¿™ç§è°ƒç”¨ï¼‰ã€‚åœ¨æ¡†æ¶å±‚ï¼Œè¿™äº›é€šå¸¸æ˜ å°„åˆ° NCCL è°ƒç”¨ã€‚é™¤äº†é€‰æ‹©åˆé€‚ç®—æ³•å¤–ï¼Œä¹Ÿè¦è€ƒè™‘é€šä¿¡ç®—å­çš„å¼‚æ­¥é‡å é…ç½®ã€‚åœ¨ Rail-only æƒ…å†µä¸‹ï¼Œä¹Ÿè®¸å¯ä»¥æ›´åŠ å¤§èƒ†åœ°è®©é€šä¿¡å¼‚æ­¥åŒ–ï¼Œå› ä¸ºç½‘ç»œå±‚æ¬¡æ¸…æ™°ï¼Œoverlap æ›´å®‰å…¨ã€‚æ¡†æ¶å¯èƒ½æä¾› torch.distributed ä¸€äº›é€‰é¡¹ï¼Œå¯ä»¥è°ƒä¼˜ä»¥å……åˆ†éšè— railä¹‹é—´ç¨æ…¢çš„é€šä¿¡ã€‚æ€»ä¹‹ï¼Œç®—å­å®ç°å±‚æ›´å¤šæ˜¯å‚æ•°è°ƒä¼˜ï¼Œå¹¶ä¸éœ€è¦é‡å†™å·²æœ‰æ ¸å¿ƒ kernelã€‚\nç›‘æ§ä¸è°ƒè¯•ï¼šå¼•å…¥ Rail-only åï¼Œç›‘æ§ç³»ç»Ÿéœ€èƒ½è¯†åˆ«æ–°çš„ç½‘ç»œç»“æ„ã€‚æ¯”å¦‚ï¼Œä»¥å‰ GPU é—´é€šä¿¡å»¶è¿Ÿå¯ä»¥ä»»æ„pingï¼Œç°åœ¨éœ€è¦æŒ‰ rail æŸ¥çœ‹ã€‚ç›‘æ§å·¥å…·éœ€å¢åŠ æŒ‡æ ‡ï¼Œå¦‚æ¯æ¡ rail çš„å¸¦å®½åˆ©ç”¨ç‡ã€åŸŸå†… vs åŸŸé—´é€šä¿¡æ¯”ç­‰ï¼Œä»¥ä¾¿å·¥ç¨‹å¸ˆéªŒè¯ç³»ç»Ÿè¿è½¬æ­£å¸¸ã€‚è°ƒè¯•æ–¹é¢ï¼Œå¦‚æœå‡ºç°è·¨åŸŸé€šä¿¡å¼‚å¸¸ï¼ˆæ¯”å¦‚æŸGPUå°è¯•å’Œä¸åŒ rail GPUé€šä¿¡å¯¼è‡´hangï¼‰ï¼Œéœ€è¦å·¥å…·å¿«é€Ÿå‘ç°ã€‚è¿™å¯èƒ½éœ€è¦è‡ªå®šä¹‰ NCCL æ—¥å¿—æˆ–ç½‘ç»œæ¨¡æ‹Ÿæµ‹è¯•ï¼Œç¡®ä¿é…ç½®æ­£ç¡®ã€‚debug æˆæœ¬ä¼šä¸Šå‡ï¼Œå› ä¸ºé—®é¢˜å®šä½éœ€è€ƒè™‘æ‹“æ‰‘ï¼Œè¿™è¦æ±‚å·¥ç¨‹å›¢é˜Ÿå…·æœ‰ç½‘ç»œå’Œåˆ†å¸ƒå¼è®­ç»ƒçš„åŒé‡çŸ¥è¯†å‚¨å¤‡ï¼Œæ˜¯ä¸ªæ½œåœ¨æŒ‘æˆ˜ã€‚\né…ç½®æœç´¢ä¸è‡ªåŠ¨è°ƒå‚ï¼šRail-only è§£è€¦äº†éƒ¨åˆ†ç½‘ç»œèµ„æºï¼Œå› æ­¤ä»¥å¾€æ¡†æ¶è‡ªåŠ¨è°ƒå‚å¯èƒ½ä¸å†æœ€ä¼˜ã€‚ä¾‹å¦‚ DeepSpeed Autotuning ä»¥å‰å‡è®¾å…¨å¸¦å®½ï¼Œä½†ç°åœ¨éœ€è¦æŠŠHBåŸŸå¸¦å®½å’ŒNICå¸¦å®½åˆ†åˆ«è€ƒè™‘ã€‚å› æ­¤è‡ªåŠ¨è°ƒå‚æ¨¡å—è¦åŠ å…¥æ‹“æ‰‘æ„ŸçŸ¥ï¼šé€šè¿‡è°ƒç”¨è®ºæ–‡æä¾›çš„è¿­ä»£æ—¶é—´æ¨¡å‹ï¼Œè¾“å…¥å½“å‰ clusterçš„HBåŸŸå¤§å°ã€å¸¦å®½ï¼Œä»¥åŠæ¨¡å‹è§„æ¨¡ï¼Œæ¥æ¨è P/T/D å¹¶è¡Œåº¦ã€‚è¿™ç›¸å½“äºåœ¨è®­ç»ƒæ ˆä¸­åµŒå…¥ä¸€ä¸ªå°ä¸“å®¶ç³»ç»Ÿã€‚å®ç°æ–¹æ³•å¯ä»¥æ˜¯ç¦»çº¿è®¡ç®—ä¸€ä¸ªé…ç½®è¡¨ï¼Œæˆ–è€…åœ¨å¯åŠ¨æ—¶è·‘çŸ­æš‚çš„æµ‹è¯•è¡¡é‡åŸŸå†…/åŸŸé—´å¸¦å®½ï¼Œå†é€‰æ‹©é…ç½®ã€‚è™½ç„¶ä¸æ˜¯å¿…é¡»ï¼Œä½†æœ‰æ­¤ä¼˜åŒ–å¯ç¡®ä¿ç”¨æˆ·ä¸ç”¨æ‰‹åŠ¨çŒœæœ€ä½³å¹¶è¡Œç­–ç•¥ï¼Œè®©Rail-onlyçœŸæ­£æ–¹ä¾¿æ˜“ç”¨ã€‚\n\nç»¼ä¸Šï¼Œå¼•å…¥ Rail-only éœ€è¦è·¨å±‚é¢çš„ååŒä¿®æ”¹ï¼šä»è°ƒåº¦åˆ°æ¡†æ¶å¹¶è¡Œè®¾ç½®ï¼Œå†åˆ°é€šä¿¡åº“ã€‚å·¥ç¨‹å·¥ä½œé‡ä¸å°ï¼Œä½†å¤§å¤šå±äºâ€œåŠ æ–°ç­–ç•¥â€è€Œéæ¨ç¿»é‡åšï¼Œé£é™©åœ¨äºè°ƒè¯•å‘¨æœŸï¼Œç‰¹åˆ«æ˜¯ç¡®ä¿æ€§èƒ½æ¨¡å‹é¢„æœŸä¸å®é™…å»åˆã€‚ä¸»è¦é£é™©ç‚¹åŒ…æ‹¬ï¼šå…¼å®¹æ€§ï¼ˆä¿®æ”¹NCCLå¯èƒ½å½±å“åˆ«çš„éƒ¨åˆ†ï¼‰ã€æ˜¾å­˜å³°å€¼ï¼ˆæ›´å¤§ batch æˆ–åˆ†å±‚é€šä¿¡å¯èƒ½ä¸´æ—¶å ç”¨å¤šä¸€ç‚¹ bufferï¼‰ã€è°ƒè¯•å¤æ‚åº¦ï¼ˆç½‘ç»œé—®é¢˜æ›´éš¾å¤ç°ï¼‰ã€‚ä½†å¦‚æœé€æ­¥éªŒè¯ï¼Œæ¯å±‚æµ‹è¯•é€šè¿‡ï¼Œå†é›†æˆï¼Œæœ€ç»ˆè½åœ°æ˜¯å¯è¡Œçš„ã€‚ä¸€æ—¦è½åœ°æˆåŠŸï¼Œå¯¹äºå·²æœ‰è®­ç»ƒæ ˆæ¥è¯´å°±æ˜¯å¤§å¹…èŠ‚çœç¡¬ä»¶æŠ•å…¥çš„èƒœåˆ©ã€‚\nä¹ã€å€¼å¾—è¿›ä¸€æ­¥æ¢ç´¢çš„ç ”ç©¶æ–¹å‘\n\næ‹“æ‰‘æ„ŸçŸ¥çš„ä½œä¸šè°ƒåº¦ç³»ç»Ÿï¼šå¼€å‘ä¸€ç§è°ƒåº¦ç­–ç•¥æˆ–ç³»ç»Ÿç»„ä»¶ï¼Œä½¿é›†ç¾¤èµ„æºåˆ†é…èƒ½è‡ªåŠ¨é€‚é…ç½‘ç»œæ‹“æ‰‘ã€‚å…·ä½“é—®é¢˜åœ¨äºï¼šå½“å¤šä¸ªè®­ç»ƒä½œä¸šåŒæ—¶è¿è¡Œæ—¶ï¼Œå¦‚ä½•å°†å®ƒä»¬åˆç†æ˜ å°„åˆ°ä¸åŒ rails æˆ– HB åŸŸï¼Œä»¥å‡å°‘å½¼æ­¤é€šä¿¡å¹²æ‰°å¹¶å……åˆ†åˆ©ç”¨å¸¦å®½ï¼Ÿè¿™éœ€è¦è§£å†³ä½œä¸šé€šä¿¡æ¨¡å¼å»ºæ¨¡å’Œæ‹“æ‰‘æ‰“åˆ†çš„é—®é¢˜ï¼Œä¸ºæ¯ä¸ªæ–°ä½œä¸šæŒ‘é€‰æœ€ä½³çš„ä½ç½®ã€‚è¿™æ ·çš„ç ”ç©¶å¯æé«˜ Rail-only åœ¨å¤šç§Ÿæˆ·ç¯å¢ƒä¸‹çš„å¯ç”¨æ€§å’Œå…¬å¹³æ€§ï¼Œå¯¹äº‘æœåŠ¡å•†å®é™…éƒ¨ç½²ä»·å€¼é‡å¤§ã€‚\nåŠ¨æ€å¯é‡æ„ç½‘ç»œä¸è®­ç»ƒååŒï¼šæ¢ç´¢å°†å…‰è·¯äº¤æ¢ç­‰åŠ¨æ€å¯é‡æ„ç½‘ç»œæŠ€æœ¯ä¸ LLM è®­ç»ƒç»“åˆï¼Œä½¿æ‹“æ‰‘èƒ½å¤Ÿåœ¨è¿è¡Œä¸­è°ƒæ•´ã€‚ç›®æ ‡æ˜¯è§£å†³å½“å‰ Rail-only é™æ€æ‹“æ‰‘çš„å±€é™ï¼Œè®©ç½‘ç»œéšé€šä¿¡éœ€æ±‚å˜åŒ–è€Œåˆ‡æ¢ï¼Œä¾‹å¦‚åœ¨ MoE all-to-all é˜¶æ®µä¸´æ—¶å»ºç«‹ç›´è¿é€šè·¯ã€‚ç ”ç©¶é‡ç‚¹åŒ…æ‹¬ï¼šè®­ç»ƒæ¡†æ¶å¦‚ä½•ä¸ç½‘ç»œæ§åˆ¶å™¨äº¤äº’ï¼ˆä½•æ—¶è§¦å‘æ‹“æ‰‘é‡æ„ï¼‰ï¼Œé‡æ„å»¶è¿Ÿå¯¹è®­ç»ƒçš„å½±å“ï¼Œä»¥åŠå¦‚ä½•ä¿æŒæ¨¡å‹æ”¶æ•›ç¨³å®šæ€§ã€‚å¦‚æœæˆåŠŸï¼Œå°†æé«˜ç½‘ç»œåˆ©ç”¨æ•ˆç‡å¹¶å…¼é¡¾æ›´å¤šæ ·åŒ–é€šä¿¡æ¨¡å¼ã€‚\né€‚ç”¨äºä¸“ç”¨æ‹“æ‰‘çš„é€šä¿¡ç®—æ³•ï¼šè®¾è®¡æ–°çš„åˆ†å¸ƒå¼è®­ç»ƒé€šä¿¡ç®—æ³•ï¼Œå……åˆ†åˆ©ç”¨ Rail-only ç­‰å±€éƒ¨å…¨è¿æ¥æ‹“æ‰‘çš„ç‰¹ç‚¹ã€‚ä¾‹å¦‚ï¼Œå¯ä»¥ç ”ç©¶åˆ†å±‚æ¢¯åº¦å‹ç¼©æˆ–æµæ°´é€šä¿¡è°ƒåº¦ï¼Œè®©è·¨åŸŸé€šä¿¡æ•°æ®é‡è¿›ä¸€æ­¥å‡å°‘æˆ–å»¶è¿Ÿã€‚ä¾‹å¦‚ï¼Œåœ¨æ•°æ®å¹¶è¡Œ All-Reduce ä¸­å¼•å…¥é€‰æ‹©æ€§åŒæ­¥ï¼Œåªåœ¨ä¸€å®šè¿­ä»£é—´éš”è·¨ rail æ±‡æ€»ï¼›æˆ–è€…åœ¨æµæ°´å¹¶è¡Œä¸­ï¼Œé€šè¿‡å†—ä½™è®¡ç®—æ¢å–å‡å°‘éƒ¨åˆ†è·¨åŸŸæ¿€æ´»ä¼ è¾“ã€‚è¿™äº›æ–¹æ³•éœ€è¦æ•°å­¦è¯æ˜åœ¨ç²¾åº¦æŸå¤±å¯æ§èŒƒå›´ï¼ŒåŒæ—¶ç»“åˆæ‹“æ‰‘ä¼˜åŒ–ç®—æ³•ï¼Œå®ç°æ›´ç½‘ç»œå‹å¥½çš„å¹¶è¡Œã€‚\nç»Ÿä¸€çš„æ€§èƒ½å»ºæ¨¡æ¡†æ¶ï¼šå°†è®ºæ–‡æå‡ºçš„è¿­ä»£æ—¶é—´æ¨¡å‹æ‰©å±•ä¸ºä¸€ä¸ªé€šç”¨æ€§èƒ½é¢„æµ‹å·¥å…·ã€‚è¿™ä¸ªæ–¹å‘ç€çœ¼äºä¸ºä»»æ„ç»™å®šçš„æ¨¡å‹ã€å¹¶è¡Œé…ç½®å’Œç½‘ç»œæ‹“æ‰‘ï¼Œå¿«é€Ÿç»™å‡ºååã€é€šä¿¡å æ¯”ã€ç“¶é¢ˆåˆ†æã€‚å®ƒå¯ä»¥æ•´åˆæ›´å¤šç°å®å› ç´ ï¼ˆæ¯”å¦‚ä¸åŒæ¨¡å‹å±‚çš„å¼‚è´¨æ€§ã€æ··åˆå¹¶è¡Œæ¨¡å¼ã€å»¶è¿Ÿæ¨¡å‹ç­‰ï¼‰ï¼Œé€šè¿‡å’Œå®é™…æµ‹é‡æ ¡å‡†ï¼Œæˆä¸ºç³»ç»Ÿè®¾è®¡è€…çš„å†³ç­–æ”¯æŒå·¥å…·ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæœ‰è¿™æ ·ä¸€ä¸ªå¼€æºåº“ï¼Œè¾“å…¥â€œæŸæ¨¡å‹+Rail-only+é…ç½®Xâ€å³å¯ç®—å‡ºé¢„æœŸé€Ÿåº¦å’Œæˆæœ¬ï¼Œå¯¹æ¯”â€œClos+é…ç½®Yâ€ï¼Œå°†æå¤§åŠ é€Ÿä¸šç•Œé‡‡çº³æ–°æ‹“æ‰‘çš„ä¿¡å¿ƒã€‚è¿™æ˜¯å°†è®ºæ–‡æ–¹æ³•å­¦å•†å“åŒ–çš„é‡è¦ä¸€æ­¥ã€‚\nè·¨å±‚ååŒä¼˜åŒ–è®­ç»ƒï¼šè¿›ä¸€æ­¥çš„ç ”ç©¶å¯ä»¥è¶…è¶Šç½‘ç»œèŒƒç•´ï¼Œè€ƒè™‘é€šä¿¡ã€å­˜å‚¨ã€è®¡ç®—ä¸‰è€…çš„ååŒä¼˜åŒ–ã€‚ä¾‹å¦‚ï¼ŒRail-only å‡å°‘äº†ç½‘ç»œæˆæœ¬ï¼Œé‚£ä¹ˆä¸‹ä¸€ä¸ªç“¶é¢ˆå¯èƒ½æ˜¯å­˜å‚¨IOæˆ–å†…å­˜ã€‚æœªæ¥å·¥ä½œå¯ä»¥ç ”ç©¶åœ¨å®šåˆ¶ç½‘ç»œä¸‹ï¼Œå¦‚ä½•è°ƒæ•´checkpoint ç­–ç•¥ï¼ˆå‡å°‘å…¨èŠ‚ç‚¹åŒæ­¥å­˜ç›˜ï¼‰ï¼Œæˆ–è€…æ˜¾å­˜ç®¡ç†ï¼ˆæ¯”å¦‚èƒ½å¦åˆ©ç”¨Rail-onlyå±€éƒ¨æ€§åšåˆ†å¸ƒå¼ç¼“å­˜ï¼‰ã€‚è¿™ä¸ªæ–¹å‘çš„ä»·å€¼åœ¨äºï¼Œé€šè¿‡è·¨å±‚ä¼˜åŒ–ï¼ŒæŠŠæ¯ä¸€ä»½ç¡¬ä»¶èµ„æºéƒ½åˆ©ç”¨åˆ°æè‡´ï¼Œä¸ºæ›´å¤§æ¨¡å‹è®­ç»ƒé“ºå¹³é“è·¯ã€‚å®ƒä½“ç°ä¸ºä¸€ç³»åˆ—å­è¯¾é¢˜ï¼Œå¦‚â€œæ‹“æ‰‘ä¼˜åŒ–ä¸‹çš„é›¶å†—ä½™ä¼˜åŒ–ï¼ˆZeROï¼‰ç­–ç•¥è°ƒæ•´â€æˆ–â€œé¢å‘Railæ‹“æ‰‘çš„åˆ†å¸ƒå¼ä¼˜åŒ–å™¨è®¾è®¡â€ç­‰ã€‚\n\nåã€çŸ¥è¯†å›¾è°±æ€ç»´é“¾\n\nå¹¶è¡Œä¸è°ƒåº¦ï¼šè¿™ç¯‡è®ºæ–‡ç´§å¯†è¿æ¥äº†æ¨¡å‹å¹¶è¡Œç­–ç•¥ä¸ç½‘ç»œè®¾è®¡ã€‚å®ƒæä¾›äº†ä¸€ä¸ªèŒƒä¾‹ï¼Œè¯´æ˜åˆ†å¸ƒå¼è®­ç»ƒä¸­å¦‚ä½•æ ¹æ®å¹¶è¡Œç®—æ³•æ¥å®šåˆ¶ç¡¬ä»¶æ‹“æ‰‘ã€‚ä¾‹å¦‚ï¼Œå®ƒå¼ºè°ƒäº†3D å¹¶è¡Œ (æ•°æ®-å¼ é‡-æµæ°´) çš„é€šä¿¡æ¨¡å¼å†³å®šäº†ç½‘ç»œè¿é€šéœ€æ±‚ï¼Œè¿™åˆ·æ–°äº†æˆ‘ä»¬å¯¹å¹¶è¡Œè°ƒåº¦-ç³»ç»Ÿæ¶æ„ååŒè®¾è®¡çš„è®¤è¯†ã€‚åœ¨æˆ‘çš„çŸ¥è¯†å›¾è°±ä¸­ï¼Œå®ƒè®©â€œå¹¶è¡Œè®¡ç®—â€èŠ‚ç‚¹å’Œâ€œç½‘ç»œæ‹“æ‰‘â€èŠ‚ç‚¹å»ºç«‹äº†æ–°çš„å¼ºå…³è”â€”â€”å¹¶è¡Œç­–ç•¥ä¸å†ä»…ç”±ç®—æ³•å†³å®šï¼Œä¹Ÿåº”å½±å“é›†ç¾¤å¸ƒçº¿ã€‚\nå†…å­˜ç®¡ç†ä¸æ˜¾å­˜ä¼˜åŒ–ï¼šè™½ç„¶è®ºæ–‡ä¸»è¦è®¨è®ºé€šä¿¡ï¼Œä½†éšå«å…³ç³»æ˜¯ï¼šå¦‚æœç½‘ç»œç“¶é¢ˆé™ä½ï¼Œæˆ‘ä»¬æˆ–å¯é€‰æ‹©ä¸åŒçš„å†…å­˜/æ˜¾å­˜æƒè¡¡ç­–ç•¥ã€‚æ¯”å¦‚ä»¥å¾€ä¸ºäº†å‡å°‘é€šä¿¡ï¼ŒZeROæŠŠæ¨¡å‹æ‹†åˆ†å¢åŠ æ˜¾å­˜å ç”¨ï¼›ç°åœ¨é€šä¿¡å»‰ä»·å±€éƒ¨åŒ–ï¼Œæˆ–è®¸å¯ä»¥ç‰ºç‰²äº›ç½‘ç»œæ¢æ˜¾å­˜æ•ˆç‡ã€‚è¿™æé†’æˆ‘åœ¨çŸ¥è¯†å›¾è°±ä¸­å°†â€œæ˜¾å­˜ä¼˜åŒ–ç­–ç•¥ï¼ˆZeRO/Offloadï¼‰â€ä¸â€œç½‘ç»œæ¶æ„â€å…³è”èµ·æ¥ï¼Œæœªæ¥ä¼˜åŒ–éœ€è¦ç»¼åˆè€ƒè™‘ä¸¤è€…ã€‚ä¾‹å¦‚ï¼ŒRail-onlyä½¿æˆ‘æ„è¯†åˆ°ç½‘ç»œä¸ä¸€å®šæ€»æ˜¯å›ºå®šçŸ­æ¿ï¼Œå†…å­˜å’Œé€šä¿¡çš„ååŒå†³ç­–ç©ºé—´æ›´å¤§äº†ã€‚\né€šä¿¡ä¸é›†ä½“æ“ä½œï¼šè®ºæ–‡ç›´æ¥æ‹“å±•äº†æˆ‘åœ¨é›†ä½“é€šä¿¡ç®—æ³•æ–¹é¢çš„å›¾è°±ã€‚å®ƒå€Ÿé‰´äº†åˆ†å±‚ AllReduce/AllGather æ€æƒ³ï¼Œå¹¶åº”ç”¨äºæ–°æ‹“æ‰‘ã€‚æˆ‘å­¦åˆ°åœ¨ç‰¹å®šæ‹“æ‰‘ä¸‹å¯ä»¥è®¾è®¡æœ€ä¼˜å¤æ‚åº¦çš„ collective ç®—æ³•ï¼ˆå¦‚å…¬å¼æ¨å¯¼çš„å¸¦å®½æœ€ä¼˜ AllGatherï¼‰ã€‚è¿™åŠ å¼ºäº†â€œæ‹“æ‰‘æ„ŸçŸ¥çš„é€šä¿¡ç®—æ³•â€è¿™ä¸€çŸ¥è¯†é“¾æ¡ï¼Œè®©æˆ‘æƒ³åˆ°å»å…³æ³¨ NCCL ç­‰æ¡†æ¶æ˜¯å¦‚ä½•åˆ©ç”¨ç½‘ç»œç»“æ„åšä¼˜åŒ–çš„ã€‚ä¹‹å‰æˆ‘çš„çŸ¥è¯†å›¾è°±é‡Œ â€œAllReduce ç®—æ³•â€ ä¸»è¦åˆ† ringã€æ ‘ç­‰ï¼Œç°åœ¨åˆ™å¢åŠ äº† â€œåˆ†å±‚/hierarchicalâ€ï¼ˆé’ˆå¯¹åˆ†æ®µæ‹“æ‰‘ï¼‰ è¿™ä¸€ç±»åˆ«ã€‚\nKernel ä¸ç®—å­ä¼˜åŒ–ï¼šRail-only æç¤ºæˆ‘ï¼Œé™¤äº†ç®—æœ¯è®¡ç®— kernel ä¼˜åŒ–å¤–ï¼Œé€šä¿¡ç›¸å…³çš„ç®—å­ï¼ˆå¦‚åˆ†å¸ƒå¼æ¢¯åº¦å½’çº¦ï¼‰ä¹Ÿéœ€è¦æ ¹æ®ç¡¬ä»¶ä¼˜åŒ–ã€‚å®ƒå…³è”äº†â€œç½‘ç»œæ‹“æ‰‘â€ä¸â€œåˆ†å¸ƒå¼ç®—å­å®ç°â€ä¸¤ä¸ªé¢†åŸŸã€‚åœ¨æˆ‘çš„å›¾è°±é‡Œï¼Œè¿™å±äº ç³»ç»Ÿä¼˜åŒ– éƒ¨åˆ†çš„ä¸€ç¯ï¼šç¡¬ä»¶æ‹“æ‰‘-&gt;åº“å®ç°-&gt;æ¨¡å‹ç®—å­ã€‚ç‰¹åˆ«æ˜¯è®ºæ–‡ä¸­å¼•ç”¨çš„ Hierarchical AllReduce ç®—æ³•å°±åƒæ˜¯ä¸€ç§â€œç‰¹æ®Šç®—å­ä¼˜åŒ–â€ã€‚è¿™é¼“åŠ±æˆ‘ä»¥åè®¾è®¡å¤§æ¨¡å‹è®­ç»ƒç­–ç•¥æ—¶ï¼Œä¸ä»…å…³æ³¨GPUä¸Šçš„çŸ©é˜µä¹˜æ³•ä¼˜åŒ–ï¼Œä¹Ÿè¦å…³æ³¨è·¨GPUçš„æ•°æ®ä¼ è¾“ç®—å­æ˜¯ä¸æ˜¯ç”¨äº†æœ€ä½³è·¯å¾„ã€‚\næ¨¡å‹ç»“æ„ä¸æ¶æ„è®¾è®¡ï¼šè®ºæ–‡å‡å®šTransformerå±‚ç»“æ„å‡åŒ€ï¼Œå¹¶ä¸”æåˆ°äº† MoE æ¨¡å‹çš„ç‰¹æ®Šé€šä¿¡æ¨¡å¼ã€‚è¿™è®©æˆ‘å°†æ¨¡å‹æ¶æ„ä¸ç³»ç»Ÿç“¶é¢ˆçš„è”ç³»æ›´ç´§å¯†åœ°çº³å…¥è€ƒè™‘ã€‚åœ¨çŸ¥è¯†å›¾è°±ä¸­ï¼Œæˆ‘ä¼šæŠŠ â€œMixture-of-Experts (MoE)â€ ä¸ â€œå…¨å±€ all-to-all é€šä¿¡â€ å…³è”æ ‡æ³¨ï¼Œå› ä¸ºå®ƒæ˜¯å°‘æ•°éœ€è¦å…¨äº’è”çš„æƒ…å†µã€‚è€Œ â€œæ ‡å‡† Transformerâ€ åˆ™å’Œ â€œå±€éƒ¨é€šä¿¡â€ å¼ºå…³è”ã€‚Rail-only æé†’æˆ‘ï¼Œæ¨¡å‹è®¾è®¡å¯èƒ½é©±åŠ¨ç³»ç»Ÿè®¾è®¡ï¼šæœªæ¥å¦‚æœæœ‰æ–°æ¨¡å‹ç»“æ„å¯¼è‡´ä¸åŒé€šä¿¡å›¾è°±ï¼Œæˆ‘ä»¬ä¹Ÿè®¸éœ€è¦ç›¸åº”æ–°çš„ç½‘ç»œæ¶æ„ã€‚è¿™ä¸ªæ„è¯†è®©æˆ‘åœ¨æ¨¡å‹åˆ›æ–°å’Œç³»ç»Ÿä¼˜åŒ–ä¹‹é—´å»ºç«‹äº†æ›´ç›´æ¥çš„è”ç³»ã€‚\næ•°æ®ã€é¢„å¤„ç†ä¸æ‰“åŒ…ç­–ç•¥ï¼šè®ºæ–‡çš„å®éªŒæ˜¾ç¤ºæ‰¹å¤§å°å½±å“é€šä¿¡æ•ˆç‡ã€‚è¿™ä¸ºæˆ‘åœ¨çŸ¥è¯†å›¾è°±ä¸­å°† â€œæ•°æ®æ‰¹å¤„ç†ç­–ç•¥â€ èŠ‚ç‚¹ä¸ â€œé€šä¿¡/ç½‘ç»œâ€ èŠ‚ç‚¹ç”»ä¸Šä¸€æ¡è¿çº¿ã€‚ä»¥å¾€æ‰¹å¤§å°é€‰å–ä¸»è¦è€ƒè™‘ GPU ç®—åŠ›ã€æ”¶æ•›ç¨³å®šæ€§ï¼Œç°åœ¨æ¸…æ¥šäº†æ‰¹å¤§å°è¿˜å½±å“é€šä¿¡å æ¯”ï¼Œè¿›è€Œå½±å“å¯¹ç½‘ç»œæ‹“æ‰‘çš„è¦æ±‚ã€‚æ¯”å¦‚ï¼Œå°æ‰¹ä½¿å¾—å…¨äº’è”æµªè´¹ä¸¥é‡ï¼Œå¤§æ‰¹åˆ™æ›´èƒ½åˆ©ç”¨Rail-onlyã€‚ä»Šååœ¨å®è·µä¸­è°ƒæ•´ batch æˆ– sequence packing æ—¶ï¼Œæˆ‘ä¼šè€ƒè™‘ç½‘ç»œå› ç´ ã€‚å¦å¤–ï¼ŒRail-onlyä¹Ÿå…³è”åˆ°æ•°æ®åˆ‡åˆ†ç­–ç•¥â€”â€”æ•°æ®å¹¶è¡Œå°½é‡åœ¨ rail å†…å®Œæˆæ¢¯åº¦æ±‡æ€»ï¼Œæ‰€ä»¥æ•°æ®åˆ‡åˆ†å’Œå¹¶è¡Œ mapping æœ‰äº’åŠ¨ã€‚æ€»ä¹‹ï¼Œå®ƒæ‹“å®½äº†æˆ‘å¯¹â€œæ•°æ®å¸ƒç½®å½±å“ç½‘ç»œæ•ˆç‡â€çš„ç†è§£ã€‚\n\n10.1 ä¸ªäººæ”¶è·ä¸åæ€\nè¯»å®Œè¿™ç¯‡è®ºæ–‡ï¼Œæˆ‘æœ€å¤§çš„å¯å‘åœ¨äºï¼šç³»ç»Ÿæ¶æ„å¯ä»¥è€Œä¸”åº”å½“é’ˆå¯¹ç‰¹å®šAIå·¥ä½œè´Ÿè½½è¿›è¡Œå®šåˆ¶ä¼˜åŒ–ã€‚ä»¥å¾€è®­ç»ƒå¤§æ¨¡å‹é‡åˆ°ç“¶é¢ˆæ—¶ï¼Œæˆ‘ä»¬æ›´å¤šä»ç®—æ³•ã€è½¯ä»¶ä¸Šæƒ³åŠæ³•ï¼Œå¦‚åˆ†å¸ƒå¼ä¼˜åŒ–ç®—æ³•æˆ–è€…æ¨¡å‹å‹ç¼©ã€‚ä½†è¿™é¡¹å·¥ä½œæé†’æˆ‘ï¼Œæœ‰æ—¶çªç ´ç“¶é¢ˆçš„é’¥åŒ™åœ¨äºæ”¹å˜åº•å±‚å‡è®¾â€”â€”è¿™é‡Œå°±æ˜¯è´¨ç–‘äº†â€œæ•°æ®ä¸­å¿ƒç½‘ç»œå¿…é¡»å…¨äº’è”â€è¿™ä¸ªé»˜è®¤å‰æã€‚ä½œè€…ç”¨æ•°æ®è¯æ˜å¤§å¤šæ•°è¿æ¥ç”¨ä¸ä¸Šï¼Œä»è€Œå¤§èƒ†åœ°é‡æ–°æ¶æ„ç½‘ç»œã€‚è¿™ç§é—®é¢˜å¯¼å‘ã€ç›´å‡»æœ¬æºçš„æ€è·¯ä»¤æˆ‘åæ€ï¼šåœ¨è‡ªå·±çš„å·¥ä½œä¸­ï¼Œæ˜¯å¦å­˜åœ¨é»˜è®¤ä¸ºçœŸå´å¯èƒ½è¢«æ‰“ç ´çš„å‡è®¾ï¼Ÿæˆ–è®¸åœ¨æ¨¡å‹å¹¶è¡Œã€å†…å­˜ç®¡ç†ç­‰é¢†åŸŸï¼Œä¹Ÿæœ‰ç±»ä¼¼ç©ºé—´ã€‚æˆ‘å­¦åˆ°è¦æ•¢äºè·³å‡ºä¼ ç»Ÿæ¡†æ¶å®¡è§†é—®é¢˜ï¼ŒæŠŠå·¥ç¨‹å®è·µä¸­çš„è§„å¾‹æç‚¼ä¸ºæ–°è®¾è®¡çš„ä¾æ®ã€‚\nå…·ä½“åˆ°å®è·µæ–¹é¢ï¼Œæˆ‘è®¤ä¸ºå€¼å¾—è¿ç§»çš„æ˜¯é€šä¿¡å±€éƒ¨åŒ–ã€æ‹“æ‰‘æ„ŸçŸ¥ä¼˜åŒ–çš„ç†å¿µã€‚æ¯”å¦‚åœ¨æˆ‘çš„åç»­é¡¹ç›®ä¸­ï¼Œå¦‚æœä½¿ç”¨ Megatron-LM è¿™æ ·çš„æ¡†æ¶ï¼Œæˆ‘ä¼šè€ƒè™‘åœ¨ä»»åŠ¡è°ƒåº¦å’Œ GPU æ‹“æ‰‘ä¸Šåšæ–‡ç« ï¼šå°½é‡è®©å¼ºä¾èµ–é€šä¿¡çš„GPUå®‰æ’åœ¨åŒä¸€èŠ‚ç‚¹æˆ–æœºæ¶ï¼Œå‡å°‘è¿œç¨‹é€šä¿¡ã€‚è¿™å…¶å®æ˜¯ Rail-only æ€æƒ³çš„ä¸€ä¸ªç®€åŒ–ç‰ˆåº”ç”¨ã€‚æˆ‘ä¹Ÿè®¡åˆ’å°è¯•è°ƒæ•´NCCLçš„åˆ†å±‚é€šä¿¡è®¾ç½®ï¼šè¿‡å»å¯èƒ½é»˜è®¤ä½¿ç”¨æ ‘æˆ–ç¯ï¼Œä½†ç°åœ¨çŸ¥é“HBåŸŸå†…å¤–å¸¦å®½æ‚¬æ®Šï¼Œå¯ä»¥æ‰‹å·¥è®¾ç½® NCCL_IB_HIERARCHY ç­‰å‚æ•°ï¼Œçœ‹çœ‹èƒ½å¦è·å¾—æ€§èƒ½æå‡ã€‚å¦å¤–ï¼Œä½œè€…çš„è¿­ä»£æ—¶é—´æ¨¡å‹å¯¹æˆ‘å¾ˆæœ‰ä»·å€¼ï¼Œæˆ‘æ‰“ç®—åœ¨æˆ‘ä»¬é›†ç¾¤ä¸Šçº¿å‰å…ˆç”¨ç±»ä¼¼æ¨¡å‹è¯„ä¼°ä¸åŒå¹¶è¡Œé…ç½®çš„æ•ˆç‡ï¼Œä½œä¸ºè°ƒå‚ä¾æ®ã€‚\næ€»çš„æ¥è¯´ï¼Œè¿™ç¯‡è®ºæ–‡åœ¨ç†è®ºä¸Šè´¨ç–‘äº†ä¼ ç»Ÿï¼Œåœ¨å·¥ç¨‹ä¸Šç»™å‡ºäº†å¯è¡Œæ–¹æ¡ˆï¼Œå¯¹å½“å‰å¤§æ¨¡å‹è®­ç»ƒç”Ÿæ€çš„å½±å“æ˜¯ç§¯æä¸”æ·±è¿œçš„ã€‚å®ƒé€‚åˆé‚£äº›å¸Œæœ›çªç ´ç®—åŠ›ç“¶é¢ˆã€ä¼˜åŒ–é›†ç¾¤æŠ•å…¥çš„ä»ä¸šè€…æ·±å…¥é˜…è¯»ã€‚è®ºæ–‡åé‡ç³»ç»Ÿè®¾è®¡å’Œé‡åŒ–åˆ†æï¼Œæä¾›äº†ä¸€ä¸ªä»¥å·¥ç¨‹å®æ•ˆä¸ºå¯¼å‘çš„åˆ›æ–°èŒƒä¾‹ï¼Œè€Œéç©ºæƒ³ã€‚å¯¹äºæ­£åœ¨å»ºè®¾è¶…å¤§è§„æ¨¡è®­ç»ƒåŸºç¡€è®¾æ–½çš„å›¢é˜Ÿï¼Œè¿™é¡¹ç ”ç©¶æ— ç–‘å€¼å¾—é‡ç‚¹å…³æ³¨å’Œå°è¯•åº”ç”¨ã€‚\n","categories":["è®ºæ–‡é˜…è¯»"],"tags":["paper"]},{"title":"Reducing Energy Bloat in Large Model Training","url":"/2025/12/28/paper/reducing_energy/","content":"\n\nåŸæ–‡ï¼šReducing Energy Bloat in Large Model Training Â· arXiv\n\nä¸€ã€è®ºæ–‡é€Ÿè§ˆ\nè¯¥è®ºæ–‡æ—¨åœ¨è§£å†³å¤§è§„æ¨¡æ¨¡å‹è®­ç»ƒä¸­çš„èƒ½æºæµªè´¹é—®é¢˜ã€‚ä½œè€…æŒ‡å‡ºåœ¨å¤š GPU åˆ†å¸ƒå¼è®­ç»ƒä¸­ï¼Œå¹¶éæ‰€æœ‰è€—è´¹çš„èƒ½é‡éƒ½ç”¨äºæé«˜ååç‡ï¼Œå…¶ä¸­æœ‰ç›¸å½“ä¸€éƒ¨åˆ†èƒ½è€—å¯¹è®­ç»ƒé€Ÿåº¦æ²¡æœ‰è´¡çŒ®ï¼Œç§°ä¹‹ä¸ºâ€œèƒ½è€—å†—ä½™ï¼ˆenergy bloatï¼‰â€ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡æå‡ºäº†ä¸€ä¸ªçº¯è½¯ä»¶æ–¹æ³• Perseusï¼šé€šè¿‡å¯¹è®­ç»ƒè¿‡ç¨‹å»ºç«‹æ—¶é—´-èƒ½é‡æ¨¡å‹ï¼Œå¹¶åˆ©ç”¨å›¾å‰²ç®—æ³•ä¼˜åŒ–æ¯ä¸ªè®¡ç®—é˜¶æ®µçš„é€Ÿåº¦ï¼Œåœ¨ä¸é™ä½è®­ç»ƒååçš„å‰æä¸‹å‡å°‘å¤šè¾¾ 30% çš„èƒ½è€—ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æ— éœ€å®šåˆ¶ç¡¬ä»¶å³å¯å®ç°æ˜¾è‘—èŠ‚èƒ½ï¼ŒåŒæ—¶ä¿æŒæ¨¡å‹è®­ç»ƒæ—¶é—´åŸºæœ¬ä¸å˜ã€‚\näºŒã€è®ºæ–‡ç»“æ„\n\nèƒŒæ™¯ä¸åŠ¨æœºï¼ˆIntroduction &amp; Motivationï¼‰ï¼šä»‹ç»å¤§æ¨¡å‹è®­ç»ƒçš„èƒ½è€—ç°çŠ¶ï¼Œå¹¶å®šä¹‰äº†â€œèƒ½è€—å†—ä½™â€çš„æ¦‚å¿µï¼ŒåŒ…æ‹¬å†…åœ¨å‹ï¼ˆæµæ°´çº¿é˜¶æ®µä¸å‡è¡¡å¯¼è‡´ï¼‰å’Œå¤–åœ¨å‹ï¼ˆåŒæ­¥å¹¶è¡Œä¸­çš„æ…¢ç®¡çº¿å¯¼è‡´ï¼‰ä¸¤ä¸ªæ¥æºã€‚é€šè¿‡å¯¹GPT-3ç­‰æ¨¡å‹çš„åˆ†æï¼Œè¯´æ˜è¿™äº›èƒ½è€—æµªè´¹çš„å­˜åœ¨å’Œä¼˜åŒ–ç©ºé—´ã€‚\nPerseus æ–¹æ³•æ¦‚è§ˆï¼ˆPerseus Overviewï¼‰ï¼šæå‡º Perseus ç³»ç»Ÿçš„æ€»ä½“æ€è·¯ã€‚é¦–å…ˆç»™å‡ºç»Ÿä¸€çš„ä¼˜åŒ–æ¡†æ¶ï¼Œå°†å»é™¤å†…åœ¨å’Œå¤–åœ¨èƒ½è€—å†—ä½™å½¢å¼åŒ–ä¸ºæ—¶é—´-èƒ½é‡ä¼˜åŒ–é—®é¢˜ï¼›ç„¶åä»‹ç» Perseus çš„æ¶æ„ï¼ŒåŒ…æ‹¬è®­ç»ƒæ¡†æ¶ä¸­çš„å®¢æˆ·ç«¯å’Œç‹¬ç«‹çš„æœåŠ¡å™¨ç»„ä»¶ï¼Œä»¥åŠå…¶å·¥ä½œæµç¨‹ã€‚\nä¼˜åŒ–ç®—æ³•ä¸å®ç°ï¼ˆOptimization Algorithm &amp; Implementationï¼‰ï¼šè¯¦ç»†æè¿°è®ºæ–‡çš„æ ¸å¿ƒç®—æ³•ã€‚ä½œè€…è¯æ˜ç›´æ¥æ±‚è§£æœ€ä½³æ—¶é—´-èƒ½é‡æŠ˜ä¸­æ–¹æ¡ˆæ˜¯ NP-éš¾çš„ï¼Œå› æ­¤é‡‡ç”¨æ¾å¼›å¤„ç†å’Œå›¾å‰²ç®—æ³•é«˜æ•ˆå¯»æ‰¾æ¥è¿‘æœ€ä¼˜çš„æ–¹æ¡ˆã€‚è¯¥éƒ¨åˆ†è¿˜ä»‹ç»äº† Perseus ç³»ç»Ÿå¦‚ä½•ä¸ç°æœ‰è®­ç»ƒæ¡†æ¶é›†æˆã€å¯¹æ¯ä¸ªè®¡ç®—é˜¶æ®µè¿›è¡Œèƒ½è€—æµ‹é‡å’Œé¢‘ç‡æ§åˆ¶çš„å…·ä½“å®ç°ç»†èŠ‚ã€‚\nå®éªŒè®¾è®¡ä¸ç»“æœï¼ˆEvaluationï¼‰ï¼šä»‹ç»å®éªŒç¯å¢ƒå’Œè¯„ä¼°æŒ‡æ ‡ï¼ˆå¦‚å•è¿­ä»£èƒ½è€—ã€è®­ç»ƒé€Ÿåº¦ã€èƒ½è€—é™ä½æ¯”ç­‰ï¼‰ï¼Œå¹¶ç»™å‡ºåœ¨ GPT-3ã€BERTã€T5ã€Bloom ç­‰å¤šç§å¤§å‹æ¨¡å‹ä¸Šçš„å®éªŒç»“æœã€‚åŒ…æ‹¬æ— æ…¢èŠ‚ç‚¹æƒ…å†µä¸‹çš„å†…åœ¨èƒ½è€—å†—ä½™å»é™¤æ•ˆæœï¼Œä»¥åŠæ¨¡æ‹Ÿæ…¢èŠ‚ç‚¹å‡ºç°æ—¶å¤–åœ¨èƒ½è€—å†—ä½™é™ä½çš„æ•ˆæœå¯¹æ¯”ã€‚\nç›¸å…³å·¥ä½œä¸ç»“è®ºï¼ˆRelated Work &amp; Conclusionï¼‰ï¼šå¯¹æ¯” Perseus ä¸ä¹‹å‰çš„èƒ½è€—ä¼˜åŒ–æ–¹æ¡ˆï¼ˆå¦‚ Zeusã€EnvPipe ç­‰ï¼‰çš„å¼‚åŒï¼Œå¼ºè°ƒæœ¬ç ”ç©¶çš„è½¯ä»¶ä¼˜å…ˆå’Œé€šç”¨æ€§ä¼˜åŠ¿ï¼Œå¹¶æ€»ç»“äº†è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œå¯¹æœªæ¥å¯æŒç»­è®­ç»ƒçš„æ„ä¹‰ã€‚\n\n\næ ¸å¿ƒæ€æƒ³ï¼š å¤§è§„æ¨¡æ¨¡å‹è®­ç»ƒä¸­å­˜åœ¨æ˜¾è‘—çš„èƒ½æºæµªè´¹ï¼ˆå› æµæ°´çº¿ä¸å¹³è¡¡å’Œæ…¢èŠ‚ç‚¹ç­‰å¾…ï¼‰ã€‚Perseus ç³»ç»Ÿé€šè¿‡æ„å»ºè®­ç»ƒè¿­ä»£çš„æœ‰å‘æ— ç¯å›¾æ¨¡å‹ï¼Œåº”ç”¨å›¾å‰²ä¼˜åŒ–ç®—æ³•ç²¾ç¡®å‡ç¼“éå…³é”®è·¯å¾„è®¡ç®—é€Ÿåº¦ï¼Œå®ç°äº†åœ¨ä¸å½±å“è®­ç»ƒè¿›åº¦çš„æƒ…å†µä¸‹å°½å¯èƒ½é™ä½èƒ½è€—ï¼Œä¸º AI è®­ç»ƒå¸¦æ¥äº†ç¡¬ä»¶æ— å…³çš„èŠ‚èƒ½å¢ç›Šã€‚\n\nä¸‰ã€æ–¹æ³•ä¸ç³»ç»Ÿè®¾è®¡\nPerseus çš„æ•´ä½“è®¾è®¡å›´ç»•ä¸€ä¸ªæ ¸å¿ƒæ€æƒ³ï¼šæ ¹æ®è®­ç»ƒè¿­ä»£ä¸­å„è®¡ç®—ä»»åŠ¡çš„é‡è¦ç¨‹åº¦ï¼Œè°ƒæ•´å…¶æ‰§è¡Œé€Ÿåº¦ä»¥èŠ‚çœèƒ½è€—ã€‚ä¸ºæ­¤ï¼Œä½œè€…éœ€è¦è§£å†³ä»¥ä¸‹å­é—®é¢˜ï¼š - è¯†åˆ«ä¸é‡åŒ–èƒ½è€—å†—ä½™ï¼šå¦‚ä½•æ‰¾åˆ°æµæ°´çº¿ä¸­å“ªäº›é˜¶æ®µæˆ–ç®—å­æ‰§è¡Œå¾—â€œè¿‡å¿«â€è€Œæ— ç›Šäºæ€»è€—æ—¶ï¼Ÿ - è‡ªåŠ¨åŒ–å‡é€Ÿç­–ç•¥è§„åˆ’ï¼šå¦‚ä½•å†³å®šå¯¹å“ªäº›è®¡ç®—é™ä½é€Ÿç‡ã€é™ä½å¤šå°‘ï¼Œæ‰èƒ½æ—¢å‡å°‘èƒ½è€—åˆä¸å»¶é•¿è®­ç»ƒè¿­ä»£æ—¶é—´ï¼Ÿ - åº”å¯¹æ…¢èŠ‚ç‚¹ï¼ˆstragglerï¼‰ï¼šå½“å¹¶è¡Œçš„æŸä¸€æ¡è®­ç»ƒæµæ°´çº¿æ„å¤–å˜æ…¢æ—¶ï¼Œæ€æ ·åŠ¨æ€è°ƒæ•´å…¶ä»–æµæ°´çº¿çš„é€Ÿåº¦ä»¥é¿å…èƒ½æºæµªè´¹ï¼Ÿ - ç³»ç»Ÿé›†æˆä¸å¼€é”€ï¼šå¦‚ä½•å°†ä¸Šè¿°ä¼˜åŒ–åµŒå…¥ç°æœ‰è®­ç»ƒæ¡†æ¶ï¼Œå¹¶å°†é¢å¤–çš„èƒ½è€—æµ‹é‡å’Œæ§åˆ¶å¼€é”€é™è‡³æœ€ä½ï¼Ÿ\n3.1 æ ¸å¿ƒæ¨¡å—ä¸€è§ˆ\n\nPerseus å®¢æˆ·ç«¯åº“ï¼šåµŒå…¥åœ¨è®­ç»ƒæ¡†æ¶ä¸­ï¼Œè´Ÿè´£åœ¨æ¯æ¬¡è¿­ä»£ä¸­å¯¹å„ä¸ªå‰å‘/åå‘è®¡ç®—æ­¥éª¤è¿›è¡Œè®¡æ—¶å’Œèƒ½è€—æµ‹é‡ï¼Œå¹¶é€šè¿‡é©±åŠ¨æ¥å£åŠ¨æ€æ§åˆ¶ GPU çš„æ‰§è¡Œé¢‘ç‡ã€‚å®ƒç›¸å½“äºè®­ç»ƒæµç¨‹ä¸­çš„ä¼ æ„Ÿå™¨å’Œæ‰§è¡Œå™¨ï¼Œç”¨äºé‡‡é›†èƒ½è€—æ•°æ®å¹¶è°ƒæ•´è®¡ç®—é€Ÿåº¦ã€‚\nPerseus æœåŠ¡å™¨ï¼šç‹¬ç«‹è¿è¡Œçš„ä¼˜åŒ–æœåŠ¡ã€‚å®ƒæ¥æ”¶å®¢æˆ·ç«¯ä¸Šä¼ çš„è®¡ç®—å›¾ç»“æ„å’Œæµ‹é‡æ•°æ®ï¼Œè¿è¡Œä¼˜åŒ–ç®—æ³•ç”Ÿæˆèƒ½é‡è°ƒåº¦æ–¹æ¡ˆï¼ˆenergy scheduleï¼‰ã€‚æ–¹æ¡ˆåŒ…å«æ¯ä¸ªè®¡ç®—èŠ‚ç‚¹åº”è¯¥ä»¥ä½•ç§é€Ÿåº¦æ‰§è¡Œã€‚æœåŠ¡å™¨è¿˜è´Ÿè´£ç›‘æ§è®­ç»ƒè¿‡ç¨‹ä¸­æ˜¯å¦å‡ºç°æ…¢èŠ‚ç‚¹ï¼Œå¹¶åœ¨éœ€è¦æ—¶åˆ‡æ¢èƒ½é‡æ–¹æ¡ˆåº”å¯¹ã€‚\næ—¶é—´-èƒ½é‡å‰æ²¿ä¼˜åŒ–å™¨ï¼šPerseus æœåŠ¡å™¨å†…çš„ç®—æ³•æ¨¡å—ã€‚é’ˆå¯¹è®­ç»ƒè¿­ä»£çš„æœ‰å‘æ— ç¯å›¾ (DAG) æ¨¡å‹ï¼Œè®¡ç®—æ‰€æœ‰å¯èƒ½çš„æ—¶é—´-èƒ½è€—æŠ˜ä¸­å¸•ç´¯æ‰˜å‰æ²¿ã€‚å®ƒè¿ç”¨é«˜æ•ˆçš„å›¾å‰²ç®—æ³•ï¼Œä»â€œå…¨é€Ÿè¿è¡Œâ€ï¼ˆæœ€çŸ­æ—¶é—´ã€æœ€é«˜èƒ½è€—ï¼‰å¼€å§‹ï¼Œé€æ­¥æšä¸¾åˆ°â€œå°½é‡èŠ‚èƒ½â€ï¼ˆæœ€é•¿å…è®¸æ—¶é—´ã€æœ€ä½èƒ½è€—ï¼‰ä¹‹é—´çš„ä¸€ç³»åˆ—æœ€ä¼˜æ–¹æ¡ˆï¼Œä¸ºåç»­å†³ç­–æä¾›å…¨é›†ã€‚\nåœ¨çº¿ç›‘æµ‹ä¸è°ƒæ•´æœºåˆ¶ï¼šå½“é›†ç¾¤ç›‘æ§æˆ–å®¢æˆ·ç«¯æ£€æµ‹åˆ°æŸä¸€æµæ°´çº¿å˜æ…¢ï¼ˆä¾‹å¦‚å› è¿‡çƒ­é™é¢‘æˆ–I/Oå¡é¡¿ï¼‰ï¼Œæ­¤æ¨¡å—å°†åŠæ—¶é€šçŸ¥ Perseus æœåŠ¡å™¨ã€‚æœåŠ¡å™¨æ®æ­¤ä»é¢„å…ˆç®—å¥½çš„å‰æ²¿æ–¹æ¡ˆä¸­æŒ‘é€‰åŒ¹é…å½“å‰è¾ƒé•¿è¿­ä»£æ—¶é—´çš„æ–¹æ¡ˆï¼Œä¸‹å‘ç»™å®¢æˆ·ç«¯æ‰§è¡Œï¼Œè®©å…¶ä»–èŠ‚ç‚¹æ”¾æ…¢æ­¥è°ƒä»¥çœç”µã€‚\n\n3.2 æ•°æ®æµä¸æ§åˆ¶æµ\n\nåˆå§‹åŒ–é…ç½®ï¼šåœ¨è®­ç»ƒå¼€å§‹æ—¶ï¼Œç”¨æˆ·åœ¨è®­ç»ƒè„šæœ¬ä¸­å¯ç”¨ Perseusï¼Œå¹¶æä¾›æ¨¡å‹çš„åˆ†å¸ƒå¼å¹¶è¡Œé…ç½®ï¼ˆæ•°æ®å¹¶è¡Œåº¦ã€æµæ°´çº¿åˆ†æ®µã€å¼ é‡å¹¶è¡Œç­‰ï¼‰ã€‚Perseus å®¢æˆ·ç«¯æ®æ­¤æ„å»ºè¯¥æ¨¡å‹å•æ¬¡è¿­ä»£çš„è®¡ç®— DAGï¼Œå°†æ¯ä¸ªå‰å‘å’Œåå‘å­ä»»åŠ¡ä½œä¸ºèŠ‚ç‚¹ã€‚æœåŠ¡å™¨è®°å½•ä¸‹ DAG ç»“æ„ã€‚\nåŸºå‡†å‰–æï¼šæ­£å¼è®­ç»ƒå‰ï¼ŒPerseus å®¢æˆ·ç«¯å¯¹æ¯ä¸ªæµæ°´çº¿é˜¶æ®µè¿›è¡Œä¸€æ¬¡Profiling å‰–æã€‚å®ƒä¼šä»¤å„é˜¶æ®µä»¥é»˜è®¤æœ€é«˜é¢‘ç‡è¿è¡Œä¸€ä¸ªè¿­ä»£ï¼Œæµ‹é‡æ¯ä¸ªèŠ‚ç‚¹ï¼ˆç®—å­å—ï¼‰çš„æ‰§è¡Œæ—¶é—´å’Œèƒ½è€—ï¼ˆé€šè¿‡ GPU åŠŸè€—è®¡æ•°å™¨ï¼‰ã€‚è¿™äº›æµ‹é‡å€¼å‘é€ç»™ Perseus æœåŠ¡å™¨ã€‚\nç¦»çº¿ä¼˜åŒ–ï¼šPerseus æœåŠ¡å™¨å°† DAG å’Œæµ‹é‡æ•°æ®ä½œä¸ºè¾“å…¥ï¼Œè¿è¡Œæ—¶é—´-èƒ½é‡å‰æ²¿ä¼˜åŒ–ç®—æ³•ã€‚è¯¥ç®—æ³•å¯»æ‰¾åœ¨ä¸åŒè¿­ä»£æ—¶é—´é™åˆ¶ä¸‹çš„æœ€å°èƒ½è€—æ–¹æ¡ˆï¼Œå¹¶è¾“å‡ºä¸€ç³»åˆ—å¯èƒ½çš„â€œé¢‘ç‡è®¡åˆ’â€ï¼ˆå³å“ªä¸ªè®¡ç®—èŠ‚ç‚¹ç”¨é«˜é¢‘ï¼Œå“ªä¸ªé™é¢‘ï¼‰ã€‚\næ–¹æ¡ˆä¸‹å‘ï¼šæœåŠ¡å™¨é€‰æ‹©å…¶ä¸­è¿­ä»£æ—¶é—´ç­‰äºåŸºå‡†æœ€å¿«æ—¶é—´çš„æ–¹æ¡ˆï¼ˆå³ä¸é™ä½ååä½†èƒ½è€—æœ€ä½çš„ç»„åˆï¼‰ä½œä¸ºåˆå§‹è¿è¡Œè®¡åˆ’ï¼Œå‘é€ç»™å®¢æˆ·ç«¯ã€‚è¿™ä¸ªè®¡åˆ’å‘Šè¯‰æ¯ä¸ª GPU çš„å®¢æˆ·ç«¯åœ¨æ‰§è¡Œæ¯ä¸ªå…·ä½“è®¡ç®—æ—¶åº”ä½¿ç”¨çš„é¢‘ç‡ã€‚\nè¿­ä»£æ‰§è¡Œï¼šè®­ç»ƒæ­£å¼å¼€å§‹ï¼Œå„ GPU æŒ‰ç…§è®¡åˆ’è°ƒæ•´é¢‘ç‡æ‰§è¡Œæ¯ä¸ªå‰å‘/åå‘è®¡ç®—ã€‚Perseus å®¢æˆ·ç«¯åœ¨åå°æŒç»­ç›‘æ§å®é™…ç”¨æ—¶ï¼Œç¡®ä¿å„é˜¶æ®µæ²¡æœ‰å› é™é¢‘è€Œæ‹–æ…¢æ•´ä½“è¿›åº¦ã€‚å¦‚æœå‘ç°åå·®ï¼Œå¯ä»¥æç¤ºæœåŠ¡å™¨ä¼˜åŒ–ã€‚\næ…¢èŠ‚ç‚¹åº”å¯¹ï¼šè‹¥åœ¨æŸæ¬¡è¿­ä»£ä¸­æ£€æµ‹åˆ°æŸä¸€æ•°æ®å¹¶è¡Œåˆ†ç»„è€—æ—¶å¼‚å¸¸å¢é•¿ï¼ˆæ…¢èŠ‚ç‚¹å‡ºç°ï¼‰ï¼ŒPerseus å®¢æˆ·ç«¯æˆ–é›†ç¾¤ç®¡ç†ä¼šå‘å‡ºè­¦æŠ¥ï¼Œå‘ŠçŸ¥æœåŠ¡å™¨è¯¥è¿­ä»£é¢„è®¡è€—æ—¶ ğ‘‡â€² é•¿äºæ­£å¸¸ã€‚æœåŠ¡å™¨éšå³æŸ¥æ‰¾é¢„è®¡ç®—çš„å‰æ²¿ä¸­å¯¹åº” ğ‘‡â€² çš„èƒ½è€—æœ€ä¼˜æ–¹æ¡ˆï¼Œå¹¶åœ¨ä¸‹ä¸€ä¸ªè¿­ä»£å°†æ­¤æ–°æ–¹æ¡ˆä¸‹å‘å®¢æˆ·ç«¯ã€‚\nåŠ¨æ€è°ƒæ•´ï¼šæ”¶åˆ°æ–°æ–¹æ¡ˆåï¼Œå…¶å®ƒéæ…¢èŠ‚ç‚¹çš„ GPU å®¢æˆ·ç«¯å°†åœ¨åç»­è¿­ä»£ä¸­é‡‡ç”¨æ›´ä½é¢‘ç‡æ‰§è¡Œéƒ¨åˆ†è®¡ç®—ï¼Œä½¿è‡ªèº«è¿­ä»£æ—¶é—´æ”¾æ…¢æ¥è¿‘ ğ‘‡â€²ã€‚è¿™æ ·ä¸€æ¥ï¼Œæ‰€æœ‰å¹¶è¡Œæµæ°´çº¿å‡ ä¹åŒæ­¥å®Œæˆï¼Œé¿å…äº†åŸæœ¬ä¼šç­‰å¾…æ…¢èŠ‚ç‚¹çš„é‚£äº› GPU ç™½ç™½çƒ§èƒ½è€—ã€‚\næŒç»­è®­ç»ƒä¸æ”¶æ•›ï¼šåœ¨æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒPerseus ä¸æ–­é‡å¤ä¸Šè¿°ç›‘æµ‹å’Œä¼˜åŒ–ã€‚æ­£å¸¸æƒ…å†µä¸‹ç³»ç»Ÿä¸€ç›´ä»¥èŠ‚èƒ½æ–¹æ¡ˆè¿è¡Œï¼›å¦‚æ…¢èŠ‚ç‚¹æƒ…å†µæ¶ˆå¤±ï¼ˆä¾‹å¦‚å†·å´åæ€§èƒ½æ¢å¤ï¼‰ï¼ŒæœåŠ¡å™¨å¯å†æ¬¡é€‰ç”¨æ›´å¿«çš„æ–¹æ¡ˆã€‚è®­ç»ƒå®Œæˆæ—¶ï¼Œå„èŠ‚ç‚¹çš„æ€»èƒ½è€—æ˜¾è‘—é™ä½ï¼Œä½†æ€»è€—æ—¶å‡ ä¹ä¸æœªå¯ç”¨ Perseus æ—¶ç›¸åŒã€‚\n\n3.3 å…³é”®å‡è®¾ä¸é€‚ç”¨èŒƒå›´\n\nè¿­ä»£æµç¨‹ç¨³å®šå¯å»ºæ¨¡ï¼šå‡è®¾æ¨¡å‹æ¯æ¬¡è¿­ä»£æ‰§è¡Œçš„è®¡ç®—å›¾æ˜¯å›ºå®šçš„ï¼ˆä¾‹å¦‚æ¯æ­¥å‰å‘åå‘æ“ä½œåºåˆ—ç›¸åŒï¼‰ã€‚è¿™ä½¿å¾— Perseus å¯ä»¥ç”¨ä¸€æ¬¡ Profiling æ„å»ºå¯é çš„ DAG æ¨¡å‹ã€‚å¦‚æœè®­ç»ƒè¿‡ç¨‹ä¸­æ¨¡å‹è®¡ç®—å‘ç”Ÿé¢‘ç¹å˜åŒ–ï¼ˆå¦‚å¯å˜åºåˆ—é•¿åº¦ã€åŠ¨æ€ç½‘ç»œç»“æ„ï¼‰ï¼Œåˆ™é¢„å…ˆä¼˜åŒ–çš„æ–¹æ¡ˆå¯èƒ½å¤±æ•ˆï¼Œéœ€é‡æ–°åˆ†æï¼Œä¼šå¢åŠ å¼€é”€ã€‚\nGPU é¢‘ç‡å¯è°ƒä¸”èƒ½è€—å•è°ƒï¼šPerseus å‡è®¾æ‰€ç”¨ GPU æ”¯æŒå¤šä¸ªç¦»æ•£é¢‘ç‡/åŠŸç‡çŠ¶æ€ï¼Œå¹¶ä¸”é™ä½æ ¸å¿ƒé¢‘ç‡èƒ½é™ä½åŠŸè€—ä¸”ä¸ä¼šå‡ºç°åç›´è§‰çš„æ€§èƒ½å¼‚å¸¸ï¼ˆä¾‹å¦‚æ²¡æœ‰é¢‘ç‡é™ä½å´åŠŸè€—ä¸é™çš„æƒ…å†µï¼‰ã€‚è‹¥ç¡¬ä»¶ä¸æ”¯æŒ DVFS æˆ–é¢‘ç‡ä¸èƒ½è€—å…³ç³»ä¸ç¨³å®šï¼Œåˆ™è¯¥æ–¹æ³•æ— æ³•æ­£å¸¸å·¥ä½œã€‚\nå­˜åœ¨è®¡ç®—ä¸å¹³è¡¡å’Œå¶å‘æ…¢å¡ï¼šæ–¹æ³•å‡å®šå®é™…è®­ç»ƒä¸­ç¡®å®å­˜åœ¨å¯ä¼˜åŒ–çš„èƒ½è€—å†—ä½™ï¼Œä¾‹å¦‚æµæ°´çº¿å„é˜¶æ®µè´Ÿè½½ä¸å‡ã€éƒ¨åˆ†è¿­ä»£å‡ºç°æ…¢å¡ç­‰ã€‚å¦‚æœè®­ç»ƒä»»åŠ¡æœ¬èº«å·²ç»éå¸¸å¹³è¡¡ï¼ˆæ¯ä¸ªé˜¶æ®µè€—æ—¶å‡ ä¹ç›¸ç­‰ï¼‰ä¸”ä»æ— æ…¢å¡å‡ºç°ï¼Œé‚£ä¹ˆ Perseus çš„èŠ‚èƒ½ç©ºé—´ä¼šå¾ˆæœ‰é™ï¼ˆåªæœ‰å¾ˆå°çš„èƒ½è€—æ”¹å–„ï¼Œä¸” Profiling ç­‰å¸¦æ¥çš„é¢å¤–å¤æ‚åº¦æœªå¿…å€¼å¾—ï¼‰ã€‚\nåŒé˜¶æ®µ GPU æ€§èƒ½ä¸€è‡´ï¼šé’ˆå¯¹å¼ é‡å¹¶è¡Œç­‰åœºæ™¯ï¼ŒPerseus å‡è®¾æ¯ä¸ªæµæ°´çº¿é˜¶æ®µå†…çš„å„ GPU æ‹¥æœ‰ç›¸ä¼¼çš„æ€§èƒ½ç‰¹æ€§ã€‚å®é™…åº”ç”¨ä¸­é€šå¸¸å¤šå¡æ˜¯åŒå‹å·ã€æ‰§è¡Œç›¸åŒæ“ä½œï¼Œè¿™ä¸€å‡è®¾æˆç«‹ã€‚å› æ­¤åªéœ€å‰–ææ¯ä¸ªé˜¶æ®µçš„ä¸€å°ä»£è¡¨ GPUå³å¯ï¼Œå°†è®¡ç®—è®¡åˆ’å¤åˆ¶åˆ°è¯¥é˜¶æ®µå…¶ä»– GPU ä¸Šã€‚å¦‚æœåŒä¸€é˜¶æ®µå­˜åœ¨ç¡¬ä»¶å·®å¼‚æˆ–è´Ÿè½½å·®å¼‚ï¼Œç”¨ä¸€ä¸ªä»£è¡¨å¯èƒ½ä¸å‡†ï¼Œæ–¹æ¡ˆæ•ˆæœä¼šä¸‹é™ã€‚\nå¤–éƒ¨æ…¢èŠ‚ç‚¹å¯è¢«åŠæ—¶æ£€æµ‹ï¼šPerseus å€šèµ–ç³»ç»Ÿèƒ½å¤Ÿå¿«é€Ÿè·çŸ¥æŸèŠ‚ç‚¹çš„å¼‚å¸¸å˜æ…¢ï¼ˆä¾‹å¦‚ GPU è¢«æ“ä½œç³»ç»Ÿé™é¢‘æˆ–ç½‘ç»œå µå¡ï¼‰ã€‚å‡å¦‚æ…¢èŠ‚ç‚¹æœªè¢«åŠæ—¶å‘ç°å¹¶é€šçŸ¥ï¼Œé‚£ä¹ˆå…¶ä»–èŠ‚ç‚¹ä»ä¼šé«˜é€Ÿè¿è¡Œå¹¶ç­‰å¾…ï¼Œä»è€Œç»§ç»­æµªè´¹èƒ½é‡ã€‚æ‰€å¹¸å¾ˆå¤šé›†ç¾¤éƒ½æœ‰ç›‘æ§æ¸©åº¦/åŠŸè€—çš„æœºåˆ¶ï¼Œå¯ç”¨äºåŠæ—¶è§¦å‘ Perseus çš„è°ƒæ•´ã€‚\n\n3.4 æ•°å­¦å…¬å¼ä¸ç®—æ³•è§£è¯»\nè®ºæ–‡çš„æ–¹æ³•éƒ¨åˆ†åŸºäºä¸€ä¸ªèƒ½è€—ä¼˜åŒ–æ¨¡å‹ï¼Œå®ƒå°†æ¯æ¬¡è®­ç»ƒè¿­ä»£è§†ä¸ºä¸€ç»„æœ‰å…ˆåä¾èµ–çš„è®¡ç®—ä»»åŠ¡ã€‚ä¸‹é¢æ˜¯ä½œè€…æå‡ºçš„æ ¸å¿ƒä¼˜åŒ–ç›®æ ‡çš„æ•°å­¦æè¿°ï¼š\nåŸæ–‡ä¸­çš„å…¬å¼ï¼šè®¾è®­ç»ƒè¿­ä»£çš„è®¡ç®—å›¾åŒ…å« \\(n\\) ä¸ªè®¡ç®—èŠ‚ç‚¹ï¼Œæ¯ä¸ªèŠ‚ç‚¹ \\(i\\) æœ‰ä¸¤ç§æ‰§è¡Œæ¨¡å¼ï¼šé«˜é¢‘ï¼ˆå¿«é€Ÿï¼‰å’Œä½é¢‘ï¼ˆèŠ‚èƒ½ï¼‰ã€‚è®° \\(t_i(H), t_i(L)\\) ä¸ºä¸¤ç§æ¨¡å¼ä¸‹èŠ‚ç‚¹çš„æ‰§è¡Œæ—¶é—´ï¼Œ\\(e_i(H), e_i(L)\\) ä¸ºå¯¹åº”çš„èƒ½é‡æ¶ˆè€—ã€‚ç»™å®šä¸€ä¸ªè¿­ä»£æ—¶é—´ä¸Šé™ \\(T\\)ï¼ˆä¸æ…¢äºæ­¤æ—¶é—´å®Œæˆè¿­ä»£ï¼‰ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯ï¼š\n\\[\n\\min_{x_1,...,x_n \\in \\{H,L\\}} \\sum_{i=1}^{n} e_i(x_i) \\quad\n\\text{s.t. å¯¹äºè®¡ç®—å›¾ä¸­çš„æ¯ä¸€æ¡ä»èµ·ç‚¹åˆ°ç»ˆç‚¹çš„è·¯å¾„ } p: \\sum_{i \\in p} t_i(x_i) \\le T.\n\\]\nè¿™ä¸€å®šå¼è¡¨è¾¾äº†åœ¨ä¸è¶…è¿‡ç»™å®šè¿­ä»£æ—¶é•¿ \\(T\\) çš„å‰æä¸‹ï¼Œæœ€å°åŒ–æ€»èƒ½è€—ã€‚å…¶ä¸­çº¦æŸæ„å‘³ç€ï¼šæ— è®ºè®¡ç®—å›¾çš„å“ªæ¡è·¯å¾„ï¼ˆå³æµæ°´çº¿ä¸­å“ªä¸²å…ˆåæ‰§è¡Œçš„æ“ä½œï¼‰éƒ½ä¸èƒ½è¶…æ—¶ \\(T\\)ï¼Œå¦åˆ™å°±è¿åäº†æ€»æ—¶é—´é™åˆ¶ã€‚\\(x_i\\) æ˜¯å†³ç­–å˜é‡ï¼Œè¡¨ç¤ºç¬¬ \\(i\\) ä¸ªè®¡ç®—èŠ‚ç‚¹é‡‡ç”¨é«˜é¢‘ (H) è¿˜æ˜¯ä½é¢‘ (L) æ¨¡å¼ã€‚\né€æ­¥è§£é‡Šç¬¦å·å’Œå«ä¹‰ï¼šä¸Šå¼æ±‚å’Œé¡¹æ˜¯æ‰€æœ‰è®¡ç®—èŠ‚ç‚¹åœ¨æ‰€é€‰æ¨¡å¼ä¸‹çš„èƒ½é‡æ¶ˆè€—ä¹‹å’Œï¼Œä¹Ÿæ˜¯æˆ‘ä»¬è¦æœ€å°åŒ–çš„æ€»èƒ½è€—ã€‚è·¯å¾„æ—¶é—´çº¦æŸç¡®ä¿ä»»ä½•ä¸€æ¡å…³é”®è·¯å¾„çš„ç´¯è®¡æ‰§è¡Œæ—¶é—´ä¸è¶…è¿‡ \\(T\\)ï¼Œæ¢è¨€ä¹‹ï¼Œæ€»è¿­ä»£æ—¶é—´å—æœ€æ…¢çš„ä¸€æ¡æµæ°´çº¿è·¯å¾„å†³å®šï¼Œæˆ‘ä»¬å¿…é¡»è®©å®ƒä¸å˜é•¿ã€‚é€šè¿‡é€‰æ‹©ä¸€äº›èŠ‚ç‚¹é™é¢‘ï¼Œæˆ‘ä»¬å¯ä»¥å‡å°‘èƒ½è€—ï¼Œä½†å¦‚æœè¯¥èŠ‚ç‚¹ä½äºå…³é”®è·¯å¾„ä¸Šå°±ä¼šå¢åŠ æ€»æ—¶é—´ï¼Œå› æ­¤åªæœ‰ä¸åœ¨å…³é”®è·¯å¾„ï¼ˆæˆ–å…³é”®è·¯å¾„æœ‰å¯Œä½™ï¼‰çš„èŠ‚ç‚¹æ‰èƒ½é™é¢‘ã€‚\nç›´è§‚ç‰ˆç†è§£ï¼šä»¥ä¸Šä¼˜åŒ–ç›¸å½“äºèƒŒåŒ…é—®é¢˜çš„å˜ä½“ï¼šæ¯ä¸ªè®¡ç®—èŠ‚ç‚¹é™é¢‘å¯ä»¥â€œèŠ‚çœâ€ä¸€å®šèƒ½è€—ï¼Œä½†ä¼šâ€œèŠ±è´¹â€ä¸€äº›é¢å¤–æ—¶é—´ã€‚å¦‚æœæŸèŠ‚ç‚¹ä¸åœ¨å…³é”®è·¯å¾„ä¸Šï¼Œé‚£ä¹ˆå®ƒæœ¬æ¥å°±æœ‰ç©ºé—²æ—¶é—´å¯ä»¥åˆ©ç”¨ï¼Œé™é¢‘ç›¸å½“äºç”¨æ‰è¿™éƒ¨åˆ†ç©ºé—²è€Œä¸å½±å“æ€»ä½“æ—¶é—´ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯åœ¨ä¸ç»™è®­ç»ƒé€ æˆå»¶è¿Ÿçš„æƒ…å†µä¸‹ï¼ŒæŒ‘é€‰ä¸€ç»„èŠ‚ç‚¹é™é¢‘ï¼Œæœ€å¤§åŒ–èŠ‚çœçš„èƒ½è€—ã€‚å¯¹äºåŒæ­¥æ…¢èŠ‚ç‚¹åœºæ™¯ï¼Œä¸Šè¿° \\(T\\) å°†å¢å¤§ï¼ˆç”±æ…¢èŠ‚ç‚¹å†³å®šæ›´å¤§çš„è¿­ä»£æ—¶é—´ï¼‰ï¼Œåˆ™å…è®¸å…¶ä»–èŠ‚ç‚¹æœ‰æ›´å¤šé™é¢‘ä½™åœ°ï¼Œæˆ‘ä»¬å¯ä»¥å¯¹æ›´å¤šèŠ‚ç‚¹é™é¢‘æ¥èŠ‚çº¦èƒ½æºã€‚\nä½œè€…æå‡ºçš„å›¾å‰²ç®—æ³•æ­£æ˜¯ç”¨æ¥é«˜æ•ˆæ±‚è§£ä¸Šè¿°é—®é¢˜çš„æ¾å¼›ç‰ˆæœ¬ã€‚ç®€è¨€ä¹‹ï¼Œä»–ä»¬å°†è®¡ç®—å›¾è½¬åŒ–ä¸ºä¸€ä¸ªå¸¦å®¹é‡æƒé‡çš„ç½‘ç»œæµæ¨¡å‹ï¼Œå…¶ä¸­åˆ‡å‰²ç½‘ç»œç›¸å½“äºå†³å®šå“ªäº›èŠ‚ç‚¹ä»¥é«˜é¢‘ã€å“ªäº›ä»¥ä½é¢‘è¿è¡Œã€‚é€šè¿‡æœ€å°å‰²/æœ€å¤§æµç®—æ³•ï¼ˆå¦‚ Edmonds-Karpï¼‰ï¼Œå¯ä»¥åœ¨å¤šé¡¹å¼æ—¶é—´å†…æ‰¾åˆ°æ»¡è¶³æ—¶é—´çº¦æŸä¸‹èƒ½è€—æœ€å°çš„é™é¢‘æ–¹æ¡ˆã€‚ç®—æ³•ä¼šè¿­ä»£å¤šæ¬¡ï¼Œæ¯æ¬¡æŠŠå…¨å±€è¿­ä»£æ—¶é—´ \\(T\\) ç¼©çŸ­ä¸€ä¸ªå°å¢é‡ \\(\\tau\\)ï¼Œé‡æ–°æ±‚æœ€å°å‰²ï¼Œä»è€Œé€æ­¥æ¢ç´¢æ•´æ¡æ—¶é—´-èƒ½é‡å¸•ç´¯æ‰˜å‰æ²¿æ›²çº¿ã€‚å½“æ— æ³•å†ç¼©çŸ­è€Œä¸è¿åçº¦æŸæ—¶ï¼Œå°±æ‰¾åˆ°äº†æœ€çŸ­æ—¶é—´ \\(T_{min}\\) æ–¹æ¡ˆï¼›åä¹‹æœ€æ”¾æ¾çº¦æŸå¯è¾¾åˆ°æœ€ä½èƒ½è€—æ–¹æ¡ˆ \\(T_{max}\\)ã€‚Perseus å°†è¿™äº›è§£ç¦»æ•£åœ°å­˜å‚¨ï¼Œä¾›è¿è¡Œæ—¶å¿«é€ŸæŸ¥è¡¨ä½¿ç”¨ã€‚\nä¸å¸¸è§è®­ç»ƒæ ˆçš„å¯¹åº”å…³ç³»ï¼š - ä¸Šè¿°æ¨¡å—å¯¹åº”äºå¤§è§„æ¨¡è®­ç»ƒç³»ç»Ÿä¸­çš„å„å±‚é¢ï¼šPerseus å®¢æˆ·ç«¯ç±»ä¼¼äºåœ¨ è®­ç»ƒæ¡†æ¶å†…éƒ¨ï¼ˆå¦‚ Megatron-LM æˆ– DeepSpeedï¼‰å¢åŠ ä¸€ä¸ªæ€§èƒ½ç›‘æ§ä¸è°ƒé€Ÿæ¨¡å—ï¼Œå®ƒé’©ä½äº†å„ä¸ªç®—å­/å±‚çš„æ‰§è¡Œï¼›Perseus æœåŠ¡å™¨ç›¸å½“äºåœ¨ è°ƒåº¦å±‚ å¢åŠ ä¸€ä¸ªå…¨å±€ä¼˜åŒ–æœåŠ¡ï¼Œå†³å®šå„å¡çš„é€Ÿåº¦ç­–ç•¥ã€‚ - æ—¶é—´-èƒ½é‡å‰æ²¿ä¼˜åŒ–å™¨å¯ä»¥çœ‹ä½œè®­ç»ƒ pipeline è°ƒåº¦ç®—æ³•çš„æ‰©å±•ï¼Œä¸é€šå¸¸çš„ æµæ°´å¹¶è¡Œ/å¾®æ‰¹è°ƒåº¦ ç»“åˆåœ¨ä¸€èµ·ï¼šä¼ ç»Ÿè°ƒåº¦å…³æ³¨è´Ÿè½½å‡è¡¡å’Œæµæ°´çº¿æ°”æ³¡ï¼Œè€Œ Perseus åˆ™åœ¨æ­¤åŸºç¡€ä¸Šå¢åŠ äº†DVFS è°ƒåº¦ç»´åº¦æ¥é™ä½èƒ½è€—ã€‚ - GPU é¢‘ç‡æ§åˆ¶æ¶‰åŠåˆ°åº•å±‚ ç¡¬ä»¶ä¸é©±åŠ¨ï¼šç›¸å½“äºå¯¹ GPU å†…æ ¸æ—¶é’Ÿï¼ˆç±»ä¼¼äº kernel çº§åˆ«æ“ä½œï¼‰è¿›è¡Œè°ƒèŠ‚ã€‚ä¸€èˆ¬è®­ç»ƒæ ˆå¾ˆå°‘è§¦åŠè¿™ä¸€å±‚ï¼Œä½† Perseus é€šè¿‡æ ‡å‡†é©±åŠ¨æ¥å£ï¼ˆå¦‚ NVIDIA ç®¡ç†åº“ NVMLï¼‰æ¥å®ç°ï¼Œä¸æ¡†æ¶æœ¬èº«è§£è€¦ã€‚ - å¯¹äº æ•°æ®å¹¶è¡Œ çš„æ…¢èŠ‚ç‚¹æ£€æµ‹ï¼ŒPerseus åˆ©ç”¨äº†é›†ç¾¤ç›‘æ§æˆ–åˆ†å¸ƒå¼è®­ç»ƒçš„åŒæ­¥å±éšœæœºåˆ¶ï¼šè¿™ç±»ä¼¼äºåœ¨åˆ†å¸ƒå¼ä¼˜åŒ–å™¨ä¸­åŠ å…¥äº†ä¸€ä¸ª é€šä¿¡åè°ƒ ç»„ä»¶ï¼Œä¸€æ—¦å‘ç°åŒæ­¥ç­‰å¾…æ—¶é—´å¼‚å¸¸å¢å¤§ï¼Œå°±è§¦å‘é¢‘ç‡è®¡åˆ’è°ƒæ•´ã€‚ - æ•´ä½“è€Œè¨€ï¼ŒPerseus æ¨ªè·¨äº†è®­ç»ƒæ ˆçš„å¤šä¸ªå±‚æ¬¡ï¼šä¸Šæ¥è®­ç»ƒæ¡†æ¶ï¼ˆè´Ÿè´£æ’æ¡©å’Œæ‰§è¡Œç­–ç•¥ï¼‰ï¼Œä¸‹æ¢ç¡¬ä»¶é©±åŠ¨ï¼ˆè´Ÿè´£èƒ½è€—æ§åˆ¶ï¼‰ï¼Œå±äºç³»ç»Ÿä¸ç¡¬ä»¶ååŒä¼˜åŒ–èŒƒç•´ï¼Œä½†åˆå®Œå…¨ä»¥è½¯ä»¶å½¢å¼éƒ¨ç½²ï¼Œæ–¹ä¾¿é›†æˆåˆ°ç°æœ‰å¤§æ¨¡å‹è®­ç»ƒç®¡çº¿ä¸­ã€‚\nå››ã€å»ºæ¨¡æ–¹å¼ä¸è¯„ä¼°æŒ‡æ ‡\n4.1 é—®é¢˜æ˜¯å¦‚ä½•å½¢å¼åŒ–çš„ï¼Ÿ\nä½œè€…å°†èƒ½è€—ä¼˜åŒ–ç›®æ ‡å½¢å¼åŒ–ä¸ºä¸ŠèŠ‚æåˆ°çš„æ—¶é—´-èƒ½é‡ä¼˜åŒ–é—®é¢˜ã€‚å…¶æ ¸å¿ƒæ˜¯åœ¨è®­ç»ƒè¿­ä»£çš„ DAG æ¨¡å‹ä¸Šåšé€‰æ‹©ï¼šå“ªäº›ç®—å­ä»¥ä½åŠŸè€—æ¨¡å¼æ‰§è¡Œã€å“ªäº›ç»´æŒé«˜é€Ÿæ¨¡å¼ï¼Œä»¥æœ€å°åŒ–æ€»èƒ½è€—ä¸”ä¸è¶…å‡ºç»™å®šè¿­ä»£æ—¶é—´ä¸Šé™ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œä¼˜åŒ–å™¨éœ€è¦æ‰¾åˆ°è®­ç»ƒæ—¶é—´ \\(T\\) ä¸æ€»èƒ½è€— \\(E\\) çš„å¸•ç´¯æ‰˜æœ€ä¼˜ç»„åˆã€‚å½“æ²¡æœ‰æ…¢èŠ‚ç‚¹æ—¶ï¼Œè¿™ä¸ªä¸Šé™ \\(T\\) å°±æ˜¯åŸå§‹æœ€å¿«è¿­ä»£æ—¶é—´ï¼›å¦‚æœå‡ºç°æ…¢èŠ‚ç‚¹å¯¼è‡´æŸæ¬¡è¿­ä»£æ—¶é—´å˜ä¸º \\(T&#39; &gt; T_{min}\\)ï¼Œåˆ™ \\(T\\) æ”¹ä¸º \\(T&#39;\\)ã€‚åœ¨æ­¤çº¦æŸä¸‹ï¼Œæ¨¡å‹ä¼šè¿‘ä¼¼åœ°å°†é—®é¢˜è½¬åŒ–ä¸ºä¸€ä¸ª0-1 å†³ç­–é—®é¢˜ï¼ˆæ¯ä¸ªèŠ‚ç‚¹é™é¢‘ä¸å¦ï¼‰ï¼Œå¹¶é€šè¿‡å›¾å‰²/æµç½‘ç»œçš„æ–¹æ³•é«˜æ•ˆæœç´¢æ»¡è¶³æ¡ä»¶çš„è§£ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè®ºæ–‡è¯æ˜ç›´æ¥æ±‚å…¨å±€æœ€ä¼˜å¸•ç´¯æ‰˜å‰æ²¿æ˜¯ NP-å›°éš¾çš„ï¼Œå› æ­¤ä»–ä»¬é‡‡ç”¨äº†ä¸Šè¿°æ¾å¼› + è¿­ä»£çš„æ–¹æ³•æ¥é€¼è¿‘æ±‚è§£ã€‚\nåœ¨å»ºæ¨¡è¿‡ç¨‹ä¸­ï¼Œä½œè€…åšäº†ä¸€äº›ç®€åŒ–å‡è®¾ï¼šä¾‹å¦‚ï¼Œå°† GPU é¢‘ç‡æ§åˆ¶ç¦»æ•£ä¸ºæœ‰é™çš„å‡ æ¡£ï¼ˆé€šå¸¸åªè€ƒè™‘æœ€é«˜å’Œæœ€ä½ä¸¤æ¡£ï¼Œæˆ–å‡ æ¡£å…¸å‹é¢‘ç‡ï¼‰è€Œéè¿ç»­å˜é‡ï¼›å°†é€šä¿¡ç­‰å¾…è§†ä¸ºå›ºå®šè€—æ—¶æ“ä½œèŠ‚ç‚¹ï¼ˆä¸èƒ½ç¼©çŸ­ï¼Œåªèƒ½é€šè¿‡é™é¢‘å¡«å……ï¼‰ï¼›å‡å®šæ¯æ¬¡è¿­ä»£ä¸­æ…¢èŠ‚ç‚¹çš„å½±å“å¯ä»¥é€šè¿‡è®¾å®šä¸€ä¸ªæ–°çš„ç»Ÿä¸€è¿­ä»£æ—¶é—´æ¥å¤„ç†ã€‚è¿™äº›ç®€åŒ–ä½¿é—®é¢˜æ˜“äºè®¡ç®—ï¼Œä½†ä¹Ÿæ„å‘³ç€æŸäº›æ›´ç»†ç²’åº¦çš„åŠ¨æ€ï¼ˆå¦‚é¢‘ç‡è¿ç»­è°ƒèŠ‚ã€æ…¢èŠ‚ç‚¹çš„ä¸´æ—¶æŠ–åŠ¨ï¼‰æœªè¢«ç›´æ¥å»ºæ¨¡ã€‚\n4.2 æ ¸å¿ƒè¯„ä¼°æŒ‡æ ‡\nè®ºæ–‡ä¸ºäº†éªŒè¯ Perseus çš„æ•ˆæœï¼Œé‡‡ç”¨äº†å¤šæ–¹é¢çš„æŒ‡æ ‡æ¥è¯„ä¼°ï¼š - å•è¿­ä»£èƒ½é‡æ¶ˆè€—ï¼ˆJouleï¼‰ï¼šæ¯å®Œæˆä¸€æ¬¡è®­ç»ƒè¿­ä»£æ¶ˆè€—çš„èƒ½é‡ï¼Œé€šå¸¸é€šè¿‡ç´¯ç§¯ GPU å®æ—¶åŠŸç‡å¾—åˆ°ã€‚è¿™ä¸ªæŒ‡æ ‡ç›´æ¥ä½“ç°äº†èƒ½è€—ä¼˜åŒ–çš„æˆæœâ€”â€”Perseus å¸Œæœ›é™ä½æ¯è¿­ä»£èƒ½è€—ï¼ŒåŒæ—¶ä¸å½±å“åˆ«çš„æŒ‡æ ‡ã€‚ - è®­ç»ƒåå/è¿­ä»£æ—¶é•¿ï¼šé€šå¸¸ä»¥æ¯æ­¥è¿­ä»£æ‰€éœ€çš„æ—¶é—´ï¼ˆç§’ï¼‰æˆ–æ¯ç§’å¤„ç†çš„æ ·æœ¬æ•°æ¥è¡¨ç¤ºã€‚ä¿æŒååä¸ä¸‹é™æ˜¯å…³é”®ç›®æ ‡ï¼Œå› æ­¤ä¼šæ¯”è¾ƒå¯ç”¨ Perseus å‰åçš„è¿­ä»£æ—¶é—´å˜åŒ–ã€‚å¦‚æœæ…¢èŠ‚ç‚¹åœºæ™¯ä¸‹å¿…ç„¶å˜æ…¢ï¼Œåˆ™å…³æ³¨ Perseus æ˜¯å¦é¿å…é¢å¤–æ”¾æ…¢å…¶å®ƒèŠ‚ç‚¹ã€‚ - èƒ½è€—èŠ‚çœæ¯”ä¾‹ï¼šç›¸å¯¹äº baseline æœªä¼˜åŒ–æ—¶çš„èƒ½è€—ä¸‹é™ç™¾åˆ†æ¯”ã€‚ä¾‹å¦‚â€œèƒ½è€—é™ä½ 20%â€ç­‰ã€‚è¿™æ±‡æ€»äº†èŠ‚èƒ½æ•ˆæœï¼Œåˆ†å†…åœ¨å‹ï¼ˆæ— æ…¢èŠ‚ç‚¹æ—¶ï¼‰å’Œå¤–åœ¨å‹ï¼ˆæœ‰æ…¢èŠ‚ç‚¹æ—¶é¢å¤–èŠ‚èƒ½ï¼‰ä¸¤ç§æƒ…å½¢æŠ¥å‘Šï¼Œè¯´æ˜ Perseus å¯¹ä¸åŒåœºæ™¯çš„è´¡çŒ®ã€‚ - å¹³å‡åŠŸç‡é™ä½ï¼šè®­ç»ƒè¿‡ç¨‹ä¸­ GPU çš„å¹³å‡åŠŸç‡ï¼ˆç“¦ç‰¹ï¼‰ã€‚è¿™ä»ä¾›ç”µè§†è§’è¯„ä¼°ï¼ŒPerseus é€šè¿‡é™ä½ä¸å¿…è¦åŠŸè€—ï¼Œèƒ½æŠŠ GPU å¹³å‡åŠŸç‡é™åˆ¶åœ¨è¾ƒä½æ°´å¹³ï¼Œæœ‰åŠ©äºç¼“è§£æ•°æ®ä¸­å¿ƒä¾›ç”µç“¶é¢ˆã€‚å¹³å‡åŠŸç‡ = èƒ½è€—/æ—¶é—´ï¼Œå› æ­¤è¯¥æŒ‡æ ‡ä¸å‰ä¸¤ä¸ªå¯†åˆ‡ç›¸å…³ã€‚ - ç³»ç»Ÿå¼€é”€ï¼šåŒ…æ‹¬ Profiling é˜¶æ®µè€—æ—¶ã€ä¼˜åŒ–ç®—æ³•è¿è¡Œæ—¶é—´ç­‰ã€‚è™½ç„¶ä¸æ˜¯ä¸»è¦æ€§èƒ½æŒ‡æ ‡ï¼Œä½†è®ºæ–‡æŠ¥å‘Šäº†è¿™äº›æ•°å€¼ä»¥è¯æ˜ Perseus å¸¦æ¥çš„é¢å¤–æ—¶é—´å¼€é”€å¾ˆå°ï¼ˆä¾‹å¦‚å‰–æåå‡ åˆ†é’Ÿï¼Œç›¸æ¯”é•¿è¾¾æ•°å¤©çš„è®­ç»ƒå¯ä»¥å¿½ç•¥ä¸è®¡ï¼‰ã€‚ - è´Ÿè½½ä¸å¹³è¡¡åº¦ï¼ˆèƒŒæ™¯æŒ‡æ ‡ï¼‰ï¼šè®ºæ–‡è¿˜åˆ—ä¸¾äº†å„æ¨¡å‹åœ¨ä¸åŒå¹¶è¡Œé…ç½®ä¸‹çš„æµæ°´çº¿ä¸å¹³è¡¡æ¯”ï¼Œå³æœ€é•¿ stage æ—¶é—´ä¸æœ€çŸ­ stage æ—¶é—´ä¹‹æ¯”ã€‚è¿™ä¸æ˜¯ç®—æ³•æ•ˆæœæŒ‡æ ‡ï¼Œä½†èƒ½è¯´æ˜ä¸åŒæ¨¡å‹çš„å…ˆå¤©ä¸å¹³è¡¡ç¨‹åº¦å¦‚ä½•å½±å“èŠ‚èƒ½ç©ºé—´ï¼ˆä¸å¹³è¡¡è¶Šå¤§ï¼Œæ½œåœ¨èŠ‚èƒ½è¶Šå¤šï¼‰ã€‚\näº”ã€ä¸»è¦å®éªŒå‘ç°\n\næ— ååæŸå¤±çš„èƒ½è€—é™ä½ï¼šåœ¨æ²¡æœ‰æ…¢èŠ‚ç‚¹çš„æ­£å¸¸è®­ç»ƒä¸­ï¼ŒPerseus å¯¹å¤šç§æ¨¡å‹éƒ½å®ç°äº†æ˜æ˜¾çš„èŠ‚èƒ½è€Œå‡ ä¹ä¸å¢åŠ è®­ç»ƒæ—¶é—´ã€‚ä¾‹å¦‚ï¼Œåœ¨ GPT-3ã€BERTã€T5 ç­‰æ¨¡å‹ä¸Šï¼Œæ¯æ­¥è¿­ä»£èƒ½è€—å¹³å‡é™ä½çº¦ 10%~20%ï¼Œè€Œè¿­ä»£è€—æ—¶å˜åŒ–åœ¨ 1% ä»¥å†…ï¼Œè¾¾åˆ°â€œé›¶æˆæœ¬çœç”µâ€çš„ç†æƒ³æ•ˆæœã€‚\nåº”å¯¹æ…¢èŠ‚ç‚¹æ•ˆæœæ˜¾è‘—ï¼šæ¨¡æ‹Ÿæ•°æ®å¹¶è¡Œçš„æŸä¸€ GPU é™é€Ÿï¼ˆæ¯”å¦‚æ¸©åº¦è¿‡é«˜é™é¢‘ï¼‰åœºæ™¯ä¸‹ï¼ŒPerseus èƒ½è®©å…¶ä»– GPU è‡ªåŠ¨é™é€Ÿï¼Œä¸æ…¢å¡ä¿æŒåŒæ­¥ï¼Œå‡ ä¹æ¶ˆé™¤é¢å¤–çš„èƒ½æºæµªè´¹ã€‚å®éªŒæ˜¾ç¤ºï¼Œå½“å‡ºç° 10% çš„è¿­ä»£å˜æ…¢æ—¶ï¼Œå…¶ä½™ GPU è·Ÿéšé™é¢‘å¯å›æ”¶çº¦ 70% ä»¥ä¸Šæœ¬å¯æµªè´¹çš„èƒ½é‡ã€‚\nä¼˜äºæ—¢æœ‰æ–¹æ¡ˆï¼šä¸æ­¤å‰çš„èƒ½è€—ä¼˜åŒ–ç­–ç•¥ç›¸æ¯”ï¼ŒPerseus çš„æ•ˆæœæ›´å…¨é¢ã€‚ç›¸è¾ƒåªå¤„ç†æµæ°´çº¿ä¸å¹³è¡¡çš„ EnvPipeï¼ŒPerseus åœ¨ç›¸åŒæ¨¡å‹ä¸ŠèŠ‚èƒ½æ•ˆæœæå‡ä¸€å€ä»¥ä¸Šï¼›è€Œç›¸è¾ƒä¸“æ³¨å• GPU åŠŸè€—è°ƒèŠ‚çš„ Zeusï¼ŒPerseus åœ¨å¤š GPU åœºæ™¯ä¸‹è¾¾åˆ°äº†æ›´ä½çš„èƒ½è€—-æ—¶é—´æŠ˜ä¸­æ›²çº¿ï¼ŒPareto å‰æ²¿å…¨é¢å ä¼˜ã€‚\né€‚ç”¨äºå¤šç§æ¨¡å‹å’Œç¡¬ä»¶ï¼šå®éªŒè¦†ç›–äº† Transformer è¯­è¨€æ¨¡å‹ã€å·ç§¯ç½‘ç»œç­‰ï¼Œè§„æ¨¡ä»åäº¿åˆ°åƒäº¿å‚æ•°ï¼ŒGPU åŒ…æ‹¬ A100 å’Œ A40 ç­‰ã€‚ç»“æœè¡¨æ˜ Perseus æ™®éæœ‰æ•ˆï¼šå¯¹äºä¸åŒæ¶æ„å’Œç¡¬ä»¶éƒ½èƒ½å¸¦æ¥å¯è§‚çš„èŠ‚èƒ½ã€‚ç‰¹åˆ«åœ°ï¼ŒGPU æ”¯æŒçš„é¢‘ç‡èŒƒå›´è¶Šå¹¿ï¼ˆå¦‚ A40ï¼‰ï¼ŒèŠ‚èƒ½æ½œåŠ›è¶Šå¤§ã€‚\nç³»ç»Ÿå¼€é”€å¯å¿½ç•¥ï¼šPerseus åœ¨è®­ç»ƒåˆæœŸèŠ±è´¹å°‘é‡æ—¶é—´å‰–æå’Œè®¡ç®—ä¼˜åŒ–æ–¹æ¡ˆï¼ˆå‡ åç§’åˆ°åå‡ åˆ†é’Ÿä¸ç­‰ï¼‰ï¼Œä½†ç›¸å¯¹äºæ€»è®­ç»ƒæ—¶é•¿ï¼ˆå¸¸å¸¸æ•°å°æ—¶åˆ°æ•°å¤©ï¼‰æ¥è¯´å æ¯”æå°ã€‚è¿è¡Œè¿‡ç¨‹ä¸­å¯¹é€šä¿¡å’Œè®¡ç®—çš„é¢å¤–å»¶è¿Ÿä¹Ÿå¾®ä¹å…¶å¾®ï¼Œæ²¡æœ‰å¼•å…¥æ˜æ˜¾çš„åŒæ­¥å¼€é”€ã€‚\n\n5.1 å…³é”®å›¾è¡¨è§£è¯»\n\nå¤šæ¨¡å‹å†…åœ¨èŠ‚èƒ½æ•ˆæœè¡¨ï¼šè®ºæ–‡æä¾›äº†ä¸€ä¸ªè¡¨æ ¼ï¼Œå¯¹æ¯”äº†ä¸åŒæ¨¡å‹åœ¨æ— æ…¢èŠ‚ç‚¹æ—¶ä½¿ç”¨ Perseus çš„èƒ½è€—é™ä½æ¯”ä¾‹å’Œè¿­ä»£æ—¶é—´å˜åŒ–ã€‚ä¾‹å¦‚ï¼ŒGPT-3 1.3B åœ¨ 4 å¡æµæ°´çº¿ä¸Šèƒ½è€—é™ä½çº¦ 13%ï¼Œè¿­ä»£ä»…æ…¢ 0.8%ï¼›BERT 1.3B èŠ‚èƒ½ 16%ï¼Œå‡ ä¹æ— æ…¢åŒ–ã€‚è€Œä¸€äº›æœ¬èº«å¹³è¡¡åº¦å¾ˆé«˜çš„æ¨¡å‹ï¼ˆå¦‚ç»è¿‡ç‰¹æ®Šåˆ’åˆ†çš„ Wide-ResNetï¼‰èŠ‚èƒ½åªæœ‰ 2%~3%ã€‚è¿™ä¸€è¡¨æ ¼è¯æ˜äº† Perseus åœ¨å…¸å‹ä¸å¹³è¡¡çš„å¤§æ¨¡å‹ä¸Šæ•ˆæœæ˜¾è‘—ï¼Œä¸”ä»£ä»·å‡ ä¹ä¸ºé›¶ã€‚\næ—¶é—´-èƒ½é‡å¸•ç´¯æ‰˜æ›²çº¿ï¼šå¦‚è®ºæ–‡çš„å›¾9æ‰€ç¤ºï¼Œä¸åŒæ–¹æ¡ˆçš„èƒ½è€—-æ—¶é—´å…³ç³»æ›²çº¿æ¸…æ™°åœ°è¡¨æ˜ Perseus çš„æ–¹æ¡ˆæ•´ä½“ä¼˜äºåŸºçº¿ã€‚æ¨ªè½´ä¸ºæ¯æ­¥è¿­ä»£æ—¶é—´ï¼Œçºµè½´ä¸ºèƒ½è€—ï¼›Perseus çš„æ›²çº¿åœ¨ Zeus è¡ç”ŸåŸºçº¿ä¹‹ä¸‹ï¼Œè¡¨ç¤ºåœ¨ä»»æ„ç»™å®šè®­ç»ƒæ—¶é—´è¦æ±‚ä¸‹ï¼ŒPerseus éƒ½èƒ½ä»¥æ›´ä½çš„èƒ½è€—å®Œæˆè®­ç»ƒã€‚è¿™éªŒè¯äº†å…¶ä¼˜åŒ–ç®—æ³•åœ¨å…¨å±€ä¸Šçš„ä¼˜åŠ¿ã€‚\næ…¢èŠ‚ç‚¹åœºæ™¯èƒ½è€—éšå»¶è¿Ÿæ›²çº¿ï¼šå¦ä¸€ä¸ªé‡è¦å›¾è¡¨å±•ç¤ºäº†åœ¨æŸä¸€æ¨¡å‹ä¸Šå¼•å…¥ä¸åŒç¨‹åº¦çš„æ…¢èŠ‚ç‚¹ï¼ˆä¾‹å¦‚è¿­ä»£æ—¶é—´æ¯”æ­£å¸¸å¢åŠ  5%ã€10%ã€20%ï¼‰æ—¶ï¼ŒPerseus å®ç°çš„èƒ½è€—èŠ‚çœæ¯”ä¾‹ã€‚ç»“æœæ˜¾ç¤ºï¼Œéšç€æ…¢èŠ‚ç‚¹å˜æ…¢ï¼ŒPerseus å¯èŠ‚çœçš„èƒ½é‡å…ˆå¢åŠ åè¶‹äºé¥±å’Œã€‚ä¾‹å¦‚ï¼Œå½“æ…¢èŠ‚ç‚¹è®©è¿­ä»£å˜æ…¢ 10% æ—¶ï¼Œèƒ½è€—é™ä½ç‡å¯èƒ½è¾¾åˆ° 20%ä»¥ä¸Šï¼›ä½†å¦‚æœæ…¢å¾ˆå¤šï¼ˆè¶…è¿‡å‰æ²¿æ›²çº¿æœ€èŠ‚èƒ½ç‚¹ï¼‰ï¼Œå…¶ä½™èŠ‚ç‚¹å³ä½¿å…¨é™è‡³æœ€ä½é¢‘ç‡ï¼Œä¹Ÿæ— æ³•è¿›ä¸€æ­¥èŠ‚èƒ½ã€‚è¿™ä¸ªå›¾ä½è¯äº†ç®—æ³•å¯¹å¤–åœ¨èƒ½è€—å†—ä½™çš„å¤„ç†èƒ½åŠ›åŠå…¶æé™ã€‚\n\nç»“æœè§£è¯»ä¸è¾¹ç•Œï¼šæ€»ä½“è€Œè¨€ï¼Œè¿™äº›å®éªŒç»“æœæœ‰åŠ›åœ°æ”¯æŒäº†è®ºæ–‡çš„æ ¸å¿ƒç»“è®ºâ€”â€”è½¯ä»¶ä¼˜åŒ–èƒ½å¤§å¹…æå‡å¤§æ¨¡å‹è®­ç»ƒçš„èƒ½æºæ•ˆç‡ã€‚åœ¨å„ç§æµ‹è¯•åœºæ™¯ä¸‹ï¼ŒPerseus éƒ½æˆåŠŸå‡å°‘äº†èƒ½è€—ä¸”å‡ ä¹ä¸å½±å“æ€§èƒ½ï¼Œè¯æ˜äº†å…¶é€šç”¨æ€§å’Œæœ‰æ•ˆæ€§ã€‚ä¸è¿‡ï¼Œéœ€è¦æ³¨æ„ä»¥ä¸‹å‡ ç‚¹è¾¹ç•Œï¼š - å®éªŒä¸»è¦åœ¨å•æ¬¡è¿­ä»£å’Œå›ºå®šæ¨¡å‹é…ç½®ä¸Šè¯„ä¼°ï¼Œæ²¡æœ‰å®Œæ•´è¦†ç›–æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­çš„å˜åŒ–ã€‚ä¾‹å¦‚ï¼Œéšç€æ¨¡å‹è®­ç»ƒè¿›è¡Œï¼Œå¯èƒ½å‡ºç°è´Ÿè½½å˜åŒ–æˆ–å¤šæ¬¡æ…¢èŠ‚ç‚¹æ³¢åŠ¨ï¼ŒPerseus åœ¨é•¿æœŸè®­ç»ƒä¸­çš„ç¨³å®šæ€§å°šéœ€è¿›ä¸€æ­¥éªŒè¯ã€‚ - è®ºæ–‡ä¾§é‡äºGPU æ ¸å¿ƒé¢‘ç‡çš„è°ƒèŠ‚ï¼Œå¯¹å…¶ä»–å¯èƒ½çš„èŠ‚èƒ½æ‰‹æ®µï¼ˆå¦‚å†…å­˜é¢‘ç‡è°ƒèŠ‚ã€ç®—å­æ··åˆç²¾åº¦ç­‰ï¼‰æ²¡æœ‰æ¶‰åŠã€‚è¿™æ„å‘³ç€ç»“æœçš„æ”¹è¿›å®Œå…¨å½’åŠŸäº DVFSï¼Œä½†ä¹Ÿç•™ä¸‹äº†è¿›ä¸€æ­¥ç»„åˆä¼˜åŒ–çš„ç©ºé—´ã€‚ - å®éªŒç¯å¢ƒç›¸å¯¹å¯æ§ï¼Œæ¨¡æ‹Ÿçš„æ…¢èŠ‚ç‚¹ç”¨å¯çŸ¥çš„å‡é€Ÿæ¯”ä¾‹ã€‚åœ¨çœŸå®é›†ç¾¤ä¸­ï¼Œæ…¢èŠ‚ç‚¹çš„å‘ç”Ÿéšæœºæ€§å’Œæ£€æµ‹æ»åå¯èƒ½å½±å“ Perseus çš„åŠæ—¶å“åº”æ•ˆæœï¼Œéœ€è¦å®é™…éƒ¨ç½²æ£€éªŒã€‚ - æ­¤å¤–ï¼ŒPerseus å‡å®šæ¨¡å‹åˆ’åˆ†å·²æœ‰åˆç†ä¼˜åŒ–ï¼ˆå°½é‡å¹³è¡¡ï¼‰ï¼Œç„¶ååœ¨æ­¤åŸºç¡€ä¸Šé™é¢‘èŠ‚èƒ½ã€‚å¦‚æœæ¨¡å‹åˆ’åˆ†æä¸åˆç†æˆ–è€…é€šä¿¡æˆä¸ºä¸»è¦ç“¶é¢ˆï¼Œèƒ½è€—å†—ä½™çš„æ¨¡å¼å¯èƒ½ä¸åŒï¼ŒPerseus çš„æ•ˆæœä¹Ÿå¯èƒ½æ‰“æŠ˜ï¼Œéœ€è¦å’Œå…¶å®ƒä¼˜åŒ–ï¼ˆå¦‚é‡æ–°åˆ’åˆ†ã€åŠ å¤§å¾®æ‰¹æ•°ï¼‰é…åˆè€ƒè™‘ã€‚\nå…­ã€ä¼˜ç‚¹ä¸å±€é™\näº®ç‚¹ï¼ˆStrengthsï¼‰ï¼š - ç ”ç©¶é—®é¢˜ï¼šèšç„¦äºå¤§æ¨¡å‹è®­ç»ƒçš„èƒ½æºæ•ˆç‡è¿™ä¸€ç´§è¿«ä¸”å®é™…çš„é—®é¢˜ï¼Œæå‡ºäº†â€œèƒ½è€—å†—ä½™â€è¿™ä¸€æ–°é¢–æ¦‚å¿µï¼Œå°†ä»¥å¾€å°‘è¢«å…³æ³¨çš„èƒ½é‡æµªè´¹ç°è±¡ç³»ç»ŸåŒ–åœ°æ­ç¤ºå‡ºæ¥ã€‚ - æ–¹æ³•è®¾è®¡ï¼šæå‡ºäº†ç»Ÿä¸€æ¡†æ¶åŒæ—¶è§£å†³å†…åœ¨å’Œå¤–åœ¨ä¸¤ç±»èƒ½è€—æµªè´¹ï¼Œä¸”é‡‡ç”¨çº¯è½¯ä»¶æ–¹æ¡ˆï¼ˆåŠ¨æ€è°ƒèŠ‚ GPU é¢‘ç‡ï¼‰å®ç°ï¼Œæ— éœ€ç¡¬ä»¶æ”¹é€ ï¼Œå…·æœ‰å¾ˆå¼ºçš„é€šç”¨æ€§å’Œå¯éƒ¨ç½²æ€§ã€‚ - ç®—æ³•ä¸ç†è®ºï¼šå°†é—®é¢˜å½¢å¼åŒ–ä¸ºå›¾ä¼˜åŒ–ï¼Œå¹¶ç”¨å›¾å‰²ç®—æ³•æ‰¾åˆ°æ—¶é—´-èƒ½é‡æœ€ä¼˜è§£ï¼Œæ–¹æ³•ä¸Šå·§å¦™åœ°å°†å¤æ‚ä¼˜åŒ–é—®é¢˜è½¬åŒ–ä¸ºç½‘ç»œæµæ±‚è§£ï¼Œç†è®ºä¸¥è°¨ä¸”æ•ˆç‡é«˜ã€‚åŒæ—¶è¯æ˜äº†ç›´æ¥æ±‚è§£çš„éš¾åº¦å’Œé‡‡ç”¨æ¾å¼›ç®—æ³•çš„åˆç†æ€§ã€‚ - å®éªŒè®¾è®¡ï¼šè¯„ä¼°å…¨é¢ï¼Œæ¶µç›–ä¸åŒæ¨¡å‹ç±»å‹ã€æ¨¡å‹è§„æ¨¡å’Œç¡¬ä»¶å¹³å°ï¼Œæ—¢æœ‰ç°å®è®­ç»ƒï¼ˆGPT-3 ç­‰ï¼‰çš„å®éªŒï¼Œä¹Ÿæœ‰ä»¿çœŸæ¨æ¼”ï¼ˆæ”¾å¤§åˆ°åƒå¡è§„æ¨¡ï¼‰çš„ç»“æœï¼Œè®ºè¯å……åˆ†ã€‚ - ç»“æœä¸å†™ä½œï¼šå®éªŒç»“æœè¯´æœåŠ›å¼ºï¼ŒæˆåŠŸå®ç°äº†æ˜¾è‘—èŠ‚èƒ½ä¸”åŸºæœ¬æ— æ€§èƒ½æŸå¤±çš„ç›®æ ‡ã€‚è®ºæ–‡è¡Œæ–‡æ¸…æ™°ï¼Œå±‚æ¬¡åˆ†æ˜ï¼Œå¯¹æ¦‚å¿µï¼ˆå¦‚ä¸¤ç±»èƒ½è€—å†—ä½™ï¼‰çš„è§£é‡Šå’Œå›¾è¡¨ç¤ºä¾‹éƒ½å¸®åŠ©è¯»è€…ç†è§£å…³é”®æ€æƒ³ã€‚\nå±€é™ï¼ˆLimitationsï¼‰ï¼š - ç ”ç©¶é—®é¢˜ï¼šå½“å‰èšç„¦äºåŒæ­¥å¹¶è¡Œçš„æ·±åº¦å­¦ä¹ è®­ç»ƒåœºæ™¯ï¼Œå¯¹äºå¼‚æ­¥è®­ç»ƒæˆ–å…¶ä»–éåŒæ­¥èŒƒå¼ï¼ˆå¦‚å‚æ•°æœåŠ¡å™¨æ¶æ„ï¼‰ä¸ä¸€å®šé€‚ç”¨ï¼Œå› ä¸ºèƒ½è€—å†—ä½™çš„æ¨¡å¼å¯èƒ½ä¸åŒã€‚ - æ–¹æ³•è®¾è®¡ï¼šPerseus å¼ºä¾èµ– GPU çš„ DVFS èƒ½åŠ›ï¼Œåœ¨ç¡¬ä»¶ä¾èµ–ä¸Šæœ‰ä¸€å®šå±€é™ã€‚å¦‚æœéƒ¨ç½²ç¯å¢ƒä¸å…è®¸ç”¨æˆ·æ€è°ƒèŠ‚é¢‘ç‡æˆ–è€…ç¡¬ä»¶é¢‘ç‡èŒƒå›´æœ‰é™ï¼Œæ–¹æ³•æ•ˆæœä¼šå—é™ã€‚æ­¤å¤–ï¼Œå®ƒå‡å®šäº†è®¡ç®—å›¾ç¨³å®šé‡å¤ï¼Œè¿™å¯¹äºæŸäº›åŒ…å«åŠ¨æ€é€»è¾‘çš„æ¨¡å‹å¹¶ä¸æˆç«‹ã€‚ - ç®—æ³•å®ç°ï¼šè™½ç„¶ç®—æ³•æ•´ä½“é«˜æ•ˆï¼Œä½†æ¶‰åŠè·¨æ¨¡å—é›†æˆï¼ˆæ¡†æ¶ã€é©±åŠ¨ã€è°ƒåº¦ï¼‰çš„å·¥ç¨‹å¤æ‚åº¦è¾ƒé«˜ã€‚å®é™…è½åœ°éœ€è¦æ”¹åŠ¨è®­ç»ƒæ¡†æ¶å†…éƒ¨ï¼Œå¢åŠ èƒ½è€—ç›‘æ§ï¼Œå¯èƒ½å¸¦æ¥ä¸€å®šè°ƒè¯•å’Œç»´æŠ¤æˆæœ¬ã€‚ - å®éªŒéªŒè¯ï¼šè®ºæ–‡ä¸­çš„å®éªŒå¤šä¸ºå•ä»»åŠ¡åœºæ™¯ï¼Œä¸”å‡è®¾æ…¢èŠ‚ç‚¹å‡ºç°æ—¶ç³»ç»Ÿå¯ä»¥ç«‹å³å“åº”ã€‚åœ¨ç°å®å¤šä»»åŠ¡é›†ç¾¤ä¸­ï¼Œå¤šä¸ªè®­ç»ƒä½œä¸šç«äº‰èµ„æºï¼Œæ…¢èŠ‚ç‚¹æˆå› æ›´å¤æ‚ï¼ŒPerseus å¦‚ä½•ä¸é›†ç¾¤è°ƒåº¦å™¨ååŒã€åœ¨å¤šä»»åŠ¡ä¸‹ä¿æŒä¼˜åŠ¿å°šæœªæœ‰æ·±å…¥è®¨è®ºã€‚ - ç»“è®ºè§£è¯»ï¼šè®ºæ–‡å¼ºè°ƒâ€œæ— æ€§èƒ½æŸå¤±â€ï¼Œä½†ä¸¥æ ¼æ¥è¯´åœ¨éƒ¨åˆ†é…ç½®ä¸‹è¿˜æ˜¯å­˜åœ¨æå°çš„å»¶è¿Ÿï¼ˆå¦‚ 0.x% çš„è¿­ä»£å˜æ…¢ï¼‰ã€‚è¿™äº›å¼€é”€è™½å¯ä»¥å¿½ç•¥ï¼Œä½†åœ¨æè‡´è¿½æ±‚æ•ˆç‡çš„åœºåˆéœ€è¦æ³¨æ„ã€‚åŒæ—¶éœ€è¦è­¦æƒ•çš„æ˜¯ï¼ŒPerseus ç›®å‰åªä¼˜åŒ–èƒ½è€—æœªè€ƒè™‘æ¨¡å‹ç²¾åº¦ç­‰å…¶ä»–å› ç´ ï¼Œå¥½åœ¨é¢‘ç‡è°ƒèŠ‚é€šå¸¸ä¸å½±å“æ•°å€¼ç»“æœã€‚\nä¸ƒã€ä¸šå†…ç›¸å…³å·¥ä½œå¯¹æ¯”\n\nEnvPipeï¼ˆå†…æºèŠ‚èƒ½æ–¹æ¡ˆï¼‰ï¼šEnvPipe ä¸“æ³¨äºæµæ°´çº¿å†…çš„ä¸å¹³è¡¡ï¼Œé€šè¿‡é™ä½æœ€åä¸€å±‚çš„ GPU é¢‘ç‡æ¥å‡å°‘æµæ°´çº¿æ°”æ³¡å¸¦æ¥çš„æµªè´¹ã€‚å®ƒåªè§£å†³äº†å†…åœ¨èƒ½è€—å†—ä½™ï¼Œä¸”ç­–ç•¥å•ä¸€ï¼ˆå‡è®¾æœ€åé˜¶æ®µæ˜¯éå…³é”®è·¯å¾„ï¼‰ã€‚Perseus åˆ™æä¾›äº†æ›´é€šç”¨çš„æ¡†æ¶ï¼Œå¯ä»¥å¯¹ä»»æ„éå…³é”®ç®—å­é™é¢‘ï¼Œå› æ­¤åœ¨ç›¸åŒåœºæ™¯ä¸‹è¾¾åˆ°äº†æ›´é«˜çš„èŠ‚èƒ½ç‡ã€‚åŒæ—¶ï¼ŒEnvPipe æ— æ³•å¤„ç†æ…¢èŠ‚ç‚¹çš„æƒ…å†µï¼Œè€Œ Perseus çš„ç»Ÿä¸€æ¨¡å‹å¯ä»¥è¦†ç›–è¿™éƒ¨åˆ†ä¼˜åŒ–ã€‚\nZeusï¼ˆå•æœºèƒ½è€—ä¼˜åŒ–ï¼‰ï¼šZeus æ˜¯æ­¤å‰çš„ä¸€é¡¹å·¥ä½œï¼Œé’ˆå¯¹å• GPU è®­ç»ƒé€šè¿‡åŠ¨æ€è°ƒæ•´åŠŸç‡ä¸Šé™æ¥æ‰¾åˆ°èƒ½è€—å’Œè®­ç»ƒé€Ÿåº¦çš„æœ€ä½³æŠ˜ä¸­ã€‚ç„¶è€Œ Zeus æœªè€ƒè™‘æµæ°´çº¿å¹¶è¡Œæƒ…å½¢ï¼Œåœ¨å¤š GPU è®­ç»ƒä¸­ä¼šå¿½ç•¥å†…åœ¨ä¸å¹³è¡¡ï¼ˆå®ƒè‹¥ç»Ÿä¸€é™é¢‘ä¼šè¿å…³é”®è·¯å¾„ä¸€èµ·å˜æ…¢ï¼‰ã€‚Perseus å¯ä»¥çœ‹ä½œ Zeus æ€è·¯åœ¨å¤§æ¨¡å‹åˆ†å¸ƒå¼åœºæ™¯çš„æ‹“å±•ï¼šåˆ©ç”¨æ›´ç»†ç²’åº¦çš„å›¾æ¨¡å‹ï¼Œåˆ†åˆ«è°ƒèŠ‚ä¸åŒç®—å­çš„é€Ÿåº¦ã€‚å› æ­¤åœ¨å¤š GPU å®éªŒä¸­ Perseus æ˜æ˜¾èƒœè¿‡ Zeus å¼çš„å…¨å±€è°ƒèŠ‚æ–¹æ³•ã€‚\næµæ°´çº¿å¹¶è¡Œè´Ÿè½½å‡è¡¡ï¼ˆå¦‚ GPipe/PipeDream ç­‰ï¼‰ï¼šè¿™äº›ç³»ç»Ÿè‡´åŠ›äºå°†æ¨¡å‹åˆ’åˆ†å¾—å„é˜¶æ®µè®¡ç®—é‡å°½å¯èƒ½å‡è¡¡ï¼Œä»æºå¤´ä¸Šå‡å°‘æµæ°´çº¿ç©ºé—²æ—¶é—´ã€‚å®ƒä»¬æå‡çš„æ˜¯æ€§èƒ½ï¼Œé—´æ¥ä¹Ÿå‡å°‘äº†ä¸€äº›èƒ½è€—æµªè´¹ã€‚ç„¶è€Œå®Œå…¨å‡è¡¡åœ¨å®é™…å¾ˆéš¾åšåˆ°ï¼Œä»ä¼šæœ‰æ®‹ä½™ä¸å‡ã€‚Perseus å¯ä»¥è§†ä¸ºå¯¹è¿™ç±»æ¡†æ¶çš„è¡¥å……ï¼šåœ¨å·²ç»è¿‘ä¼¼å‡è¡¡çš„åŸºç¡€ä¸Šï¼Œè¿›ä¸€æ­¥åˆ©ç”¨ DVFS æ¶ˆé™¤ç»†å¾®çš„å‰©ä½™ä¸å¹³è¡¡å’Œå› æ…¢å¡å¯¼è‡´çš„ç­‰å¾…ã€‚ä»è´¡çŒ®ä¸Šçœ‹ï¼Œä¼ ç»Ÿæµæ°´çº¿å¹¶è¡Œä¸»è¦è§£å†³â€œæ›´å¿«è®­ç»ƒâ€ï¼Œè€Œ Perseus åˆ™èšç„¦â€œæ›´çœç”µè®­ç»ƒâ€ï¼Œä¸¤è€…å¯ç»“åˆå®ç°åˆå¿«åˆçœã€‚\n\n7.1 ä¸ªäººè§‚ç‚¹\næ€»ä½“è€Œè¨€ï¼Œæˆ‘è®¤ä¸ºè¿™ç¯‡è®ºæ–‡åœ¨å¤§æ¨¡å‹ç³»ç»Ÿä¼˜åŒ–é¢†åŸŸæä¾›äº†ä¸€ä¸ªæ–°çš„è§†è§’ï¼šä¸ä»…å…³æ³¨è®­ç»ƒé€Ÿåº¦ï¼Œä¹ŸæŠŠèƒ½æºæ•ˆç‡çº³å…¥ä¼˜åŒ–ç›®æ ‡ï¼Œå¹¶é€šè¿‡è½¯ç¡¬ä»¶ååŒè¾¾åˆ°ç›®çš„ã€‚å®éªŒåŸºçº¿çš„é€‰æ‹©æ¯”è¾ƒåˆç†ï¼Œæ¶µç›–äº†ç°æœ‰èƒ½è€—ä¼˜åŒ–æ–¹æ¡ˆå’Œç»å…¸å¹¶è¡Œæ¡†æ¶ï¼Œè¯æ˜äº†ä½œè€…çš„æ”¹è¿›æ˜¯æ˜¾è‘—çš„ã€‚\nä¸è¿‡æˆ‘ä¹Ÿæ³¨æ„åˆ°ä¸€äº›å¯ä»¥æ”¹è¿›ä¹‹å¤„ã€‚ä¾‹å¦‚ï¼ŒåŸºäºå½“ä¸‹çš„å®éªŒï¼ŒPerseus è¿˜å¯ä»¥å°è¯•èå…¥é›†ç¾¤è°ƒåº¦ç­–ç•¥ï¼šæ¯”å¦‚åœ¨æ•°æ®ä¸­å¿ƒç”µåŠ›é«˜å³°æ—¶è‡ªåŠ¨åˆ‡æ¢åˆ°æ›´èŠ‚èƒ½çš„é¢‘ç‡æ–¹æ¡ˆï¼Œä»¥é™ä½ç¬æ—¶åŠŸè€—å³°å€¼ï¼Œè¿™ä¼šä½¿æ–¹æ¡ˆæ›´æœ‰å®ç”¨ä»·å€¼ã€‚å¦å¤–ï¼Œåœ¨å®éªŒè®¾ç½®ä¸Šï¼Œä½œè€…ä¸»è¦æ¨¡æ‹Ÿäº†å•ä¸ªæ…¢èŠ‚ç‚¹ï¼Œå¦‚æœèƒ½æµ‹è¯•ä¸åŒæ…¢èŠ‚ç‚¹é¢‘å‘æ¨¡å¼ï¼ˆå¦‚éšæœºå¤šèŠ‚ç‚¹æŠ–åŠ¨ï¼‰ä¸‹ Perseus çš„æ•ˆæœï¼Œä¼šæ›´å…¨é¢å±•ç¤ºç³»ç»Ÿé²æ£’æ€§ã€‚å¦‚æœç”±æˆ‘æ¥ç»§ç»­è¿™é¡¹ç ”ç©¶ï¼Œæˆ‘ä¼šè€ƒè™‘è®¾è®¡ä¸€äº›é•¿æ—¶é—´ã€å¤šä»»åŠ¡çš„å®éªŒåœºæ™¯ï¼Œå¼•å…¥çœŸå®çš„å¤–éƒ¨æ‰°åŠ¨ï¼Œè§‚å¯Ÿ Perseus æ˜¯å¦ä¾ç„¶èƒ½å¤Ÿæœ‰æ•ˆåœ°èŠ‚èƒ½ä¸”ä¸å¹²æ‰°è®­ç»ƒè¿‡ç¨‹ï¼Œä»è€Œè¿›ä¸€æ­¥éªŒè¯å…¶å®ç”¨æ€§ã€‚\nå…«ã€åœ¨å®é™…è®­ç»ƒæ ˆä¸­å¦‚ä½•è½åœ°ï¼Ÿ\nè¦å°† Perseus æ–¹æ³•å¼•å…¥åˆ°å®é™…çš„å¤§è§„æ¨¡è®­ç»ƒæ¡†æ¶ä¸­ï¼Œéœ€è¦å¯¹è®­ç»ƒæ ˆçš„å¤šä¸ªéƒ¨åˆ†è¿›è¡Œæ‰©å±•å’Œæ”¹é€ ï¼š - æ•°æ®åŠ è½½ä¸é¢„å¤„ç†ï¼šé€šå¸¸ä¸éœ€è¦æ”¹åŠ¨æ•°æ®åŠ è½½é€»è¾‘ï¼Œä½†è¦ç¡®ä¿æ•°æ®åŠ è½½çš„å»¶è¿Ÿèƒ½å¤Ÿè¢«ç›‘æ§ã€‚å¦‚æœå› ä¸ºæ•°æ® I/O å¯¼è‡´æŸæ­¥è¿­ä»£å˜æ…¢ï¼Œåº”å°†æ­¤è§†ä½œâ€œå¤–åœ¨æ…¢èŠ‚ç‚¹â€å¹¶é€šçŸ¥ Perseusã€‚å·¥ç¨‹ä¸Šï¼Œå¯ä»¥åœ¨æ•°æ® loader å®Œæˆä¸€ä¸ª batch åŠ è½½åæ‰“æ ‡è®°è®¡æ—¶ï¼Œå¦‚æœå‘ç°æŸæ‰¹æ¬¡å‡†å¤‡è¶…æ—¶ï¼Œåˆ™è§¦å‘ Perseus é™é¢‘å…¶å®ƒè®¡ç®—èŠ‚ç‚¹ï¼Œä»¥å… GPU å¹²ç­‰ã€‚ - æ¨¡å‹å¹¶è¡Œä¸æµæ°´è°ƒåº¦ï¼šåœ¨è®­ç»ƒæ¡†æ¶ï¼ˆå¦‚ Megatron-LMã€DeepSpeedï¼‰çš„æµæ°´å¹¶è¡Œå®ç°ä¸­ï¼ŒåŠ å…¥ Perseus å®¢æˆ·ç«¯é€»è¾‘ã€‚ä¾‹å¦‚åœ¨æ¯ä¸ªå¾®æ‰¹æ¬¡æ‰§è¡Œå‰åæ’å…¥è°ƒç”¨ï¼Œç”¨äºæµ‹é‡è¯¥é˜¶æ®µè€—æ—¶å’Œèƒ½è€—ï¼Œå¹¶æ ¹æ®æœåŠ¡å™¨ä¸‹å‘çš„ç­–ç•¥è°ƒæ•´ GPU é¢‘ç‡ã€‚è¿™æ„å‘³ç€ä¿®æ”¹æ¡†æ¶çš„è°ƒåº¦ä»£ç è·¯å¾„ï¼Œå¢åŠ é’©å­ (hook) å‡½æ•°ã€‚å·¥ç¨‹å·¥ä½œé‡ä¸­ç­‰ï¼Œéœ€è¦ç†Ÿæ‚‰æ¡†æ¶çš„ pipeline æ‰§è¡Œæµç¨‹ã€‚ - å¼ é‡å¹¶è¡Œä¸é€šä¿¡ï¼šå¯¹ä½¿ç”¨å¼ é‡å¹¶è¡Œçš„æ¨¡å‹ï¼ŒåŒä¸€æµæ°´æ®µä¸Šçš„å¤šå— GPU åº”åŒæ­¥è°ƒé¢‘ï¼Œä»¥å…å‡ºç°ä¸€å— GPU å˜æ…¢æ‹–ç´¯å…¶ä»–ã€‚å®ç°ä¸Šï¼Œå¯ä»¥è®©åŒä¸€å¼ é‡å¹¶è¡Œç»„å†…çš„å®¢æˆ·ç«¯é€šè¿‡ MPI/NCCL äº’é€šï¼Œç»Ÿä¸€æŒ‰ç…§æœåŠ¡å™¨è®¡åˆ’è°ƒæ•´é¢‘ç‡ã€‚æ­¤å¤–ï¼Œæ¢¯åº¦åŒæ­¥ All-Reduce ç­‰é€šä¿¡æ“ä½œæœ¬èº«æ— æ³•é€šè¿‡é™é¢‘èŠ‚èƒ½ï¼Œä½† Perseus å¯ä»¥åœ¨é€šä¿¡æœŸé—´é™ä½å‚ä¸é€šä¿¡çš„ GPU æ ¸å¿ƒé¢‘ç‡ï¼ˆåæ­£è®¡ç®—å•å…ƒé—²ç€ï¼‰ï¼Œä»¥å‡å°‘ç­‰å¾…æ—¶çš„ç©ºè½¬åŠŸè€—ã€‚è¿™éœ€è¦æ¡†æ¶åœ¨è°ƒç”¨é€šä¿¡åº“æ—¶å¢åŠ å‰åé¢‘ç‡è°ƒæ•´æŒ‡ä»¤ã€‚ - åº•å±‚ Kernel ä¸ç®—å­ï¼šPerseus ä¸ä¿®æ”¹å…·ä½“ç®—å­å®ç°ï¼Œä½†é€šè¿‡è°ƒæ•´ç¡¬ä»¶é¢‘ç‡å½±å“ç®—å­çš„æ‰§è¡Œã€‚å·¥ç¨‹ä¸Šå¯èƒ½éœ€è¦ç¡®ä¿è¿™ç§é¢‘ç‡åˆ‡æ¢å¯¹æ˜¾å­˜ã€å†…å­˜æ²¡æœ‰å‰¯ä½œç”¨ï¼Œå¹¶å…¼å®¹æ¡†æ¶çš„å¼‚æ­¥æ‰§è¡Œã€‚ç‰¹åˆ«æ˜¯éœ€è¦æ³¨æ„é¢‘ç‡åˆ‡æ¢çš„å¼€é”€ï¼šåœ¨ NVIDIA GPU ä¸Šæ›´æ”¹ SM é¢‘ç‡é€šå¸¸æ˜¯æ¯«ç§’çº§çš„ï¼Œä¼šé˜»å¡ GPU æµæ°´ï¼Œå› æ­¤è¦åœ¨æ‰¹ä¸æ‰¹ä¹‹é—´æˆ–è®¡ç®—ç©ºéš™æ‰§è¡Œï¼Œé¿å…å¹²æ‰°æ­£å¸¸è®¡ç®—ã€‚è°ƒåº¦ä¸å¥½å¯èƒ½å¯¼è‡´ååä¸‹é™ã€‚ - ç›‘æ§ä¸é›†æˆï¼šåœ¨è¿ç»´å±‚é¢ï¼Œéœ€è¦å°† Perseus æœåŠ¡éƒ¨ç½²ä¸ºé›†ç¾¤çš„ä¸€éƒ¨åˆ†ï¼Œç›‘æ§å„ GPU çš„åŠŸè€—ã€æ¸©åº¦ç­‰ã€‚å½“å®é™…åº”ç”¨æ—¶ï¼Œå¯èƒ½éœ€è¦æä¾›ä¸€ä¸ªé…ç½®å¼€å…³æˆ–å‚æ•°ï¼Œè®©ç”¨æˆ·å†³å®šæ˜¯å¦å¼€å¯èŠ‚èƒ½æ¨¡å¼ã€‚è¿˜è¦æ‰©å±•è®­ç»ƒä»ªè¡¨æ¿ï¼Œå¢åŠ èƒ½è€—æŒ‡æ ‡ï¼ˆæ¯ç§’ç„¦è€³ã€ç´¯è®¡èƒ½è€—ç­‰ï¼‰ä¾›ç”¨æˆ·è§‚å¯Ÿã€‚ - è¶…å‚å’Œè‡ªåŠ¨è°ƒä¼˜ï¼šPerseus æœ¬èº«ä¸»è¦ä¾èµ– Profiling è‡ªåŠ¨ç”Ÿæˆç­–ç•¥ï¼Œä½†åœ¨å·¥ç¨‹ä¸­å¯èƒ½éœ€è¦ä¸€äº›ä¿å®ˆå› å­ã€‚ä¾‹å¦‚ï¼Œå¯è®¾ç½®æœ€ä½å…è®¸é¢‘ç‡æˆ–æœ€å¤§å®¹å¿æ…¢åŒ–ç™¾åˆ†æ¯”ï¼Œä»¥é˜²æ­¢è¿‡åº¦é™é¢‘å½±å“è®­ç»ƒç¨³å®šã€‚æ­¤å¤–ï¼Œç”±äºä¸åŒ GPU çš„ DVFS ç‰¹æ€§å·®å¼‚ï¼Œå¯èƒ½è¦é’ˆå¯¹å¸¸ç”¨ GPU ç±»å‹ç¦»çº¿å¾®è°ƒ Perseus ç®—æ³•çš„å‚æ•°ï¼ˆå¦‚æ—¶é—´æ­¥é•¿ Ï„ï¼‰ã€‚\næ•´ä½“æ¥çœ‹ï¼Œå°† Perseus èå…¥å¤§è§„æ¨¡è®­ç»ƒæ ˆéœ€è¦ä¸€å®šçš„å·¥ç¨‹æŠ•å…¥ï¼Œä½†æ”¶ç›Šä¹Ÿå¾ˆæ˜ç¡®ï¼šåªè¦è®­ç»ƒå­˜åœ¨ä¸å‡è¡¡æˆ–ç­‰å¾…ï¼Œä»˜å‡ºæ”¹åŠ¨å°±èƒ½æ¢æ¥èƒ½æºæˆæœ¬çš„é™ä½ã€‚åœ¨å®ç°è¿‡ç¨‹ä¸­éœ€é‡ç‚¹å…³æ³¨é¢‘ç‡æ§åˆ¶çš„å®‰å…¨æ€§å’Œè·¨è¿›ç¨‹åè°ƒï¼Œå¹¶ä»”ç»†è¯„ä¼°åœ¨çœŸå®é›†ç¾¤ä¸Šçš„æ•ˆæœã€‚\nä¹ã€å€¼å¾—è¿›ä¸€æ­¥æ¢ç´¢çš„ç ”ç©¶æ–¹å‘\n\nå¤šä»»åŠ¡èƒ½è€—è°ƒåº¦ï¼šåœ¨é›†ç¾¤ä¸­å¤šä¸ªè®­ç»ƒä½œä¸šåŒæ—¶è¿›è¡Œæ—¶ï¼Œå¦‚ä½•åè°ƒå®ƒä»¬çš„èƒ½è€—ä¼˜åŒ–ï¼Ÿä¾‹å¦‚ï¼Œä¸€ä¸ªä½œä¸šå‡ºç°ç©ºé—²æ—¶ï¼Œæ˜¯å¦å¯ä»¥æš‚æ—¶æé«˜å¦ä¸€ä½œä¸šçš„é¢‘ç‡ä»¥åŠ å¿«è¿›åº¦ï¼Œåä¹‹åœ¨è´Ÿè½½é«˜å³°æœŸç»Ÿä¸€é™é¢‘ä»¥é¿å…ç”µåŠ›å°–å³°ã€‚è¿™æ¶‰åŠå°† Perseus çš„æ€è·¯æ¨å¹¿åˆ°é›†ç¾¤è°ƒåº¦å±‚é¢ï¼Œå®ç°è·¨ä½œä¸šçš„èƒ½æºåˆ†é…ä¼˜åŒ–ã€‚\næ›´ç»†ç²’åº¦çš„ç¡¬ä»¶èŠ‚èƒ½ï¼šé™¤äº†è°ƒæ•´ GPU æ ¸å¿ƒé¢‘ç‡ï¼Œåç»­å¯æ¢ç´¢æ§åˆ¶å…¶ä»–ç¡¬ä»¶å•å…ƒä»¥èŠ‚èƒ½ï¼Œä¾‹å¦‚æ˜¾å­˜é¢‘ç‡ã€GPU çš„å¤šä¸ªç”µå‹/é¢‘ç‡åŸŸï¼Œç”šè‡³ CPU ä¸ç½‘ç»œè®¾å¤‡çš„èŠ‚èƒ½è”åŠ¨ã€‚è¿™éœ€è¦æ‰©å±•èƒ½è€—æ¨¡å‹å’Œæ§åˆ¶æ¥å£ï¼Œè®©ç³»ç»Ÿåœ¨ä¿è¯è®­ç»ƒæ€§èƒ½çš„å‰æä¸‹ï¼Œä»æ›´å¤šè§’åº¦å‰Šå‡æ— æ•ˆåŠŸè€—ã€‚\nè®­ç»ƒä»»åŠ¡å¼¹æ€§ä¸èƒ½æ•ˆï¼šæœªæ¥ç ”ç©¶å¯ä»¥è€ƒè™‘è®©è®­ç»ƒè¿‡ç¨‹æœ¬èº«æ›´å…·å¼¹æ€§ï¼Œä¾‹å¦‚æ ¹æ®èƒ½æºé¢„ç®—åŠ¨æ€æ”¹å˜è®­ç»ƒå‚æ•°ï¼ˆå¾®æ‰¹å¤§å°ã€æ¨¡å‹å¹¶è¡Œåº¦ï¼‰ä»¥è°ƒèŠ‚åŠŸè€—ã€‚åœ¨èƒ½è€—ç´§å¼ æˆ–ç¢³æ’æ”¾å—é™çš„ç¯å¢ƒä¸‹ï¼Œè®­ç»ƒå¯ä»¥â€œé™æ¡£â€ï¼Œè€Œåœ¨å®½æ¾æ—¶æ®µå†â€œè¡¥å›â€ï¼Œä»¥å®ç°èƒ½æºæ„ŸçŸ¥çš„æ·±åº¦å­¦ä¹ è®­ç»ƒã€‚\nèƒ½è€—ä¼˜åŒ–ä¸æ¨¡å‹æ¶æ„è”åˆè®¾è®¡ï¼šç›®å‰ç¡¬ä»¶èŠ‚èƒ½ä¼˜åŒ–ä¸æ¨¡å‹æœ¬èº«è®¾è®¡æ˜¯è§£è€¦çš„ã€‚ä¸€ä¸ªæ–°æ–¹å‘æ˜¯åœ¨è®¾è®¡æ¨¡å‹ï¼ˆå°¤å…¶æ˜¯è¶…å¤§æ¨¡å‹çš„å±‚ç»“æ„ï¼‰æ—¶å°±è€ƒè™‘èƒ½è€—å‡è¡¡çš„é—®é¢˜ï¼Œå‡å°‘æç«¯è€—æ—¶å±‚ã€‚æˆ–è€…è®­ç»ƒæ¡†æ¶è‡ªåŠ¨ä¸ºä¸åŒå±‚åˆ†é…ä¸åŒçš„ç¡¬ä»¶èµ„æº/é¢‘ç‡ï¼Œä½¿æ•´ä½“æ›´èŠ‚èƒ½ã€‚è¿™å°†ç»“åˆç³»ç»Ÿä¼˜åŒ–ä¸æ¨¡å‹æ¶æ„ä¼˜åŒ–ï¼Œè¿›ä¸€æ­¥æå‡èƒ½æ•ˆæ¯”ã€‚\næ¨ç†åœºæ™¯çš„èƒ½æºä¼˜åŒ–ï¼šå¤§æ¨¡å‹æ¨ç†åŒæ ·å­˜åœ¨è´Ÿè½½ä¸å‡å’Œèµ„æºæµªè´¹ï¼ˆä¾‹å¦‚æ‰¹å¤„ç†ä¸­é•¿çŸ­åºåˆ—æ··æ‚å¯¼è‡´çš„ç©ºé—²ï¼‰ã€‚å°† Perseus çš„æ€æƒ³åº”ç”¨åˆ°æ¨ç†ç³»ç»Ÿä¸­ï¼Œä¾‹å¦‚ vLLM ç­‰æ¨¡å‹æœåŠ¡æ¡†æ¶ï¼Œåœ¨ä½è´Ÿè½½æ—¶ä¸»åŠ¨é™é¢‘èŠ‚èƒ½ï¼Œåœ¨é«˜è´Ÿè½½æ—¶è¿…é€Ÿæ¢å¤ï¼Œå…¨å±€ä¼˜åŒ–æ¨ç†ååå’Œèƒ½è€—çš„å¹³è¡¡ï¼Œä¹Ÿæ˜¯å¾ˆæœ‰ä»·å€¼çš„æ–¹å‘ã€‚\n\nåã€çŸ¥è¯†å›¾è°±æ€ç»´é“¾\n\nå¹¶è¡Œä¸è°ƒåº¦ï¼šPerseus æä¾›äº†ä¸€ç§å…¨æ–°çš„å¹¶è¡Œè°ƒåº¦ä¼˜åŒ–è§†è§’â€”â€”ä¸ä»…è°ƒåº¦è®¡ç®—ä»»åŠ¡çš„é¡ºåºå’Œæ˜ å°„ï¼Œè¿˜è°ƒåº¦å®ƒä»¬çš„æ‰§è¡Œé€Ÿåº¦ã€‚è¿™ä¸°å¯Œäº†å¤§æ¨¡å‹è®­ç»ƒå¹¶è¡Œç­–ç•¥çš„å†…æ¶µï¼Œä¸æ•°æ®å¹¶è¡Œã€æ¨¡å‹å¹¶è¡Œã€æµæ°´çº¿å¹¶è¡Œå…±åŒæ„æˆå®Œæ•´çš„ä¼˜åŒ–ç»„åˆã€‚\nå†…å­˜ç®¡ç†ä¸æ˜¾å­˜ä¼˜åŒ–ï¼šè¯¥æ–¹æ³•æœ¬èº«å¯¹æ˜¾å­˜å ç”¨å½±å“ä¸å¤§ï¼Œå®ƒä¸æ”¹å˜æ¨¡å‹å’Œæ¿€æ´»çš„å­˜å‚¨ã€‚ä½†ä»æ€ç»´ä¸Šå¯å‘æˆ‘ä»¬ï¼šæ­£å¦‚å¯ä»¥é€šè¿‡äº¤æ¢æ˜¾å­˜æ¢æ—¶é—´ï¼Œä¹Ÿå¯ä»¥é€šè¿‡å¢åŠ æ—¶é—´ä½™é‡æ¥æ¢å–èƒ½è€—èŠ‚çœã€‚åœ¨ä¸ç¼ºæ˜¾å­˜åœºæ™¯ä¸‹ï¼ŒPerseus ç­‰äºç”¨å†—ä½™ç®—åŠ›æ¢å–äº†èƒ½æ•ˆã€‚\né€šä¿¡ä¸é›†ä½“æ“ä½œï¼šPerseus æ¶‰åŠåŒæ­¥è®­ç»ƒä¸­çš„é€šä¿¡ç­‰å¾…ä¼˜åŒ–ã€‚å®ƒé€šè¿‡è®©éå…³é”®è·¯å¾„çš„ GPU é™é¢‘ï¼Œå¡«å¹³äº†åŸæœ¬å› ç­‰å¾…é€šä¿¡è€Œæµªè´¹çš„èƒ½è€—ã€‚è¿™æé†’æˆ‘ä»¬åœ¨ä¼˜åŒ–é€šä¿¡æ—¶ï¼Œä¸ä»…å¯ä»¥æ”¹ç®—æ³•å‡å°‘ç­‰å¾…ï¼Œä¹Ÿå¯ä»¥åœ¨ç­‰å¾…æœŸé—´é™ä½åŠŸè€—ï¼ŒåŒæ ·è¾¾åˆ°æ•ˆç‡æå‡çš„ç›®çš„ã€‚\nKernel ä¸ç®—å­ä¼˜åŒ–ï¼šä¼ ç»Ÿç®—å­ä¼˜åŒ–å…³æ³¨åŠ é€Ÿæ‰§è¡Œï¼Œè€Œ Perseus åˆ™ä»å¦ä¸€ä¸ªç»´åº¦ä¼˜åŒ–ç®—å­â€”â€”é™ä½èƒ½è€—ã€‚é€šè¿‡å¯¹æ¯ä¸ªç®—å­çš„èƒ½è€—ç‰¹æ€§ Profilingï¼Œå¹¶é’ˆå¯¹æ€§åœ°è°ƒæ•´æ‰§è¡Œé€Ÿåº¦ï¼Œå®ƒæä¾›äº†ä¸€ç§ç®—å­çº§èŠ‚èƒ½ä¼˜åŒ–çš„èŒƒä¾‹ï¼Œè¡¥å……äº†æ€§èƒ½ä¼˜åŒ–èŒƒç•´ã€‚\næ¨¡å‹ç»“æ„ä¸æ¶æ„è®¾è®¡ï¼šæ¨¡å‹çš„å±‚ç»“æ„ä¼šå½±å“æµæ°´çº¿çš„è´Ÿè½½å‡è¡¡ï¼Œè¿›è€Œå½±å“èƒ½è€—æµªè´¹æ¯”ä¾‹ã€‚Perseus çš„å‡ºç°ä¿ƒä½¿æˆ‘ä»¬åœ¨è®¾è®¡æ¨¡å‹å¹¶åˆ’åˆ†æµæ°´çº¿æ—¶ï¼Œä¸ä»…è€ƒè™‘è®¡ç®—é‡ï¼Œä¹Ÿå¯è€ƒè™‘èƒ½è€—å‡è¡¡ã€‚ä¾‹å¦‚ï¼Œæ˜¯å¦èƒ½å°†æè€—æ—¶çš„å±‚æ‹†åˆ†ï¼Œæˆ–è€…å°†ä¸€äº›è®¡ç®—å‰ç§»/åç§»æ¥å¹³è¡¡æ¯æ®µæ—¶é—´ã€‚è¿™ç§æ¶æ„å±‚é¢çš„æ€è€ƒä¸ Perseus è¿è¡Œæ—¶ä¼˜åŒ–ç›¸è¾…ç›¸æˆã€‚\næ•°æ®ã€é¢„å¤„ç†ä¸æ‰“åŒ…ç­–ç•¥ï¼šè™½ç„¶ Perseus ä¸ç›´æ¥å¤„ç†æ•°æ®æ‰“åŒ…ï¼Œä½†å®ƒä¸ºæ•°æ®å±‚é¢çš„ä¼˜åŒ–æä¾›äº†æ–°æ€è·¯ï¼šå¦‚æœæ•°æ®åˆ†å¸ƒå¯¼è‡´æŸäº› batch è®¡ç®—ç‰¹åˆ«æ…¢ï¼Œé‚£ä¹ˆåœ¨ç­‰å¾…è¿™äº› batch å®Œæˆæ—¶å…¶ä»– GPU å¯ä»¥é™é¢‘çœç”µã€‚è¿™æç¤ºæˆ‘ä»¬åœ¨è®¾è®¡æ•°æ®æ‰“åŒ…ç­–ç•¥æ—¶ï¼Œä¹Ÿè¦ç•™æ„æ‰¹æ¬¡è€—æ—¶çš„ä¸€è‡´æ€§é—®é¢˜ï¼Œå¿…è¦æ—¶å¯ç»“åˆåƒ Perseus è¿™æ ·çš„æœºåˆ¶åº”å¯¹ä¸ä¸€è‡´å¯¼è‡´çš„èƒ½è€—æµªè´¹ã€‚\n\n10.1 ä¸ªäººæ”¶è·ä¸åæ€\né˜…è¯»è¿™ç¯‡è®ºæ–‡è®©æˆ‘æ„è¯†åˆ°ï¼Œåœ¨è¿½æ±‚å¤§æ¨¡å‹è®­ç»ƒé€Ÿåº¦çš„åŒæ—¶ï¼Œèƒ½æºæ•ˆç‡ä¹Ÿæ˜¯ä¸å¯å¿½è§†çš„è¡¡é‡ç»´åº¦ã€‚ä»¥å¾€æˆ‘ä»¬æ›´å¤šå…³æ³¨é€šè¿‡å¹¶è¡Œå’Œæ›´å¼ºç¡¬ä»¶æ¥åŠ é€Ÿè®­ç»ƒï¼Œä½†ä½œè€…æŒ‡å‡ºå°±ç®—åœ¨å›ºå®šç¡¬ä»¶ä¸‹ï¼Œä»…å‡­è½¯ä»¶è°ƒåº¦ä¹Ÿèƒ½æŒ–æ˜å‡ºæ•°å%çš„èƒ½è€—å†—ä½™ã€‚è¿™ç§å¯¹ç³»ç»Ÿâ€œç¢ç‰‡â€çš„åˆ©ç”¨æ€è·¯ä»¤æˆ‘å°è±¡æ·±åˆ»â€”â€”åŸæ¥ GPU ç©ºè½¬ç­‰å¾…çš„é‚£äº›æ—¶åˆ»ï¼Œå¯ä»¥è½¬åŒ–ä¸ºå®å®åœ¨åœ¨çš„èŠ‚çœã€‚\nå¯¹æˆ‘è€Œè¨€ï¼Œæœ€å¤§çš„å¯å‘åœ¨äºè½¯ç¡¬ä»¶ååŒä¼˜åŒ–çš„å¯èƒ½æ€§ã€‚Perseus å±•ç¤ºäº†ä¸ä¿®æ”¹æ¨¡å‹ã€ä¸æ”¹å˜ç¡¬ä»¶ï¼Œä»…é€šè¿‡èªæ˜çš„ç³»ç»Ÿå±‚è°ƒåº¦ï¼Œå°±å¯ä»¥æå‡æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹çš„èƒ½æ•ˆæ¯”ã€‚è¿™è®©æˆ‘åæ€åœ¨è‡ªå·±çš„å·¥ä½œä¸­ï¼Œæ˜¯å¦ä¹Ÿå­˜åœ¨ç±»ä¼¼çš„ä¼˜åŒ–å¥‘æœºã€‚ä¾‹å¦‚ï¼Œæˆ–è®¸å¯ä»¥å¼€å§‹å…³æ³¨è®­ç»ƒæ—¶çš„åŠŸè€—æ•°æ®ï¼Œå°†å…¶çº³å…¥ç›‘æ§æŒ‡æ ‡ï¼Œå¹¶å°è¯•ç®€å•çš„ç­–ç•¥ï¼ˆæ¯”å¦‚åœ¨æ•°æ®åŠ è½½ç­‰å¾…æ—¶é™ä½ GPU åŠŸç‡ä¸Šé™ï¼‰æ¥éªŒè¯èŠ‚èƒ½æ•ˆæœã€‚\nåŒæ—¶ï¼Œæœ¬è®ºæ–‡ä¹Ÿè®©æˆ‘æ„è¯†åˆ°æ¨è¿›è¿™ç±»ä¼˜åŒ–éœ€è¦è·¨è¶Šè½¯ä»¶å’Œç¡¬ä»¶è¾¹ç•Œçš„çŸ¥è¯†ã€‚ä¾‹å¦‚ï¼Œç†è§£æ¨¡å‹çš„å¹¶è¡Œæœºåˆ¶å’Œç†Ÿæ‚‰ GPU çš„ DVFS æ¥å£åŒç­‰é‡è¦ã€‚åœ¨ä»Šåçš„å®è·µä¸­å¤šç•™æ„åº•å±‚ç¡¬ä»¶ç‰¹æ€§ï¼Œæ¯”å¦‚ä¸åŒ GPU çš„é¢‘ç‡è°ƒèŠ‚èƒ½åŠ›ã€åŠŸè€—æ›²çº¿ç­‰ï¼Œä»è€Œåœ¨è®¾è®¡è®­ç»ƒç³»ç»Ÿæ—¶å¼•å…¥èƒ½è€—æ„ŸçŸ¥çš„ç†å¿µã€‚æ€»çš„æ¥è¯´ï¼ŒPerseus ä¸ºå¤§è§„æ¨¡ AI è®­ç»ƒçš„å¯æŒç»­æ€§æä¾›äº†å®ç”¨çš„æ–¹æ¡ˆï¼Œä¹Ÿä¸ºç³»ç»Ÿä¼˜åŒ–æä¾›äº†æ–°çš„æ€è·¯ï¼Œæˆ‘å¸Œæœ›åœ¨è‡ªå·±çš„å¹³å°ä¸­å°è¯•å¼•å…¥è¿™äº›ç†å¿µï¼Œä¸ºèŠ‚èƒ½é™è€—è´¡çŒ®ä¸€ä»½åŠ›é‡ã€‚\n\næ€»ä½“è¯„ä»·ï¼š è¿™æ˜¯ä¸€é¡¹é¢å‘å·¥ç¨‹å®è·µçš„å‡ºè‰²å·¥ä½œï¼Œå®ƒæé†’æˆ‘ä»¬åœ¨è¿½æ±‚æè‡´æ€§èƒ½çš„åŒæ—¶ï¼Œä¸åº”å¿½è§†èƒ½æºä»£ä»·ã€‚åœ¨è¶…å¤§æ¨¡å‹è®­ç»ƒé¢†åŸŸï¼ŒPerseus æä¾›äº†ä¸€ç§æ— éœ€ç¡¬ä»¶å‡çº§çš„èŠ‚èƒ½é€”å¾„ï¼Œéå¸¸å€¼å¾—ç›¸å…³ä»ä¸šè€…å€Ÿé‰´ã€‚æ•´ä½“æ¥çœ‹ï¼Œè¿™ç¯‡è®ºæ–‡åç³»ç»Ÿå®ç”¨å¯¼å‘ï¼Œå¯¹äºæ„å»ºå’Œä¼˜åŒ–å¤§è§„æ¨¡è®­ç»ƒå¹³å°æœ‰ç›´æ¥çš„å‚è€ƒä»·å€¼ã€‚\n\n","categories":["è®ºæ–‡é˜…è¯»"],"tags":["paper"]},{"title":"Reducing Activation Recomputation in Large Transformer Models","url":"/2025/11/23/paper/reducing_activation_recomputation/","content":"\n\nä¸€ã€è®ºæ–‡é€Ÿè§ˆ\nè¿™ç¯‡è®ºæ–‡å…³æ³¨çš„å¤§é—®é¢˜æ˜¯ï¼šåœ¨å¤§è§„æ¨¡ Transformer æ¨¡å‹è®­ç»ƒä¸­ï¼Œæ¿€æ´»ï¼ˆactivationsï¼‰å ç”¨çš„æ˜¾å­˜è¶Šæ¥è¶Šå¤¸å¼ ï¼Œä¸ºäº†çœæ˜¾å­˜æ™®éä½¿ç”¨â€œå…¨å±‚æ¿€æ´»é‡è®¡ç®—ï¼ˆå…¨ checkpointï¼‰â€ï¼Œä½†è¿™ä¼šå¸¦æ¥ 30%â€“40% çš„é¢å¤–ç®—åŠ›å¼€é”€ã€‚ ä½œè€…ä» Transformer ç»“æ„å‡ºå‘ï¼Œå»ºç«‹äº†ä¸€å¥—è¿‘ä¼¼ä½†éå¸¸å®ç”¨çš„â€œæ¿€æ´»å†…å­˜æ¨¡å‹â€ï¼Œç³»ç»Ÿåˆ†æäº†å¼ é‡å¹¶è¡Œï¼ˆTPï¼‰ã€åºåˆ—å¹¶è¡Œï¼ˆSPï¼‰ã€æµæ°´å¹¶è¡Œï¼ˆPPï¼‰å¯¹æ¿€æ´»å†…å­˜çš„å½±å“ï¼Œå¹¶æå‡ºä¸¤å¤§æŠ€æœ¯ï¼šå°†åºåˆ—å¹¶è¡Œä¸å¼ é‡å¹¶è¡Œèåˆï¼Œä»¥åŠå¯¹æ¿€æ´»è¿›è¡Œé€‰æ‹©æ€§é‡è®¡ç®—ã€‚ ç»¼åˆèµ·æ¥ï¼Œè¿™äº›æ–¹æ³•åœ¨ä¸å¢åŠ é€šä¿¡é‡çš„å‰æä¸‹ï¼Œå®ç°äº†æ¿€æ´»æ˜¾å­˜çº¦ 5Ã— çš„å‹ç¼©ï¼Œç›¸æ¯”â€œå…¨å±‚é‡ç®—â€åªä¿ç•™äº† ~2%â€“7% çš„è®¡ç®—å¼€é”€ï¼›åœ¨ 22Bâ€“1T è§„æ¨¡æ¨¡å‹ä¸Šï¼Œè¿­ä»£ throughput æå‡å¤§çº¦ 30%ï¼ŒGPU FLOPs åˆ©ç”¨ç‡èƒ½ç¨³å®šåœ¨ 50%+ã€‚\näºŒã€è®ºæ–‡ç»“æ„\n\nå¼•è¨€ä¸ç›¸å…³å·¥ä½œ ä»‹ç»å¤§æ¨¡å‹è®­ç»ƒä¸­çš„å†…å­˜ç“¶é¢ˆã€ç°æœ‰å¹¶è¡Œ/å†…å­˜ä¼˜åŒ–æŠ€æœ¯ï¼ˆTP/PPã€ZeROã€offloadã€å·²æœ‰ SP ç­‰ï¼‰ï¼Œå¹¶è¯´æ˜æœ¬æ–‡èšç„¦åœ¨â€œæ¨¡å‹å¹¶è¡Œ + æ¿€æ´»å†…å­˜â€è¿™ä¸ªç»´åº¦ã€‚é€‚åˆå¿«é€Ÿäº†è§£é—®é¢˜èƒŒæ™¯å’Œä¸å…¶å®ƒæ–¹æ¡ˆå…³ç³»æ—¶é˜…è¯»ã€‚\nTransformer ç»“æ„ä¸ç¬¦å·çº¦å®šï¼ˆSection 3ï¼‰ ç»Ÿä¸€å®šä¹‰ \\(s,b,h,a,L,t,p,v\\) ç­‰ç¬¦å·ï¼Œå¹¶æ‹†å¼€åˆ†æ self-attention ä¸ MLP å†…éƒ¨çš„æ¿€æ´»ç»“æ„ã€‚é€‚åˆåœ¨è‡ªå·±åšæ¨å¯¼ã€å¯¹æ¥ä»£ç å®ç°æ—¶é‡ç‚¹çœ‹ã€‚\næ¿€æ´»å†…å­˜å»ºæ¨¡ä¸å¹¶è¡Œç­–ç•¥ï¼ˆSection 4ï¼‰ å…ˆç»™å‡ºâ€œå•å±‚æ¿€æ´»å†…å­˜è¿‘ä¼¼å…¬å¼â€ï¼Œå†ä¾æ¬¡å åŠ ï¼šå¼ é‡å¹¶è¡Œï¼ˆTPï¼‰ã€TP+SPã€å†åˆ°æµæ°´å¹¶è¡Œï¼ˆPPï¼‰ï¼Œæ¨å¯¼å‡ºæ€»æ¿€æ´»å†…å­˜çš„é—­å¼è¡¨è¾¾ï¼Œæ˜¯å…¨æ–‡æœ€æ ¸å¿ƒçš„ç†è®ºéƒ¨åˆ†ã€‚\né€‰æ‹©æ€§æ¿€æ´»é‡è®¡ç®—ï¼ˆSection 5ï¼‰ å¯¹æ¯”â€œå…¨å±‚é‡ç®—â€å’Œâ€œåªé‡ç®— attention ä¸­ä¸€éƒ¨åˆ†ç®—å­â€çš„å·®å¼‚ï¼Œç»™å‡ºåœ¨ GPT-3 / MT-NLG è§„æ¨¡ä¸‹çš„å†…å­˜ä¸ FLOPs é‡çº§ï¼Œå¯¹å·¥ç¨‹ä¸Šâ€œè¯¥ checkpoint å“ªäº› opâ€ç»™å‡ºæ˜ç¡®æŒ‡å¼•ã€‚\nå®éªŒè¯„ä¼°ï¼ˆSection 6ï¼‰ é€šè¿‡å•å±‚ micro benchmark + ç«¯åˆ°ç«¯è®­ç»ƒï¼ˆ22B/175B/530B/1Tï¼‰éªŒè¯æ¨¡å‹ä¸å®éªŒçš„ä¸€è‡´æ€§ï¼ŒæŠ¥å‘Šæ˜¾å­˜å ç”¨ã€æ¯å±‚æ—¶å»¶ã€è¿­ä»£æ—¶é—´ã€MFU/HFU ç­‰æŒ‡æ ‡ï¼Œæ˜¯åˆ¤æ–­â€œå€¼ä¸å€¼çš„ä¸Šå·¥ç¨‹å®ç°â€çš„å…³é”®ã€‚\næ€»ç»“ä¸æœªæ¥å·¥ä½œï¼ˆSection 7 + Appendixï¼‰ å°ç»“ä¸¤å¤§æŠ€æœ¯ï¼ˆTP+SP + selective recomputeï¼‰çš„è´¡çŒ®ï¼Œå¹¶è®¨è®º pipeline é¦–æ®µæ˜¾å­˜ç¢ç‰‡ã€è‡ªåŠ¨åŒ–æœç´¢ checkpoint ç­–ç•¥ç­‰æœªæ¥æ–¹å‘ã€‚\n\n\næ ¸å¿ƒæ€æƒ³ï¼šé’ˆå¯¹å¤§è§„æ¨¡ Transformerï¼Œå…ˆç”¨è§£ææ¨¡å‹ç²¾ç¡®åˆ»ç”»æ¿€æ´»å†…å­˜ï¼Œå†é€šè¿‡â€œå¼ é‡å¹¶è¡Œ + åºåˆ—å¹¶è¡Œâ€çš„ç»„åˆå°†æ¿€æ´»å‡åŒ€åˆ†æ‘Šåˆ°å„è®¾å¤‡ï¼Œå¹¶åªå¯¹ FLOPs ä¾¿å®œä½†å†…å­˜å·¨å¤§çš„å­ç®—å­åšé€‰æ‹©æ€§é‡è®¡ç®—ï¼Œåœ¨å‡ ä¹ä¸å¢åŠ é€šä¿¡ã€æå°ç®—åŠ›å¼€é”€çš„å‰æä¸‹ï¼Œå®ç°çº¦ 5Ã— çš„æ¿€æ´»æ˜¾å­˜å‹ç¼©ä¸ 30% å·¦å³çš„ååæå‡ã€‚\n\n\nä¸‰ã€æ–¹æ³•ä¸ç³»ç»Ÿè®¾è®¡\nä»å·¥ç¨‹è§†è§’çœ‹ï¼Œæœ¬æ–‡è¦è§£å†³çš„æ˜¯ï¼š\n\nâ€œå¦‚ä½•åœ¨ä¸å´©æ‰è®­ç»ƒååçš„å‰æä¸‹ï¼ŒæŠŠæ¿€æ´»æ˜¾å­˜å‹åˆ°èƒ½è·‘ trillion-scale æ¨¡å‹çš„æ°´å¹³ï¼Ÿâ€\n\næ•´ä½“æ€è·¯æ˜¯â€œä¸¤æ­¥èµ°â€ï¼š\n\nå»ºæ¨¡ï¼šæŠŠ Transformer æ¯ä¸€å±‚ã€æ¯ä¸€å—ï¼ˆattention / MLP / LayerNorm / Dropoutï¼‰çš„æ¿€æ´»å†…å­˜ç”¨å…¬å¼æ•°æ¸…æ¥šï¼Œé¡ºå¸¦æŠŠ TP / SP / PP çš„å½±å“éƒ½ä»£å…¥è¿›å»ã€‚\nä¼˜åŒ–ï¼š\n\nåœ¨ç»“æ„å±‚é¢ï¼šè®¾è®¡ä¸€ç§ TP + SP ç»„åˆçš„å¹¶è¡Œæ–¹å¼ï¼Œé€šè¿‡ \\(g / \\bar g\\) æ“ä½œæŠŠé TP åŒºåŸŸæŒ‰åºåˆ—åˆ‡ç‰‡ï¼Œé¿å… LayerNorm/Dropout è¿™ç±»æ¿€æ´»åœ¨ TP ç»„å†…é‡å¤å­˜å‚¨ã€‚\nåœ¨ç®—å­å±‚é¢ï¼šåªå¯¹ attention ä¸­â€œå¤§æ¿€æ´»ã€ä½ FLOPsâ€é‚£ä¸€éƒ¨åˆ†åš é€‰æ‹©æ€§é‡è®¡ç®—ï¼Œå…¶å®ƒåœ°æ–¹ç…§å¸¸ç¼“å­˜ï¼Œä»è€Œåœ¨â€œæ˜¾å­˜â€å’Œâ€œé‡ç®—å¼€é”€â€ä¹‹é—´å–å¾—æ›´ä¼˜æŠ˜ä¸­ã€‚\n\n\nå¯ä»¥æ‹†æˆå‡ ä¸ªå…·ä½“å­é—®é¢˜ï¼š\n\nå­é—®é¢˜ 1ï¼š å¦‚ä½•ç”¨ä¸€ä¸ªç®€æ´çš„å…¬å¼åˆ»ç”»â€œå•å±‚ Transformer çš„æ¿€æ´»å†…å­˜â€ï¼Œå¹¶èƒ½å¹³æ»‘ä»£å…¥ TP/SP/PP ç­‰å¹¶è¡Œå‚æ•°ï¼Ÿ\nå­é—®é¢˜ 2ï¼š å¦‚ä½•æŠŠåºåˆ—å¹¶è¡Œå’Œå¼ é‡å¹¶è¡Œæ‰åœ¨ä¸€èµ·ï¼Œåœ¨ä¸å¢åŠ é€šä¿¡å¸¦å®½çš„å‰æä¸‹ï¼ŒæŠŠä¹‹å‰ TP é‡Œâ€œæ²¡æ³•åˆ‡â€çš„é‚£ä¸€éƒ¨åˆ†æ¿€æ´»æŒ‰åºåˆ—åˆ†ç‰‡ï¼Ÿ\nå­é—®é¢˜ 3ï¼š åœ¨ä¸€å±‚å†…éƒ¨ï¼Œå“ªäº›æ¿€æ´»é€‚åˆ checkpointï¼ˆé‡ç®—ï¼‰ï¼Œå“ªäº›åº”è¯¥ç›´æ¥å­˜ï¼Ÿæ€æ ·åœ¨ QKV/softmax/attention over V è¿™äº›å­ç®—å­ä¹‹é—´åˆ‡åˆ†ï¼Ÿ\nå­é—®é¢˜ 4ï¼š å½“å†å åŠ æµæ°´å¹¶è¡Œæ—¶ï¼Œç¬¬ä¸€ stage éœ€è¦å­˜å¤šå°‘ micro-batch çš„æ¿€æ´»ï¼Œä»¥åŠå¦‚ä½•åœ¨å®è·µä¸­æ§åˆ¶ recompute çš„å¼€é”€ä¸å¤±æ§ï¼Ÿ\n\n3.1 æ ¸å¿ƒæ¨¡å—ä¸€è§ˆ\næŒ‰è®ºæ–‡æ€è·¯ï¼ŒæŠŠæ–¹æ³•æ‹†æˆå‡ ä¸ªâ€œå·¥ç¨‹æ¨¡å—â€ä¼šæ›´æ¸…æ™°ï¼š\n\næ¿€æ´»å†…å­˜è¿‘ä¼¼æ¨¡å‹ï¼šç»™å‡ºæ— å¹¶è¡Œæ—¶çš„â€œå•å±‚æ¿€æ´»å†…å­˜å…¬å¼â€ï¼ŒæŠŠ attention / MLP / LayerNorm / Dropout å„è‡ªçš„è´¡çŒ®æ‹†å¼€ï¼Œå¹¶æ˜ç¡®å“ªäº›å¯ä»¥å¿½ç•¥ï¼ˆå° bufferï¼‰ã€‚\nå¼ é‡å¹¶è¡Œï¼ˆTensor Parallel, TPï¼‰åŸºçº¿ï¼šå‡è®¾ TP åªåˆ‡ attention / MLP å†…éƒ¨çš„å¤§ GEMMï¼ŒæŠŠæ¿€æ´»åœ¨è¿™äº› op å†…éƒ¨å‡åŒ€åˆ†æ‘Šåˆ° \\(t\\) ä¸ªè®¾å¤‡ï¼Œä½† LayerNorm / Dropout ç­‰é TP åŒºåŸŸä»æ˜¯æ¯å¡ä¸€ä»½ã€‚\nåºåˆ—å¹¶è¡Œï¼ˆSequence Parallel, SPï¼‰+ è½¬æ¢ç®—å­ \\(g/\\bar g\\)ï¼šåœ¨é TP åŒºåŸŸæ²¿åºåˆ—ç»´ \\(s\\) åˆ‡åˆ†ï¼Œè®¾è®¡ \\(g\\)ï¼ˆall-gatherï¼‰å’Œ \\(\\bar g\\)ï¼ˆreduce-scatterï¼‰æ¥åœ¨â€œåºåˆ—åˆ‡åˆ†åŸŸâ€å’Œâ€œå¼ é‡åˆ‡åˆ†åŸŸâ€ä¹‹é—´æ— ç¼è½¬æ¢ã€‚\né€‰æ‹©æ€§æ¿€æ´»é‡è®¡ç®—ï¼ˆSelective Activation Recomputationï¼‰ï¼šåªé‡ç®— attention ä¸­åœ¨ \\(QK^\\top\\)ã€softmaxã€softmax dropoutã€attention over V åŒºåŸŸçš„æ¿€æ´»ï¼Œå®ƒä»¬å†…å­˜å·¨å¤§ä½†æ¯å…ƒç´  FLOPs ä¸å¤šï¼›å…¶ä½™éƒ¨åˆ†ç…§å¸¸ç¼“å­˜ã€‚\nä¸æµæ°´å¹¶è¡Œçš„ç»“åˆï¼ˆ1F1B / interleaved 1F1Bï¼‰ï¼šåˆ†æåœ¨ç»å…¸ 1F1B è°ƒåº¦ä¸‹ï¼Œé¦–ä¸ªæµæ°´ stage æ°¸è¿œéœ€è¦åŒæ—¶ hold \\(L\\) å±‚æ¿€æ´»ï¼›åœ¨æ­¤åŸºç¡€ä¸Šç»™å‡ºæ€»æ¿€æ´»å†…å­˜å…¬å¼ï¼Œå¹¶è®¨è®º interleaved pipeline æ—¶çš„ä¿®æ­£å› å­ã€‚\n\n3.2 æ•°æ®æµä¸æ§åˆ¶æµ\nç”¨â€œä»è¾“å…¥åˆ° lossï¼Œå†åˆ°åå‘â€çš„è§†è§’ï¼Œå¯ä»¥æŠŠæ•°æ®æµ/æ§åˆ¶æµä¸²æˆå¦‚ä¸‹æ­¥éª¤ï¼ˆåªå…³æ³¨å•ä¸ª stackï¼‰ï¼š\n\nè¾“å…¥åµŒå…¥å±‚\n\nè¯è¡¨ embeddingï¼šæŸ¥è¡¨å¾—åˆ°å½¢çŠ¶ä¸º \\((s, b, h)\\) çš„ token è¡¨ç¤ºã€‚\nåŠ ä¸Šå¯å­¦ä¹ çš„ä½ç½®ç¼–ç ï¼ˆåŒå½¢çŠ¶ï¼‰ï¼Œå¾—åˆ° \\(X^{(0)}\\) ä½œä¸ºç¬¬ 1 å±‚è¾“å…¥ã€‚\nåœ¨å¯ç”¨ SP æ—¶ï¼Œè¿™ä¸€å±‚çš„ Dropout mask ä¹Ÿå¯ä»¥æŒ‰åºåˆ—åˆ‡åˆ†å­˜å‚¨ã€‚\n\nç¬¬ \\(\\ell\\) ä¸ª Transformer å±‚çš„å‰å‘ï¼ˆæ— å¹¶è¡Œè§†è§’ï¼‰\n\nLayerNormï¼š\\(Y = \\text{LN}(X)\\)ï¼Œè¾“å‡ºä»ä¸º \\((s,b,h)\\)ï¼Œéœ€è¦ç¼“å­˜è¾“å…¥ \\(X\\) ä½œä¸ºæ¿€æ´»ã€‚\nSelf-Attentionï¼š\n\nQKV æŠ•å½±ï¼šä» \\(Y\\) ç»è¿‡ä¸‰æ¬¡çº¿æ€§å±‚å¾—åˆ° \\(Q,K,V\\)ï¼Œå°ºå¯¸ $ (s,b,h)$ æˆ– \\((s,b,h/a)\\)ã€‚\n\\(QK^\\top\\)ï¼šè®¡ç®—æ³¨æ„åŠ› logitsï¼Œå°ºå¯¸å¤§çº¦ä¸º \\((a,s,s,b)\\)ã€‚\nsoftmax + dropoutï¼šå¾—åˆ°æ³¨æ„åŠ›æƒé‡ï¼Œå†æ–½åŠ  dropoutã€‚\nattention over Vï¼šç”¨æ³¨æ„åŠ›æƒé‡åŠ æƒ Vï¼Œå¾—åˆ° \\((s,b,h)\\) çš„è¾“å‡ºã€‚\nè¾“å‡ºçº¿æ€§ï¼šå†æŠ•å½±å› \\((s,b,h)\\)ã€‚è¿™äº›æ­¥éª¤äº§ç”Ÿå¤§é‡ä¸­é—´æ¿€æ´»ã€‚\n\næ®‹å·® + LayerNormï¼šæŠŠ attention è¾“å‡ºåŠ å›è¾“å…¥ï¼Œåšç¬¬äºŒæ¬¡ LNã€‚\nMLPï¼š\n\nçº¿æ€§ \\(h \\to 4h\\)ï¼Œäº§ç”Ÿ \\((s,b,4h)\\)ã€‚\nGeLU éçº¿æ€§ï¼Œéœ€è¦ç¼“å­˜è¾“å…¥ã€‚\nçº¿æ€§ \\(4h \\to h\\)ï¼Œå†åŠ  Dropoutã€‚\næ®‹å·®åŠ å›ã€‚\n\n\nTP + SP ä¸‹çš„å‰å‘æ§åˆ¶æµï¼ˆä»¥ MLP ä¸ºä¾‹ï¼‰\n\nåœ¨ LayerNorm å‰ï¼Œè¾“å…¥ \\(X\\) å·²æŒ‰åºåˆ—ç»´åˆ‡åˆ†ï¼š\\([X^{s}_1, X^{s}_2, \\dots, X^{s}_t]\\)ã€‚\nLayerNorm åœ¨å„ rank æœ¬åœ°åšï¼Œè¾“å‡º \\([Y^{s}_1,\\dots,Y^{s}_t]\\)ï¼Œæ­¤æ—¶ä»æŒ‰åºåˆ—åˆ‡åˆ†ã€‚\nä¸ºé€å…¥ MLP ä¸­çš„ GEMMï¼Œéœ€è¦å®Œæ•´åºåˆ—ï¼šè°ƒç”¨ \\(g\\) åš all-gather æŠŠ \\(Y\\) åœ¨æ¯ä¸ª TP rank ä¸Šæ‹¼æˆå®Œæ•´çš„ \\((s,b,h)\\)ã€‚\nçº¿æ€§ + GeLU + çº¿æ€§å†…éƒ¨æ²¿éšè—ç»´åˆ‡åˆ†ï¼ˆæ ‡å‡† TPï¼‰ï¼Œæ¯å¡åªå¤„ç† \\(h/t\\) æˆ– \\(4h/t\\) çš„ sliceã€‚\nMLP è¾“å‡º \\(W_1, W_2, \\dots, W_t\\) éœ€è¦å…ˆæ±‚å’Œå†æŒ‰åºåˆ—åˆ‡åˆ†ç»™ä¸‹æ¸¸ Dropoutï¼Œäºæ˜¯ç”¨ \\(\\bar g\\) å®ç°â€œæ±‚å’Œ + æŒ‰åºåˆ— RSâ€çš„ reduce-scatterã€‚\nDropoutã€æ®‹å·®åœ¨åºåˆ—åˆ‡åˆ†åŸŸä¸­æœ¬åœ°å®Œæˆã€‚\n\né€‰æ‹©æ€§é‡è®¡ç®—çš„æ§åˆ¶æµï¼ˆä»¥ attention ä¸ºä¸»ï¼‰\n\næ­£å¸¸å‰å‘æ—¶ï¼Œåªä¿ç•™ï¼š\n\nè¾“å…¥ LN å‰åçš„å¼ é‡ï¼›\nMLP è¾“å…¥/è¾“å‡ºï¼›\nä»¥åŠ attention ä¸­â€œå®½åº¦å°šæœªæ”¾å¤§â€çš„éƒ¨åˆ†ã€‚\n\nå¯¹äº \\(QK^\\top\\)ã€softmaxã€softmax dropoutã€attention over V ç­‰åŒºåŸŸï¼š\n\nä¸ç¼“å­˜ä¸­é—´æ¿€æ´»ï¼Œåªåœ¨åå‘éœ€è¦æ—¶é‡è·‘ä¸€æ¬¡å‰å‘å­å›¾ã€‚\n\nåå‘æ—¶ï¼Œæ¡†æ¶çš„ checkpoint é©±åŠ¨ï¼š\n\nå…ˆé‡ç®—è¢«æ ‡è®°çš„å­å›¾ï¼Œå†åŸºäºé‡ç®—æ¿€æ´»åšåå‘ã€‚\nå…¶å®ƒæœª checkpoint çš„éƒ¨åˆ†ç›´æ¥ç”¨ç¼“å­˜æ¿€æ´»åå‘ã€‚\n\n\næµæ°´å¹¶è¡Œä¸‹çš„æ—¶åºå…³ç³»\n\né‡‡ç”¨ 1F1B è°ƒåº¦ï¼Œé¦–ä¸ª stage å¿…é¡»åŒæ—¶ hold å¤šä¸ª micro-batch çš„æ¿€æ´»ï¼Œä»¥å¡«æ»¡æµæ°´ã€‚\nå¯¹é¦–ä¸ª stage æ¥è¯´ï¼Œæœ‰æ•ˆâ€œå±‚æ•°â€æ˜¯ \\(L\\)ï¼Œå³ä½¿å®ƒå®é™…åªåŒ…å« \\(L/p\\) ä¸ªç‰©ç†å±‚ã€‚\nselective recompute å…è®¸ä¼˜å…ˆå¯¹æœ€å å†…å­˜çš„éƒ¨åˆ†é‡ç®—ï¼Œrest full-cacheï¼Œä»è€Œåœ¨æ˜¾å­˜å’Œé‡ç®—å¼€é”€é—´æŒ‰å®é™…å¡å®¹é‡åšæŠ˜ä¸­ã€‚\n\n\n3.3 å…³é”®å‡è®¾ä¸é€‚ç”¨èŒƒå›´\nè®ºæ–‡ä¸­çš„æ¨å¯¼å’Œç»“è®ºåŸºäºè‹¥å¹²é‡è¦å‡è®¾ï¼Œåœ¨å®è·µä¸­éœ€è¦æ„è¯†åˆ°å®ƒä»¬çš„è¾¹ç•Œï¼š\n\nåªè€ƒè™‘ä¸»å¹² Transformer å—ï¼Œå¿½ç•¥â€œå° bufferâ€\n\nå‡è®¾ï¼šLayerNorm çš„å‡å€¼/æ–¹å·®ï¼ˆ\\(2sb\\)ï¼‰å’Œ bias ç­‰ \\(O(h)\\) çº§åˆ« buffer å¯ä»¥å¿½ç•¥ï¼Œä»…å…³æ³¨ \\(O(sbh)\\) çš„æ¿€æ´»ã€‚\nå¯èƒ½å¤±æ•ˆçš„åœºæ™¯ï¼šæçŸ­åºåˆ—ã€å° hidden size æˆ–å¤§é‡é¢å¤–è¾…åŠ©åˆ†æ”¯ï¼ˆä¾‹å¦‚å¤šä»»åŠ¡å¤´ï¼‰æ—¶ï¼Œè¿™äº›â€œå° bufferâ€å æ¯”ä¸Šå‡ï¼Œç†è®ºæ¨¡å‹ä¸å®é™…æ˜¾å­˜å¯èƒ½æœ‰æ•°ä¸ªç™¾åˆ†ç‚¹åå·®ã€‚\n\nç»Ÿä¸€ä½¿ç”¨ 16-bit æ¿€æ´»ï¼ˆæ¯å…ƒç´  2 bytesï¼‰ï¼Œdropout mask 1 byte\n\nå‡è®¾ï¼šæ‰€æœ‰æ¿€æ´»éƒ½ä»¥ FP16/BF16 å­˜å‚¨ï¼Œåªæœ‰ logits ç­‰å°‘é‡å¼ é‡ä½¿ç”¨ FP32ã€‚\né£é™©ï¼šå¦‚æœä½ çš„æ ˆä¸­ä»å¤§é‡ä¿ç•™ FP32 æ¿€æ´»ï¼ˆæ¯”å¦‚ç¨³å®šæ€§åŸå› ï¼‰ã€æˆ–è€…æœ‰è‡ªå®šä¹‰ kernel ä½¿ç”¨æ›´å®½çš„ä¸­é—´æ ¼å¼ï¼Œå®é™…æ˜¾å­˜ä¼šé«˜äºæ¨¡å‹é¢„æµ‹ã€‚\n\nå±‚ç»“æ„é«˜åº¦åŒè´¨ï¼Œå¿½ç•¥ embedding / output å±‚è´¡çŒ®\n\nå‡è®¾ï¼šæ‰€æœ‰ Transformer å—çš„ç»“æ„ç›¸åŒï¼Œembedding å’Œæœ€åä¸€å±‚ FC / loss çš„é¢å¤–æ¿€æ´»å¯ä»¥è¿‘ä¼¼å¿½ç•¥ã€‚\nä¾‹å¤–ï¼šåœ¨éå¸¸æµ…çš„ç½‘ç»œï¼ˆå° \\(L\\)ï¼‰æˆ– embedding/output æå¤§ï¼ˆè¶…å¤§ vocabï¼‰æ—¶ï¼Œè¿™ä¸€è¿‘ä¼¼ä¼šå˜å·®ï¼Œéœ€è¦æ‰‹å·¥åŠ ä¸Šé¢å¤–é¡¹ã€‚\n\né‡‡ç”¨ 1F1B æˆ– interleaved 1F1B æµæ°´è°ƒåº¦ï¼Œé¦– stage ä¸ºç“¶é¢ˆ\n\nå‡è®¾ï¼šæµæ°´è°ƒåº¦ä¸º 1F1B æˆ–æ–‡ä¸­çš„ interleaved å˜ä½“ï¼Œå¹¶é€šè¿‡å¢å¤§ micro-batch æ•°é‡æŠŠæµæ°´â€œå‹æ»¡â€ï¼Œä½¿é¦–ä¸ª stage çš„æ¿€æ´»æ˜¾å­˜æˆä¸ºç³»ç»Ÿç“¶é¢ˆã€‚\nåœ¨éå…¸å‹è°ƒåº¦ï¼ˆå¤§é‡ pipeline bubbleã€å¼‚æ„ stageã€åŠ¨æ€åˆ†é…ï¼‰æˆ–å¼º offload åœºæ™¯ï¼Œè¿™ä¸ªå‡è®¾å¯èƒ½ä¸æˆç«‹ï¼Œéœ€è¦é‡æ–°è®¡ç®—æ¯ä¸ª stage çš„å³°å€¼ã€‚\n\nattention å¤´æ•° \\(a\\)ã€åºåˆ—é•¿åº¦ \\(s\\) è¶³å¤Ÿå¤§ï¼Œä½¿ \\(5as/h \\gg 34\\)\n\nå‡è®¾ï¼šåœ¨ GPT-3ã€MT-NLG è¿™ç§è§„æ¨¡ä¸‹ï¼Œattention ååŠæ®µæ¿€æ´»ï¼ˆ\\(QK^\\top\\)ã€softmax ç­‰ï¼‰å äº†ç»å¤§å¤šæ•°æ˜¾å­˜ã€‚\nå½“ \\(s\\) å¾ˆçŸ­ã€\\(a\\) å¾ˆå°‘ã€\\(h\\) å¾ˆå¤§æ—¶ï¼Œ\\(5as/h\\) ä¸å†æ˜¾è‘—å¤§äº 34ï¼Œè¿™æ—¶ selective recompute çš„æ”¶ç›Šä¼šä¸‹é™ã€‚\n\n\n3.4 æ•°å­¦å…¬å¼ä¸ç®—æ³•è§£è¯»\nè¿™ä¸€å°èŠ‚æŒ‘å‡ºè®ºæ–‡ä¸­å‡ ä¸ªå…³é”®å…¬å¼ï¼Œåˆ†åˆ«ä»â€œåŸæ–‡å½¢å¼ â†’ å«ä¹‰ â†’ ç›´è§‚æ“ä½œâ€ä¸‰ä¸ªå±‚æ¬¡æ¥ç†è§£ã€‚\n3.4.1 å•å±‚æ¿€æ´»å†…å­˜ï¼ˆæ— æ¨¡å‹å¹¶è¡Œï¼‰\nåŸæ–‡ä¸­çš„å…¬å¼ï¼ˆå¼ (1)ï¼‰ï¼š\n\\[\nM_{\\text{act, layer}} = sbh \\left( 34 + 5a \\frac{s}{h} \\right)\n\\]\n\nåœ¨è§£å†³ä»€ä¹ˆé—®é¢˜ï¼Ÿ è¿™æ˜¯â€œä¸€ä¸ª Transformer å±‚åœ¨å‰å‘ä¸­éœ€è¦ç¼“å­˜å¤šå°‘æ¿€æ´»â€çš„è¿‘ä¼¼å…¬å¼ï¼Œç”¨æ¥ä¼°ç®—åœ¨ä¸ä½¿ç”¨ä»»ä½• TP/SP/PP æ—¶ï¼Œæ¯å±‚æ¿€æ´»å ç”¨çš„æ˜¾å­˜ã€‚\nç¬¦å·å«ä¹‰ï¼š\n\n\\(s\\)ï¼šåºåˆ—é•¿åº¦ï¼ˆsequence lengthï¼‰\n\\(b\\)ï¼šmicro-batch å¤§å°\n\\(h\\)ï¼šhidden ç»´åº¦\n\\(a\\)ï¼šattention å¤´æ•°\n\\(M_{\\text{act, layer}}\\)ï¼šè¿™ä¸€å±‚çš„æ€»æ¿€æ´»å†…å­˜ï¼ˆå•ä½æ˜¯ bytesï¼Œå› ä¸ºæ¯å…ƒç´ å·²ç»ä¹˜ä¸Šäº† 2 bytesï¼‰\n\nå¦‚ä½•å¾—åˆ° 34 å’Œ \\(5a s/h\\)ï¼Ÿï¼ˆç›´è§‚ç‰ˆï¼‰\n\næŠŠä¸€ä¸ªå±‚æ‹†æˆï¼šä¸¤æ¬¡ LayerNormã€ä¸€ä¸ª attention å—ã€ä¸€ä¸ª MLP å—ã€‚\nç²—ç•¥ç»Ÿè®¡æ¯éƒ¨åˆ†éœ€è¦ç¼“å­˜çš„å¼ é‡æ•°é‡å’Œå¤§å°ï¼š\n\nattention å—çº¦è´¡çŒ® \\(11sbh + 5as^2b\\)ï¼›\nMLP çº¦è´¡çŒ® \\(19sbh\\)ï¼›\nä¸¤ä¸ª LayerNorm åˆè®¡è´¡çŒ® \\(4sbh\\)ã€‚\n\nåˆèµ·æ¥å°±æ˜¯ \\((11 + 19 + 4) s b h = 34sbh\\)ï¼Œå†æŠŠ \\(5as^2b\\) å†™æˆ \\(sbh \\cdot 5a s/h\\)ï¼Œå¾—åˆ°ä¸Šå¼ã€‚\n\nç­‰ä»·é‡å†™ï¼ˆä»…ä¸ºç›´è§‚ï¼‰ï¼š\n\n\\[\nM_{\\text{act, layer}}\n= s b h \\cdot 34 ;+; 5 a s^2 b\n\\]\nå¯ä»¥ç›´æ¥çœ‹æˆâ€œä¸åºåˆ—é•¿åº¦çº¿æ€§ç›¸å…³çš„ä¸»å¹²éƒ¨åˆ† + ä¸ \\(s^2\\) ç›¸å…³çš„ attention å¤æ‚éƒ¨åˆ†â€ã€‚\n\nç›´è§‚æ“ä½œæè¿°ï¼š å¦‚æœä½ ç»™å®š \\((s, b, h, a)\\)ï¼Œé‚£ä¹ˆï¼š\n\nå…ˆç®—å‡ºâ€œæ¯å±‚ä¸»å¹²æ¿€æ´»â€çš„å¤§å°ï¼š\\(34sbh\\)ï¼›\nå†ç®—å‡ºâ€œattention æ­£æ–¹å½¢çŸ©é˜µç›¸å…³â€çš„å¤§å°ï¼š\\(5as^2b\\)ï¼›\näºŒè€…ç›¸åŠ å°±æ˜¯è¿™ä¸€å±‚éœ€è¦ç¼“å­˜çš„æ¿€æ´»å­—èŠ‚æ•°ã€‚\n\n\n3.4.2 å¼ é‡å¹¶è¡Œä¸‹çš„å•å±‚æ¿€æ´»ï¼ˆTPï¼‰\nåŸæ–‡ä¸­çš„å…¬å¼ï¼ˆå¼ (2)ï¼‰ï¼š\n\\[\nM_{\\text{act, layer}}^{\\text{TP}}\n= sbh \\left(\n10 + \\frac{24}{t} + 5a \\frac{s}{ht}\n\\right)\n\\]\n\nå«ä¹‰ï¼š åœ¨ \\(t\\) è·¯å¼ é‡å¹¶è¡Œï¼ˆTPï¼‰ä¸‹ï¼Œåªæœ‰ attention å’Œ MLP å†…éƒ¨â€œåˆ‡å¾—åŠ¨â€çš„é‚£éƒ¨åˆ†æ¿€æ´»æŒ‰ \\(1/t\\) åˆ†æ‘Šåˆ°äº†å„å¡ï¼Œè€Œ LayerNorm å’Œè‹¥å¹² Dropout åŒºåŸŸä»ç„¶åœ¨æ¯å¡å®Œæ•´ä¿ç•™ï¼Œå¯¼è‡´å¸¸æ•°ä» 34 å˜æˆäº† \\(10 + 24/t\\)ï¼Œè€Œ attention ä¸­çš„ \\(5as^2b\\) é¡¹å˜æˆäº† \\(5as^2b/t\\)ã€‚\nç›´è§‚ç†è§£ï¼š\n\nâ€œ10â€ï¼šæœªåˆ‡åˆ†ã€åœ¨æ¯å¼ å¡ä¸Šé‡å¤å­˜åœ¨çš„ LayerNorm + Dropout ç­‰æ¿€æ´»ã€‚\n\\(24/t\\)ï¼šTP åçœŸæ­£è¢«å‡åˆ†çš„éƒ¨åˆ†ï¼ˆå¤§ GEMM ç›¸å…³ï¼‰ã€‚\n\\(5a s/(ht)\\)ï¼šattention ä¸­ \\(s^2\\) çº§åˆ«çš„æ¿€æ´»åœ¨ \\(t\\) å¡ä¸Šå¹³å‡åˆ†æ‘Šã€‚\n\nç›´è§‚æ“ä½œæè¿°ï¼š\n\nå…ˆåƒå¼ (1) é‚£æ ·ç®—ä¸€éâ€œæ€»çš„ä¸»å¹²æ¿€æ´»â€ä¸ â€œattention æ¿€æ´»â€ï¼›\nå†æŠŠèƒ½åˆ‡çš„éƒ¨åˆ†é™¤ä»¥ \\(t\\)ï¼Œä¸èƒ½åˆ‡çš„éƒ¨åˆ†ä¿æŒä¸å˜ï¼›\næŠŠå®ƒä»¬åˆèµ·æ¥ï¼Œå°±å¾—åˆ°äº†ä¸Šå¼ã€‚\n\n\n3.4.3 å¼ é‡ + åºåˆ—å¹¶è¡Œï¼ˆTP+SPï¼‰\nåŸæ–‡ä¸­çš„å…¬å¼ï¼ˆå¼ (4)ï¼‰ï¼š\n\\[\n\\begin{aligned}\nM_{\\text{act, layer}}^{\\text{TP+SP}}\n&amp;= sbh \\left(\n\\frac{10}{t} + \\frac{24}{t} + 5a \\frac{s}{ht}\n\\right) \\\n&amp;= \\frac{sbh}{t}\\left(\n34 + 5a \\frac{s}{h}\n\\right)\n\\end{aligned}\n\\]\n\nå«ä¹‰ï¼š æŠŠä¹‹å‰ TP ä¸‹ä»ç„¶é‡å¤çš„ 10\\(sbh\\) è¿™å—ï¼Œé€šè¿‡æ²¿åºåˆ—ç»´çš„ SP å†åˆ‡ä¸€åˆ€ï¼Œæœ€ç»ˆæ•´å±‚æ¿€æ´»ï¼ˆåŒ…æ‹¬ attention çš„é‚£ä¸€å—ï¼‰éƒ½è¢«å‡åŒ€åœ°åˆ†æ‘Šåˆ°äº† \\(t\\) ä¸ª TP rank ä¸Šâ€”â€”ç›´è§‚å°±æ˜¯â€œæ¿€æ´»å†…å­˜æ•´ä½“é™¤ä»¥ \\(t\\)â€ã€‚\nå…³é”®ç‚¹ï¼š\n\nä¾é  \\(g\\)ï¼ˆall-gatherï¼‰å’Œ \\(\\bar g\\)ï¼ˆreduce-scatterï¼‰è¿™å¯¹â€œè½¬æ¢ç®—å­â€æŠŠ LayerNorm / Dropout åŒºåŸŸä»åºåˆ—åˆ‡åˆ†åŸŸåˆ‡å›å¼ é‡åˆ‡åˆ†åŸŸå†åˆ‡å›å»ã€‚\né€šä¿¡å¸¦å®½ä¸å˜ï¼šå› ä¸ºåŸæ¥çš„ ring all-reduce æœ¬èº«å°±æ˜¯ reduce-scatter + all-gather çš„ç»„åˆã€‚\n\nç›´è§‚æ“ä½œæè¿°ï¼š\n\nå…ˆæŒ‰å¼ (1) ç®—å‡ºæ— å¹¶è¡Œæ—¶ \\(M_{\\text{act, layer}}\\)ï¼›\nå†ç®€å•é™¤ä»¥ \\(t\\)ï¼Œå°±å¾—åˆ° TP+SP ä¸‹æ¯å¡éœ€è¦çš„æ¿€æ´»å†…å­˜ã€‚\n\n\n3.4.4 åŠ ä¸Šæµæ°´å¹¶è¡Œåçš„æ€»æ¿€æ´»å†…å­˜\nåŸæ–‡ä¸­çš„å…¬å¼ï¼ˆå¼ (5)ï¼‰ï¼š\n\\[\nM_{\\text{total}}^{\\text{acts}} =\n\\frac{s b h L}{t}\\left(\n34 + 5 a \\frac{s}{h}\n\\right)\n\\]\n\nå«ä¹‰ï¼š åœ¨ 1F1B æµæ°´è°ƒåº¦ä¸‹ï¼Œé¦–ä¸ª pipeline stage å°½ç®¡åªè´Ÿè´£ \\(L/p\\) ä¸ªç‰©ç†å±‚ï¼Œä½†å› ä¸ºè¦åŒæ—¶â€œåœ¨é£â€\\(p\\) ä¸ª micro-batchï¼Œæœ€ç»ˆ peak æ¿€æ´»é‡ç­‰ä»·äºâ€œ\\(L\\) å±‚éƒ½å‹åœ¨è¿™ä¸€å¡ä¸Šâ€ã€‚å› æ­¤æ€»æ¿€æ´»å†…å­˜ç­‰äºâ€œå•å±‚æ¿€æ´» Ã— \\(L\\) å±‚ / \\(t\\)â€ã€‚\nç›´è§‚æ“ä½œï¼š\n\nç”¨å¼ (4) ç®—å‡ºå•å±‚ TP+SP ä¸‹çš„æ¿€æ´»ï¼š\\(\\frac{s b h}{t}(34 + 5 a s/h)\\)ï¼›\nä¹˜ä¸Šéœ€è¦åŒæ—¶é©»ç•™çš„â€œç­‰æ•ˆå±‚æ•°â€â€”â€”åœ¨ç»å…¸ 1F1B ä¸­å°±æ˜¯ \\(L\\)ï¼›\nå¾—åˆ°ä¸Šå¼ã€‚\n\n\n\nå¦‚æœé‡‡ç”¨ interleaved pipelineï¼Œè®ºæ–‡æŒ‡å‡ºéœ€è¦å†ä¹˜ä¸Šä¸€ä¸ª \\((1 + \\frac{p-1}{pm})\\) çš„ä¿®æ­£å› å­ï¼Œè¿™é‡Œä¸å±•å¼€ã€‚\n\n3.4.5 å…¨å±‚é‡ç®— vs é€‰æ‹©æ€§é‡ç®—\n\nå…¨å±‚æ¿€æ´»é‡ç®—çš„å†…å­˜ï¼ˆç®€å•æƒ…å½¢ï¼‰\nåŸæ–‡ä¸­çš„ç»“è®ºï¼š\n\\[M_{\\text{full-recompute}} \\approx 2 s b h L\\]\n\nå«ä¹‰ï¼šå¦‚æœä½ åª checkpoint æ¯å±‚è¾“å…¥/è¾“å‡ºï¼ˆå‡è®¾æ¯å±‚åªä¸€ç»„ï¼‰ï¼Œå¿½ç•¥å…¶å®ƒæ¿€æ´»ï¼Œé‚£ä¹ˆæ¯å±‚åªéœ€è¦å­˜ä¸¤ä»½ \\((s,b,h)\\)ï¼Œæ€»å…±å°±æ˜¯ \\(2sbhL\\)ã€‚\né—®é¢˜ï¼šæ˜¾å­˜æ˜¯ä¸‹æ¥äº†ï¼Œä½†æ¯æ¬¡åå‘è¦å¤šè·‘ä¸€ä¸ªå®Œæ•´å‰å‘ï¼ŒFLOPs å¢åŠ çº¦ 33%â€“40%ï¼Œåœ¨å¤§æ¨¡å‹ä¸Šéå¸¸è‚‰ç–¼ã€‚\n\né€‰æ‹©æ€§æ¿€æ´»é‡ç®—ï¼ˆé‡ç‚¹ï¼‰\nåŸæ–‡ä¸­çš„å…¬å¼ï¼ˆå¼ (6)ï¼‰ï¼š\n\\[\nM_{\\text{selective}} =\n\\frac{34 s b h L}{t}\n\\]\n\nå«ä¹‰ï¼šåœ¨ TP+SP çš„åŸºç¡€ä¸Šï¼Œåªå¯¹ attention ä¸­â€œå¤§æ¿€æ´»ã€ä½ FLOPsâ€çš„é‚£å‡ å—åšé‡ç®—ï¼ŒæŠŠ \\(5 a s^2 b\\) é‚£ä¸€å¨æ¿€æ´»å®Œå…¨ä»æ˜¾å­˜ä¸­ç§»é™¤ï¼Œåªå‰©ä¸‹ä¸»å¹²çš„ \\(34sbh\\)ï¼Œç„¶åå†é™¤ä»¥ \\(t\\)ã€‚\nç›´è§‚ï¼š\n\næ— å¹¶è¡Œ + æ— é‡ç®—ï¼š\\(L \\times sbh(34 + 5as/h)\\)ï¼›\nTP+SP + æ— é‡ç®—ï¼šå†é™¤ä»¥ \\(t\\)ï¼›\nTP+SP + é€‰æ‹©æ€§é‡ç®—ï¼šå†æŠŠ \\(5as/h\\) é‚£å—æ•´ä¸ªç æ‰ï¼Œå¯¹åº”å°±å˜æˆå¼ (6)ã€‚\n\nä»¥ GPT-3 / MT-NLG ä¸ºä¾‹ï¼š å¯¹äº GPT-3 (\\(a=96,s=2048,h=12288\\))ï¼Œæœ‰ \\(5 a s/h \\approx 80\\)ï¼› å¯¹äº MT-NLG (\\(a=128,s=2048,h=20480\\))ï¼Œæœ‰ \\(5 a s/h \\approx 64\\)ã€‚ ç›¸æ¯”ä¸»å¹²å¸¸æ•° 34ï¼Œè¿™è¯´æ˜ç»å¤§å¤šæ•°æ¿€æ´»å…¶å®æ¥è‡ªé‚£ä¸€å°æ’® attention å­ç®—å­ï¼Œç æ‰å®ƒä»¬èƒ½çœæ‰ 60%â€“70% çš„æ¿€æ´»ï¼Œè€Œç›¸åº”é‡ç®— FLOPs ä»…å¢åŠ  1.6%â€“2.7%ã€‚\n\n\n\nä¸å¸¸è§è®­ç»ƒæ ˆçš„å¯¹åº”å…³ç³»\nä»â€œæˆ‘çš„å¤§è§„æ¨¡è®­ç»ƒæ ˆï¼ˆå¦‚ Megatron / DeepSpeed / vLLM ç­‰ï¼‰â€è§†è§’ï¼Œå¯ä»¥è¿™ä¹ˆç†è§£è¿™äº›æ¨¡å—å¯¹åº”åˆ°å“ªå‡ å±‚ï¼š\n\næ¿€æ´»å†…å­˜æ¨¡å‹ â†’ é…ç½®æœç´¢/è‡ªåŠ¨è°ƒå‚å±‚\n\nç”¨ä¸Šé¢çš„å…¬å¼å¿«é€Ÿé¢„ä¼°åœ¨ç»™å®š \\((s,b,h,a,L,t,p)\\) ä¸‹çš„æ¿€æ´»å³°å€¼ï¼Œå¸®åŠ©é€‰æ‹© TP/SP/PP ç»„åˆå’Œ micro-batch å¤§å°ã€‚\n\nTP+SP ç»„åˆå¹¶è¡Œ â†’ æ¨¡å‹å¹¶è¡Œç­–ç•¥å±‚\n\nå¯¹åº”æ¡†æ¶é‡Œâ€œå¼ é‡å¹¶è¡Œ + åºåˆ—å¹¶è¡Œâ€çš„ç»´åº¦é…ç½®ï¼Œä¾‹å¦‚ tensor_model_parallel_sizeã€sequence_parallel_sizeï¼Œä»¥åŠç›¸å…³ shard è§„åˆ™ã€‚\n\n\\(g/\\bar g\\) ç®—å­ â†’ é€šä¿¡ backend + kernel å±‚\n\nå®é™…è½åœ°å°±æ˜¯æŠŠåŸæ¥çš„ all_reduce æ›¿æ¢æˆé…å¯¹çš„ all_gather + reduce_scatterï¼Œå¸¸å¸¸ä¸ GEMM kernel èåˆåœ¨ä¸€èµ·ä»¥å‡å°‘ä¸­é—´ç¼“å†²æ‹·è´ã€‚\n\né€‰æ‹©æ€§æ¿€æ´»é‡ç®— â†’ Checkpoint ç­–ç•¥/è‡ªåŠ¨é‡ç®—å±‚\n\nå¯¹åº”æ¡†æ¶é‡Œçš„ activation_checkpoint_methodã€checkpoint_attention ä¹‹ç±»çš„å¼€å…³ï¼Œä»¥åŠåœ¨ Python å›¾é‡ŒåŒ…ä¸€å±‚ checkpoint(function, *args)ã€‚\n\nPipeline åˆ†æ â†’ å¹¶è¡Œè°ƒåº¦ä¸ä½œä¸šç¼–æ’å±‚\n\nå†³å®šæ¯ä¸ª stage æ”¾å¤šå°‘å±‚ã€micro-batch æ•°é‡ã€æ˜¯å¦ä½¿ç”¨ interleaved pipelineï¼Œå¹¶ç¡®ä¿é¦– stage çš„æ˜¾å­˜å³°å€¼æ»¡è¶³å¡å®¹é‡ã€‚\n\n\n\nå››ã€å»ºæ¨¡æ–¹å¼ä¸è¯„ä¼°æŒ‡æ ‡\n4.1 é—®é¢˜æ˜¯å¦‚ä½•å½¢å¼åŒ–çš„ï¼Ÿ\næ ¸å¿ƒä¼˜åŒ–ç›®æ ‡å¯ä»¥ç®€å•æ¦‚æ‹¬ä¸ºï¼š\n\nåœ¨ç»™å®šè®¾å¤‡æ˜¾å­˜çº¦æŸä¸å¹¶è¡Œé…ç½®ï¼ˆTP/SP/PPï¼‰çš„æ¡ä»¶ä¸‹ï¼Œ æœ€å°åŒ–æ¿€æ´»å†…å­˜å³°å€¼ä¸é‡ç®—å¸¦æ¥çš„é¢å¤– FLOPs å¼€é”€ä¹‹å’Œã€‚\n\nè®ºæ–‡æ²¡æœ‰å†™æˆä¸¥æ ¼çš„ä¼˜åŒ–é—®é¢˜ï¼Œä½†é€šè¿‡å…¬å¼åŸºæœ¬éšå¼å®Œæˆäº†å»ºæ¨¡ï¼š\n\næ¿€æ´»å†…å­˜æ¨¡å‹ï¼š\n\næ— å¹¶è¡Œæ—¶å•å±‚æ¿€æ´»ï¼š \\(M_{\\text{act, layer}} = sbh(34 + 5 a s/h)\\)ã€‚\nTP+SP+PP åé¦– stage æ€»æ¿€æ´»ï¼š \\(M_{\\text{total}} = \\dfrac{s b h L}{t} (34 + 5 a s/h)\\)ã€‚\nselective recompute åï¼š \\(M_{\\text{selective}} = \\dfrac{34 s b h L}{t}\\)ã€‚\n\nFLOPs æ¨¡å‹ï¼š\nè¡¨ 2 ä¸­ç»™å‡ºäº†ä¸åŒé…ç½®ä¸‹æ¯å±‚ FLOPsï¼Œä¾‹å¦‚æ— å¹¶è¡Œæ—¶ï¼š\n$$ _{} =================================\n72 s b h^2 (1 + ) $$\nå…¶å®ƒé…ç½®åˆ™åœ¨æ­¤åŸºç¡€ä¸Šé™¤ä»¥ \\(t\\)ï¼Œæˆ–å¢åŠ éƒ¨åˆ†é‡ç®—ç›¸å…³é¡¹ï¼ˆæ¯”å¦‚ selective recompute ä¸‹çš„ \\(1 + \\frac{2s}{9h}\\) ç­‰ï¼‰ã€‚\nç®€åŒ–ä¸çº¦æŸï¼š\n\nå‡è®¾æ‰€æœ‰å±‚åŒæ„ï¼Œå¿½ç•¥ embedding/output ç­‰å°å¤´ï¼›\nåªè€ƒè™‘å• precisionï¼ˆ16-bitï¼‰æ¿€æ´»ï¼›\nåªåˆ†æ FP ç®—åŠ›ï¼Œæš‚ä¸å¼•å…¥é€šä¿¡æ—¶å»¶æ¨¡å‹ï¼ˆé€šä¿¡é€šè¿‡â€œbytes communicatedâ€å•ç‹¬æŠ¥å‘Šï¼‰ã€‚\n\n\næ•´ä¸ªå»ºæ¨¡çš„æ€è·¯æ˜¯ï¼šå…ˆç”¨è§£æå¼é”å®šâ€œç†è®ºä¸Šæœ€ä¼˜çš„å†…å­˜åˆ†æ‘Šæ–¹å¼â€ï¼Œå†åœ¨è¿™ä¸ªç©ºé—´å†…è®¨è®ºä¸åŒ checkpoint ç­–ç•¥çš„ä»£ä»·ã€‚\n4.2 æ ¸å¿ƒè¯„ä¼°æŒ‡æ ‡\nè®ºæ–‡é‡Œçš„æŒ‡æ ‡éå¸¸å·¥ç¨‹å‘ï¼ŒåŸºæœ¬å¯ä»¥ç›´æ¥æ˜ å°„åˆ°ä½ çš„ç›‘æ§é¢æ¿ä¸Šï¼š\n\næ¿€æ´»å†…å­˜ï¼ˆActivations Memoryï¼‰\n\nå«ä¹‰ï¼šå•å±‚æˆ–æ•´ä¸ªæ¨¡å‹åœ¨å‰å‘/åå‘æ—¶ä¸ºæ¿€æ´»åˆ†é…çš„æ˜¾å­˜å³°å€¼ï¼ˆé€šå¸¸ä»¥ GB æˆ–å å¡æ€»æ˜¾å­˜çš„ç™¾åˆ†æ¯”è¡¨ç¤ºï¼‰ã€‚\nå¯¹åº”å…³ç³»ï¼šç›´æ¥å†³å®šâ€œèƒ½ä¸èƒ½åœ¨ä¸€å¼ å¡ä¸Šè·‘ä¸‹è¿™ä¸ªé…ç½®â€ï¼Œä¹Ÿæ˜¯æ˜¯å¦éœ€è¦å†æ‰“å¼€é‡ç®—çš„ç¬¬ä¸€åˆ¤æ–­ä¾æ®ã€‚\n\næ¯å±‚å‰å‘/åå‘æ—¶å»¶ï¼ˆForward / Backward Time per Layerï¼‰\n\nå«ä¹‰ï¼šå›ºå®šæ¨¡å‹ &amp; batch è®¾ç½®ä¸‹ï¼Œå•å±‚ forward + backward çš„ wall-clock æ—¶é—´ï¼ˆmsï¼‰ï¼Œæ–‡ä¸­ç”¨å•å±‚ 22B æ¨¡å‹æ¥åš micro benchmarkã€‚\nå¯¹åº”å…³ç³»ï¼šç”¨æ¥æ‹†åˆ†â€œé‡ç®—å¤šè€—äº†å¤šå°‘æ—¶é—´â€ã€â€œSP/TP å¯¹ LayerNorm/Dropout åŠ é€Ÿäº†å¤šå°‘â€ã€‚\n\né‡ç®—å¼€é”€ï¼ˆRecompute Overheadï¼‰\n\nå«ä¹‰ï¼šåœ¨â€œæ— é‡ç®— baselineâ€çš„å‰æä¸‹ï¼Œé‡ç®—ä¹‹å forward+backward æ€»æ—¶å»¶çš„ç›¸å¯¹æå‡ï¼Œæ¯”å¦‚ full recompute çš„ +39% vs selective+SP çš„ +4%ã€‚\nå¯¹åº”å…³ç³»ï¼šå¸®åŠ©åˆ¤æ–­â€œå¤šçœçš„æ˜¾å­˜æ˜¯å¦å€¼è¿™ç‚¹æ—¶é—´â€ï¼Œå¯¹äºæ•´æœºè®­ç»ƒååå°¤ä¸ºå…³é”®ã€‚\n\nç«¯åˆ°ç«¯è¿­ä»£æ—¶é—´ï¼ˆIteration Time / Throughputï¼‰\n\nå«ä¹‰ï¼šä¸€æ¬¡å®Œæ•´è¿­ä»£ï¼ˆforward+backward+ä¼˜åŒ–å™¨æ›´æ–°ï¼‰æ‰€éœ€æ—¶é—´ï¼Œè®ºæ–‡ä¸­æŠ¥å‘Šçš„æ˜¯ 22B/175B/530B/1T æ¨¡å‹çš„è¿­ä»£æ—¶é—´ä¸å¯¹åº” throughput æå‡ï¼ˆçº¦ 29%â€“32%ï¼‰ã€‚\nå¯¹åº”å…³ç³»ï¼šè¿™æ˜¯æœ€è´´è¿‘â€œè®­ç»ƒæ€»æ—¶é•¿â€çš„æŒ‡æ ‡ï¼Œä¹Ÿæœ€å®¹æ˜“æ˜ å°„åˆ°é¢„ç®—ä¸Šã€‚\n\næ¨¡å‹ FLOPs åˆ©ç”¨ç‡ï¼ˆMFUï¼‰ä¸ç¡¬ä»¶ FLOPs åˆ©ç”¨ç‡ï¼ˆHFUï¼‰\n\nå«ä¹‰ï¼š\n\nMFUï¼šæ¨¡å‹ç†è®º FLOPs / å³°å€¼ç®—åŠ›ï¼›\nHFUï¼šå®é™…æ‰§è¡Œ FLOPsï¼ˆåŒ…æ‹¬é‡ç®—ï¼‰/ å³°å€¼ç®—åŠ›ã€‚\n\nå¯¹åº”å…³ç³»ï¼šè¯´æ˜åœ¨åº”ç”¨ selective recompute åï¼Œè™½ç„¶å®é™… FLOPs ç¨æœ‰å¢åŠ ï¼Œä½†æ€»ä½“ç®—åŠ›åˆ©ç”¨ç‡ä»ç„¶å¯ä»¥ç»´æŒç”šè‡³ç•¥å‡ï¼Œæ¯”å¦‚ 1T æ¨¡å‹çš„ MFU/HFU åœ¨ 56% å·¦å³ã€‚\n\né€šä¿¡é‡ï¼ˆBytes Communicatedï¼‰\n\nå«ä¹‰ï¼šæ¯å±‚åœ¨ä¸åŒé…ç½®ä¸‹çš„æ€»é€šä¿¡å­—èŠ‚æ•°ï¼Œè¡¨ 2 ä¸­ä»¥ bytes å½¢å¼ç»™å‡ºã€‚\nå¯¹åº”å…³ç³»ï¼šå¯¹æ¯”â€œTP vs TP+SP vs full/partial recomputeâ€æ˜¯å¦å¼•å…¥é¢å¤– all-gather / reduce-scatterï¼Œå¸®åŠ©åˆ¤æ–­åœ¨ä¸åŒç½‘ç»œæ‹“æ‰‘ï¼ˆå•æœº NVLinkã€å¤šæœº IBï¼‰ä¸‹æ˜¯å¦ä¼šè¢«é€šä¿¡ç“¶é¢ˆå¡ä½ã€‚\n\n\n\näº”ã€ä¸»è¦å®éªŒå‘ç°\nç”¨å‡ æ¡ç»“è®ºæŠŠæ•´ç¯‡å®éªŒçš„è¦ç‚¹ä¸²ä¸€ä¸‹ï¼š\n\nTP+SP / selective recompute å•ç‹¬ä½¿ç”¨æ—¶ï¼Œå„è‡ªéƒ½èƒ½å°†æ¿€æ´»æ˜¾å­˜å‹åˆ° TP åŸºçº¿çš„çº¦ä¸€åŠï¼š ä»…åŠ  sequence parallelismï¼Œå°±èƒ½æŠŠæ¿€æ´»é™åˆ°åŸæ¥çš„ ~50%ï¼›ä»…åŠ  selective recomputeï¼ŒåŒæ ·çº¦åŠï¼›ä¸¤è€…å åŠ å¯è¾¾åˆ°çº¦ 5Ã— çš„å‹ç¼©ï¼Œä½¿å¾— 175B / 530B / 1T é…ç½®åœ¨ 80GB å¡ä¸Šå˜å¾—å¯è¡Œã€‚\né€‰æ‹©æ€§é‡ç®—æå¤§é™ä½äº†é‡ç®—å¼€é”€ï¼š åœ¨ 22B å•å±‚å®éªŒä¸­ï¼š\n\nå…¨å±‚é‡ç®—ï¼šforward+backward æ€»æ—¶å»¶å¢åŠ  39%ï¼›\nselective é‡ç®—ï¼šå¢åŠ  7%ï¼›\nselective + SPï¼šä»…å¢åŠ  4%ã€‚\n\nå¯¹å¤§æ¨¡å‹è¶Šå‹å¥½ï¼Œæ¨¡å‹è¶Šå¤§æ”¶ç›Šè¶Šé«˜ï¼š å¯¹ 530B å’Œ 1T æ¨¡å‹ï¼Œfull recompute çš„é‡ç®— overhead çº¦ 36%ï¼Œè€Œ selective+SP çš„ overhead ä»… 2%ã€‚\nç«¯åˆ°ç«¯ååæå‡çº¦ 30%ï¼š åœ¨ 4 ç»„æ¨¡å‹ï¼ˆ22B/175B/530B/1Tï¼‰ä¸Šï¼Œä¸â€œfull recompute + æ—  SPâ€ç›¸æ¯”ï¼Œæœ¬æ–‡æ–¹æ¡ˆçš„è¿­ä»£æ—¶é—´ç¼©çŸ­ 29%â€“32%ï¼Œå¯¹åº” throughput åŒæ¯”ä¾‹æå‡ã€‚\nFLOPs åˆ©ç”¨ç‡ç¨³æ­¥æå‡ï¼š éšæ¨¡å‹è§„æ¨¡å˜å¤§ï¼ŒMFU / HFU ä» 40%+ æå‡åˆ° 56% å·¦å³ï¼Œè¯´æ˜æ¿€æ´»å†…å­˜ä¼˜åŒ–å¸¦æ¥çš„â€œæ›´å¤§ batchã€æ›´å¥½å¹¶è¡Œé…ç½®â€å¯¹æ•´ä½“ç¡¬ä»¶åˆ©ç”¨ç‡æ”¶ç›Šæ˜¾è‘—ã€‚\n\n5.1 å…³é”®å›¾è¡¨è§£è¯»\n\nå›¾ 7ï¼šä¸åŒæ–¹æ¡ˆçš„æ¿€æ´»å†…å­˜å æ¯”ï¼ˆç›¸å¯¹äº TP baselineï¼‰\n\nç°è±¡ï¼šéšç€æ¨¡å‹è§„æ¨¡å¢å¤§ï¼Œsequence parallelism ä¸ selective recompute å•ç‹¬ä½¿ç”¨æ—¶éƒ½èƒ½å°†æ¿€æ´»å‹åˆ°çº¦ 50%ï¼›åˆç”¨åèƒ½é™åˆ°ä¸åˆ° 20%ï¼Œè€Œ full recompute åœ¨ 10% å·¦å³ã€‚\næ”¯æ’‘ä¸»å¼ ï¼šè¯´æ˜åœ¨â€œåªä»˜å‡º 2%â€“7% é‡ç®—å¼€é”€â€çš„å‰æä¸‹ï¼ŒTP+SP+selective å·²ç»éå¸¸æ¥è¿‘ full recompute çš„å†…å­˜æ•ˆç‡ï¼Œä½†å°‘äº†å¤§é‡æ— è°“çš„ç®—åŠ›å¼€é”€ï¼Œæ˜¯å®è·µä¸­æ›´å¹³è¡¡çš„æ–¹æ¡ˆã€‚\n\nå›¾ 8ï¼šæ¯å±‚ forward / backward / recompute æ—¶é—´æ‹†åˆ†\n\nç°è±¡ï¼š\n\nbaseline æ— é‡ç®—æ—¶ï¼Œbackward æ—¶é—´è¿œå¤§äº forwardï¼›\nfull recompute ç»™ backward é¡¶ä¸Šå»ä¸€å¤§å—ï¼›\nselective+SP çš„â€œé‡ç®—æ¡â€éå¸¸ç»†ï¼Œå¯¹æ•´ä½“å½±å“æå°ã€‚\n\næ”¯æ’‘ä¸»å¼ ï¼šè¯æ˜ selective é‡ç®—ç¡®å®åªæŠŠé‡ç®—é›†ä¸­åœ¨ FLOPs ç¨å¤šçš„é‚£ä¸€å°å—ï¼Œä¸”é€šè¿‡é‡å é€šä¿¡/è®¡ç®—æŠŠ overhead å‹å¾—å¾ˆä½ã€‚\n\nè¡¨ 5ï¼šç«¯åˆ°ç«¯è¿­ä»£æ—¶é—´ä¸ FLOPs åˆ©ç”¨ç‡\n\nç°è±¡ï¼šæ‰€æœ‰è§„æ¨¡æ¨¡å‹çš„ iteration time éƒ½ä» â€œfull recomputeâ€ é…ç½®ä¸­å‡æ‰äº† ~30%ï¼›åŒæ—¶ MFU/HFU éšè§„æ¨¡å¢å¤§è€Œå‡é«˜ï¼Œ1T æ¨¡å‹å¯åˆ° 56%+ã€‚\næ”¯æ’‘ä¸»å¼ ï¼šè¯´æ˜æœ¬æ–‡ä¸ä»…ä»…æ˜¯â€œæŠŠæ˜¾å­˜å‡‘å¤Ÿå°±å®Œäº‹â€ï¼Œè€Œæ˜¯åœ¨å®é™…è®­ç»ƒååå’Œç¡¬ä»¶åˆ©ç”¨ç‡ä¸Šéƒ½è¯æ˜äº†å·¥ç¨‹ä»·å€¼ã€‚\n\n\nç»“æœè§£è¯»ä¸è¾¹ç•Œ\næ€»ä½“æ¥çœ‹ï¼Œå®éªŒéå¸¸æœ‰è¯´æœåŠ›ï¼šå…¬å¼æ¨å¯¼å’Œå®æµ‹æ•°æ®é«˜åº¦åŒ¹é…ï¼Œä»å•å±‚ micro benchmark åˆ°ä¸Šç™¾å±‚ã€ä¸Šä¸‡å¡çš„ç«¯åˆ°ç«¯å®éªŒï¼Œéƒ½å±•ç¤ºäº† TP+SP+selective çš„ç¨³å®šä¼˜åŠ¿ã€‚\nä½†ä¹Ÿå­˜åœ¨ä¸€äº›æœªå®Œå…¨è¦†ç›–çš„ç»´åº¦ï¼Œä¾‹å¦‚ï¼š\n\nå¹¶æœªç³»ç»Ÿè¯„ä¼° æ›´å¤æ‚çš„é‡å¤ç»“æ„ï¼ˆMoEã€å¸¦å¤šè·¯åˆ†æ”¯çš„ encoder-decoderï¼‰ä¸­ selective recompute çš„æ”¶ç›Šä¸å¼€é”€ï¼›\nå¯¹ æ¢¯åº¦ checkpoint æœç´¢ç®—æ³•ï¼ˆå¦‚ CVPR 2021 çš„ Optimal Checkpoint Searchï¼‰åªåœ¨ç›¸å…³å·¥ä½œä¸­æåŠï¼Œæœªåšç›´æ¥å¯¹æ¯”ï¼›\nå®éªŒä¸»è¦é›†ä¸­åœ¨å•ä¸€ç¡¬ä»¶å¹³å°ä¸ç½‘ç»œæ‹“æ‰‘ï¼Œå¯¹ä½å¸¦å®½å¤šæœºç¯å¢ƒä¸‹â€œall-gather / reduce-scatter æ•°é‡å¢åŠ æ˜¯å¦æˆä¸ºç“¶é¢ˆâ€ç¼ºä¹ç³»ç»Ÿè¯„ä»·ã€‚\n\n\nå…­ã€ä¼˜ç‚¹ä¸å±€é™\näº®ç‚¹ï¼ˆStrengthsï¼‰\n\né—®é¢˜åˆ»ç”»éå¸¸ç²¾å‡†ï¼šä»â€œæ¿€æ´»å†…å­˜â€è€Œä¸æ˜¯â€œæ€»æ˜¾å­˜â€åˆ‡å…¥ï¼Œå°† attention / MLP / LN / Dropout çš„æ¿€æ´»å æ¯”æ‹†å¾—éå¸¸ç»†ï¼Œæœ‰åˆ©äºå·¥ç¨‹ä¸Šé’ˆå¯¹æ€§ä¼˜åŒ–ã€‚\nè§£ææ¨¡å‹ç®€å•ä½†å¨åŠ›å¤§ï¼šå‡ ä¸ªçŸ­å…¬å¼å°±è§£é‡Šäº† TP / SP / PP çš„å†…å­˜è¡Œä¸ºï¼Œå¹¶è‡ªç„¶ç»™å‡ºâ€œæ¿€æ´»å‡åŒ€åˆ†æ‘Šåˆ° TP ç»„â€çš„æœ€ä¼˜å½¢å¼ï¼Œä¸ºåç»­å·¥ä½œæä¾›äº†ç»Ÿä¸€çš„åº¦é‡å°ºã€‚\nTP+SP è®¾è®¡ä¼˜é›…ï¼šé€šè¿‡ \\(g/\\bar g\\) å°† all-reduce æ‹†æˆ all-gather + reduce-scatterï¼Œä¸æ”¹å˜é€šä¿¡å¸¦å®½ï¼Œä»…æ”¹å˜é€šä¿¡ç®—å­çš„å½¢æ€ï¼Œå°±è§£å†³äº†é TP åŒºåŸŸçš„æ¿€æ´»é‡å¤é—®é¢˜ã€‚\né€‰æ‹©æ€§é‡ç®—éå¸¸å·¥ç¨‹å‹å¥½ï¼šåªéœ€è¦åœ¨ attention å†…éƒ¨åŠ å‡ å¤„ checkpoint æ ‡è®°ï¼Œæ—¢å‡å°‘å¤§é‡æ¿€æ´»ï¼Œåˆé¿å…åƒâ€œå…¨å±‚é‡ç®—â€é‚£æ ·åŠ¨è¾„ +30% FLOPsã€‚\nå®éªŒè¦†ç›–åˆ° trillion-scaleï¼šåœ¨ 22Bâ€“1T å››ä¸ªé‡çº§æ¨¡å‹ä¸Šå®Œæ•´è¯„ä¼°ï¼ŒåŒ…å«å•å±‚æ—¶å»¶ã€æ•´æ¨¡å‹è¿­ä»£æ—¶é—´ã€MFU/HFUï¼Œéå¸¸è´´è¿‘å®é™…å¤§æ¨¡å‹è®­ç»ƒåœºæ™¯ã€‚\nä¸ç°æœ‰å¹¶è¡Œæ ˆé«˜åº¦å…¼å®¹ï¼šTP+SP+PP çš„ç»„åˆå¯ä»¥è‡ªç„¶åµŒå…¥åˆ°ä¸»æµ 3D å¹¶è¡Œæ¡†æ¶ä¸­ï¼Œä¸ä¸ ZeRO/FSDP ç­‰å‚æ•°/ä¼˜åŒ–å™¨åˆ‡åˆ†æŠ€æœ¯å†²çªã€‚(arXiv)\n\nå±€é™ï¼ˆLimitationsï¼‰\n\nç»“æ„å‡è®¾è¾ƒå¼ºï¼šåªé’ˆå¯¹æ ‡å‡†å• stack Transformerï¼Œä¸”é»˜è®¤å±‚ç»“æ„é«˜åº¦ä¸€è‡´ï¼Œå¯¹ MoEã€encoder-decoderã€å¤šä»»åŠ¡å¤´ç­‰å¤æ‚æ‹“æ‰‘çš„é€‚é…å¹¶æœªæ·±å…¥è®¨è®ºã€‚\nå®Œå…¨æ‰‹å·¥çš„ checkpoint ç­–ç•¥ï¼šå½“å‰ selective recompute æ–¹æ¡ˆåŸºäºäººå·¥åˆ†æï¼Œå¹¶æœªåˆ©ç”¨å›¾æœç´¢/è‡ªåŠ¨è°ƒåº¦ç®—æ³•å»è¿›ä¸€æ­¥é€¼è¿‘ç†è®ºæœ€ä¼˜ã€‚\nç¼ºå°‘å¯¹æ¿€æ´»ç¢ç‰‡åŒ–é—®é¢˜çš„å®šé‡åˆ†æï¼šè™½ç„¶ç»“è®ºéƒ¨åˆ†æåˆ°ç¢ç‰‡å’Œé¦– stage å†…å­˜ä¸å‡æ˜¯æœªæ¥å·¥ä½œæ–¹å‘ï¼Œä½†æ­£æ–‡æœªç»™å‡ºç³»ç»Ÿæµ‹é‡æˆ–æ¨¡å‹ã€‚\né€šä¿¡æ€§èƒ½å‡è®¾åç†æƒ³ï¼šå°† all-reduce = reduce-scatter + all-gather è§†ä½œâ€œé€šä¿¡å¸¦å®½ä¸å˜â€ï¼Œåœ¨è·¨æœºã€éå…¨è¿æ¥æ‹“æ‰‘ä¸‹å¯èƒ½ä¸å®Œå…¨æˆç«‹ã€‚\nä¸å…¶å®ƒå†…å­˜ä¼˜åŒ–æŠ€æœ¯çš„ç»„åˆåˆ†ææœ‰é™ï¼šä¾‹å¦‚ä¸ ZeRO/FSDPã€offloadã€FlashAttention ç­‰ç»„åˆåçš„æ•´ä½“æ”¶ç›Šï¼Œç›®å‰ä»éœ€è¯»è€…è‡ªè¡Œæ¢ç´¢ã€‚(arXiv)\n\n\nä¸ƒã€ä¸šå†…ç›¸å…³å·¥ä½œå¯¹æ¯”\nä¸‹é¢é€‰ 3 ç±»ä»£è¡¨æ€§å·¥ä½œï¼Œä¸æœ¬æ–‡åšä¸€ä¸ªå·¥ç¨‹è§†è§’ä¸‹çš„å¯¹æ¯”ï¼š\n\n\n\n\n\n\n\n\n\nå·¥ä½œ\né—®é¢˜å®šä¹‰\næ–¹æ³•è·¯çº¿\nè´¡çŒ®ä¸å®ç”¨ä»·å€¼ï¼ˆä¸»è§‚ï¼‰\n\n\n\n\næœ¬æ–‡ï¼šå‡å°‘æ¿€æ´»é‡è®¡ç®—\nå¤§è§„æ¨¡ Transformer è®­ç»ƒä¸­ï¼Œæ¿€æ´»æ˜¾å­˜æˆä¸ºä¸»è¦ç“¶é¢ˆï¼Œfull recompute å¸¦æ¥å·¨å¤§ç®—åŠ›å¼€é”€ã€‚\nç²¾ç¡®å»ºæ¨¡æ¿€æ´»å†…å­˜ï¼Œç»“åˆ TP + SP å‡åˆ†æ¿€æ´»ï¼Œå¹¶åœ¨å±‚å†…å¯¹å­ç®—å­åš selective recomputeã€‚\nåœ¨ä¸æ”¹æ¨¡å‹ç»“æ„çš„å‰æä¸‹ï¼Œæ˜¾å­˜å‹ç¼© 5Ã—ï¼Œååæå‡ ~30%ï¼Œå¯¹äºå·²æœ‰ 3D å¹¶è¡Œæ ˆå‡ ä¹æ˜¯â€œå¿…é€‰é¡¹â€ã€‚\n\n\nZeRO / FSDP ç³»åˆ—(arXiv)\nèšç„¦ å‚æ•°+ä¼˜åŒ–å™¨çŠ¶æ€ çš„å†…å­˜å†—ä½™ï¼Œä½¿æ¨¡å‹è§„æ¨¡éšè®¾å¤‡æ•°çº¿æ€§æ‰©å±•ã€‚\né€šè¿‡åˆ‡åˆ† optimizer stateã€gradientã€parameterï¼Œå°†æ•°æ®å¹¶è¡Œä¸­çš„å†—ä½™å…¨éƒ¨æ‰“æ•£ï¼Œé…åˆ offloadã€‚\nå¤§å¹…å‡å°â€œæ¨¡å‹çŠ¶æ€â€å ç”¨ï¼Œé€‚åˆåœ¨ DP ç»´åº¦æ‰©å±•ï¼Œå’Œæœ¬æ–‡åœ¨ç»´åº¦ä¸Šé«˜åº¦äº’è¡¥ã€‚\n\n\nGSPMD / é€šç”¨ SPMD å¹¶è¡Œ(arXiv)\næä¾›ä¸€ç§ç»Ÿä¸€çš„å›¾çº§ SPMD å¹¶è¡ŒæŠ½è±¡ï¼Œæ”¯æŒ TP/PP/DP/æ··åˆã€‚\nå°†å¹¶è¡Œè§†ä½œå¯¹ tensor shape çš„â€œsharding specâ€ï¼Œç”±ç¼–è¯‘å™¨è‡ªåŠ¨å®Œæˆè°ƒåº¦ä¸é€šä¿¡æ’å…¥ã€‚\nåœ¨ç¼–è¯‘å±‚é¢å¯¹å„ç§å¹¶è¡Œå½¢å¼è¿›è¡Œç»Ÿä¸€æè¿°ï¼Œé€‚åˆä½œä¸º TP+SP+selective è¿™ç±»ä¼˜åŒ–çš„â€œè½½ä½“â€ã€‚\n\n\nSequence Parallelism from System Perspectiveï¼ˆSP ç³»åˆ—å·¥ä½œï¼‰(ResearchGate)\né¢å‘è¶…é•¿åºåˆ—è®­ç»ƒï¼Œå…³æ³¨ æ²¿åºåˆ—ç»´åˆ‡åˆ† activations/å‚æ•° çš„ç³»ç»Ÿè®¾è®¡ã€‚\næå‡ºå¤šç§ SP å˜ä½“ï¼ˆring attention ç­‰ï¼‰ï¼Œé€šè¿‡åœ¨ attention å†…åŠ å…¥ç‰¹æ®Šé€šä¿¡æ¨¡å¼å‡å°‘ \\(s^2\\) å­˜å‚¨å’Œè®¡ç®—ã€‚\nå¯¹é•¿ä¸Šä¸‹æ–‡æ¨¡å‹æä¸ºé‡è¦ï¼Œä¸æœ¬æ–‡çš„ SP æ€è·¯ç±»ä¼¼ä½†æ›´å…³æ³¨â€œé•¿åºåˆ—ä¸‹ attention çš„è®¡ç®— patternâ€ã€‚\n\n\n\næ•´ä½“è€Œè¨€ï¼Œæœ¬æ–‡å¯ä»¥çœ‹ä½œæ˜¯ â€œTP-centric 3D å¹¶è¡Œæ ˆä¸­é’ˆå¯¹æ¿€æ´»çš„ä¸€å—è¡¥å®Œâ€ï¼š\n\nåœ¨å‚æ•°/ä¼˜åŒ–å™¨ç»´åº¦ï¼Œå®ƒè‡ªç„¶å¯ä»¥ä¸ ZeRO/FSDP ååŒï¼›\nåœ¨ç¼–è¯‘/å›¾è°ƒåº¦ç»´åº¦ï¼Œå¯ä»¥è¢« GSPMD ç­‰ SPMD æ¡†æ¶å®ç°ä¸ºä¸€å¥— sharding è§„åˆ™ä¸é€šä¿¡é‡å†™ï¼›\nåœ¨é•¿åºåˆ—åœºæ™¯ä¸‹ï¼Œå¯ä¸æ›´æ¿€è¿›çš„ SP / context parallel / ring attention ç­‰æ–¹æ¡ˆäº’è¡¥ã€‚\n\n7.1 ä¸ªäººè§‚ç‚¹\nä»â€œå¦‚ä½•å†™ä¸€ç¯‡ç³»ç»Ÿè®ºæ–‡â€çš„è§’åº¦çœ‹ï¼Œè¿™ç¯‡æ–‡ç« çš„è®ºè¯è·¯çº¿éå¸¸æ¸…æ™°ï¼š\n\nå…ˆç”¨è§£ææ¨¡å‹è§£é‡Šæ¸…æ¥š â€œä¸ºä»€ä¹ˆéœ€è¦ TP+SP + selectiveâ€ï¼Œä»¥åŠå®ƒåœ¨å…¬å¼ä¸Šçš„æœ€ä¼˜æ€§ï¼›\nå†ç”¨å¤šç»„å®éªŒéªŒè¯â€œæ¨¡å‹å’Œç°å®åŸºæœ¬ä¸€è‡´â€ï¼Œå¹¶è´¯ç©¿ä¸åŒæ¨¡å‹è§„æ¨¡ï¼Œé¿å…åªåœ¨å•ä¸€è§„æ¨¡åš cherry-pickã€‚\n\nå¦‚æœè¦æŒ‘åˆºï¼Œæˆ‘è§‰å¾—å¯ä»¥åŠ å¼ºçš„éƒ¨åˆ†æœ‰ï¼š\n\nbaseline æ›´ä¸°å¯Œï¼šç›®å‰é‡ç®—éƒ¨åˆ†ä¸»è¦å¯¹æ¯”çš„æ˜¯â€œfull recompute vs selectiveâ€ï¼Œå¦‚æœèƒ½å†åŠ ä¸Šâ€œä¸€äº›è‡ªåŠ¨ checkpoint æœç´¢ç®—æ³•â€ï¼ˆä¾‹å¦‚ Feng &amp; Huang 2021ï¼‰æˆ–ç°æœ‰æ¡†æ¶ä¸­çš„é»˜è®¤ç­–ç•¥ï¼Œå¯¹å·¥ç¨‹é€‰å‹ä¼šæ›´æœ‰å‚è€ƒæ„ä¹‰ã€‚\nä¸å…¶å®ƒå†…å­˜ä¼˜åŒ–çš„ç»„åˆå®éªŒï¼šä¾‹å¦‚å°† TP+SP+selective ä¸ ZeRO/FSDP/FlashAttention/å‚æ•° offload ä¸€èµ·æ”¾å…¥åŒä¸€å¼ å¯¹æ¯”è¡¨ä¸­ï¼Œè¯´æ˜ä¸åŒç»´åº¦ä¸Šçš„å¯å åŠ æ€§ã€‚\nå¯¹ç¢ç‰‡å’Œè°ƒåº¦çš„æ›´ç³»ç»Ÿåˆ†æï¼šå¦‚èƒ½åœ¨é™„å½•ä¸­è¡¥å…… pipeline é¦– stage çš„å†…å­˜ç¢ç‰‡åˆ†å¸ƒã€ä¸åŒ micro-batch æ•°é‡å¯¹ç¢ç‰‡çš„å½±å“ï¼Œä¼šæ›´åˆ©äºå·¥ç¨‹è½åœ°æ—¶åšäºŒæ¬¡æƒè¡¡ã€‚\n\n\nå…«ã€åœ¨å®é™…è®­ç»ƒæ ˆä¸­å¦‚ä½•è½åœ°ï¼Ÿ\nå‡è®¾ä½ å·²ç»æœ‰ä¸€å¥—â€œ3D å¹¶è¡Œ + æ¿€æ´» checkpointâ€ çš„è®­ç»ƒæ ˆï¼ˆæ¯”å¦‚æŸç§ Megatron/DeepSpeed é£æ ¼ï¼‰ï¼Œè¦å¼•å…¥æœ¬æ–‡æ–¹æ³•ï¼Œå¤§è‡´å¯ä»¥ä»ä»¥ä¸‹å‡ ä¸ªå±‚é¢åŠ¨æ‰‹ï¼š\n\nå¹¶è¡Œè°ƒåº¦ï¼ˆTP / SP / PP ç»„åˆï¼‰\n\nåœ¨ç°æœ‰ TP é…ç½®ä¸Šï¼Œæ–°å¢ sequence parallel ç»´åº¦ï¼Œä¾‹å¦‚å¢åŠ  sequence_parallel_sizeï¼Œå¹¶ä¸º LN/Dropout/embedding/output ç­‰é TP åŒºåŸŸæŒ‡å®šâ€œæŒ‰åºåˆ—åˆ‡åˆ†â€çš„ layoutã€‚\nåœ¨ pipeline åˆ‡åˆ†æ—¶ï¼Œæ˜¾å¼è€ƒè™‘â€œé¦– stage éœ€è¦ hold \\(L\\) å±‚æ¿€æ´»â€çš„äº‹å®ï¼Œç”¨ä¸Šé¢çš„å…¬å¼è¯„ä¼°ä¸åŒ pipeline_model_parallel_size ä¸‹çš„ peak æ˜¾å­˜ã€‚\nå¯¹å¤šæœºåœºæ™¯ï¼Œç¡®è®¤ SP çš„é€šä¿¡ç»„ï¼ˆé€šå¸¸å’Œ TP ç»„ä¸€è‡´ï¼‰ï¼Œé¿å…è·¨èŠ‚ç‚¹é¢‘ç¹åš all-gather / reduce-scatterã€‚\n\nkernel / ç®—å­å®ç°\n\nä¸º LN/Dropout/write-back ç­‰ç®—å­å¢åŠ  SP awarenessï¼šè¾“å…¥å¼ é‡åœ¨åºåˆ—ç»´ä¸Šæ˜¯ shard çš„ï¼Œç®—å­åº”èƒ½åœ¨å±€éƒ¨ shard ä¸Šå·¥ä½œã€‚\nå°†åŸæœ¬åœ¨ TP å†…éƒ¨ä½¿ç”¨çš„ all_reduce æ”¹å†™æˆæˆå¯¹çš„ all_gather + reduce_scatterï¼Œå¹¶å°½å¯èƒ½ä¸ GEMM kernel èåˆï¼Œå‡å°‘ä¸­é—´ bufferã€‚\nåœ¨ attention ä¸­ï¼Œå¯¹ \\(QK^\\top\\)ã€softmaxã€dropoutã€attention over V é‚£ä¸€æ®µå­å›¾å¢åŠ â€œä¾¿äºé‡ç®—â€çš„è¾¹ç•Œï¼Œæ¯”å¦‚ä½¿ç”¨æ¡†æ¶å†…çš„ checkpoint åŒ…ä¸€å±‚ã€‚\n\næ¿€æ´» checkpoint / é‡ç®—ç­–ç•¥\n\næä¾›ä¸€ä¸ªç»†ç²’åº¦çš„é‡ç®—é…ç½®æ¥å£ï¼Œå…è®¸ç”¨æˆ·å•ç‹¬æ§åˆ¶ï¼š\n\næ˜¯å¦å¯¹ attention å†…éƒ¨åš selective checkpointï¼›\næ˜¯å¦å¯¹ MLP æˆ–æ•´å±‚åšé¢å¤– checkpointï¼ˆåœ¨æ›´ç´§å¼ æ˜¾å­˜ä¸‹ï¼‰ã€‚\n\nå°†è®ºæ–‡é‡Œçš„â€œGPU çº§ FLOPs overhead ä¼°ç®—å…¬å¼â€å›ºåŒ–ä¸ºå·¥å…·å‡½æ•°ï¼Œè®©ç”¨æˆ·åœ¨é…ç½®æ–‡ä»¶ä¸­çœ‹åˆ°â€œé¢„ä¼°é‡ç®— overhead ä¸æ¿€æ´»èŠ‚çœæ¯”ä¾‹â€ï¼Œä»¥å¸®åŠ©é€‰è¾¹ç•Œã€‚\n\né€šä¿¡ä¸é›†ä½“æ“ä½œ backend\n\nåœ¨é€šä¿¡å±‚é¢å¤–æ”¯æŒâ€œåŸºäºå½¢çŠ¶ä¸ layout çš„ all-reduce â†” AG+RS é‡å†™â€ï¼Œå¿…è¦æ—¶å¯¹ all_gather å’Œ reduce_scatter åšä¸“é—¨è°ƒä¼˜ï¼ˆpipeline overlapã€ç»„å†…æ‹“æ‰‘ awareness ç­‰ï¼‰ã€‚\nä¸º SP/TP çš„é€šä¿¡ group æä¾›ç»Ÿä¸€ç®¡ç†ï¼Œé¿å…å‡ºç°â€œä¸€ä¸ª rank åŒæ—¶éš¶å±å¤ªå¤š group å¯¼è‡´ NCCL resource ç´§å¼ â€çš„é—®é¢˜ã€‚\n\nDataLoader / é¢„å¤„ç†ä¸æ‰“åŒ…ç­–ç•¥\n\nè™½ç„¶æœ¬æ–‡ä¸ç›´æ¥æ”¹å˜ DataLoaderï¼Œä½†åœ¨å®è·µä¸­é€šå¸¸ä¼šåˆ©ç”¨â€œèŠ‚çœä¸‹æ¥çš„æ¿€æ´»æ˜¾å­˜â€å»å¢åŠ  micro-batch æˆ– global batchï¼Œæ­¤æ—¶éœ€è¦æ£€æŸ¥ï¼š\n\næ•°æ®æ‰“åŒ…æ˜¯å¦æ”¯æŒæ›´å¤§ batchï¼ˆå°¤å…¶æ˜¯å¤šä»»åŠ¡æ··åˆæ•°æ®é›†ï¼‰ï¼›\né•¿åºåˆ—è®­ç»ƒæ—¶ï¼Œæ˜¯å¦ä¸ SP / context parallel ç­‰ç­–ç•¥å†²çªã€‚\n\n\né…ç½®æœç´¢ / è‡ªåŠ¨è°ƒå‚\n\nå°†æ¿€æ´»å†…å­˜æ¨¡å‹ä¸ FLOPs æ¨¡å‹åšæˆä¸€ä¸ªå°å·¥å…·ï¼ˆç”šè‡³å¯ä»¥å†™æˆ Python è„šæœ¬ï¼‰ï¼Œåœ¨ç»™å®šç¡¬ä»¶è§„æ ¼å’Œæ¨¡å‹é…ç½®çš„æƒ…å†µä¸‹ï¼Œè‡ªåŠ¨æœç´¢å¯è¡Œçš„ (TP, SP, PP, micro-batch) ç»„åˆã€‚\nå¯¹äºè‡ªåŠ¨åŒ–çš„ launcherï¼Œå¯ä»¥åœ¨æäº¤å‰ç›´æ¥ç»™å‡ºâ€œé¢„ä¼° peak æ˜¾å­˜ã€é‡ç®—å¼€é”€ã€MFU ä¸Šé™â€ç­‰ä¿¡æ¯ã€‚\n\nç›‘æ§ä¸è°ƒè¯•\n\nåœ¨æ¡†æ¶ä¸­å¢åŠ  per-layer / per-stage çš„ æ¿€æ´»å†…å­˜è¿½è¸ªï¼ˆé€šè¿‡ forward/backward hooksï¼‰ï¼ŒéªŒè¯æ˜¯å¦ç¬¦åˆè®ºæ–‡å…¬å¼çš„é¢„ä¼°ã€‚\nç›‘æ§â€œé‡ç®—åŒºâ€çš„æ—¶é—´å æ¯”ï¼Œç¡®è®¤ selective é‡ç®—çš„ overhead æ˜¯å¦æ¥è¿‘è®ºæ–‡ä¸­çš„ 2%â€“7%ï¼Œè‹¥è¿œé«˜äºæ­¤éœ€è¦æ£€æŸ¥é€šä¿¡ overlap æ˜¯å¦ç”Ÿæ•ˆã€‚\n\n\næ€»çš„æ¥è¯´ï¼Œå¼•å…¥æœ¬æ–‡æ–¹æ³•çš„å·¥ç¨‹å·¥ä½œé‡ä¸»è¦é›†ä¸­åœ¨ ç®—å­ layout æ”¹å†™ + é€šä¿¡æ¨¡å¼é‡å†™ + checkpoint ç­–ç•¥ç»†åŒ–ï¼Œå¯¹ä¸Šå±‚æ¨¡å‹ä»£ç ä¾µå…¥è¾ƒå°ã€‚\n\nä¹ã€å€¼å¾—è¿›ä¸€æ­¥æ¢ç´¢çš„ç ”ç©¶æ–¹å‘\n\nè‡ªåŠ¨åŒ–æ¿€æ´»é‡ç®—ç­–ç•¥æœç´¢\n\né—®é¢˜ï¼šç›®å‰ selective recompute ä»åŸºäºæ‰‹å·¥åˆ’åˆ†ï¼›å¯¹äºæ›´å¤æ‚çš„ç½‘ç»œç»“æ„ï¼Œäººè‚‰é€‰æ‹© checkpoint è¾¹ç•Œæ—¢è´¹æ—¶åˆå¯èƒ½ sub-optimalã€‚\nä»·å€¼ï¼šç»“åˆå·²æœ‰çš„â€œæœ€ä¼˜ checkpoint æœç´¢â€ç®—æ³•ï¼ˆå¦‚ CVPR 2021 Feng &amp; Huangï¼‰ä¸æœ¬æ–‡çš„æ¿€æ´»å†…å­˜æ¨¡å‹ï¼Œæœ‰æœ›è‡ªåŠ¨ç»™å‡ºåœ¨ä¸åŒæ˜¾å­˜é¢„ç®—ä¸‹çš„æœ€ä½³é‡ç®—ç­–ç•¥ã€‚\n\nä¸ ZeRO / FSDP / offload çš„ç»Ÿä¸€å»ºæ¨¡\n\né—®é¢˜ï¼šå½“å‰å®è·µå¾€å¾€åŒæ—¶å¯ç”¨å‚æ•°/æ¢¯åº¦/ä¼˜åŒ–å™¨çš„åˆ‡åˆ†ä¸ offloadï¼Œä»¥åŠæ¿€æ´»å±‚é¢çš„ TP+SP+selectiveï¼Œç¼ºä¹ç»Ÿä¸€çš„æˆæœ¬æ¨¡å‹ã€‚\nä»·å€¼ï¼šæ„å»ºä¸€ä¸ªç»Ÿä¸€çš„â€œæ˜¾å­˜+FLOPs+é€šä¿¡ä¸‰å…ƒæ¨¡å‹â€ï¼Œè‡ªåŠ¨åœ¨â€œåŠ å¤§ DPã€åŠ å¤§ TP/SPã€åŠ å¤§å°é‡ç®—â€ä¹‹é—´å¹³è¡¡ï¼ŒæŒ‡å¯¼ trillion-scale è®­ç»ƒæ ˆè®¾è®¡ã€‚\n\né¢å‘é•¿ä¸Šä¸‹æ–‡çš„åºåˆ—å¹¶è¡Œä¸é‡ç®—ååŒ\n\né—®é¢˜ï¼šéšç€ 128K+ ä¸Šä¸‹æ–‡æ¨¡å‹æ™®åŠï¼Œå„ç±» sequence/context parallelï¼ˆring attentionã€Ulysses ç­‰ï¼‰å°† attention å˜å¾—æ›´åŠ å¤æ‚ã€‚(ResearchGate)\nä»·å€¼ï¼šåœ¨è¿™äº› SP å˜ä½“ä¸­å¼•å…¥ selective recomputeï¼Œåˆ†æåœ¨ \\(s\\gg h\\) æƒ…å†µä¸‹é‡ç®—å¼€é”€çš„ç²¾ç¡®è¡Œä¸ºï¼Œå¯èƒ½ä¼šç»™é•¿ä¸Šä¸‹æ–‡æ¨¡å‹å¸¦æ¥æ–°çš„å¯è¡Œé…ç½®ã€‚\n\né’ˆå¯¹ MoE ä¸ç¨€ç–ç»“æ„çš„æ¿€æ´»å†…å­˜ä¼˜åŒ–\n\né—®é¢˜ï¼šMoE å°†è®¡ç®—ç¨€ç–åŒ–ï¼Œä½†æ¿€æ´»å†…å­˜ä»å¯èƒ½è¾ƒé«˜ï¼Œä¸”è·¯ç”±/é—¨æ§å¸¦æ¥æ–°çš„é€šä¿¡ä¸å­˜å‚¨æ¨¡å¼ã€‚\nä»·å€¼ï¼šæ‰©å±•æœ¬æ–‡çš„æ¿€æ´»æ¨¡å‹åˆ°â€œç¨€ç–æ¿€æ´»â€åœºæ™¯ï¼Œå®šä¹‰ per-expert çš„æ¿€æ´»ä¸é‡ç®—ç­–ç•¥ï¼Œæœ‰åŠ©äºåœ¨ä¿æŒç¨€ç–è®¡ç®—ä¼˜åŠ¿çš„åŒæ—¶è¿›ä¸€æ­¥å‹ç¼©æ˜¾å­˜ã€‚\n\npipeline é¦– stage å†…å­˜ç¢ç‰‡ä¸åŠ¨æ€è°ƒåº¦\n\né—®é¢˜ï¼šè®ºæ–‡æåˆ° pipeline é¦– stage çš„æ˜¾å­˜ä¸å‡ä¸ç¢ç‰‡åŒ–æ˜¯æœªæ¥æ–¹å‘ä¹‹ä¸€ï¼Œä½†å°šæ— ç³»ç»Ÿæ–¹æ¡ˆã€‚\nä»·å€¼ï¼šç»“åˆ allocator è¡Œä¸ºï¼ˆå¦‚ buddy / caching allocatorï¼‰ä¸ dynamic micro-batchingï¼Œæ¢ç´¢åœ¨ä¸æ”¹æ¨¡å‹ç»“æ„çš„å‰æä¸‹ï¼Œé€šè¿‡è°ƒåº¦ä¸åˆ†é…ç­–ç•¥è¿›ä¸€æ­¥é™ä½é¦– stage å³°å€¼ã€‚\n\n\n\nåã€çŸ¥è¯†å›¾è°±æ€ç»´é“¾\nä»â€œå¤§æ¨¡å‹ç³»ç»Ÿâ€çš„çŸ¥è¯†å›¾è°±æ¥çœ‹ï¼Œè¿™ç¯‡è®ºæ–‡æ¶‰åŠçš„è¿æ¥ç‚¹å¤§è‡´å¦‚ä¸‹ï¼š\n\nå¹¶è¡Œä¸è°ƒåº¦\n\næä¾›äº†ä¸€ä¸ªæŠŠ TP+SP+PP ä¸€èµ·æ”¾è¿›æ¿€æ´»å†…å­˜å…¬å¼çš„æ¡†æ¶ï¼Œè®©â€œå¦‚ä½•é€‰ TP/SP/PP ç»„åˆâ€ä»æ‹è„‘è¢‹å˜æˆå¯è®¡ç®—çš„é—®é¢˜ã€‚\næŠŠ 1F1B / interleaved pipeline çš„æ˜¾å­˜å³°å€¼ç‰¹æ€§ç”¨ç®€æ´å…¬å¼åˆ»ç”»å‡ºæ¥ï¼Œä¸ºä¹‹åçš„æµæ°´è°ƒåº¦è®ºæ–‡ï¼ˆå¦‚å¤šç§ 1F1B å˜ä½“ï¼‰æä¾›äº†å¯¹æ¯”åŸºçº¿ã€‚(ACL Anthology)\n\nå†…å­˜ç®¡ç†ä¸æ˜¾å­˜ä¼˜åŒ–\n\næŠŠæ¿€æ´»å†…å­˜æ‹†è§£æˆâ€œä¸»å¹²ï¼ˆ\\(34sbh\\)ï¼‰+ attention æ–¹é˜µï¼ˆ\\(5as^2b\\)ï¼‰â€ï¼Œè®©äººä¸€çœ¼çœ‹å‡ºä¼˜åŒ–ç©ºé—´åœ¨å“ªé‡Œã€‚\nselective recompute å±•ç¤ºäº†â€œé€šè¿‡ç²¾ç»†å®šä½ FLOPs ä¾¿å®œåŒºâ€æ¥æ¢æ˜¾å­˜ï¼Œæ˜¯ä¸€ç±»å€¼å¾—åœ¨å…¶ä»–ç»“æ„ä¸Šé‡å¤ä½¿ç”¨çš„æ¨¡å¼ã€‚\n\né€šä¿¡ä¸é›†ä½“æ“ä½œ\n\næ˜¾å¼åˆ©ç”¨â€œall-reduce = RS + AGâ€è¿™ä¸€äº‹å®ï¼Œé€šè¿‡ \\(g/\\bar g\\) æ”¹å†™é€šä¿¡å›¾ï¼Œå®ç°æ¿€æ´»åˆ‡åˆ†è€Œä¸å¢åŠ æ€»é€šä¿¡é‡ã€‚\nå¯¹æ¯”äº†ä¸åŒæ–¹æ¡ˆä¸‹ per-layer é€šä¿¡ bytesï¼Œä¸ºä¹‹åçš„é€šä¿¡ä¼˜åŒ–å·¥ä½œæä¾›äº†ä¸€ä¸ªå¯å‚è€ƒçš„ baselineã€‚\n\nkernel ä¸ç®—å­ä¼˜åŒ–\n\nå¼ºè°ƒåœ¨ LN / Dropout / embedding / output ç­‰ç®—å­ä¸­ä¹Ÿåš SPï¼Œè®©è¿™äº›â€œçœ‹ä¼¼ç®€å•â€çš„ç®—å­çœŸæ­£äº«å—åˆ°å¹¶è¡Œå¸¦æ¥çš„å†…å­˜ä¸é€Ÿåº¦æ”¶ç›Šã€‚\né¼“åŠ±æŠŠé€šä¿¡ç®—å­å’Œ GEMM èåˆï¼Œä»è€Œå‡å°‘ä¸­é—´ buffer ä¸ kernel launch overheadã€‚\n\næ¨¡å‹ç»“æ„ä¸æ¶æ„è®¾è®¡\n\nè™½ç„¶æ¨¡å‹ç»“æ„æœ¬èº«æœªä¿®æ”¹ï¼Œä½†æ¿€æ´»å†…å­˜åˆ†æå¯ä»¥ç›´æ¥ç”¨æ¥è¯„ä¼°â€œåŠ å®½/åŠ æ·±/åŠ å¤´æ•°/åŠ åºåˆ—é•¿åº¦â€å¯¹æ˜¾å­˜çš„å½±å“ï¼Œä¸ºè®¾è®¡æ–°æ¶æ„æä¾›é‡åŒ–ä¾æ®ã€‚\nå¯¹ GPT-3/MT-NLG çš„å…·ä½“å‚æ•°åšäº†ä»£å…¥ï¼Œä¸ä»…å‘Šè¯‰ä½ â€œå…¬å¼é•¿å•¥æ ·â€ï¼Œè¿˜å‘Šè¯‰ä½ â€œåœ¨çœŸå®é…ç½®ä¸‹æ•°å€¼æ˜¯å¤šå¤§â€ã€‚\n\næ•°æ®ã€é¢„å¤„ç†ä¸æ‰“åŒ…ç­–ç•¥\n\nä»ä¾§é¢è¯´æ˜äº†â€œèŠ‚çœæ¿€æ´»æ˜¾å­˜ä¹‹åå¯ä»¥åšä»€ä¹ˆâ€ï¼šå¯ä»¥æ¢æˆæ›´å¤§ micro-batchã€æ›´é•¿åºåˆ—æˆ–æ›´å¤š global batchï¼Œå¯¹ DataLoader ä¸æ•°æ®æ‰“åŒ…ç­–ç•¥æå‡ºäº†æ–°çš„éœ€æ±‚ã€‚\n\n\n10.1 ä¸ªäººæ”¶è·ä¸åæ€\nå¯¹æˆ‘ä¸ªäººæ¥è¯´ï¼Œè¿™ç¯‡è®ºæ–‡æœ€å¤§çš„å¯å‘åœ¨äºâ€”â€”å¾ˆå¤šçœ‹ä¼¼â€œç»éªŒä¸»ä¹‰â€çš„å¹¶è¡Œ/é‡ç®—æŠ€å·§ï¼Œå…¶å®å¯ä»¥è¢«ä¸€ä¸ªéå¸¸ç®€æ´çš„è§£ææ¨¡å‹ç»Ÿä¸€æè¿°ã€‚ä¸€æ—¦æŠŠæ¿€æ´»å†…å­˜æ‹†æˆ \\(34sbh\\) å’Œ \\(5as^2b\\) ä¸¤å—ï¼Œå¾ˆå¤šé€‰æ‹©å°±å˜å¾—æ˜¾è€Œæ˜“è§ï¼šTP+SP åº”è¯¥æ€ä¹ˆåˆ‡ã€attention ä¸­å“ªä¸€éƒ¨åˆ†å€¼å¾— checkpointã€pipeline stage æ€ä¹ˆåˆ†å±‚ç­‰ï¼Œéƒ½å¯ä»¥ä»å…¬å¼é‡Œç›´æ¥è¯»å‡ºæ¥ã€‚\nå¦ä¸€ä¸ªæ”¶è·æ˜¯å¯¹ â€œå±€éƒ¨é‡ç®—â€è¿™ä¸€æ¨¡å¼çš„å†è®¤è¯†ï¼šä»¥å‰æåˆ° gradient checkpointï¼Œå¤šæ•°äººåªæƒ³åˆ°â€œæŒ‰å±‚ checkpointâ€ï¼›æœ¬æ–‡å±•ç¤ºäº†â€œæŒ‰å±‚å†…å­ç®—å­ checkpointâ€å¯ä»¥æ›´ç²¾ç»†åœ°è°ƒèŠ‚æ˜¾å­˜/ç®—åŠ›çš„ trade-offï¼Œè€Œä¸”å®ç°æˆæœ¬å¹¶æ²¡æœ‰æƒ³è±¡ä¸­é‚£ä¹ˆé«˜â€”â€”åªè¦ä½ æ„¿æ„åœ¨ç®—å­å›¾ä¸Šå¤šç”»å‡ æ¡è¾¹ç•Œã€‚\nä»å®è·µè§’åº¦ï¼Œæˆ‘è®¤ä¸ºå€¼å¾—ç«‹åˆ»å°è¯•è¿ç§»åˆ°è‡ªå·±è®­ç»ƒæ ˆé‡Œçš„ç‚¹ä¸»è¦æœ‰ä¸¤ä¸ªï¼š\n\nç¬¬ä¸€æ˜¯ åœ¨ç°æœ‰ TP æ ˆä¸Šè¡¥é½ SPï¼Œè‡³å°‘è¦è®© LN/Dropout/embedding/output è¿™äº›æ¿€æ´»ä¹Ÿèƒ½æŒ‰åºåˆ— shardï¼›\nç¬¬äºŒæ˜¯åœ¨ attention å†…éƒ¨å®ç°ç±»ä¼¼çš„ selective recomputeï¼ŒæŠŠ \\(QK^\\top\\)ã€softmaxã€attention over V é‚£å—æŠ½æˆä¸€ä¸ª checkpoint å­å›¾ï¼Œå¹¶é…åˆé€šä¿¡/è®¡ç®— overlap åšäº›å¾®è°ƒã€‚\n\n\næ€»ä½“è¯„ä»·ï¼šè¿™ç¯‡å·¥ä½œåœ¨ä¸æ”¹å˜æ¨¡å‹ç»“æ„ã€ä¸è¿‡åº¦ä¾µå…¥è®­ç»ƒæ ˆçš„å‰æä¸‹ï¼Œç”¨ä¸€å¥—ç®€æ´çš„ç†è®ºå’Œä¸€ç»„æ‰å®çš„å¤§è§„æ¨¡å®éªŒï¼Œç»™å‡ºäº†ä¸€ä¸ªå‡ ä¹â€œé»˜è®¤åº”å½“å¯ç”¨â€çš„æ¿€æ´»å†…å­˜ä¼˜åŒ–æ–¹æ¡ˆã€‚å¯¹äºå·²ç»è¿è¡Œ 3D å¹¶è¡Œå¤§æ¨¡å‹è®­ç»ƒçš„å›¢é˜Ÿï¼Œå®ƒæ›´åå·¥ç¨‹å®è·µï¼›è€Œå¯¹äºæ­£åœ¨æ­å»ºè®¾å¤‡/å¹¶è¡Œæ ˆçš„äººï¼Œåˆ™æä¾›äº†ä¸€ä¸ªéå¸¸æ¸…æ™°çš„â€œå¹¶è¡Œ+é‡ç®—è”åˆè®¾è®¡â€å‚è€ƒèŒƒå¼ã€‚\n\n","categories":["è®ºæ–‡é˜…è¯»"],"tags":["paper"]}]