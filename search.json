[{"title":"Attention TP与GQA","url":"/2025/08/17/distribute/attention/","content":"\n\n例子配置（贯穿全文）： hidden_size=4096, num_attention_heads=32, tensor_parallel_size=4, num_query_groups=8（GQA）, kv_channels=hidden/heads=128。 输入形状用 [B, S, H] 记（批、序列、隐藏）。\n\n\n1. 名词与派生变量（先把量算清楚）\n\n单头维度（也是缩放用的 \\(d_k\\)）：kv_channels = 4096 / 32 = 128\nQ 投影总维：query_projection_size = kv_channels * num_attention_heads = 128*32 = 4096\nK/V 投影总维（GQA）：kv_projection_size = kv_channels * num_query_groups = 128*8 = 1024\n每卡 Q 头数：num_attention_heads_per_partition = 32 / TP = 8\n每卡 KV 组数：num_query_groups_per_partition = 8 / TP = 2\n每卡投影维（列并行后本地输出维）：hidden_size_per_partition = 4096 / TP = 1024\n\n\nGQA 的含义：当 num_key_value_heads (=num_query_groups) 小于 num_attention_heads 时，为较少的 KV 头/组 产出 K/V，让多个 Q 头共享它们；=heads 退化为 MHA，=1 是 MQA。这一点在 HF 模型文档中是明确的定义。(Hugging Face)\n\n\n2. 端到端计算与形状流（以单层自注意力为例）\nMegatron 经典做法：Q/K/V 的线性层用列并行（Column-Parallel），按输出列切给各卡；输出投影用行并行（Row-Parallel），按输入行切给各卡，前向只在输出投影做一次 all-reduce。这是 Megatron-LM 论文与 Megatron-Core 文档推荐的张量并行切法。(arXiv, NVIDIA Docs)\n2.1 线性投影（列并行）\n\nQ 投影（全局权重 [4096,4096] → 每卡 [4096,1024]）： 本卡输出 Q_local: [B,S,1024] → reshape 为 [B, 8, S, 128]（本卡 8 个 Q 头）。\nK 投影（全局权重 [4096,1024] → 每卡 [4096,256]）： K_local: [B,S,256] → reshape 为 [B, 2, S, 128]（本卡 2 个 KV 组）。\nV 投影 同 K。\n\n\n为什么必须 reshape 出 head 维？ 多头注意力的语义是“头内独立”的点积注意力，内核（SDPA/FlashAttention）与广播（mask、RoPE、repeat_kv）都要求显式的 head 维 [B,H,S,D] 或展平为 [B·H,S,D]。不拆头会把不同 head 的子空间混在一起，也无法自然执行 GQA 的 repeat_kv。(PyTorch)\n\n2.2 GQA 的 K/V 对齐（repeat/expand）\n本卡只有 2 个 KV 组，但要服务 8 个 Q 头 ⇒ 在头维做逻辑重复/广播： [B, 2, S, 128] → [B, 8, S, 128]（每个 KV 组服务 4 个 Q 头）。主流实现直接在 head 维做 repeat_kv。(Hugging Face)\n2.3 Scaled Dot-Product Attention（每卡只算自己的 8 个头）\n\nscores = (Q @ K^T) / sqrt(128) → softmax(scores) @ V\n得到上下文 ctx_local: [B, 8, S, 128] → 拼接为 [B,S,1024]\n这一步可以由 PyTorch SDPA 或闪存注意力内核高效完成。(PyTorch)\n\n2.4 输出投影（行并行 + 1 次 all-reduce）\n\n每卡把 [B,S,1024] 乘以本卡的输出权重分片，得到 Y_local: [B,S,4096] 的部分和；\n跨卡做 all-reduce(sum) 得到最终 Y: [B,S,4096]。 Megatron 论文指出：自注意力本体不需通信，只在输出投影处做一次规约即可。(arXiv)\n\n\n3. 列并行 / 行并行的数学等价（为何“切了再拼/求和”仍等价单卡）\n把 [B,S,·] 展平为矩阵 \\(X\\in\\mathbb{R}^{N\\times(HD)}\\)（\\(N=B\\cdot S\\)），输出隐藏记为 \\(H\\)。\n3.1 列并行（Column-Parallel Linear）≡ 拼接\n设 Q 的全量权重 \\(W_Q\\in\\mathbb{R}^{(HD)\\times(HD)}\\)，沿列切成 \\(p\\) 块：\n\\[\nW_Q=\\big[W_Q^{(0)}\\;\\;W_Q^{(1)}\\;\\;\\cdots\\;\\;W_Q^{(p-1)}\\big],\n\\quad W_Q^{(i)}\\in\\mathbb{R}^{(HD)\\times(H/p\\cdot D)}.\n\\]\n则\n\\[\nQ=XW_Q=\\big[XW_Q^{(0)}\\;\\;XW_Q^{(1)}\\;\\;\\cdots\\;\\;XW_Q^{(p-1)}\\big]\n      =\\operatorname{Concat}(Q^{(0)},\\dots,Q^{(p-1)}).\n\\]\n每卡独立计算自己的 \\(Q^{(i)}\\)，无须通信。K/V 同理。这就是 Column-Parallel 的精确定义。(arXiv, NVIDIA Docs)\n3.2 每头独立 ⇒ 按头切给各卡仍然正确\n单头/单组注意力：\n\\[\nY_h=\\operatorname{softmax}\\!\\Big(\\tfrac{Q_hK_{g(h)}^\\top}{\\sqrt{D}}\\Big)V_{g(h)}.\n\\]\nGQA 下 \\(g(h)\\) 把多个 Q 头映射到同一 KV 组；由于头间互不相干，把 32 个头平均分成 4 份到 4 张卡，各卡只依赖自己的 KV 组，就与单卡一致。repeat_kv 正是沿 head 维把 KV 对齐到 Q 头数。(Hugging Face)\n3.3 行并行（Row-Parallel Linear）≡ 求和（all-reduce）\n把注意力输出的拼接张量 \\(C\\in\\mathbb{R}^{N\\times(HD)}\\) 按列（特征）切块：\n\\[\nC=\\big[C^{(0)}\\;\\;C^{(1)}\\;\\;\\cdots\\;\\;C^{(p-1)}\\big],\\quad\nC^{(i)}\\in\\mathbb{R}^{N\\times(H/p\\cdot D)}.\n\\]\n输出权重 \\(W_O\\in\\mathbb{R}^{(HD)\\times H}\\) 按行切块：\n\\[\nW_O=\\begin{bmatrix}\nW_O^{(0)}\\\\ W_O^{(1)}\\\\ \\vdots\\\\ W_O^{(p-1)}\n\\end{bmatrix},\n\\quad W_O^{(i)}\\in\\mathbb{R}^{(H/p\\cdot D)\\times H}.\n\\]\n块乘法恒等式：\n\\[\nC\\,W_O=\\sum_{i=0}^{p-1} C^{(i)}W_O^{(i)}.\n\\]\n因此各卡计算 \\(Y^{(i)}=C^{(i)}W_O^{(i)}\\)，再 all-reduce(sum)，就得到与单卡完全相同的 \\(Y\\)。这正是 Row-Parallel 的本质。(arXiv)\n\n4. 为什么 GQA 会让 kv_projection_size 变小、KV cache 变省？\n\nK/V 线性层只为 num_query_groups 产出通道：从 4096（=32×128）降为 1024（=8×128），K/V 投影的 参数量与 FLOPs 约为原来的 1/4；\n推理阶段的 KV cache 以「KV 头 × 序列 × 头维」计量，KV 头从 32 变 8，缓存与相关带宽均相应下降。HF 文档明确以 num_key_value_heads 描述该行为。(Hugging Face)\n\n\n5. 形状速查（以本例为准）\n\n\n\n张量/步骤\n全局（不分片）\n每卡（TP=4）\n说明\n\n\n\n\nQ 线性输出维\n4096\n1024\nColumn-Parallel，无通信\n\n\nK 线性输出维\n1024\n256\nGQA：只出 8 个 KV 组\n\n\nV 线性输出维\n1024\n256\n同上\n\n\nQ 头数\n32\n8\n本卡只算自己 8 个头\n\n\nKV 组数\n8\n2\n每组服务 4 个 Q 头\n\n\n头维 \\(D\\)\n128\n128\n用于 \\(1/\\sqrt{D}\\)\n\n\n本卡注意力输出（拼头后）\n–\n[B,S,1024]\n进入输出投影\n\n\n最终输出（all-reduce 后）\n[B,S,4096]\n[B,S,4096]\nRow-Parallel + sum\n\n\n\n（若启用 Sequence Parallel，只会沿 S 再切一维，不影响上述头/通道维逻辑。列/行并行与一次通信的结构是 Megatron-LM 的“经典拆分”。）(awsdocs-neuron.readthedocs-hosted.com, Better Tomorrow with Computer Science)\n\n6. Mermaid：一张“维度/并行方式”小图\n%%&#123;init: &#123; &quot;flowchart&quot;: &#123; &quot;htmlLabels&quot;: true, &quot;wrap&quot;: true &#125; &#125;&#125;%%flowchart TB  X[&quot;Input X: [B,S,4096]&quot;] --&gt; QKV[&quot;Column-Parallel Q/K/V&lt;br/&gt;Q:[B,S,1024]  K/V:[B,S,256]&quot;]  QKV --&gt; Reshape[&quot;Reshape by heads&lt;br/&gt;Q:[B,8,S,128]&lt;br/&gt;K/V:[B,2,S,128]&quot;]  Reshape --&gt; RepeatKV[&quot;repeat_kv on head dim&lt;br/&gt;K/V:[B,8,S,128]&quot;]  RepeatKV --&gt; SDPA[&quot;SDPA per head&lt;br/&gt;ctx_local:[B,8,S,128]&lt;br/&gt;concat-&gt;[B,S,1024]&quot;]  SDPA --&gt; OutProj[&quot;Row-Parallel OutProj&lt;br/&gt;Y_local:[B,S,4096]&quot;]  OutProj --&gt; AllReduce[&quot;all-reduce(sum)&quot;]  AllReduce --&gt; Y[&quot;Final Y: [B,S,4096]&quot;]\n\n7. 极简伪码（PyTorch 风格）\n# 列并行的线性：每卡拿到 Q/K/V 的一段输出列Q_local = linear_col_parallel_Q(X)   # [B,S,1024] -&gt; view [B,8,S,128]K_local = linear_col_parallel_K(X)   # [B,S,256]  -&gt; view [B,2,S,128]V_local = linear_col_parallel_V(X)   # [B,S,256]  -&gt; view [B,2,S,128]Q = Q_local.view(B, S, 8, 128).transpose(1, 2)  # [B,8,S,128]K = K_local.view(B, S, 2, 128).transpose(1, 2)  # [B,2,S,128]V = V_local.view(B, S, 2, 128).transpose(1, 2)  # [B,2,S,128]# GQA: 让 2 个 KV 组匹配 8 个 Q 头（逻辑 repeat/expand）K = repeat_kv(K, n_rep=4)   # [B,8,S,128]V = repeat_kv(V, n_rep=4)   # [B,8,S,128]# SDPA（每卡只算自己的 8 个头）ctx = torch.nn.functional.scaled_dot_product_attention(Q, K, V)  # [B,8,S,128]ctx = ctx.transpose(1, 2).reshape(B, S, 1024)                    # [B,S,1024]# 行并行输出 + 一次 all-reduce(sum)Y_local = linear_row_parallel_out(ctx)   # partial: [B,S,4096]Y = all_reduce_sum(Y_local)              # final:   [B,S,4096]\n\nSDPA 的接口与语义见 PyTorch 文档；repeat_kv 的语义与 GQA 的配置在 HF 文档/实现中有明确定义。(PyTorch, Hugging Face)\n\n\n8. 正确性 Checklist（实践中最常见的坑）\n\n整除关系： num_attention_heads % TP == 0，num_query_groups % TP == 0，且 num_attention_heads % num_query_groups == 0（GQA）。(Hugging Face)\n显式 head 维：形状应为 [B,H,S,D] 或展平为 [B·H,S,D]，以契合 SDPA/FlashAttention 与 repeat_kv。(PyTorch)\n通信位置：自注意力本体无跨卡通信；仅输出投影需要一次 all-reduce。(arXiv)\n\n\n参考与延伸阅读\n\nMegatron-LM 论文：提出层内（张量）并行，注意力用列并行，输出用行并行，前向仅一处通信。(arXiv, ar5iv)\nMegatron-Core 文档：Tensor Parallel API/用户指南（NVIDIA 官方）。(NVIDIA Docs)\nPyTorch SDPA 文档/教程：官方的缩放点积注意力接口与高性能实现。(PyTorch, PyTorch Docs)\nHF 文档（Llama/Qwen 系列）：num_key_value_heads 的定义、GQA/MQA/MHA 的关系；实现里 repeat_kv 的用法。(Hugging Face)\n列并行/行并行可视化讲解：对 ColumnParallelLinear / RowParallelLinear 的直观图解。(awsdocs-neuron.readthedocs-hosted.com, Better Tomorrow with Computer Science)\n\n\n","categories":["distribute"],"tags":["attention"]},{"title":"pytorch DeviceMesh：实现原理与实战","url":"/2025/06/14/distribute/device_mesh/","content":"\n一、为何使用 DeviceMesh？\n在混合并行（DP/TP/PP/HSDP/…）中，需要管理多个子通信组（ProcessGroup），对应复杂的设备拓扑结构。DeviceMesh 提供了：\n\n理论上无缝支持任意维度的多维拓扑；\n自动拆分进程组(new_group/split_group)；\n灵活切片子 Mesh；\n经历设计周全的高效初始化方案 (docs.pytorch.org, pytorch.org)。\n\n\n二、初始化流程\ninit_device_mesh(...) 的作用\n一个一行搞定的方法，它会：\n\n初始化全局 init_process_group(...)（若未初始化）；\n根据 mesh_shape 自动构造 CPU 上的 torch.arange(...).view(...)；\n创建 DeviceMesh(...)。内部完成子组拆分原理（见下一节）。\n\n\nDeviceMesh.__init__() + _init_process_groups()\n\n存储：device_type、mesh、mesh_dim_names；\n通信组拆分：遍历每个维度 dim：\n\n使用 mesh.swapdims(-1, dim).reshape(-1, size(dim)) 列出该维所有子组 rank；\n若 NCCL 已绑定 GPU，即可用 split_group 一次拆出全部子组；\n否则使用 new_group() 分 group 拆；\n并将当前 rank 属于的那组信息放入 self._dim_group_infos[dim]；\n\n结果：每个维度对应一个包含当前 rank 的 ProcessGroup 信息列表。\n\n#ppmesh = torch.tensor([  [0, 1],  # pp=0  [2, 3],  # pp=1  [4, 5],  # pp=2  [6, 7]   # pp=3])mesh.swapdims(-1, 0)tensor([[0,2,4,6],        [1,3,5,7]])pg_ranks_by_dim = tmp.reshape(-1, mesh.size(0))[  [0,2,4,6],  # 对应 tp 行 0 各 pp 段  [1,3,5,7]   # 对应 tp 行 1 各 pp 段]#tptmp = mesh.swapdims(-1, 1)  # 等于 transpose(1,1)，本身无变化pg_ranks_by_dim = tmp.reshape(-1, mesh.size(1))[  [0,1],  # pp=0  [2,3],  [4,5],  [6,7]]\n\n三、核心接口与内部实现解析\n1. 属性与方法\nmesh.shape  # tuple(self.mesh.shape)mesh.ndim   # int(self.mesh.ndim)mesh.size(dim=None)  # 总元素数 or self.mesh.size(dim)\n用于获取 mesh 元结构和规模，适用于判断维度数量、循环迭代、并行策略配置等场景。\n\n2. Rank 与坐标\n\nget_rank()：等价于 torch.distributed.get_rank()，返回全局 rank；\nget_local_rank(mesh_dim)：内部调用 get_rank(self.get_group(mesh_dim)) → 当前维度的小组内编号；\nget_coordinate()：返回 self._coordinate_on_dim，其在初始化中通过 (self.mesh==global_rank).nonzero() 获得。\n\n示例：mesh_shape=(4,2)，rank=5 → local_pp=2、local_tp=1，coordinate [2,1]。\n\n3. 通信组获取\n\nget_group(mesh_dim)：\n\n若 1D 且不传参，直接返回唯一子进程组；\n多维则根据 mesh_dim（索引或名字）检索 self._dim_group_infos[dim]，用 _find_pg_by_ranks_and_tag() 获取对应 ProcessGroup。\n\nget_all_groups()：返回所有维度的 group 列表；\n__getitem__(dims)：切片接口调用 _mesh_resources._get_slice_mesh_dims(...)，创建新的子 mesh，保留底层 communicator，但维度降。\n\n支持单维或多维切片，且返回的 submesh 顺序按传入顺序排列 (discuss.ray.io, gemfury.com, pytorch.org)。\n\n\n\n4. from_group(...) 方法\n\n可接受单 group 或 group 列表；\n创建新的 DeviceMesh 时不会调用 backend 初始化；\n会复用现有 ProcessGroup，并填充 _dim_group_infos，因此 get_group(...) 将直接返回传入的实例，避免重复创建 group。\n\n\n四、完整单机 8 卡 Demo：tp=2, pp=4\n下面演示如何调用所有接口并输出结果。注意：需在 torchrun --nproc_per_node=8 下运行。\nimport os, torch, torch.distributed as distfrom torch.distributed.device_mesh import init_device_meshdef run_device_mesh_demo():    dist.init_process_group(&quot;nccl&quot;)    # ⬇️ 初始化 2-维 mesh：pp=4, tp=2    mesh = init_device_mesh(&quot;cuda&quot;, mesh_shape=(4, 2), mesh_dim_names=(&quot;pp&quot;, &quot;tp&quot;))        # ✅ rank 和坐标    gr = mesh.get_rank()            # 全局 rank    coord = mesh.get_coordinate()   # [pp_idx, tp_idx]    local_pp = mesh.get_local_rank(&quot;pp&quot;)    local_tp = mesh.get_local_rank(&quot;tp&quot;)        # ⬇️ mesh 基本结构    total = mesh.size()    pp_size, tp_size = mesh.size(&quot;pp&quot;), mesh.size(&quot;tp&quot;)    ndim = mesh.ndim    shape = mesh.shape        # ⬇️ 获取通信组    pp_group = mesh.get_group(&quot;pp&quot;)    tp_group = mesh.get_group(&quot;tp&quot;)    all_groups = mesh.get_all_groups()        # ⬇️ 切片出子 mesh    tp_mesh = mesh[&quot;tp&quot;]    pp_mesh = mesh[&quot;pp&quot;]        # ⬇️ 输出结果    print(f&quot;rank=&#123;gr&#125;, coord=&#123;coord&#125;, local_pp=&#123;local_pp&#125;, local_tp=&#123;local_tp&#125;&quot;)    print(f&quot;ndim=&#123;ndim&#125;, shape=&#123;shape&#125;, total=&#123;total&#125;, pp=&#123;pp_size&#125;, tp=&#123;tp_size&#125;&quot;)    print(&quot;pp_group ranks:&quot;, dist.get_process_group_ranks(pp_group))    print(&quot;tp_group ranks:&quot;, dist.get_process_group_ranks(tp_group))    print(&quot;all_groups sizes:&quot;, [len(dist.get_process_group_ranks(g)) for g in all_groups])    print(&quot;tp_mesh ndim, shape:&quot;, tp_mesh.ndim, tp_mesh.shape)    print(&quot;pp_mesh ndim, shape:&quot;, pp_mesh.ndim, pp_mesh.shape)if __name__ == &quot;__main__&quot;:    run_device_mesh_demo()\n💬 预期输出（例如 rank = 5）：\nrank=5, coord=[2,1], local_pp=2, local_tp=1 ndim=2, shape=(4,2), total=8, pp=4, tp=2 pp_group ranks: [4,5,6,7] tp_group ranks: [5,7] all_groups sizes: [4,2] tp_mesh ndim, shape: 1 (2,) pp_mesh ndim, shape: 1 (4,)\n说明： - rank=5 位于 pipeline 段 2，tp 内编号 1； - pp_group 包含与其同 segment 的 4 张卡； - tp_group 包含同 segment tp 维度的两张卡； - 切片后 tp_mesh、pp_mesh 成为 1 维结构，用于后续 parallelization。\n\n👏 总结\n\nDeviceMesh 构建自身通过 init_device_mesh() 完成初始化与子组拆分；\n接口内部实现逻辑与 Group 管理机制清晰、高效；\n__getitem__为多维并行下子 Mesh 切片关键工具，对集成 parallel APIs 至关重要；\n通过该机制，可以简单地组织复杂的 hybrid-parallel pipelines，同时充分复用 communicator 资源并简化开发流程。\n\n","categories":["distribute"],"tags":["devicemesh"]},{"title":"pytorch send recv 用法详解","url":"/2025/06/14/distribute/send_recv/","content":"\n1. 基本概念与进程组\n2. 基本张量通信\n3. 对象列表通信\n4. 易错点与常见问题\n5. 批量点对点通信接口\n6. 总结补充\n7. 参考资料\n\n\n1. 基本概念与进程组\n\ngroup（通信组）：分布式通信时的「子集」，允许只在一部分 rank 之间通信。\nglobal rank：全局进程编号（进程启动时分配的编号）。\ngroup rank：组内进程编号，组内第几个进程（与 global rank 无必然对应关系）。\nsrc/dst：通信目标（源/目的）rank，注意：如果指定 group，这里是组内编号，不是全局编号。\n\n进程组举例\n假如 group = [2, 4, 6, 8, 10]：\n\n\n\ngroup_rank\nglobal_rank\n\n\n\n\n0\n2\n\n\n1\n4\n\n\n2\n6\n\n\n3\n8\n\n\n4\n10\n\n\n\n\n2. 基本张量通信\n2.1 send / recv / isend / irecv\n参数说明\n\nsend(tensor, dst, group=None, tag=0) 发送 tensor 到组内 rank=dst 的进程。\nrecv(tensor, src, group=None, tag=0) 从组内 rank=src 的进程接收 tensor。\nisend/irecv 异步版本，返回 Work 句柄，需要 work.wait()。\n\ntag\n\ntag 是消息编号/标签，用于区分多条并发消息，只有 tag 一致才能正确配对。\n\ngroup_dst/group_src\n\n一般不用手动传，框架会根据 dst/src 和 group 自动推算。\n\n\n2.2 通信流程示意图\n以 group = [2, 4, 6, 8, 10]，让 rank=2 发，rank=10 收为例：\ngraph TD    subgraph group [group: [2, 4, 6, 8, 10]]        A[&quot;global_rank=2&lt;br&gt;group_rank=0&quot;]        B[&quot;global_rank=10&lt;br&gt;group_rank=4&quot;]    end    A -- send(tensor, dst=4, group=group) --&gt; B    B -- recv(tensor, src=0, group=group) --&gt; A\n\n发送端（global_rank=2，group_rank=0）：send(tensor, dst=4, group=group)\n接收端（global_rank=10，group_rank=4）：recv(tensor, src=0, group=group)\n\n\n2.3 代码实例\n# 发送端（global_rank=2）group = dist.new_group([2, 4, 6, 8, 10])tensor = torch.tensor([123])dist.send(tensor, dst=4, group=group)   # dst=4 是 group 内 rank=4 → global_rank=10# 接收端（global_rank=10）group = dist.new_group([2, 4, 6, 8, 10])tensor = torch.zeros(1, dtype=torch.int)dist.recv(tensor, src=0, group=group)   # src=0 是 group 内 rank=0 → global_rank=2print(tensor)\n\n⚠️ 只要用了 group，src/dst 都是组内 rank，不是 global rank！\n\n\n2.4 异步通信（isend/irecv）\nwork = dist.isend(tensor, dst=4, group=group)work.wait()  # 等待发送完成\n异步 recv 同理。\n\n3. 对象列表通信\n3.1 send_object_list / recv_object_list 用法\n\n用于发送/接收包含任意 Python 对象的 list，底层通过序列化实现。\n发送过程拆为两步：先发每个对象序列化后的 size，再发所有内容拼接后的 tensor。\n\n\n3.2 对象通信流程图\nsequenceDiagram    participant Sender    participant Receiver    Sender-&gt;&gt;Receiver: send(object_sizes_tensor)    Sender-&gt;&gt;Receiver: send(object_tensor)    Receiver-&gt;&gt;Receiver: 1. 读取 object_sizes_tensor    Receiver-&gt;&gt;Receiver: 2. 按 size 拆 object_tensor    Receiver-&gt;&gt;Receiver: 3. 反序列化为对象\n\n3.3 典型代码示例\n发送端\nobject_list = [&quot;hello&quot;, 123, [1, 2, 3]]dist.send_object_list(object_list, dst=4, group=group)\n接收端\nrecv_list = [None, None, None]dist.recv_object_list(recv_list, src=0, group=group)print(recv_list)  # [&#x27;hello&#x27;, 123, [1, 2, 3]]\n\n3.4 接口实现核心代码\n# 接收端分割反序列化offset = 0for i, obj_size in enumerate(object_sizes_tensor):    obj_view = object_tensor[offset : offset + obj_size]    object_list[i] = _tensor_to_object(obj_view, obj_size, group)    offset += obj_size\n\nobject_sizes_tensor 记录每个对象的序列化长度\nobject_tensor 是所有内容拼起来的一维 tensor\n按顺序切片和反序列化，填回 object_list\n\n\n3.5 关于 rank_objects\n\nrank_objects 是 recv 的返回值，表示消息来自哪个 rank（一般等于 src）\n在多对多通信或 src=ANY_SOURCE 时用来确认消息来源，和实际对象内容还原无关\n\n\n4. 易错点与常见问题\n\n只要用了 group，src/dst 都是组内 rank，不是 global rank。\ntag 用于区分多条消息，必须 send 和 recv 一致。\nsend_object_list/recv_object_list 必须 object_list 长度、顺序一致。\ngroup_src/group_dst 正常业务不需要自己传。\n\n4.1. group、src/dst、group_src/group_dst 参数关系\n\ngroup 决定通信子集，src/dst 决定收发目标编号。\n如果指定 group，则 src/dst 为组内 rank，不是 global rank。\ngroup_src/group_dst 一般不用手动传，框架自动推算。\n映射关系：\n\n全局转组内：group_ranks.index(global_rank)\n组内转全局：group_ranks[group_rank]\n\n\n\n5. 批量点对点通信接口\n5.1 接口简介\ntorch.distributed.batch_isend_irecv 支持同时发起多组异步点对点通信操作（isend/irecv），显著提高大批量数据分发/收集的效率。 底层支持 NCCL、Gloo、UCC 等分布式后端，常用于分布式深度学习的 pipeline/通信 pattern 优化。\n函数签名\ntorch.distributed.batch_isend_irecv(p2p_op_list: list[P2POp]) -&gt; list[Work]\n\np2p_op_list：一组 torch.distributed.P2POp 实例，每个实例描述一次 isend/irecv。\n返回：所有操作的 request 句柄（Work 对象）列表，可通过 .wait() 同步。\n\n\n5.2 典型使用场景\n\n大批量点对点通信，例如 pipeline 并行、环形 allreduce 手写优化等场景。\n支持 isend/irecv 混合，能批量提升吞吐量。\n\n\n5.3 调用流程与参数说明\nP2POp 用法\n每个 P2POp 定义一次通信操作，如下：\nP2POp(op, tensor, peer, group=None, tag=0)\n\nop：操作类型（dist.isend 或 dist.irecv）\ntensor：要发送/接收的 tensor\npeer：目标 peer 的编号（组内 rank）\ngroup（可选）：通信组（默认为 world）\ntag（可选）：消息编号/标签\n\n\n5.4 代码实例\n假设 world_size=2，rank 0 和 rank 1 做一个环形通信：\nimport torchimport torch.distributed as distrank = dist.get_rank()world_size = dist.get_world_size()send_tensor = torch.arange(2, dtype=torch.float32) + 2 * rankrecv_tensor = torch.zeros(2, dtype=torch.float32)send_op = dist.P2POp(dist.isend, send_tensor, (rank + 1) % world_size)recv_op = dist.P2POp(dist.irecv, recv_tensor, (rank - 1 + world_size) % world_size)reqs = dist.batch_isend_irecv([send_op, recv_op])for req in reqs:    req.wait()print(f&quot;Rank &#123;rank&#125; 收到: &#123;recv_tensor&#125;&quot;)\n运行结果：\nRank 0 收到: tensor([2., 3.])Rank 1 收到: tensor([0., 1.])\n\n5.5 通信流程图\nsequenceDiagram    participant Rank0    participant Rank1    Rank0-&gt;&gt;Rank1: isend(send_tensor, dst=1)    Rank1-&gt;&gt;Rank0: isend(send_tensor, dst=0)    Rank0-&gt;&gt;Rank0: irecv(recv_tensor, src=1)    Rank1-&gt;&gt;Rank1: irecv(recv_tensor, src=0)    Note over Rank0,Rank1: batch_isend_irecv([send_op, recv_op])&lt;br&gt;并发发起通信并等待完成\n\n5.6 重要注意事项\n\n注意\n\n如果使用 NCCL 后端，必须提前用 torch.cuda.set_device 设置好当前 GPU！\n如果这是某个 group 的第一次通信，group 里的所有 rank 必须都调用 batch_isend_irecv，否则行为未定义。\n以后只要不是第一次 collective，允许只用部分 rank 参与。\n\n\n\n5.7 源码实现要点\n\n自动判断通信后端是否支持操作合并（coalescing），如 NCCL 会在同一个上下文下批量启动，提升性能。\n返回所有 request（Work）对象，用户可 wait()。\n\n\n5.8 API 文档链接\n\nPyTorch 官方 batch_isend_irecv 文档\nP2POp 官方说明\n\n\n6. 总结补充\n\n张量点对点通信：send/recv/isend/irecv/batch_isend_irecv\n对象通信：send_object_list/recv_object_list\n批量点对点通信能极大提升 pipeline 通信效率\n统一返回 Work 句柄，支持同步或异步\ngroup/src/dst 使用方式同上文描述\n\n\n7. 参考资料\n\nPyTorch Distributed 官方文档\nPyTorch distributed_c10d.py 源码\nMermaid Live Editor\n\n\n","categories":["distribute"],"tags":["send recv"]},{"title":"PyTorch Shard 实现与分析","url":"/2025/06/20/distribute/shard/","content":"\n1. _split_tensor分析\n1.1 代码实现流程图（Mermaid）\nflowchart TD  A[&quot;输入：tensor, num_chunks, with_padding, contiguous&quot;] --&gt; B&#123;&quot;dim ≤ tensor.ndim?&quot;&#125;  B -- 否 --&gt; E[&quot;AssertionError 抛出&quot;]  B -- 是 --&gt; C[&quot;调用 torch.chunk 沿 dim 分块&quot;]  C --&gt; D[&quot;tensor_list, 计算 num_empty_tensors = num_chunks - len(tensor_list)&quot;]  D --&gt; F&#123;&quot;无需 padding 或 均匀可分?&quot;&#125;  F -- 是 --&gt; G[&quot;(可选) 对每块调用 .contiguous()&quot;]  G --&gt; H[&quot;调用 fill_empty_tensor_to_shards 补空 shard&quot;]  H --&gt; I[&quot;返回 shards 列表 和 空 pad_sizes []&quot;]  F -- 否 --&gt; J[&quot;计算 full_chunk_size = ceil(dim_size / num_chunks)&quot;]  J --&gt; K[&quot;收集原始 chunk_sizes&quot;]  K --&gt; L[&quot;pad_sizes = full_chunk_size - chunk_size&quot;]  L --&gt; M[&quot;调用 fill_empty_tensor_to_shards 补空 shard&quot;]  M --&gt; N[&quot;对每个 shard：若 pad_size &gt; 0，则 pad_tensor(shard, dim, pad_size)&quot;]  N --&gt; O[&quot;(可选) shard.contiguous()&quot;]  O --&gt; P[&quot;收集 shard_list 和 pad_sizes&quot;]  P --&gt; Q[&quot;返回 shard_list 和 pad_sizes&quot;]\n\n1.2 关键点详解\n🧠 为什么要 Padding？\n用于保证在分布式环境中（比如 scatter、all_gather 等 collective 操作）每个 rank 的 shard 大小一致，避免因为尺寸不对齐导致通信失败。只有 tensor.size(dim) % num_chunks ≠ 0 且 with_padding=True 时，才会进行 padding。\n🧩 fill_empty_tensor_to_shards\ntorch.chunk 在尺寸较小或 num_chunks 更大时不会输出空 tensor。该函数用于补全：在 tensor_list 少于 num_chunks 时，补充形状合法但 dim 上为 0 的空 tensor，使 shard 数目一致，便于后续统一处理。\n🧼 pad_tensor\n若当前 shard 小于 full_chunk_size，则在指定维度末尾补零，确保所有 shard 的形状一致。\n🧱 contiguous\n为提升内存连贯性和通信效率，可调用 .contiguous() 重排内存布局。\n\n1.3 实际调用示例（需 Padding）\n以下为无法均匀分片，因 num_chunks=4 而触发 pad 的场景：\nimport torchfrom torch.distributed.tensor.placement_types import Shard# 构造张量tensor = torch.arange(1, 13).reshape(2, 6)  # shape [2, 6]# 在 dim=1 上拆为 4 份，不整除将触发 paddingsharder = Shard(dim=1)shards, pad_sizes = sharder._split_tensor(tensor, num_chunks=4, with_padding=True)print(&quot;Pad sizes:&quot;, pad_sizes)for i, (sh, pad) in enumerate(zip(shards, pad_sizes)):    print(f&quot;Shard &#123;i&#125; shape: &#123;tuple(sh.shape)&#125;, pad: &#123;pad&#125;&quot;)    print(sh)\n✅ 预期结果\n\ntensor.size(1)=6, num_chunks=4 ⇒ full_chunk_size = ceil(6/4) = 2\ntorch.chunk 会出 4 块，但最后一两块可能为 empty\npad_sizes 可能为 [0, 0, 0, 2]\n最终每块大小都是 [2] (dim=1)，padding 补齐\n\nPad sizes: [0, 0, 0, 2]Shard 0 shape: (2, 2), pad: 0tensor([[1, 2],        [7, 8]])Shard 1 shape: (2, 2), pad: 0tensor([[ 3,  4],        [ 9, 10]])Shard 2 shape: (2, 2), pad: 0tensor([[ 5,  6],        [11, 12]])Shard 3 shape: (2, 2), pad: 2tensor([[0, 0],        [0, 0]])\n\n1.4 总结\n\n_split_tensor 的作用是将一个 Tensor 沿指定维度切分为固定份数，并在 不能整除时自动补齐。\n它保障了各 shard 在通信阶段尺寸一致，适用于分布式张量并行场景。\n实际代码通过 torch.chunk、fill_empty_tensor_to_shards、pad_tensor 等手段，轻松实现这一目标。\n\n\n"},{"title":"PyTorch 分布式 TCPStore Rendezvous 机制","url":"/2025/06/14/distribute/tcpstore_rendezvous/","content":"\n🧠 背景概述\n\n目标：在 init_process_group 中实现跨进程注册、排序及 barrier 同步，为 NCCL/Gloo 通信组构建创建一致上下文。\n时序：所有 set/get/wait 操作均发生在 NCCL 通信初始化之前（即 rendezvous 阶段）。\n机制：socket 客户端—服务器模型 + backend 控制同步逻辑。\n\n\n1. 消息协议格式\n客户端向 master 发送的包格式为：\n\\[4 B 总长度]\\[1 B 操作码]\\[4 B key\\_len]\\[4 B value\\_len]\\[key]\\[value]\n\n总长度：网络字节序，不含自身；\n操作码：1=SET, 2=GET, 3=WAIT；\nkey_len, value_len：后续字段长度；\nkey, value：实际数据；\nMaster 解析后，回复：OK / value 内容 / READY 等。\n\n\n2. Rendezvous 阶段流程（2 机，4 卡 each，聚焦 rank1 &amp; rank5）\nflowchart TB  subgraph A[&quot;Machine A (rank0-3)&quot;]    master[&quot;TCPStoreBackend (master)&quot;]    r1[Worker rank1]    master --- r1  end  subgraph B[&quot;Machine B (rank4-7)&quot;]    r5[Worker rank5]    master --- r5  end  r1 --&gt;|SET key rank1_addr| master  r5 --&gt;|SET key rank5_addr| master  r1 --&gt;|WAIT  rendezvous_done| master  r5 --&gt;|WAIT  rendezvous_done| master  %% Server: waits until all ranks set, then:  master --&gt;|write READY| r1  master --&gt;|write READY| r5  %% 完成 WAIT 返回，进入 NCCL 初始化  r1 --&gt;|recv READY → NCCL init| NCCL_1[NCCL Init rank1]  r5 --&gt;|recv READY → NCCL init| NCCL_5[NCCL Init rank5]\n🧩 步骤解析\n\nMaster 在端口（如 29500）侦听，接收连接；\nrank1 / rank5 分别发送 SET（注册地址）；\n随后发送 WAIT(\"rendezvous_done\")，Socket 处于阻塞状态；\nMaster 收集所有 8 个 rank 的 SET 后，遍历 wait 阻塞的连接，逐一写入 READY；\nWorker 收到 READY，退出阻塞，进入 NCCL 初始化阶段；\n随后在这一阶段内：交换 ncclUniqueId (via store), 调用 ncclCommInitRank 构建通信组 (github.com, pytorch.org)。\n\n\n3. Backend 细节对比\n\n\n\n\n\n\n\n\nBackend\nI/O 模型\n特点与适应性\n\n\n\n\n经典 TCPStoreBackend\naccept() + per-conn 阻塞/POLL\n简单，连接较多时扩展性差\n\n\nlibuv 异步 Backend\n单线程 event-loop, readable/writeable\n默认启用（v2.4+），高并发更优 (docs.pytorch.org)\n\n\n\n\nlibuv backend 使用 uv_read_start 自动分块读取，根据 header 控制拼包；\n注册 WAIT 时，将 conn 保存在 map 中，不立即回写；当条件满足，触发 uv_write() → uv_write_cb 实现唤醒。\n\n\n4. partial-key WAIT 机制\n\n客户端可以执行 store.wait([\"kA\", \"kB\"])；\nMaster 将此等待登记至 MultiWaitRegistry；\n当 所有相关 key 均被 SET 后，才统一向该连接写 READY，触发唤醒。\n\n\n5. “广播 READY” 的实现机制\n\n不是通过 NCCL/Gloo broadcast 算子；\nMaster 遍历挂起的 WAIT sockets，逐个写 READY；\n为 rendezvous 过程自身提供同步机制，通信组尚未创建。\n\n\n6. 时间线概览\n┌──────────────────────────┐│ SET/WAIT via TCP Store   │  # rendezvous 阶段└──────────────────────────┘            ↓┌──────────────────────────┐│ recv READY → wait returns│└──────────────────────────┘            ↓┌──────────────────────────┐│ NCCL Init                │  # 调用 ncclUniqueId, CommInitRank└──────────────────────────┘            ↓┌──────────────────────────┐│ Collective Ops (DDP)     │└──────────────────────────┘\n\n✅ 总结要点\n\n标注 rank1 / rank5 的流程图，更直观；\nSET + WAIT 操作全部发生于 rendezvous 阶段，见图；\nMaster “广播 READY” 是 socket 写操作，不是通信库广播；\nNCCL 初始化在 rendezvous 完成后进行；\nlibuv backend 提供更高效 I/O 处理及 message 拼接处理能力 (docs.pytorch.org, pytorch.org, github.com)。\n\n\n","categories":["distribute"],"tags":["tcpstore"]},{"title":"Ubuntu 常见 Shell 命令","url":"/2025/08/17/other/shell/","content":"\n\n1. 磁盘占用与排序（du/sort）\n常用写法\n# 按“当前目录的直接子项”汇总（人类可读），并按大小倒序du -h --max-depth=1 . | sort -hr# 仅统计每个条目总大小（不显示子层级），并对条目排序du -sh -- * | sort -h\n2. 文本搜索（grep）\n基础\ngrep &quot;keyword&quot; file.txt          # 在单个文件中查找grep -n &quot;keyword&quot; file.txt       # 显示行号grep -i &quot;keyword&quot; file.txt       # 忽略大小写\n目录递归与上下文\ngrep -rin --color=auto &quot;keyword&quot; .      # 递归、忽略大小写、行号、高亮grep -nC 3 &quot;keyword&quot; file.txt           # 上下各 3 行grep -nA 2 &quot;keyword&quot; file.txt           # 后 2 行grep -nB 2 &quot;keyword&quot; file.txt           # 前 2 行\n精确匹配与正则\ngrep -rw &quot;\\&lt;token\\&gt;&quot; .                  # 按“整词”匹配grep -E &quot;err(or)?|fail(ed)?&quot; app.log    # 扩展正则grep -rF &quot;literal*text&quot; .               # 纯字符串（不当正则），更快\n排除文件/目录\ngrep -rin &quot;keyword&quot; . \\  --exclude-dir=&#123;.git,node_modules,dist&#125; \\  --exclude=&quot;*.min.js&quot;\n\n3. 文件路径查找（find/locate）\nfind：灵活但实时扫描（慢）\n# 按文件名（大小写不敏感）find /path -type f -iname &quot;*name*&quot;# 限制搜索深度find . -maxdepth 2 -type d -name &quot;build&quot;# 查找大文件（&gt; 100MB）并按大小降序列出前 20 个find /var -type f -size +100M -printf &#x27;%s\\t%p\\n&#x27; | sort -nr | head -20# 查找最近 1 天内修改的文件find . -type f -mtime -1# 对结果执行命令（安全处理空格）find . -type f -name &quot;*.log&quot; -print0 | xargs -0 gzip\n\n跳过系统目录且压制报错\n\nfind / \\( -path /proc -o -path /sys -o -path /run \\) -prune -o \\  -type f -name &quot;*.conf&quot; -print 2&gt;/dev/null\nlocate/plocate：基于索引（快）\nsudo apt-get install -y plocatesudo updatedb                 # 通常自动定时更新locate filename_or_pattern\n\n4. 常见网络工具安装包\n# pingsudo apt-get install -y iputils-ping# ifconfig（老工具，仍常见）sudo apt-get install -y net-tools# 现代替代：ip（通常已自带于 iproute2）ip addrip linkip route# killallsudo apt-get install -y psmisc\n\n5. 进程查杀（kill/pkill/killall）\nps -ef | grep python3 | awk &#x27;&#123;print $2&#125;&#x27; | xargs kill -9\n更安全的做法\n# 优雅终止（SIGTERM）；无 PID 时不执行 (-r)pgrep -f python3 | xargs -r kill# 直接按名称匹配（优雅终止），必要时再 -9pkill -f python3pkill -9 -f python3# 避免匹配到 grep 自身ps -ef | grep &#x27;[p]ython3&#x27; | awk &#x27;&#123;print $2&#125;&#x27; | xargs -r kill\n\n建议先尝试 SIGTERM（默认），无响应再用 SIGKILL（-9）。\n\n\n6. 高频命令清单与示例\n系统/资源\ntop                     # 实时概览htop                    # 更友好（需：sudo apt-get install -y htop）free -h                 # 内存df -h                   # 磁盘分区容量du -sh * | sort -h      # 目录占用uname -a                # 内核信息lsb_release -a          # 发行版信息\n进程/网络\nps aux | lesspstree -p               # 进程树（需：sudo apt-get install -y psmisc）lsof -i :8080           # 端口占用（需：sudo apt-get install -y lsof）ss -lntp                # 监听端口 + 进程\n文本/日志\nless file.logtail -f file.logwc -l file.txtsort file | uniq -c | sort -nrcut -d&#x27;,&#x27; -f1,3 file.csvsed -n &#x27;1,20p&#x27; file.txtawk -F: &#x27;&#123;print $1,$3&#125;&#x27; /etc/passwd\n文件/归档/传输\ntar -czf logs.tgz logs/        # 压缩tar -xzf logs.tgz              # 解压zip -r src.zip src/            # zip（需：sudo apt-get install -y zip unzip）rsync -av --progress src/ dst/scp file user@host:/path/\n权限/链接\nchmod +x run.shchown user:group fileln -s /real/path link_name\n服务与日志（systemd）\nsystemctl status nginxsudo systemctl start nginxjournalctl -u nginx --since &quot;1 hour ago&quot;\n其他\nwhich python3command -v nodedate &quot;+%F %T&quot;nohup python3 app.py &gt;out.log 2&gt;&amp;1 &amp;tmux new -s work              # 终端复用（需：sudo apt-get install -y tmux）\n\n7. 小贴士与常见坑\n\n隐藏文件：* 不匹配隐藏项，可用 .* * 组合或开启 dotglob。\n防止参数被当作选项：当文件名以 - 开头时加 --，如 rm -- -weirdfile。\nxargs 安全：二进制文件/空格用 -0 配合 -print0；无结果时不执行用 -r。\n优雅停服务优先：kill -TERM → 不行再 kill -KILL。\n权限：系统目录操作慎用 sudo，写前先 ls/du/stat 确认。\ngrep 正则 vs 字符串：纯文本匹配更稳更快用 -F。\nfind 性能：大目录用 -maxdepth 限制层级或改用 locate/plocate。\n\n\n","categories":["other"],"tags":["shell"]},{"title":"Ubuntu 搭建技术博客指南","url":"/2025/06/14/other/web_init/","content":"\n1. 安装 Hexo 环境\n2. 选择与配置 Hexo 主题\n3. 撰写与管理博客内容\n4. SEO 优化\n5. 博客部署\n6. 维护与优化\n\n本指南详细介绍了如何在 Ubuntu 服务器上搭建并部署一个 Hexo 技术博客，包括从环境安装到后期维护的完整步骤。\n1. 安装 Hexo 环境\n搭建 Hexo 博客首先需要安装 Node.js（Hexo 基于 Node.js）、npm、Git 以及 Hexo CLI 工具。请按照以下步骤配置环境：\n安装 Node.js 和 npm：\n在 Ubuntu 上，通过包管理器或 Node 官方仓库安装 Node.js。建议安装 LTS 版本（如 Node 14+）。执行以下命令添加 NodeSource 仓库并安装 Node.js：\ncurl -sL https://deb.nodesource.com/setup_18.x | sudo -E bash -sudo apt-get install -y nodejs\n安装完成后，检查版本以确保 Node 正常可用：\nnode -v  # 应返回类似 v18.20.6 的版本号npm -v   # 验证 npm 是否正常安装\n安装 Git：\nGit 是 Hexo 部署和备份的常用工具。Ubuntu 通常预装 Git，若未安装，请执行：\nsudo apt-get install -y git\n安装后，配置 Git 的全局用户名和邮箱：\ngit config --global user.name &quot;Your Name&quot;git config --global user.email &quot;youremail@example.com&quot;\n安装 Hexo CLI：\n通过 npm 全局安装 Hexo CLI：\nsudo npm install -g hexo-cli\n安装成功后，通过 hexo -v 检查版本，确保 Hexo CLI 可用。\n初始化 Hexo 博客：\n选择博客文件夹（例如 /var/www/hexo 或当前用户主目录下的 my-blog 文件夹），并在该目录下初始化 Hexo 博客：\nsudo mkdir -p /var/www/hexo &amp;&amp; sudo chown $USER:$USER /var/www/hexocd /var/www/hexohexo initnpm install\n初始化完成后，Hexo 会生成默认的博客结构，包括 _config.yml 配置文件、scaffolds/ 模板目录、source/ 内容目录和 themes/ 主题目录等。可以通过运行 hexo server 预览本地博客。\n开启防火墙：\n为了确保服务器安全，建议开启防火墙。Ubuntu 自带 UFW 防火墙，可以开启 SSH、HTTP(S) 以及 Hexo 默认预览端口 4000：\nsudo apt-get install ufw  sudo ufw allow &quot;OpenSSH&quot;  sudo ufw allow 4000  sudo ufw allow http  sudo ufw allow https  sudo ufw enable\n2. 选择与配置 Hexo 主题\nHexo 默认主题为 Landscape，但为了打造一个简洁美观的技术博客，我们推荐使用 NexT 主题，它功能强大且外观优雅。以下是主题的安装和配置步骤：\n获取 NexT 主题：\n在 Hexo 博客根目录下执行以下命令来克隆 NexT 主题：\ncd /var/www/hexogit clone https://github.com/theme-next/hexo-theme-next themes/next\n修改主题配置：\n克隆完成后，打开 _config.yml 配置文件，将 theme 配置从默认的 landscape 改为 next：\n# _config.ymltheme: next\n安装主题依赖：\n根据需要安装 NexT 主题的依赖，并启用你所需的功能。\n生成常用页面：\n为了完善网站结构，使用以下命令生成标签、分类、归档等页面：\nhexo new page &quot;tags&quot;hexo new page &quot;categories&quot;hexo new page &quot;archives&quot;hexo new page &quot;about&quot;\n编辑每个页面的 index.md，在 Front-matter 中指定页面类型：\ntitle: 标签date: 2025-03-06 15:00:00type: &quot;tags&quot;\n导航栏菜单定制：\n在 themes/next/_config.yml 中找到 menu 设置，并添加新创建的页面：\nmenu:  home: / || home  categories: /categories/ || th  tags: /tags/ || tags  archives: /archives/ || archive  about: /about/ || user\n保存修改后，重新生成站点，新的导航栏菜单即会显示。\n3. 撰写与管理博客内容\nHexo 使用 Markdown 格式来撰写文章，非常适合技术博客。以下是如何管理和编写文章的步骤：\n新建博文：\n使用 Hexo CLI 创建新的文章：\nhexo new &quot;文章标题&quot;\n这将在 source/_posts/ 目录下创建一个 Markdown 文件，文件的开头是 Front-matter，用于配置文章的元数据（如标题、日期、分类和标签等）：\ntitle: 深度学习入门指南  date: 2025-03-06 15:00:00  categories:    - 人工智能    - 深度学习  tags:    - 神经网络    - 入门教程 \n使用 Markdown 撰写内容：\n在 Front-matter 下方，用 Markdown 语法撰写正文。Hexo 默认支持 GFM（GitHub Flavored Markdown），可以方便地书写格式，例如：\n# 一级标题## 二级标题**粗体**、*斜体*强调\n插入图片和资源：\n启用 post_asset_folder: true 后，每篇文章会有独立的资源目录。可以将图片文件放入该文件夹，并在文章中引用：\n![](my-post/images/example.png)\n草稿管理与发布：\n启用草稿功能后，新创建的文章会先放在 _drafts/ 下。完成后，使用 hexo publish \"文章标题\" 将其发布。\n文章结构和分页：\nHexo 支持文章分类和标签自动整理。你也可以通过 &lt;!-- more --&gt; 来手动截断摘要，提高首页加载速度。\n4. SEO 优化\n为了让更多人看到你的技术博客，进行 SEO（搜索引擎优化）非常重要。以下是一些优化措施：\n站点标题与元信息：\n在 _config.yml 中填写有助于 SEO 的站点基本信息，包括 title（标题）、description（描述）和 keywords（关键词）。\n链接优化：\n修改永久链接格式，简化 URL 结构：\npermalink: :category/:title/\n站点地图：\n生成站点地图帮助搜索引擎抓取所有页面：\nnpm install hexo-generator-sitemap hexo-generator-baidu-sitemap --save\n并在 _config.yml 中添加配置：\nsitemap:  path: sitemap.xmlbaidusitemap:  path: baidusitemap.xml\n机器人协议：\n在 source/ 目录下创建 robots.txt 文件，并写入规则：\nUser-agent: *Allow: /Disallow: /admin/Sitemap: https://你的域名/sitemap.xml\n好的，以下是我重新生成并保持完整的 Hexo Deploy 自动部署部分，确保没有省略任何细节：\n\n5. 博客部署\n完成内容创作和优化后，就需要将博客部署上线。Hexo 生成的是纯静态网页，可以部署在任意静态服务器或托管平台上。这里介绍在 Ubuntu 服务器上使用 Nginx 部署的方案，并讨论 Nginx 配置和 Git 自动部署方法。\n本地生成静态文件：\nHexo 提供命令将 Markdown 内容生成静态网页。一般在本地或服务器上运行：\nhexo clean        # 清理上次生成的文件hexo generate (hexo g)   # 生成最新静态网页\n生成的文件位于博客目录下的 public/ 文件夹，其中包含博客的所有 HTML、CSS、JS、图片等静态资源。这个 public 文件夹即是最终部署的网站内容。\nNginx 部署静态站点：\n在服务器上安装 Nginx 并配置站点，以提供 Web 服务：\n安装 Nginx：\nsudo apt-get install -y nginx\n安装后启动 Nginx 服务：\nsudo systemctl start nginx  # 可设置开机自启\n配置站点：在 /etc/nginx/sites-available/ 目录下创建配置文件，如 hexo.conf，内容如下：\nserver &#123;    listen 80;    server_name example.com;  # 将此替换为你的域名或服务器IP    root /var/www/hexo/public;    index index.html index.htm;    location / &#123;        try_files $uri $uri/ =404;    &#125;&#125;\n上述配置指定服务器监听 80 端口，server_name 为你的域名（需要将域名解析指向该服务器）。root 指向 Hexo 生成的 public 目录，index 声明默认首页文件。\n启用站点配置：将配置文件链接到 sites-enabled：\nln -s /etc/nginx/sites-available/hexo.conf /etc/nginx/sites-enabled/nginx -t  # 测试配置语法正确性systemctl reload nginx  # 重新加载 Nginx 配置\n执行以上命令后，博客站点即可通过域名访问。如果暂时没有域名，使用服务器 IP 也能访问（此时可将 server_name 改为 _ 通配符）。\n配置 HTTPS（可选）：\n建议为博客配置 SSL 证书。可以使用 Certbot 获取 Let’s Encrypt 免费证书。步骤如下：\napt-get install -y certbot python3-certbot-nginx  certbot --nginx -d example.com -d www.example.com\n按提示完成域名所有权验证后，Certbot 会自动生成证书并配置 Nginx 将站点升级为 HTTPS。\nHexo Deploy 自动部署：\n每次更新内容后都要重新生成并上传文件，使用 Hexo 的部署功能可以简化流程。Hexo 支持多种部署方式，其中 Git 部署是常用方案之一。基本思路是利用 Git 把生成的静态文件推送到服务器或托管服务。概括了这种思路：在服务器上安装 Nginx 提供网页服务，用 Git 实现代码上传自动化，这样本地执行一次 hexo d（deploy）就能让网站更新。\n推送到远程托管：\n将博客静态文件部署到像 GitHub Pages、Coding Pages 这类平台。这需要在 _config.yml 中配置：\ndeploy:  type: git  repo: https://github.com/yourname/yourrepo.git  branch: main  # 或 gh-pages 分支等\n然后运行 hexo generate &amp;&amp; hexo deploy，Hexo 会把 public 文件夹内容推送到指定仓库的分支。对于 GitHub Pages，如果 repo 是 yourname.github.io 则直接用主分支；若是项目仓库，可以用 gh-pages 分支托管。\n部署后，GitHub Pages 服务将托管你的静态博客，你可以使用自定义域名绑定它。但注意：如果你希望博客运行在自己的服务器上（而非第三方平台），则这种方案不涉及你的服务器 Nginx。另外，国内访问 GitHub Pages 可能不稳定，需结合实际情况考虑。\n推送到自己服务器：\n搭建属于自己的 Git 自动化部署流程，实现将本地更新一键部署到服务器。步骤如下：\n\n在服务器上创建一个裸仓库（bare repository），用于接收推送。例如创建 /home/git/hexo.git 裸仓库。\n编写 Git 钩子（post-receive）：裸仓库的 hooks/post-receive 脚本会在收到新推送时执行。脚本内容可以是将更新的内容检出到 Nginx 目录。例如：\nGIT_WORK_TREE=/var/www/hexo git checkout -f  # 将仓库内容强制检出到 /var/www/hexocd /var/www/hexo &amp;&amp; hexo generate            # （若推送的是源码而非生成文件，则需要在服务器执行生成）\n给脚本可执行权限：\nchmod +x post-receive\n这样，每当推送到该仓库时，它就会把更新部署到博客目录并生成最新页面。\n本地 Hexo 配置部署：将 _config.yml 中的 deploy.repo 设置为上述裸仓库的地址（通过 SSH）。例如：\ndeploy:  type: git  repo: ssh://[email protected]/home/git/hexo.git  branch: master\n然后执行 hexo clean &amp;&amp; hexo deploy。Hexo 会通过 Git 推送到服务器仓库，触发 post-receive 钩子，实现自动部署。完成后，Nginx 会立刻提供新内容服务，无需手动登录服务器操作。\n\n通过这种方案，可以在本地写好文章后一条命令完成部署，非常高效。许多开源博客部署脚本和工具也是基于类似原理实现的。初次设置可能稍显繁琐，但一旦配置成功，日常更新将非常便捷。\n提示： 使用 Git 自动部署需确保服务器开放 Git 所用的 SSH 端口（默认为 22），并配置好公钥免密登录，以便 Hexo 在本地能顺利推送到服务器。如果你的服务器 SSH 端口不是 22，可在部署配置中加入端口号或在 .ssh/config 中配置别名。对于不熟悉 Git 钩子的新手，也可以考虑使用简单的 rsync 脚本同步文件或借助 CI 平台实现部署，但原理类似。\n\n6. 维护与优化\n博客搭建完成并不意味着一劳永逸，定期的维护和优化能保证博客稳定、安全，并持续提升用户体验。\n\n插件扩展： Hexo 拥有丰富的插件生态，可根据需要安装插件以增强功能。\n备份与版本控制： 使用 Git 管理博客源码，定期备份。\n更新与升级： 关注 Hexo 的版本更新、插件更新等。\n\n","categories":["other"]},{"title":"Lumos : Efficient Performance Modeling and Estimation for Large-scale LLM Training","url":"/2025/08/17/paper/lumos/","content":"\n\n一句话总结：Lumos 是一个基于运行时 trace 的建模/模拟工具，从 PyTorch Kineto 等采集到的事件中自动恢复精细的执行图（含算-通重叠与跨流依赖），并支持在不重新跑模型的情况下，对 DP/PP/模型结构 做 “what-if” 修改与快速估算；在 512×H100 集群上回放平均误差约 3.3%。(arXiv)\n\n\n1. 核心贡献与定位\n\n精细执行图：仅用框架内置的 profiler（如 PyTorch Kineto）即可从 CPU/GPU 事件恢复四类关键依赖（CPU→GPU、GPU→CPU、同流顺序、跨流事件），精准表达算-通重叠与同步关系。(arXiv)\n图编辑 &amp; 快速外推：在不改动模型/系统的前提下，从原始 trace-graph 出发，对 数据并行（DP）、流水并行（PP） 与模型层数/隐藏维度做图级改写，再用模拟器重放一整个迭代估算性能。(arXiv)\n高精度回放：在生产集群 最多 512×H100、多种 GPT-3 变体、不同并行策略下，迭代时间回放平均误差 3.3%，并能再现实测的执行细分占比。(arXiv)\n\n\n2. Lumos 如何从 trace 构建执行图\n\n事件来源：直接使用 PyTorch/TensorFlow 的内置 profiler（如 Kineto），无需对模型或框架做侵入式改造。(arXiv)\n依赖建模（四类）：\n\nCPU→GPU（launch）：用 correlation ID 绑定 CPU 端的 cudaLaunchKernel/cudaMemsetAsync 与对应的 GPU kernel。\nGPU→CPU（同步）：cudaDeviceSync/cudaStreamSync 等需要等到相关 GPU kernel 完成。\n同流顺序：同一 CUDA stream 内核严格顺序。\n跨流事件：cudaEventRecord 与 cudaStreamWaitEvent 形成“记录→等待”的跨流依赖，表达不同流间的有序性。(arXiv)\n\n\n\n3. 图编辑：支持哪些 “what-if” 改动\n\n数据并行（DP）：只需调整通信任务（如梯度规约类）的执行时间；本地计算不变。(arXiv)\n流水并行（PP）：\n\n先按所选调度（如 1F1B）更新各微批的前后向顺序；\n将原图中任务按层聚类后重分配到新 stage；\n在 stage 边界插入/重连激活与梯度的 send/recv；\n保留原 trace 中的依赖模式以保证可重放正确性。(arXiv)\n\n模型结构：\n\n隐藏维度变更：重写相关算子/内核的输入张量维度并重估时长；\n层数变更：复制/删减层块并重连依赖与通信。(arXiv)\n\n暂不支持：修改 Tensor Parallelism（TP）（通常受限于单机且通信重，留作未来工作）。(arXiv)\n\n\n4. 模拟器：事件驱动流程（论文算法 1 的要点）\n\n维护两个集合：\n\n固定依赖（初始化阶段一次性确定，如同线程/同流顺序、CPU→GPU 的 launch 边）；\n运行期依赖（例如 cudaStreamSync 需要等待**该流上“最后一个 kernel”**完成，这个“最后”要在调度时才能确定）。\n\n主循环：从就绪集合取任务 → 分配到其“处理器”（CPU 线程/CUDA stream）上运行 → 更新处理器可用时间与后继任务的最早可启动时间；若仍有运行期依赖未满足则延后。(arXiv)\n\n\n5. 评测设置与关键数字\n\n规模与环境：最多 512×H100（32 台主机），RoCE 数据中心网络（每主机 8×400Gbps），CUDA 12.4，PyTorch 2.5，Transformer Engine 0.12.0，Lightning 1.9.4。(arXiv)\n对比基线：与 dPRO（trace-driven 回放系统）相比，Lumos 在复杂并行配置下能更好捕捉跨流依赖与算-通重叠，显著降低回放误差。(arXiv)\n结果：回放平均误差 ~3.3%；并展示在 DP/PP/结构外推时的估算准确性与执行细分（暴露计算/暴露通信/重叠/其他）。(arXiv)\n\n\n6. 工程实现与使用门槛\n\n实现规模：约 5,200 行 Python。(arXiv)\n接入成本：在训练代码里插入 ~10 行 profiler hook 采集 Kineto trace，随后走自动化流程：建图 → 图编辑 → 模拟估算。(arXiv)\n\n\n7. 适用/不适用场景\n\n适用：\n\n需要在真实机群外快速比较并行/结构配置（DP/PP/层数/隐藏维）并估算收益；\n需要高保真回放来定位算-通重叠与跨流同步处的性能瓶颈。\n\n当前不适用/注意：\n\n修改 TP 的外推（论文暂未支持）；\n追求 FLOPs、内存、带宽、能耗等系统级指标（论文称为后续计划）；\n估算假设新配置可正常运行（不考虑 OOM 等失效情形）。(arXiv)\n\n\n\n8. 与既有工作的关系（示例：dPRO）\n\ndPRO 同样是 trace-driven 的性能诊断/回放系统，但在复杂 LLM 并行下，跨流依赖与重叠的精细建模更困难，容易导致过度乐观的并行预测；Lumos 在这些方面做了系统增强并显著降低误差。(arXiv)\n\n\n9. 论文与会议信息（可引用）\n\n论文（arXiv）：“Lumos: Efficient Performance Modeling and Estimation for Large-scale LLM Training”（2025-04-12 首次提交）。(arXiv)\nPDF（作者主页镜像/MLSys 论文）：可下载全文。(mingyu-liang.github.io)\nMLSys 2025 接收与日程页面（含报告/录播入口）。(mlsys.org)\n\n\n10. 代码与开源状态（截至 2025-08-15）\n\n未见官方代码库链接（arXiv/MLSys 页面与作者 PDF 中均未提供），社区里存在同名但无关的 “Lumos” 项目（如 Agent/视频生成/视觉等），注意区分。(arXiv, mlsys.org, GitHub)\n\n\n11. 快速上手（示意）\n\n采集 Kineto trace → 构建执行图 → 在图上编辑（DP/PP/结构）→ 模拟回放/估算。 论文正文给出了典型的 PyTorch profiler 用法示意与全流程示意图。(arXiv)\n\n\n12. 你可能关心的细节（精炼版）\n\n为什么更准？\n\n用 correlation ID 串起 CPU launch 与 GPU kernel；\n显式恢复 跨流事件（Record/Wait）与同步（Stream/Device Sync）；\n在模拟器中将依赖分为固定与运行期，确保像 “等待该流最后一个 kernel” 这类语义被正确表达。(arXiv)\n\n改 DP/PP 怎么算？\n\nDP：只重赋通信任务时长；\nPP：更新调度（如 1F1B）→ 任务按层分组并重分 stage → 在边界插入 send/recv → 保持依赖闭合。(arXiv)\n\n\n\n参考文献 / 链接\n\nLumos 论文（arXiv 页面与 PDF）：(arXiv)\nLumos（MLSys 2025 会议页面/日程/录播）：(mlsys.org)\ndPRO（trace-driven 回放基线论文）：(arXiv)\n\n\n\n注：本文档只摘取对工程落地最关键的事实与方法，更多图例（如 PP×TP 微批调度示例）与完整算法细节请参阅原论文正文与附图。(arXiv)\n\n\n","categories":["paper"],"tags":["paper"]}]