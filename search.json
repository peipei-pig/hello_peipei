[{"title":"attentionä¸­å¼ é‡å¹¶è¡Œä¸GQA","url":"/2025/08/17/distribute/attention/","content":"\n\n\nä¾‹å­é…ç½®ï¼ˆè´¯ç©¿å…¨æ–‡ï¼‰ï¼š hidden_size=4096, num_attention_heads=32, tensor_parallel_size=4, num_query_groups=8ï¼ˆGQAï¼‰, kv_channels=hidden/heads=128ã€‚ è¾“å…¥å½¢çŠ¶ç”¨ [B, S, H] è®°ï¼ˆæ‰¹ã€åºåˆ—ã€éšè—ï¼‰ã€‚\n\n\n1. åè¯ä¸æ´¾ç”Ÿå˜é‡ï¼ˆå…ˆæŠŠé‡ç®—æ¸…æ¥šï¼‰\n\nå•å¤´ç»´åº¦ï¼ˆä¹Ÿæ˜¯ç¼©æ”¾ç”¨çš„ \\(d_k\\)ï¼‰ï¼škv_channels = 4096 / 32 = 128\nQ æŠ•å½±æ€»ç»´ï¼šquery_projection_size = kv_channels * num_attention_heads = 128*32 = 4096\nK/V æŠ•å½±æ€»ç»´ï¼ˆGQAï¼‰ï¼škv_projection_size = kv_channels * num_query_groups = 128*8 = 1024\næ¯å¡ Q å¤´æ•°ï¼šnum_attention_heads_per_partition = 32 / TP = 8\næ¯å¡ KV ç»„æ•°ï¼šnum_query_groups_per_partition = 8 / TP = 2\næ¯å¡æŠ•å½±ç»´ï¼ˆåˆ—å¹¶è¡Œåæœ¬åœ°è¾“å‡ºç»´ï¼‰ï¼šhidden_size_per_partition = 4096 / TP = 1024\n\n\nGQA çš„å«ä¹‰ï¼šå½“ num_key_value_heads (=num_query_groups) å°äº num_attention_heads æ—¶ï¼Œä¸ºè¾ƒå°‘çš„ KV å¤´/ç»„ äº§å‡º K/Vï¼Œè®©å¤šä¸ª Q å¤´å…±äº«å®ƒä»¬ï¼›=heads é€€åŒ–ä¸º MHAï¼Œ=1 æ˜¯ MQAã€‚è¿™ä¸€ç‚¹åœ¨ HF æ¨¡å‹æ–‡æ¡£ä¸­æ˜¯æ˜ç¡®çš„å®šä¹‰ã€‚(Hugging Face)\n\n\n2. ç«¯åˆ°ç«¯è®¡ç®—ä¸å½¢çŠ¶æµï¼ˆä»¥å•å±‚è‡ªæ³¨æ„åŠ›ä¸ºä¾‹ï¼‰\nMegatron ç»å…¸åšæ³•ï¼šQ/K/V çš„çº¿æ€§å±‚ç”¨åˆ—å¹¶è¡Œï¼ˆColumn-Parallelï¼‰ï¼ŒæŒ‰è¾“å‡ºåˆ—åˆ‡ç»™å„å¡ï¼›è¾“å‡ºæŠ•å½±ç”¨è¡Œå¹¶è¡Œï¼ˆRow-Parallelï¼‰ï¼ŒæŒ‰è¾“å…¥è¡Œåˆ‡ç»™å„å¡ï¼Œå‰å‘åªåœ¨è¾“å‡ºæŠ•å½±åšä¸€æ¬¡ all-reduceã€‚è¿™æ˜¯ Megatron-LM è®ºæ–‡ä¸ Megatron-Core æ–‡æ¡£æ¨èçš„å¼ é‡å¹¶è¡Œåˆ‡æ³•ã€‚(arXiv, NVIDIA Docs)\n2.1 çº¿æ€§æŠ•å½±ï¼ˆåˆ—å¹¶è¡Œï¼‰\n\nQ æŠ•å½±ï¼ˆå…¨å±€æƒé‡ [4096,4096] â†’ æ¯å¡ [4096,1024]ï¼‰ï¼š æœ¬å¡è¾“å‡º Q_local: [B,S,1024] â†’ reshape ä¸º [B, 8, S, 128]ï¼ˆæœ¬å¡ 8 ä¸ª Q å¤´ï¼‰ã€‚\nK æŠ•å½±ï¼ˆå…¨å±€æƒé‡ [4096,1024] â†’ æ¯å¡ [4096,256]ï¼‰ï¼š K_local: [B,S,256] â†’ reshape ä¸º [B, 2, S, 128]ï¼ˆæœ¬å¡ 2 ä¸ª KV ç»„ï¼‰ã€‚\nV æŠ•å½± åŒ Kã€‚\n\n\nä¸ºä»€ä¹ˆå¿…é¡» reshape å‡º head ç»´ï¼Ÿ å¤šå¤´æ³¨æ„åŠ›çš„è¯­ä¹‰æ˜¯â€œå¤´å†…ç‹¬ç«‹â€çš„ç‚¹ç§¯æ³¨æ„åŠ›ï¼Œå†…æ ¸ï¼ˆSDPA/FlashAttentionï¼‰ä¸å¹¿æ’­ï¼ˆmaskã€RoPEã€repeat_kvï¼‰éƒ½è¦æ±‚æ˜¾å¼çš„ head ç»´ [B,H,S,D] æˆ–å±•å¹³ä¸º [BÂ·H,S,D]ã€‚ä¸æ‹†å¤´ä¼šæŠŠä¸åŒ head çš„å­ç©ºé—´æ··åœ¨ä¸€èµ·ï¼Œä¹Ÿæ— æ³•è‡ªç„¶æ‰§è¡Œ GQA çš„ repeat_kvã€‚(PyTorch)\n\n2.2 GQA çš„ K/V å¯¹é½ï¼ˆrepeat/expandï¼‰\næœ¬å¡åªæœ‰ 2 ä¸ª KV ç»„ï¼Œä½†è¦æœåŠ¡ 8 ä¸ª Q å¤´ â‡’ åœ¨å¤´ç»´åšé€»è¾‘é‡å¤/å¹¿æ’­ï¼š [B, 2, S, 128] â†’ [B, 8, S, 128]ï¼ˆæ¯ä¸ª KV ç»„æœåŠ¡ 4 ä¸ª Q å¤´ï¼‰ã€‚ä¸»æµå®ç°ç›´æ¥åœ¨ head ç»´åš repeat_kvã€‚(Hugging Face)\n2.3 Scaled Dot-Product Attentionï¼ˆæ¯å¡åªç®—è‡ªå·±çš„ 8 ä¸ªå¤´ï¼‰\n\nscores = (Q @ K^T) / sqrt(128) â†’ softmax(scores) @ V\nå¾—åˆ°ä¸Šä¸‹æ–‡ ctx_local: [B, 8, S, 128] â†’ æ‹¼æ¥ä¸º [B,S,1024]\nè¿™ä¸€æ­¥å¯ä»¥ç”± PyTorch SDPA æˆ–é—ªå­˜æ³¨æ„åŠ›å†…æ ¸é«˜æ•ˆå®Œæˆã€‚(PyTorch)\n\n2.4 è¾“å‡ºæŠ•å½±ï¼ˆè¡Œå¹¶è¡Œ + 1 æ¬¡ all-reduceï¼‰\n\næ¯å¡æŠŠ [B,S,1024] ä¹˜ä»¥æœ¬å¡çš„è¾“å‡ºæƒé‡åˆ†ç‰‡ï¼Œå¾—åˆ° Y_local: [B,S,4096] çš„éƒ¨åˆ†å’Œï¼›\nè·¨å¡åš all-reduce(sum) å¾—åˆ°æœ€ç»ˆ Y: [B,S,4096]ã€‚ Megatron è®ºæ–‡æŒ‡å‡ºï¼šè‡ªæ³¨æ„åŠ›æœ¬ä½“ä¸éœ€é€šä¿¡ï¼Œåªåœ¨è¾“å‡ºæŠ•å½±å¤„åšä¸€æ¬¡è§„çº¦å³å¯ã€‚(arXiv)\n\n\n3. åˆ—å¹¶è¡Œ / è¡Œå¹¶è¡Œçš„æ•°å­¦ç­‰ä»·ï¼ˆä¸ºä½•â€œåˆ‡äº†å†æ‹¼/æ±‚å’Œâ€ä»ç­‰ä»·å•å¡ï¼‰\næŠŠ [B,S,Â·] å±•å¹³ä¸ºçŸ©é˜µ \\(X\\in\\mathbb{R}^{N\\times(HD)}\\)ï¼ˆ\\(N=B\\cdot S\\)ï¼‰ï¼Œè¾“å‡ºéšè—è®°ä¸º \\(H\\)ã€‚\n3.1 åˆ—å¹¶è¡Œï¼ˆColumn-Parallel Linearï¼‰â‰¡ æ‹¼æ¥\nè®¾ Q çš„å…¨é‡æƒé‡ \\(W_Q\\in\\mathbb{R}^{(HD)\\times(HD)}\\)ï¼Œæ²¿åˆ—åˆ‡æˆ \\(p\\) å—ï¼š\n\\[\nW_Q=\\big[W_Q^{(0)}\\;\\;W_Q^{(1)}\\;\\;\\cdots\\;\\;W_Q^{(p-1)}\\big],\n\\quad W_Q^{(i)}\\in\\mathbb{R}^{(HD)\\times(H/p\\cdot D)}.\n\\]\nåˆ™\n\\[\nQ=XW_Q=\\big[XW_Q^{(0)}\\;\\;XW_Q^{(1)}\\;\\;\\cdots\\;\\;XW_Q^{(p-1)}\\big]\n      =\\operatorname{Concat}(Q^{(0)},\\dots,Q^{(p-1)}).\n\\]\næ¯å¡ç‹¬ç«‹è®¡ç®—è‡ªå·±çš„ \\(Q^{(i)}\\)ï¼Œæ— é¡»é€šä¿¡ã€‚K/V åŒç†ã€‚è¿™å°±æ˜¯ Column-Parallel çš„ç²¾ç¡®å®šä¹‰ã€‚(arXiv, NVIDIA Docs)\n3.2 æ¯å¤´ç‹¬ç«‹ â‡’ æŒ‰å¤´åˆ‡ç»™å„å¡ä»ç„¶æ­£ç¡®\nå•å¤´/å•ç»„æ³¨æ„åŠ›ï¼š\n\\[\nY_h=\\operatorname{softmax}\\!\\Big(\\tfrac{Q_hK_{g(h)}^\\top}{\\sqrt{D}}\\Big)V_{g(h)}.\n\\]\nGQA ä¸‹ \\(g(h)\\) æŠŠå¤šä¸ª Q å¤´æ˜ å°„åˆ°åŒä¸€ KV ç»„ï¼›ç”±äºå¤´é—´äº’ä¸ç›¸å¹²ï¼ŒæŠŠ 32 ä¸ªå¤´å¹³å‡åˆ†æˆ 4 ä»½åˆ° 4 å¼ å¡ï¼Œå„å¡åªä¾èµ–è‡ªå·±çš„ KV ç»„ï¼Œå°±ä¸å•å¡ä¸€è‡´ã€‚repeat_kv æ­£æ˜¯æ²¿ head ç»´æŠŠ KV å¯¹é½åˆ° Q å¤´æ•°ã€‚(Hugging Face)\n3.3 è¡Œå¹¶è¡Œï¼ˆRow-Parallel Linearï¼‰â‰¡ æ±‚å’Œï¼ˆall-reduceï¼‰\næŠŠæ³¨æ„åŠ›è¾“å‡ºçš„æ‹¼æ¥å¼ é‡ \\(C\\in\\mathbb{R}^{N\\times(HD)}\\) æŒ‰åˆ—ï¼ˆç‰¹å¾ï¼‰åˆ‡å—ï¼š\n\\[\nC=\\big[C^{(0)}\\;\\;C^{(1)}\\;\\;\\cdots\\;\\;C^{(p-1)}\\big],\\quad\nC^{(i)}\\in\\mathbb{R}^{N\\times(H/p\\cdot D)}.\n\\]\nè¾“å‡ºæƒé‡ \\(W_O\\in\\mathbb{R}^{(HD)\\times H}\\) æŒ‰è¡Œåˆ‡å—ï¼š\n\\[\nW_O=\\begin{bmatrix}\nW_O^{(0)}\\\\ W_O^{(1)}\\\\ \\vdots\\\\ W_O^{(p-1)}\n\\end{bmatrix},\n\\quad W_O^{(i)}\\in\\mathbb{R}^{(H/p\\cdot D)\\times H}.\n\\]\nå—ä¹˜æ³•æ’ç­‰å¼ï¼š\n\\[\nC\\,W_O=\\sum_{i=0}^{p-1} C^{(i)}W_O^{(i)}.\n\\]\nå› æ­¤å„å¡è®¡ç®— \\(Y^{(i)}=C^{(i)}W_O^{(i)}\\)ï¼Œå† all-reduce(sum)ï¼Œå°±å¾—åˆ°ä¸å•å¡å®Œå…¨ç›¸åŒçš„ \\(Y\\)ã€‚è¿™æ­£æ˜¯ Row-Parallel çš„æœ¬è´¨ã€‚(arXiv)\n\n4. ä¸ºä»€ä¹ˆ GQA ä¼šè®© kv_projection_size å˜å°ã€KV cache å˜çœï¼Ÿ\n\nK/V çº¿æ€§å±‚åªä¸º num_query_groups äº§å‡ºé€šé“ï¼šä» 4096ï¼ˆ=32Ã—128ï¼‰é™ä¸º 1024ï¼ˆ=8Ã—128ï¼‰ï¼ŒK/V æŠ•å½±çš„ å‚æ•°é‡ä¸ FLOPs çº¦ä¸ºåŸæ¥çš„ 1/4ï¼›\næ¨ç†é˜¶æ®µçš„ KV cache ä»¥ã€ŒKV å¤´ Ã— åºåˆ— Ã— å¤´ç»´ã€è®¡é‡ï¼ŒKV å¤´ä» 32 å˜ 8ï¼Œç¼“å­˜ä¸ç›¸å…³å¸¦å®½å‡ç›¸åº”ä¸‹é™ã€‚HF æ–‡æ¡£æ˜ç¡®ä»¥ num_key_value_heads æè¿°è¯¥è¡Œä¸ºã€‚(Hugging Face)\n\n\n5. å½¢çŠ¶é€ŸæŸ¥ï¼ˆä»¥æœ¬ä¾‹ä¸ºå‡†ï¼‰\n\n\n\nå¼ é‡/æ­¥éª¤\nå…¨å±€ï¼ˆä¸åˆ†ç‰‡ï¼‰\næ¯å¡ï¼ˆTP=4ï¼‰\nè¯´æ˜\n\n\n\n\nQ çº¿æ€§è¾“å‡ºç»´\n4096\n1024\nColumn-Parallelï¼Œæ— é€šä¿¡\n\n\nK çº¿æ€§è¾“å‡ºç»´\n1024\n256\nGQAï¼šåªå‡º 8 ä¸ª KV ç»„\n\n\nV çº¿æ€§è¾“å‡ºç»´\n1024\n256\nåŒä¸Š\n\n\nQ å¤´æ•°\n32\n8\næœ¬å¡åªç®—è‡ªå·± 8 ä¸ªå¤´\n\n\nKV ç»„æ•°\n8\n2\næ¯ç»„æœåŠ¡ 4 ä¸ª Q å¤´\n\n\nå¤´ç»´ \\(D\\)\n128\n128\nç”¨äº \\(1/\\sqrt{D}\\)\n\n\næœ¬å¡æ³¨æ„åŠ›è¾“å‡ºï¼ˆæ‹¼å¤´åï¼‰\nâ€“\n[B,S,1024]\nè¿›å…¥è¾“å‡ºæŠ•å½±\n\n\næœ€ç»ˆè¾“å‡ºï¼ˆall-reduce åï¼‰\n[B,S,4096]\n[B,S,4096]\nRow-Parallel + sum\n\n\n\nï¼ˆè‹¥å¯ç”¨ Sequence Parallelï¼Œåªä¼šæ²¿ S å†åˆ‡ä¸€ç»´ï¼Œä¸å½±å“ä¸Šè¿°å¤´/é€šé“ç»´é€»è¾‘ã€‚åˆ—/è¡Œå¹¶è¡Œä¸ä¸€æ¬¡é€šä¿¡çš„ç»“æ„æ˜¯ Megatron-LM çš„â€œç»å…¸æ‹†åˆ†â€ã€‚ï¼‰(awsdocs-neuron.readthedocs-hosted.com, Better Tomorrow with Computer Science)\n\n6. Mermaidï¼šä¸€å¼ â€œç»´åº¦/å¹¶è¡Œæ–¹å¼â€å°å›¾\n%%&#123;init: &#123; &quot;flowchart&quot;: &#123; &quot;htmlLabels&quot;: true, &quot;wrap&quot;: true &#125; &#125;&#125;%%flowchart TB  X[&quot;Input X: [B,S,4096]&quot;] --&gt; QKV[&quot;Column-Parallel Q/K/V&lt;br/&gt;Q:[B,S,1024]  K/V:[B,S,256]&quot;]  QKV --&gt; Reshape[&quot;Reshape by heads&lt;br/&gt;Q:[B,8,S,128]&lt;br/&gt;K/V:[B,2,S,128]&quot;]  Reshape --&gt; RepeatKV[&quot;repeat_kv on head dim&lt;br/&gt;K/V:[B,8,S,128]&quot;]  RepeatKV --&gt; SDPA[&quot;SDPA per head&lt;br/&gt;ctx_local:[B,8,S,128]&lt;br/&gt;concat-&gt;[B,S,1024]&quot;]  SDPA --&gt; OutProj[&quot;Row-Parallel OutProj&lt;br/&gt;Y_local:[B,S,4096]&quot;]  OutProj --&gt; AllReduce[&quot;all-reduce(sum)&quot;]  AllReduce --&gt; Y[&quot;Final Y: [B,S,4096]&quot;]\n\n7. æç®€ä¼ªç ï¼ˆPyTorch é£æ ¼ï¼‰\n# åˆ—å¹¶è¡Œçš„çº¿æ€§ï¼šæ¯å¡æ‹¿åˆ° Q/K/V çš„ä¸€æ®µè¾“å‡ºåˆ—Q_local = linear_col_parallel_Q(X)   # [B,S,1024] -&gt; view [B,8,S,128]K_local = linear_col_parallel_K(X)   # [B,S,256]  -&gt; view [B,2,S,128]V_local = linear_col_parallel_V(X)   # [B,S,256]  -&gt; view [B,2,S,128]Q = Q_local.view(B, S, 8, 128).transpose(1, 2)  # [B,8,S,128]K = K_local.view(B, S, 2, 128).transpose(1, 2)  # [B,2,S,128]V = V_local.view(B, S, 2, 128).transpose(1, 2)  # [B,2,S,128]# GQA: è®© 2 ä¸ª KV ç»„åŒ¹é… 8 ä¸ª Q å¤´ï¼ˆé€»è¾‘ repeat/expandï¼‰K = repeat_kv(K, n_rep=4)   # [B,8,S,128]V = repeat_kv(V, n_rep=4)   # [B,8,S,128]# SDPAï¼ˆæ¯å¡åªç®—è‡ªå·±çš„ 8 ä¸ªå¤´ï¼‰ctx = torch.nn.functional.scaled_dot_product_attention(Q, K, V)  # [B,8,S,128]ctx = ctx.transpose(1, 2).reshape(B, S, 1024)                    # [B,S,1024]# è¡Œå¹¶è¡Œè¾“å‡º + ä¸€æ¬¡ all-reduce(sum)Y_local = linear_row_parallel_out(ctx)   # partial: [B,S,4096]Y = all_reduce_sum(Y_local)              # final:   [B,S,4096]\n\nSDPA çš„æ¥å£ä¸è¯­ä¹‰è§ PyTorch æ–‡æ¡£ï¼›repeat_kv çš„è¯­ä¹‰ä¸ GQA çš„é…ç½®åœ¨ HF æ–‡æ¡£/å®ç°ä¸­æœ‰æ˜ç¡®å®šä¹‰ã€‚(PyTorch, Hugging Face)\n\n\n8. æ­£ç¡®æ€§ Checklistï¼ˆå®è·µä¸­æœ€å¸¸è§çš„å‘ï¼‰\n\næ•´é™¤å…³ç³»ï¼š num_attention_heads % TP == 0ï¼Œnum_query_groups % TP == 0ï¼Œä¸” num_attention_heads % num_query_groups == 0ï¼ˆGQAï¼‰ã€‚(Hugging Face)\næ˜¾å¼ head ç»´ï¼šå½¢çŠ¶åº”ä¸º [B,H,S,D] æˆ–å±•å¹³ä¸º [BÂ·H,S,D]ï¼Œä»¥å¥‘åˆ SDPA/FlashAttention ä¸ repeat_kvã€‚(PyTorch)\né€šä¿¡ä½ç½®ï¼šè‡ªæ³¨æ„åŠ›æœ¬ä½“æ— è·¨å¡é€šä¿¡ï¼›ä»…è¾“å‡ºæŠ•å½±éœ€è¦ä¸€æ¬¡ all-reduceã€‚(arXiv)\n\n\nå‚è€ƒä¸å»¶ä¼¸é˜…è¯»\n\nMegatron-LM è®ºæ–‡ï¼šæå‡ºå±‚å†…ï¼ˆå¼ é‡ï¼‰å¹¶è¡Œï¼Œæ³¨æ„åŠ›ç”¨åˆ—å¹¶è¡Œï¼Œè¾“å‡ºç”¨è¡Œå¹¶è¡Œï¼Œå‰å‘ä»…ä¸€å¤„é€šä¿¡ã€‚(arXiv, ar5iv)\nMegatron-Core æ–‡æ¡£ï¼šTensor Parallel API/ç”¨æˆ·æŒ‡å—ï¼ˆNVIDIA å®˜æ–¹ï¼‰ã€‚(NVIDIA Docs)\nPyTorch SDPA æ–‡æ¡£/æ•™ç¨‹ï¼šå®˜æ–¹çš„ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›æ¥å£ä¸é«˜æ€§èƒ½å®ç°ã€‚(PyTorch, PyTorch Docs)\nHF æ–‡æ¡£ï¼ˆLlama/Qwen ç³»åˆ—ï¼‰ï¼šnum_key_value_heads çš„å®šä¹‰ã€GQA/MQA/MHA çš„å…³ç³»ï¼›å®ç°é‡Œ repeat_kv çš„ç”¨æ³•ã€‚(Hugging Face)\nåˆ—å¹¶è¡Œ/è¡Œå¹¶è¡Œå¯è§†åŒ–è®²è§£ï¼šå¯¹ ColumnParallelLinear / RowParallelLinear çš„ç›´è§‚å›¾è§£ã€‚(awsdocs-neuron.readthedocs-hosted.com, Better Tomorrow with Computer Science)\n\n\n","categories":["åˆ†å¸ƒå¼åŸºç¡€"],"tags":["attention"]},{"title":"pytorch devicemesh","url":"/2025/06/14/distribute/device_mesh/","content":"\n\nä¸€ã€ä¸ºä½•ä½¿ç”¨ DeviceMeshï¼Ÿ\nåœ¨æ··åˆå¹¶è¡Œï¼ˆDP/TP/PP/HSDP/â€¦ï¼‰ä¸­ï¼Œéœ€è¦ç®¡ç†å¤šä¸ªå­é€šä¿¡ç»„ï¼ˆProcessGroupï¼‰ï¼Œå¯¹åº”å¤æ‚çš„è®¾å¤‡æ‹“æ‰‘ç»“æ„ã€‚DeviceMesh æä¾›äº†ï¼š\n\nç†è®ºä¸Šæ— ç¼æ”¯æŒä»»æ„ç»´åº¦çš„å¤šç»´æ‹“æ‰‘ï¼›\nè‡ªåŠ¨æ‹†åˆ†è¿›ç¨‹ç»„(new_group/split_group)ï¼›\nçµæ´»åˆ‡ç‰‡å­ Meshï¼›\nç»å†è®¾è®¡å‘¨å…¨çš„é«˜æ•ˆåˆå§‹åŒ–æ–¹æ¡ˆ (docs.pytorch.org, pytorch.org)ã€‚\n\n\näºŒã€åˆå§‹åŒ–æµç¨‹\ninit_device_mesh(...) çš„ä½œç”¨\nä¸€ä¸ªä¸€è¡Œæå®šçš„æ–¹æ³•ï¼Œå®ƒä¼šï¼š\n\nåˆå§‹åŒ–å…¨å±€ init_process_group(...)ï¼ˆè‹¥æœªåˆå§‹åŒ–ï¼‰ï¼›\næ ¹æ® mesh_shape è‡ªåŠ¨æ„é€  CPU ä¸Šçš„ torch.arange(...).view(...)ï¼›\nåˆ›å»º DeviceMesh(...)ã€‚å†…éƒ¨å®Œæˆå­ç»„æ‹†åˆ†åŸç†ï¼ˆè§ä¸‹ä¸€èŠ‚ï¼‰ã€‚\n\n\nDeviceMesh.__init__() + _init_process_groups()\n\nå­˜å‚¨ï¼šdevice_typeã€meshã€mesh_dim_namesï¼›\né€šä¿¡ç»„æ‹†åˆ†ï¼šéå†æ¯ä¸ªç»´åº¦ dimï¼š\n\nä½¿ç”¨ mesh.swapdims(-1, dim).reshape(-1, size(dim)) åˆ—å‡ºè¯¥ç»´æ‰€æœ‰å­ç»„ rankï¼›\nè‹¥ NCCL å·²ç»‘å®š GPUï¼Œå³å¯ç”¨ split_group ä¸€æ¬¡æ‹†å‡ºå…¨éƒ¨å­ç»„ï¼›\nå¦åˆ™ä½¿ç”¨ new_group() åˆ† group æ‹†ï¼›\nå¹¶å°†å½“å‰ rank å±äºçš„é‚£ç»„ä¿¡æ¯æ”¾å…¥ self._dim_group_infos[dim]ï¼›\n\nç»“æœï¼šæ¯ä¸ªç»´åº¦å¯¹åº”ä¸€ä¸ªåŒ…å«å½“å‰ rank çš„ ProcessGroup ä¿¡æ¯åˆ—è¡¨ã€‚\n\n#ppmesh = torch.tensor([  [0, 1],  # pp=0  [2, 3],  # pp=1  [4, 5],  # pp=2  [6, 7]   # pp=3])mesh.swapdims(-1, 0)tensor([[0,2,4,6],        [1,3,5,7]])pg_ranks_by_dim = tmp.reshape(-1, mesh.size(0))[  [0,2,4,6],  # å¯¹åº” tp è¡Œ 0 å„ pp æ®µ  [1,3,5,7]   # å¯¹åº” tp è¡Œ 1 å„ pp æ®µ]#tptmp = mesh.swapdims(-1, 1)  # ç­‰äº transpose(1,1)ï¼Œæœ¬èº«æ— å˜åŒ–pg_ranks_by_dim = tmp.reshape(-1, mesh.size(1))[  [0,1],  # pp=0  [2,3],  [4,5],  [6,7]]\n\nä¸‰ã€æ ¸å¿ƒæ¥å£ä¸å†…éƒ¨å®ç°è§£æ\n1. å±æ€§ä¸æ–¹æ³•\nmesh.shape  # tuple(self.mesh.shape)mesh.ndim   # int(self.mesh.ndim)mesh.size(dim=None)  # æ€»å…ƒç´ æ•° or self.mesh.size(dim)\nç”¨äºè·å– mesh å…ƒç»“æ„å’Œè§„æ¨¡ï¼Œé€‚ç”¨äºåˆ¤æ–­ç»´åº¦æ•°é‡ã€å¾ªç¯è¿­ä»£ã€å¹¶è¡Œç­–ç•¥é…ç½®ç­‰åœºæ™¯ã€‚\n\n2. Rank ä¸åæ ‡\n\nget_rank()ï¼šç­‰ä»·äº torch.distributed.get_rank()ï¼Œè¿”å›å…¨å±€ rankï¼›\nget_local_rank(mesh_dim)ï¼šå†…éƒ¨è°ƒç”¨ get_rank(self.get_group(mesh_dim)) â†’ å½“å‰ç»´åº¦çš„å°ç»„å†…ç¼–å·ï¼›\nget_coordinate()ï¼šè¿”å› self._coordinate_on_dimï¼Œå…¶åœ¨åˆå§‹åŒ–ä¸­é€šè¿‡ (self.mesh==global_rank).nonzero() è·å¾—ã€‚\n\nç¤ºä¾‹ï¼šmesh_shape=(4,2)ï¼Œrank=5 â†’ local_pp=2ã€local_tp=1ï¼Œcoordinate [2,1]ã€‚\n\n3. é€šä¿¡ç»„è·å–\n\nget_group(mesh_dim)ï¼š\n\nè‹¥ 1D ä¸”ä¸ä¼ å‚ï¼Œç›´æ¥è¿”å›å”¯ä¸€å­è¿›ç¨‹ç»„ï¼›\nå¤šç»´åˆ™æ ¹æ® mesh_dimï¼ˆç´¢å¼•æˆ–åå­—ï¼‰æ£€ç´¢ self._dim_group_infos[dim]ï¼Œç”¨ _find_pg_by_ranks_and_tag() è·å–å¯¹åº” ProcessGroupã€‚\n\nget_all_groups()ï¼šè¿”å›æ‰€æœ‰ç»´åº¦çš„ group åˆ—è¡¨ï¼›\n__getitem__(dims)ï¼šåˆ‡ç‰‡æ¥å£è°ƒç”¨ _mesh_resources._get_slice_mesh_dims(...)ï¼Œåˆ›å»ºæ–°çš„å­ meshï¼Œä¿ç•™åº•å±‚ communicatorï¼Œä½†ç»´åº¦é™ã€‚\n\næ”¯æŒå•ç»´æˆ–å¤šç»´åˆ‡ç‰‡ï¼Œä¸”è¿”å›çš„ submesh é¡ºåºæŒ‰ä¼ å…¥é¡ºåºæ’åˆ— (discuss.ray.io, gemfury.com, pytorch.org)ã€‚\n\n\n\n4. from_group(...) æ–¹æ³•\n\nå¯æ¥å—å• group æˆ– group åˆ—è¡¨ï¼›\nåˆ›å»ºæ–°çš„ DeviceMesh æ—¶ä¸ä¼šè°ƒç”¨ backend åˆå§‹åŒ–ï¼›\nä¼šå¤ç”¨ç°æœ‰ ProcessGroupï¼Œå¹¶å¡«å…… _dim_group_infosï¼Œå› æ­¤ get_group(...) å°†ç›´æ¥è¿”å›ä¼ å…¥çš„å®ä¾‹ï¼Œé¿å…é‡å¤åˆ›å»º groupã€‚\n\n\nå››ã€å®Œæ•´å•æœº 8 å¡ Demoï¼štp=2, pp=4\nä¸‹é¢æ¼”ç¤ºå¦‚ä½•è°ƒç”¨æ‰€æœ‰æ¥å£å¹¶è¾“å‡ºç»“æœã€‚æ³¨æ„ï¼šéœ€åœ¨ torchrun --nproc_per_node=8 ä¸‹è¿è¡Œã€‚\nimport os, torch, torch.distributed as distfrom torch.distributed.device_mesh import init_device_meshdef run_device_mesh_demo():    dist.init_process_group(&quot;nccl&quot;)    # â¬‡ï¸ åˆå§‹åŒ– 2-ç»´ meshï¼špp=4, tp=2    mesh = init_device_mesh(&quot;cuda&quot;, mesh_shape=(4, 2), mesh_dim_names=(&quot;pp&quot;, &quot;tp&quot;))        # âœ… rank å’Œåæ ‡    gr = mesh.get_rank()            # å…¨å±€ rank    coord = mesh.get_coordinate()   # [pp_idx, tp_idx]    local_pp = mesh.get_local_rank(&quot;pp&quot;)    local_tp = mesh.get_local_rank(&quot;tp&quot;)        # â¬‡ï¸ mesh åŸºæœ¬ç»“æ„    total = mesh.size()    pp_size, tp_size = mesh.size(&quot;pp&quot;), mesh.size(&quot;tp&quot;)    ndim = mesh.ndim    shape = mesh.shape        # â¬‡ï¸ è·å–é€šä¿¡ç»„    pp_group = mesh.get_group(&quot;pp&quot;)    tp_group = mesh.get_group(&quot;tp&quot;)    all_groups = mesh.get_all_groups()        # â¬‡ï¸ åˆ‡ç‰‡å‡ºå­ mesh    tp_mesh = mesh[&quot;tp&quot;]    pp_mesh = mesh[&quot;pp&quot;]        # â¬‡ï¸ è¾“å‡ºç»“æœ    print(f&quot;rank=&#123;gr&#125;, coord=&#123;coord&#125;, local_pp=&#123;local_pp&#125;, local_tp=&#123;local_tp&#125;&quot;)    print(f&quot;ndim=&#123;ndim&#125;, shape=&#123;shape&#125;, total=&#123;total&#125;, pp=&#123;pp_size&#125;, tp=&#123;tp_size&#125;&quot;)    print(&quot;pp_group ranks:&quot;, dist.get_process_group_ranks(pp_group))    print(&quot;tp_group ranks:&quot;, dist.get_process_group_ranks(tp_group))    print(&quot;all_groups sizes:&quot;, [len(dist.get_process_group_ranks(g)) for g in all_groups])    print(&quot;tp_mesh ndim, shape:&quot;, tp_mesh.ndim, tp_mesh.shape)    print(&quot;pp_mesh ndim, shape:&quot;, pp_mesh.ndim, pp_mesh.shape)if __name__ == &quot;__main__&quot;:    run_device_mesh_demo()\nğŸ’¬ é¢„æœŸè¾“å‡ºï¼ˆä¾‹å¦‚ rank = 5ï¼‰ï¼š\nrank=5, coord=[2,1], local_pp=2, local_tp=1 ndim=2, shape=(4,2), total=8, pp=4, tp=2 pp_group ranks: [4,5,6,7] tp_group ranks: [5,7] all_groups sizes: [4,2] tp_mesh ndim, shape: 1 (2,) pp_mesh ndim, shape: 1 (4,)\nè¯´æ˜ï¼š - rank=5 ä½äº pipeline æ®µ 2ï¼Œtp å†…ç¼–å· 1ï¼› - pp_group åŒ…å«ä¸å…¶åŒ segment çš„ 4 å¼ å¡ï¼› - tp_group åŒ…å«åŒ segment tp ç»´åº¦çš„ä¸¤å¼ å¡ï¼› - åˆ‡ç‰‡å tp_meshã€pp_mesh æˆä¸º 1 ç»´ç»“æ„ï¼Œç”¨äºåç»­ parallelizationã€‚\n\nğŸ‘ æ€»ç»“\n\nDeviceMesh æ„å»ºè‡ªèº«é€šè¿‡ init_device_mesh() å®Œæˆåˆå§‹åŒ–ä¸å­ç»„æ‹†åˆ†ï¼›\næ¥å£å†…éƒ¨å®ç°é€»è¾‘ä¸ Group ç®¡ç†æœºåˆ¶æ¸…æ™°ã€é«˜æ•ˆï¼›\n__getitem__ä¸ºå¤šç»´å¹¶è¡Œä¸‹å­ Mesh åˆ‡ç‰‡å…³é”®å·¥å…·ï¼Œå¯¹é›†æˆ parallel APIs è‡³å…³é‡è¦ï¼›\né€šè¿‡è¯¥æœºåˆ¶ï¼Œå¯ä»¥ç®€å•åœ°ç»„ç»‡å¤æ‚çš„ hybrid-parallel pipelinesï¼ŒåŒæ—¶å……åˆ†å¤ç”¨ communicator èµ„æºå¹¶ç®€åŒ–å¼€å‘æµç¨‹ã€‚\n\n","categories":["åˆ†å¸ƒå¼åŸºç¡€"],"tags":["devicemesh"]},{"title":"pytorch send and recv","url":"/2025/06/14/distribute/send_recv/","content":"\n\n1. åŸºæœ¬æ¦‚å¿µä¸è¿›ç¨‹ç»„\n2. åŸºæœ¬å¼ é‡é€šä¿¡\n3. å¯¹è±¡åˆ—è¡¨é€šä¿¡\n4. æ˜“é”™ç‚¹ä¸å¸¸è§é—®é¢˜\n5. æ‰¹é‡ç‚¹å¯¹ç‚¹é€šä¿¡æ¥å£\n6. æ€»ç»“è¡¥å……\n7. å‚è€ƒèµ„æ–™\n\n\n1. åŸºæœ¬æ¦‚å¿µä¸è¿›ç¨‹ç»„\n\ngroupï¼ˆé€šä¿¡ç»„ï¼‰ï¼šåˆ†å¸ƒå¼é€šä¿¡æ—¶çš„ã€Œå­é›†ã€ï¼Œå…è®¸åªåœ¨ä¸€éƒ¨åˆ† rank ä¹‹é—´é€šä¿¡ã€‚\nglobal rankï¼šå…¨å±€è¿›ç¨‹ç¼–å·ï¼ˆè¿›ç¨‹å¯åŠ¨æ—¶åˆ†é…çš„ç¼–å·ï¼‰ã€‚\ngroup rankï¼šç»„å†…è¿›ç¨‹ç¼–å·ï¼Œç»„å†…ç¬¬å‡ ä¸ªè¿›ç¨‹ï¼ˆä¸ global rank æ— å¿…ç„¶å¯¹åº”å…³ç³»ï¼‰ã€‚\nsrc/dstï¼šé€šä¿¡ç›®æ ‡ï¼ˆæº/ç›®çš„ï¼‰rankï¼Œæ³¨æ„ï¼šå¦‚æœæŒ‡å®š groupï¼Œè¿™é‡Œæ˜¯ç»„å†…ç¼–å·ï¼Œä¸æ˜¯å…¨å±€ç¼–å·ã€‚\n\nè¿›ç¨‹ç»„ä¸¾ä¾‹\nå‡å¦‚ group = [2, 4, 6, 8, 10]ï¼š\n\n\n\ngroup_rank\nglobal_rank\n\n\n\n\n0\n2\n\n\n1\n4\n\n\n2\n6\n\n\n3\n8\n\n\n4\n10\n\n\n\n\n2. åŸºæœ¬å¼ é‡é€šä¿¡\n2.1 send / recv / isend / irecv\nå‚æ•°è¯´æ˜\n\nsend(tensor, dst, group=None, tag=0) å‘é€ tensor åˆ°ç»„å†… rank=dst çš„è¿›ç¨‹ã€‚\nrecv(tensor, src, group=None, tag=0) ä»ç»„å†… rank=src çš„è¿›ç¨‹æ¥æ”¶ tensorã€‚\nisend/irecv å¼‚æ­¥ç‰ˆæœ¬ï¼Œè¿”å› Work å¥æŸ„ï¼Œéœ€è¦ work.wait()ã€‚\n\ntag\n\ntag æ˜¯æ¶ˆæ¯ç¼–å·/æ ‡ç­¾ï¼Œç”¨äºåŒºåˆ†å¤šæ¡å¹¶å‘æ¶ˆæ¯ï¼Œåªæœ‰ tag ä¸€è‡´æ‰èƒ½æ­£ç¡®é…å¯¹ã€‚\n\ngroup_dst/group_src\n\nä¸€èˆ¬ä¸ç”¨æ‰‹åŠ¨ä¼ ï¼Œæ¡†æ¶ä¼šæ ¹æ® dst/src å’Œ group è‡ªåŠ¨æ¨ç®—ã€‚\n\n\n2.2 é€šä¿¡æµç¨‹ç¤ºæ„å›¾\nä»¥ group = [2, 4, 6, 8, 10]ï¼Œè®© rank=2 å‘ï¼Œrank=10 æ”¶ä¸ºä¾‹ï¼š\ngraph TD    subgraph group [group: [2, 4, 6, 8, 10]]        A[&quot;global_rank=2&lt;br&gt;group_rank=0&quot;]        B[&quot;global_rank=10&lt;br&gt;group_rank=4&quot;]    end    A -- send(tensor, dst=4, group=group) --&gt; B    B -- recv(tensor, src=0, group=group) --&gt; A\n\nå‘é€ç«¯ï¼ˆglobal_rank=2ï¼Œgroup_rank=0ï¼‰ï¼šsend(tensor, dst=4, group=group)\næ¥æ”¶ç«¯ï¼ˆglobal_rank=10ï¼Œgroup_rank=4ï¼‰ï¼šrecv(tensor, src=0, group=group)\n\n\n2.3 ä»£ç å®ä¾‹\n# å‘é€ç«¯ï¼ˆglobal_rank=2ï¼‰group = dist.new_group([2, 4, 6, 8, 10])tensor = torch.tensor([123])dist.send(tensor, dst=4, group=group)   # dst=4 æ˜¯ group å†… rank=4 â†’ global_rank=10# æ¥æ”¶ç«¯ï¼ˆglobal_rank=10ï¼‰group = dist.new_group([2, 4, 6, 8, 10])tensor = torch.zeros(1, dtype=torch.int)dist.recv(tensor, src=0, group=group)   # src=0 æ˜¯ group å†… rank=0 â†’ global_rank=2print(tensor)\n\nâš ï¸ åªè¦ç”¨äº† groupï¼Œsrc/dst éƒ½æ˜¯ç»„å†… rankï¼Œä¸æ˜¯ global rankï¼\n\n\n2.4 å¼‚æ­¥é€šä¿¡ï¼ˆisend/irecvï¼‰\nwork = dist.isend(tensor, dst=4, group=group)work.wait()  # ç­‰å¾…å‘é€å®Œæˆ\nå¼‚æ­¥ recv åŒç†ã€‚\n\n3. å¯¹è±¡åˆ—è¡¨é€šä¿¡\n3.1 send_object_list / recv_object_list ç”¨æ³•\n\nç”¨äºå‘é€/æ¥æ”¶åŒ…å«ä»»æ„ Python å¯¹è±¡çš„ listï¼Œåº•å±‚é€šè¿‡åºåˆ—åŒ–å®ç°ã€‚\nå‘é€è¿‡ç¨‹æ‹†ä¸ºä¸¤æ­¥ï¼šå…ˆå‘æ¯ä¸ªå¯¹è±¡åºåˆ—åŒ–åçš„ sizeï¼Œå†å‘æ‰€æœ‰å†…å®¹æ‹¼æ¥åçš„ tensorã€‚\n\n\n3.2 å¯¹è±¡é€šä¿¡æµç¨‹å›¾\nsequenceDiagram    participant Sender    participant Receiver    Sender-&gt;&gt;Receiver: send(object_sizes_tensor)    Sender-&gt;&gt;Receiver: send(object_tensor)    Receiver-&gt;&gt;Receiver: 1. è¯»å– object_sizes_tensor    Receiver-&gt;&gt;Receiver: 2. æŒ‰ size æ‹† object_tensor    Receiver-&gt;&gt;Receiver: 3. ååºåˆ—åŒ–ä¸ºå¯¹è±¡\n\n3.3 å…¸å‹ä»£ç ç¤ºä¾‹\nå‘é€ç«¯\nobject_list = [&quot;hello&quot;, 123, [1, 2, 3]]dist.send_object_list(object_list, dst=4, group=group)\næ¥æ”¶ç«¯\nrecv_list = [None, None, None]dist.recv_object_list(recv_list, src=0, group=group)print(recv_list)  # [&#x27;hello&#x27;, 123, [1, 2, 3]]\n\n3.4 æ¥å£å®ç°æ ¸å¿ƒä»£ç \n# æ¥æ”¶ç«¯åˆ†å‰²ååºåˆ—åŒ–offset = 0for i, obj_size in enumerate(object_sizes_tensor):    obj_view = object_tensor[offset : offset + obj_size]    object_list[i] = _tensor_to_object(obj_view, obj_size, group)    offset += obj_size\n\nobject_sizes_tensor è®°å½•æ¯ä¸ªå¯¹è±¡çš„åºåˆ—åŒ–é•¿åº¦\nobject_tensor æ˜¯æ‰€æœ‰å†…å®¹æ‹¼èµ·æ¥çš„ä¸€ç»´ tensor\næŒ‰é¡ºåºåˆ‡ç‰‡å’Œååºåˆ—åŒ–ï¼Œå¡«å› object_list\n\n\n3.5 å…³äº rank_objects\n\nrank_objects æ˜¯ recv çš„è¿”å›å€¼ï¼Œè¡¨ç¤ºæ¶ˆæ¯æ¥è‡ªå“ªä¸ª rankï¼ˆä¸€èˆ¬ç­‰äº srcï¼‰\nåœ¨å¤šå¯¹å¤šé€šä¿¡æˆ– src=ANY_SOURCE æ—¶ç”¨æ¥ç¡®è®¤æ¶ˆæ¯æ¥æºï¼Œå’Œå®é™…å¯¹è±¡å†…å®¹è¿˜åŸæ— å…³\n\n\n4. æ˜“é”™ç‚¹ä¸å¸¸è§é—®é¢˜\n\nåªè¦ç”¨äº† groupï¼Œsrc/dst éƒ½æ˜¯ç»„å†… rankï¼Œä¸æ˜¯ global rankã€‚\ntag ç”¨äºåŒºåˆ†å¤šæ¡æ¶ˆæ¯ï¼Œå¿…é¡» send å’Œ recv ä¸€è‡´ã€‚\nsend_object_list/recv_object_list å¿…é¡» object_list é•¿åº¦ã€é¡ºåºä¸€è‡´ã€‚\ngroup_src/group_dst æ­£å¸¸ä¸šåŠ¡ä¸éœ€è¦è‡ªå·±ä¼ ã€‚\n\n4.1. groupã€src/dstã€group_src/group_dst å‚æ•°å…³ç³»\n\ngroup å†³å®šé€šä¿¡å­é›†ï¼Œsrc/dst å†³å®šæ”¶å‘ç›®æ ‡ç¼–å·ã€‚\nå¦‚æœæŒ‡å®š groupï¼Œåˆ™ src/dst ä¸ºç»„å†… rankï¼Œä¸æ˜¯ global rankã€‚\ngroup_src/group_dst ä¸€èˆ¬ä¸ç”¨æ‰‹åŠ¨ä¼ ï¼Œæ¡†æ¶è‡ªåŠ¨æ¨ç®—ã€‚\næ˜ å°„å…³ç³»ï¼š\n\nå…¨å±€è½¬ç»„å†…ï¼šgroup_ranks.index(global_rank)\nç»„å†…è½¬å…¨å±€ï¼šgroup_ranks[group_rank]\n\n\n\n5. æ‰¹é‡ç‚¹å¯¹ç‚¹é€šä¿¡æ¥å£\n5.1 æ¥å£ç®€ä»‹\ntorch.distributed.batch_isend_irecv æ”¯æŒåŒæ—¶å‘èµ·å¤šç»„å¼‚æ­¥ç‚¹å¯¹ç‚¹é€šä¿¡æ“ä½œï¼ˆisend/irecvï¼‰ï¼Œæ˜¾è‘—æé«˜å¤§æ‰¹é‡æ•°æ®åˆ†å‘/æ”¶é›†çš„æ•ˆç‡ã€‚ åº•å±‚æ”¯æŒ NCCLã€Glooã€UCC ç­‰åˆ†å¸ƒå¼åç«¯ï¼Œå¸¸ç”¨äºåˆ†å¸ƒå¼æ·±åº¦å­¦ä¹ çš„ pipeline/é€šä¿¡ pattern ä¼˜åŒ–ã€‚\nå‡½æ•°ç­¾å\ntorch.distributed.batch_isend_irecv(p2p_op_list: list[P2POp]) -&gt; list[Work]\n\np2p_op_listï¼šä¸€ç»„ torch.distributed.P2POp å®ä¾‹ï¼Œæ¯ä¸ªå®ä¾‹æè¿°ä¸€æ¬¡ isend/irecvã€‚\nè¿”å›ï¼šæ‰€æœ‰æ“ä½œçš„ request å¥æŸ„ï¼ˆWork å¯¹è±¡ï¼‰åˆ—è¡¨ï¼Œå¯é€šè¿‡ .wait() åŒæ­¥ã€‚\n\n\n5.2 å…¸å‹ä½¿ç”¨åœºæ™¯\n\nå¤§æ‰¹é‡ç‚¹å¯¹ç‚¹é€šä¿¡ï¼Œä¾‹å¦‚ pipeline å¹¶è¡Œã€ç¯å½¢ allreduce æ‰‹å†™ä¼˜åŒ–ç­‰åœºæ™¯ã€‚\næ”¯æŒ isend/irecv æ··åˆï¼Œèƒ½æ‰¹é‡æå‡ååé‡ã€‚\n\n\n5.3 è°ƒç”¨æµç¨‹ä¸å‚æ•°è¯´æ˜\nP2POp ç”¨æ³•\næ¯ä¸ª P2POp å®šä¹‰ä¸€æ¬¡é€šä¿¡æ“ä½œï¼Œå¦‚ä¸‹ï¼š\nP2POp(op, tensor, peer, group=None, tag=0)\n\nopï¼šæ“ä½œç±»å‹ï¼ˆdist.isend æˆ– dist.irecvï¼‰\ntensorï¼šè¦å‘é€/æ¥æ”¶çš„ tensor\npeerï¼šç›®æ ‡ peer çš„ç¼–å·ï¼ˆç»„å†… rankï¼‰\ngroupï¼ˆå¯é€‰ï¼‰ï¼šé€šä¿¡ç»„ï¼ˆé»˜è®¤ä¸º worldï¼‰\ntagï¼ˆå¯é€‰ï¼‰ï¼šæ¶ˆæ¯ç¼–å·/æ ‡ç­¾\n\n\n5.4 ä»£ç å®ä¾‹\nå‡è®¾ world_size=2ï¼Œrank 0 å’Œ rank 1 åšä¸€ä¸ªç¯å½¢é€šä¿¡ï¼š\nimport torchimport torch.distributed as distrank = dist.get_rank()world_size = dist.get_world_size()send_tensor = torch.arange(2, dtype=torch.float32) + 2 * rankrecv_tensor = torch.zeros(2, dtype=torch.float32)send_op = dist.P2POp(dist.isend, send_tensor, (rank + 1) % world_size)recv_op = dist.P2POp(dist.irecv, recv_tensor, (rank - 1 + world_size) % world_size)reqs = dist.batch_isend_irecv([send_op, recv_op])for req in reqs:    req.wait()print(f&quot;Rank &#123;rank&#125; æ”¶åˆ°: &#123;recv_tensor&#125;&quot;)\nè¿è¡Œç»“æœï¼š\nRank 0 æ”¶åˆ°: tensor([2., 3.])Rank 1 æ”¶åˆ°: tensor([0., 1.])\n\n5.5 é€šä¿¡æµç¨‹å›¾\nsequenceDiagram    participant Rank0    participant Rank1    Rank0-&gt;&gt;Rank1: isend(send_tensor, dst=1)    Rank1-&gt;&gt;Rank0: isend(send_tensor, dst=0)    Rank0-&gt;&gt;Rank0: irecv(recv_tensor, src=1)    Rank1-&gt;&gt;Rank1: irecv(recv_tensor, src=0)    Note over Rank0,Rank1: batch_isend_irecv([send_op, recv_op])&lt;br&gt;å¹¶å‘å‘èµ·é€šä¿¡å¹¶ç­‰å¾…å®Œæˆ\n\n5.6 é‡è¦æ³¨æ„äº‹é¡¹\n\næ³¨æ„\n\nå¦‚æœä½¿ç”¨ NCCL åç«¯ï¼Œå¿…é¡»æå‰ç”¨ torch.cuda.set_device è®¾ç½®å¥½å½“å‰ GPUï¼\nå¦‚æœè¿™æ˜¯æŸä¸ª group çš„ç¬¬ä¸€æ¬¡é€šä¿¡ï¼Œgroup é‡Œçš„æ‰€æœ‰ rank å¿…é¡»éƒ½è°ƒç”¨ batch_isend_irecvï¼Œå¦åˆ™è¡Œä¸ºæœªå®šä¹‰ã€‚\nä»¥ååªè¦ä¸æ˜¯ç¬¬ä¸€æ¬¡ collectiveï¼Œå…è®¸åªç”¨éƒ¨åˆ† rank å‚ä¸ã€‚\n\n\n\n5.7 æºç å®ç°è¦ç‚¹\n\nè‡ªåŠ¨åˆ¤æ–­é€šä¿¡åç«¯æ˜¯å¦æ”¯æŒæ“ä½œåˆå¹¶ï¼ˆcoalescingï¼‰ï¼Œå¦‚ NCCL ä¼šåœ¨åŒä¸€ä¸ªä¸Šä¸‹æ–‡ä¸‹æ‰¹é‡å¯åŠ¨ï¼Œæå‡æ€§èƒ½ã€‚\nè¿”å›æ‰€æœ‰ requestï¼ˆWorkï¼‰å¯¹è±¡ï¼Œç”¨æˆ·å¯ wait()ã€‚\n\n\n5.8 API æ–‡æ¡£é“¾æ¥\n\nPyTorch å®˜æ–¹ batch_isend_irecv æ–‡æ¡£\nP2POp å®˜æ–¹è¯´æ˜\n\n\n6. æ€»ç»“è¡¥å……\n\nå¼ é‡ç‚¹å¯¹ç‚¹é€šä¿¡ï¼šsend/recv/isend/irecv/batch_isend_irecv\nå¯¹è±¡é€šä¿¡ï¼šsend_object_list/recv_object_list\næ‰¹é‡ç‚¹å¯¹ç‚¹é€šä¿¡èƒ½æå¤§æå‡ pipeline é€šä¿¡æ•ˆç‡\nç»Ÿä¸€è¿”å› Work å¥æŸ„ï¼Œæ”¯æŒåŒæ­¥æˆ–å¼‚æ­¥\ngroup/src/dst ä½¿ç”¨æ–¹å¼åŒä¸Šæ–‡æè¿°\n\n\n7. å‚è€ƒèµ„æ–™\n\nPyTorch Distributed å®˜æ–¹æ–‡æ¡£\nPyTorch distributed_c10d.py æºç \nMermaid Live Editor\n\n\n","categories":["åˆ†å¸ƒå¼åŸºç¡€"],"tags":["send recv"]},{"title":"pytorch Shard","url":"/2025/06/20/distribute/shard/","content":"\n\n1. _split_tensoråˆ†æ\n1.1 ä»£ç å®ç°æµç¨‹å›¾ï¼ˆMermaidï¼‰\nflowchart TD  A[&quot;è¾“å…¥ï¼štensor, num_chunks, with_padding, contiguous&quot;] --&gt; B&#123;&quot;dim â‰¤ tensor.ndim?&quot;&#125;  B -- å¦ --&gt; E[&quot;AssertionError æŠ›å‡º&quot;]  B -- æ˜¯ --&gt; C[&quot;è°ƒç”¨ torch.chunk æ²¿ dim åˆ†å—&quot;]  C --&gt; D[&quot;tensor_list, è®¡ç®— num_empty_tensors = num_chunks - len(tensor_list)&quot;]  D --&gt; F&#123;&quot;æ— éœ€ padding æˆ– å‡åŒ€å¯åˆ†?&quot;&#125;  F -- æ˜¯ --&gt; G[&quot;(å¯é€‰) å¯¹æ¯å—è°ƒç”¨ .contiguous()&quot;]  G --&gt; H[&quot;è°ƒç”¨ fill_empty_tensor_to_shards è¡¥ç©º shard&quot;]  H --&gt; I[&quot;è¿”å› shards åˆ—è¡¨ å’Œ ç©º pad_sizes []&quot;]  F -- å¦ --&gt; J[&quot;è®¡ç®— full_chunk_size = ceil(dim_size / num_chunks)&quot;]  J --&gt; K[&quot;æ”¶é›†åŸå§‹ chunk_sizes&quot;]  K --&gt; L[&quot;pad_sizes = full_chunk_size - chunk_size&quot;]  L --&gt; M[&quot;è°ƒç”¨ fill_empty_tensor_to_shards è¡¥ç©º shard&quot;]  M --&gt; N[&quot;å¯¹æ¯ä¸ª shardï¼šè‹¥ pad_size &gt; 0ï¼Œåˆ™ pad_tensor(shard, dim, pad_size)&quot;]  N --&gt; O[&quot;(å¯é€‰) shard.contiguous()&quot;]  O --&gt; P[&quot;æ”¶é›† shard_list å’Œ pad_sizes&quot;]  P --&gt; Q[&quot;è¿”å› shard_list å’Œ pad_sizes&quot;]\n\n1.2 å…³é”®ç‚¹è¯¦è§£\nğŸ§  ä¸ºä»€ä¹ˆè¦ Paddingï¼Ÿ\nç”¨äºä¿è¯åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸­ï¼ˆæ¯”å¦‚ scatterã€all_gather ç­‰ collective æ“ä½œï¼‰æ¯ä¸ª rank çš„ shard å¤§å°ä¸€è‡´ï¼Œé¿å…å› ä¸ºå°ºå¯¸ä¸å¯¹é½å¯¼è‡´é€šä¿¡å¤±è´¥ã€‚åªæœ‰ tensor.size(dim) % num_chunks â‰  0 ä¸” with_padding=True æ—¶ï¼Œæ‰ä¼šè¿›è¡Œ paddingã€‚\nğŸ§© fill_empty_tensor_to_shards\ntorch.chunk åœ¨å°ºå¯¸è¾ƒå°æˆ– num_chunks æ›´å¤§æ—¶ä¸ä¼šè¾“å‡ºç©º tensorã€‚è¯¥å‡½æ•°ç”¨äºè¡¥å…¨ï¼šåœ¨ tensor_list å°‘äº num_chunks æ—¶ï¼Œè¡¥å……å½¢çŠ¶åˆæ³•ä½† dim ä¸Šä¸º 0 çš„ç©º tensorï¼Œä½¿ shard æ•°ç›®ä¸€è‡´ï¼Œä¾¿äºåç»­ç»Ÿä¸€å¤„ç†ã€‚\nğŸ§¼ pad_tensor\nè‹¥å½“å‰ shard å°äº full_chunk_sizeï¼Œåˆ™åœ¨æŒ‡å®šç»´åº¦æœ«å°¾è¡¥é›¶ï¼Œç¡®ä¿æ‰€æœ‰ shard çš„å½¢çŠ¶ä¸€è‡´ã€‚\nğŸ§± contiguous\nä¸ºæå‡å†…å­˜è¿è´¯æ€§å’Œé€šä¿¡æ•ˆç‡ï¼Œå¯è°ƒç”¨ .contiguous() é‡æ’å†…å­˜å¸ƒå±€ã€‚\n\n1.3 å®é™…è°ƒç”¨ç¤ºä¾‹ï¼ˆéœ€ Paddingï¼‰\nä»¥ä¸‹ä¸ºæ— æ³•å‡åŒ€åˆ†ç‰‡ï¼Œå›  num_chunks=4 è€Œè§¦å‘ pad çš„åœºæ™¯ï¼š\nimport torchfrom torch.distributed.tensor.placement_types import Shard# æ„é€ å¼ é‡tensor = torch.arange(1, 13).reshape(2, 6)  # shape [2, 6]# åœ¨ dim=1 ä¸Šæ‹†ä¸º 4 ä»½ï¼Œä¸æ•´é™¤å°†è§¦å‘ paddingsharder = Shard(dim=1)shards, pad_sizes = sharder._split_tensor(tensor, num_chunks=4, with_padding=True)print(&quot;Pad sizes:&quot;, pad_sizes)for i, (sh, pad) in enumerate(zip(shards, pad_sizes)):    print(f&quot;Shard &#123;i&#125; shape: &#123;tuple(sh.shape)&#125;, pad: &#123;pad&#125;&quot;)    print(sh)\nâœ… é¢„æœŸç»“æœ\n\ntensor.size(1)=6, num_chunks=4 â‡’ full_chunk_size = ceil(6/4) = 2\ntorch.chunk ä¼šå‡º 4 å—ï¼Œä½†æœ€åä¸€ä¸¤å—å¯èƒ½ä¸º empty\npad_sizes å¯èƒ½ä¸º [0, 0, 0, 2]\næœ€ç»ˆæ¯å—å¤§å°éƒ½æ˜¯ [2] (dim=1)ï¼Œpadding è¡¥é½\n\nPad sizes: [0, 0, 0, 2]Shard 0 shape: (2, 2), pad: 0tensor([[1, 2],        [7, 8]])Shard 1 shape: (2, 2), pad: 0tensor([[ 3,  4],        [ 9, 10]])Shard 2 shape: (2, 2), pad: 0tensor([[ 5,  6],        [11, 12]])Shard 3 shape: (2, 2), pad: 2tensor([[0, 0],        [0, 0]])\n\n1.4 æ€»ç»“\n\n_split_tensor çš„ä½œç”¨æ˜¯å°†ä¸€ä¸ª Tensor æ²¿æŒ‡å®šç»´åº¦åˆ‡åˆ†ä¸ºå›ºå®šä»½æ•°ï¼Œå¹¶åœ¨ ä¸èƒ½æ•´é™¤æ—¶è‡ªåŠ¨è¡¥é½ã€‚\nå®ƒä¿éšœäº†å„ shard åœ¨é€šä¿¡é˜¶æ®µå°ºå¯¸ä¸€è‡´ï¼Œé€‚ç”¨äºåˆ†å¸ƒå¼å¼ é‡å¹¶è¡Œåœºæ™¯ã€‚\nå®é™…ä»£ç é€šè¿‡ torch.chunkã€fill_empty_tensor_to_shardsã€pad_tensor ç­‰æ‰‹æ®µï¼Œè½»æ¾å®ç°è¿™ä¸€ç›®æ ‡ã€‚\n\n\n","categories":["åˆ†å¸ƒå¼åŸºç¡€"],"tags":["shard"]},{"title":"pytorchä¸­çš„streamå’Œevent","url":"/2025/09/07/distribute/stream_event/","content":"\n\n\nä¸€å¥è¯æ€»è§ˆï¼šæµï¼ˆstreamï¼‰æ˜¯ GPU ä¸Šçš„â€œæœ‰åºæŒ‡ä»¤é˜Ÿåˆ—â€ï¼Œäº‹ä»¶ï¼ˆeventï¼‰æ˜¯æ’åœ¨æµæ—¶é—´çº¿ä¸Šçš„â€œæ …æ /æ—¶é—´æˆ³â€ã€‚æŠŠ event.record() æ”¾åœ¨ç”Ÿäº§æµä¸Šï¼Œå†åœ¨æ¶ˆè´¹æµé‡Œ wait_event()ï¼Œå°±èƒ½åšåˆ°è®¾å¤‡ä¾§çš„æ— é˜»å¡ä¾èµ–ç¼–æ’ã€‚(docs.pytorch.org)\n\n\n1. åŸºæœ¬æ¦‚å¿µ\n\nStreamï¼ˆæµï¼‰ï¼šåŒä¸€æ¡æµå†…æŒ‰æäº¤é¡ºåºï¼ˆFIFOï¼‰æ‰§è¡Œï¼›ä¸åŒæµå½¼æ­¤ç‹¬ç«‹ï¼Œå¯å¹¶è¡Œè¿è¡Œã€‚PyTorch çš„ torch.cuda.Stream å°±æ˜¯ CUDA æµçš„å°è£…ï¼Œå¹¶æä¾› record_event / wait_event / wait_stream / synchronize ç­‰æ–¹æ³•ã€‚(docs.pytorch.org)\nEventï¼ˆäº‹ä»¶ï¼‰ï¼šåŒæ­¥æ ‡è®°ã€‚å¯ç”¨äºæµ‹æ—¶ä¸è·¨æµåŒæ­¥ï¼šåœ¨ç”Ÿäº§æµ record()ï¼Œåœ¨æ¶ˆè´¹æµ wait()/wait_event()ã€‚äº‹ä»¶ä¹Ÿå¯ elapsed_time() è¯»å–GPU ç«¯çš„æ¯«ç§’è®¡æ—¶ã€‚(docs.pytorch.org)\né»˜è®¤æµè¯­ä¹‰ï¼š\n\nLegacy default stream ä¼šä¸å…¶å®ƒï¼ˆé˜»å¡å‹ï¼‰æµäº’ç›¸åŒæ­¥ï¼›\nPer-thread default streamï¼ˆPTDSï¼‰ ä¸ä¸å…¶ä»–æµåŒæ­¥ï¼Œè¡Œä¸ºæ›´åƒæ˜¾å¼åˆ›å»ºçš„æµã€‚ ä¸¤è€…å¯åœ¨ç¼–è¯‘/å®å±‚é¢é€‰æ‹©ï¼Œè¡Œä¸ºä¸åŒä¼šå½±å“æ˜¯å¦â€œè‡ªåŠ¨åŒæ­¥â€ã€‚(NVIDIA Docs)\n\n\n\n2. ä¸‰ç§â€œç­‰å¾…â€çš„ä½œç”¨åŸŸï¼ˆè¶Šå°è¶Šå¥½ï¼‰\n\nè®¾å¤‡çº§ï¼štorch.cuda.synchronize(device) â€”â€” ç­‰è¯¥è®¾å¤‡ä¸Šæ‰€æœ‰æµåˆ°å½“å‰ä¸ºæ­¢çš„å·¥ä½œå®Œæˆã€‚æœ€é‡ï¼Œä¸€èˆ¬å°‘ç”¨ã€‚ï¼ˆè¯­ä¹‰ç­‰åŒ cudaDeviceSynchronizeï¼‰(developer.download.nvidia.com)\nå•æµçº§ï¼šstream.synchronize() â€”â€” åªç­‰è¿™ä¸€æ¡æµå·²æäº¤çš„å·¥ä½œï¼Œç­‰åŒ cudaStreamSynchronizeã€‚(docs.pytorch.org)\näº‹ä»¶çº§ï¼ševent.synchronize() â€”â€” åªç­‰è¯¥äº‹ä»¶æ‰€æ•è·çš„å·¥ä½œï¼Œç­‰åŒ cudaEventSynchronizeã€‚ç²’åº¦æœ€ç»†ï¼Œæ¨èä¼˜å…ˆç”¨äº‹ä»¶æ¥è¡¨è¾¾ä¾èµ–ã€‚(docs.pytorch.org)\n\n\nå£è¯€ï¼šdevice &gt; stream &gt; eventï¼ˆç­‰å¾…èŒƒå›´ä»å¤§åˆ°å°ï¼‰ã€‚é€‰æœ€å°å¿…è¦èŒƒå›´ï¼Œä¿ç•™å¹¶è¡Œåº¦ã€‚(developer.download.nvidia.com)\n\n\n3. è·¨æµåŒæ­¥çš„ä¸‰ç§æ–¹å¼\n\näº‹ä»¶æ …æ ï¼ˆæ¨èï¼‰\n\nç”Ÿäº§æµï¼ševent.record()\næ¶ˆè´¹æµï¼šconsumer.wait_event(event)ï¼ˆæˆ– event.wait(consumer)ï¼‰ è¯¥è°ƒç”¨ç«‹å³è¿”å›ï¼Œåªæ˜¯æŠŠâ€œç­‰å¾… eâ€è¿™æ¡ä¾èµ–å†™è¿›äº†æ¶ˆè´¹æµçš„é˜Ÿåˆ—ï¼›åç»­æäº¤çš„å·¥ä½œéƒ½ä¼šåœ¨ e å®Œæˆåæ‰§è¡Œã€‚(docs.pytorch.org)\n\næµ-æµç­‰å¾…\n\nthis.wait_stream(that)ï¼šè®© this æµåç»­å·¥ä½œï¼Œç­‰å¾… that æµå½“å‰å·²æäº¤çš„å·¥ä½œå®Œæˆã€‚(docs.pytorch.org)\n\né»˜è®¤æµè¯­ä¹‰ï¼ˆå†å²å…¼å®¹ï¼‰\n\nè‹¥ä½¿ç”¨ legacy default streamï¼Œå®ƒä¼šä¸å…¶å®ƒé˜»å¡æµäº’ç›¸åŒæ­¥ï¼›PTDS åˆ™ä¸ä¼šã€‚æ–°ä»£ç ä¸å»ºè®®ä¾èµ–è¿™ç§â€œéšå¼åŒæ­¥â€ã€‚(NVIDIA Docs)\n\n\n\n4. å¼ é‡ç”Ÿå‘½å‘¨æœŸçš„å®‰å…¨ï¼ˆsafeï¼‰ç”¨æ³•\nè·¨æµå…±äº«åŒä¸€å—æ˜¾å­˜æ—¶ï¼Œé™¤äº†â€œå†™æ¸…æ¥šä¾èµ–â€ï¼ˆäº‹ä»¶/æµç­‰å¾…ï¼‰ï¼Œè¿˜åº”åœ¨ä½¿ç”¨è¯¥å¼ é‡çš„æµä¸Šè°ƒç”¨ï¼š\ntensor.record_stream(consumer_stream)\nè¿™ä¼šå‘Šè¯‰ CUDA ç¼“å­˜åˆ†é…å™¨ï¼šè¯¥å¼ é‡ä¹Ÿåœ¨ consumer_stream ä¸Šè¢«ç”¨è¿‡ï¼Œä»è€Œé¿å…åœ¨ç”Ÿäº§æµé‡Šæ”¾åè¢«è¿‡æ—©å¤ç”¨ï¼Œé€ æˆæ½œåœ¨è¯»å†™ç«æ€ã€‚å¦åˆ™éœ€è¦åœ¨é‡Šæ”¾å‰æŠŠä½¿ç”¨åŒæ­¥å›åˆ›å»ºæµã€‚(docs.pytorch.org)\n\n5. CPUâ†”GPU æ‹·è´ä¸ non_blocking / pinned memory\n\nåªæœ‰å½“é¡µé”å®šå†…å­˜ï¼ˆpinnedï¼‰å‚ä¸æ—¶ï¼Œå¾ˆå¤šæ‹·è´æ‰èƒ½çœŸæ­£å¼‚æ­¥åŒ–å¹¶ä¸è®¡ç®—é‡å ï¼›PyTorch æ•™ç¨‹å¯¹ pin_memory() ä¸ non_blocking=True çš„è¡Œä¸ºåšäº†ç³»ç»Ÿè¯´æ˜ã€‚(docs.pytorch.org)\nè¯»å– D2H ç»“æœå‰ï¼Œåº”ç­‰å¾…æ‹·è´å®Œæˆï¼ˆäº‹ä»¶æˆ–åŒæ­¥ï¼‰ï¼Œä¸è¦ç›´æ¥åœ¨ CPU ç«¯æ¶ˆè´¹å¼‚æ­¥ç»“æœã€‚(docs.pytorch.org)\n\næ¨èæ¨¡å¼ï¼ˆD2H æ‹·è´ä¸â€œå¡ä½â€æ•´æœºï¼Œåªåœ¨ç”¨åˆ°ç»“æœæ—¶å°èŒƒå›´ç­‰å¾…ï¼‰ï¼š\nimport torchx  = torch.randn(1_000_000, device=&quot;cuda&quot;)dst = torch.empty_like(x, device=&quot;cpu&quot;, pin_memory=True)  # pinned CPU buffercopy_stream = torch.cuda.Stream()copy_done   = torch.cuda.Event()with torch.cuda.stream(copy_stream):    dst.copy_(x, non_blocking=True)  # å¼‚æ­¥ D2H    copy_done.record()               # ä»…æ‹·è´å®Œæˆå¤„æ‰“ç‚¹# â€¦â€¦CPU å¯ä»¥å…ˆåšåˆ«çš„æ´»â€¦â€¦copy_done.synchronize()              # åªæœ‰åœ¨çœŸæ­£è¦ç”¨ dst æ—¶æ‰ç­‰è¿™ä¸€æ¬¡print(dst[:5])\n\nè¦ç‚¹ï¼špinned + ä¸“ç”¨æ‹·è´æµ + äº‹ä»¶ï¼›é¿å…ç”¨è®¾å¤‡çº§ torch.cuda.synchronize() ç²—æš´â€œåˆ¹è½¦â€ã€‚(docs.pytorch.org, developer.download.nvidia.com)\n\n\n6. å¯è¿è¡Œæœ€å°ç¤ºä¾‹\n6.1 è®¡ç®—æµ â†’ é€šä¿¡/åå¤„ç†æµï¼ˆäº‹ä»¶æ …æ ï¼‰\nimport torchdevice = &quot;cuda&quot;compute = torch.cuda.Stream()comm    = torch.cuda.Stream()done    = torch.cuda.Event()x = torch.randn(1_000_000, device=device)with torch.cuda.stream(compute):    y = x.relu()    done.record()           # è®°å½•â€œy å·²å°±ç»ªâ€comm.wait_event(done)       # è®© comm æµç­‰åˆ° y å°±ç»ªwith torch.cuda.stream(comm):    z = y * 2               # åœ¨ GPU ç«¯è‡ªåŠ¨ç­‰å¾…ï¼Œä¸é˜»å¡ CPUtorch.cuda.synchronize()    # ç¤ºä¾‹æ”¶å°¾ï¼šçœŸå®å·¥ç¨‹é‡Œå¯ç»§ç»­æäº¤åç»­å·¥ä½œ\næœºåˆ¶è¯´æ˜ï¼šwait_event æŠŠâ€œç­‰å¾… eâ€æ’å…¥åˆ°æ¶ˆè´¹æµé˜Ÿåˆ—ï¼Œåªæœ‰äº‹ä»¶è§¦å‘åï¼Œæ¶ˆè´¹æµåç»­ kernel æ‰ä¼šæ‰§è¡Œï¼›è¿™éƒ½æ˜¯è®¾å¤‡ä¾§å®Œæˆï¼ŒCPU ä¸è¢«é˜»å¡ã€‚(docs.pytorch.org)\n6.2 ä¸‰æµç¤ºä¾‹ï¼ˆS2 ä¸ S3 éƒ½ç­‰ S1ï¼‰\ns1, s2, s3 = torch.cuda.Stream(), torch.cuda.Stream(), torch.cuda.Stream()e = torch.cuda.Event()with torch.cuda.stream(s1):    a = torch.randn(1024, 1024, device=&quot;cuda&quot;) @ torch.randn(1024, 1024, device=&quot;cuda&quot;)    e.record()s2.wait_event(e)s3.wait_event(e)with torch.cuda.stream(s2):    b = a.relu_()with torch.cuda.stream(s3):    c = a.sum()\n\nåŒä¸€ä¸ªäº‹ä»¶å¯ä»¥è¢«å¤šæ¡æµç­‰å¾…ï¼Œé€‚åˆâ€œä¸€å¯¹å¤šâ€çš„ä¾èµ–ã€‚(docs.pytorch.org)\n\n6.3 GPU ç«¯ç²¾å‡†è®¡æ—¶ï¼ˆEvent elapsed_timeï¼‰\nimport torchs = torch.cuda.Stream()start = torch.cuda.Event(enable_timing=True)end   = torch.cuda.Event(enable_timing=True)x = torch.randn(4096, 4096, device=&quot;cuda&quot;)w = torch.randn(4096, 4096, device=&quot;cuda&quot;)# é¢„çƒ­for _ in range(2): (x @ w).sum().relu_()with torch.cuda.stream(s):    start.record()    y = (x @ w).relu_()    end.record()end.synchronize()print(f&quot;elapsed = &#123;start.elapsed_time(end):.3f&#125; ms&quot;)\n\nelapsed_time è¿”å› start.record ä¸ end.record ä¹‹é—´çš„ GPU æ¯«ç§’æ•°ï¼›end.synchronize() ç¡®ä¿æµ‹é‡é—­åŒºé—´å·²å®Œæˆã€‚(docs.pytorch.org)\n\n\n7. å¸¸è§å‘ä¸é€Ÿè®°\n\näº‹ä»¶ä½ç½®è¦å¯¹ï¼šrecord() åªè¦†ç›–å®ƒä¹‹å‰å·²å…¥é˜Ÿçš„å·¥ä½œï¼›ä¹‹åæ–°æäº¤çš„å·¥ä½œä¸åŒ…å«åœ¨æœ¬äº‹ä»¶å†…ã€‚ä½¿ç”¨æ—¶å°† record() æ”¾åœ¨ç”Ÿäº§ç»“æŸç‚¹ã€‚(docs.pytorch.org)\nwait_event/wait_stream å‡ä¸ºâ€œå†™ä¾èµ–ã€ç«‹å³è¿”å›â€ï¼šå®ƒä»¬ä¸ä¼šé˜»å¡ CPUï¼Œåªå½±å“åç»­æäº¤åˆ°è¯¥æµçš„å·¥ä½œã€‚(docs.pytorch.org)\né»˜è®¤æµé™·é˜±ï¼šLegacy ä¸ PTDS è¯­ä¹‰ä¸åŒã€‚æ··ç”¨æ—¶ï¼Œlegacy ä¼šä¸é˜»å¡æµäº’ç›¸ç­‰å¾…ï¼›PTDS ä¸ä¼šã€‚æ–°å·¥ç¨‹å»ºè®®æ˜¾å¼å»ºæµ + æ˜¾å¼åŒæ­¥ï¼Œé¿å…è¸©éšå¼åŒæ­¥ã€‚(NVIDIA Docs)\næµä¼˜å…ˆçº§ï¼šä½æ•°å­—=é«˜ä¼˜å…ˆçº§ï¼›åªæ˜¯â€œå€¾å‘â€ï¼Œä¸æŠ¢å å·²åœ¨è¿è¡Œçš„ kernelã€‚(NVIDIA Docs)\n\n\n8. æœ¯è¯­ä¸€é¡µçº¸\n\nStreamï¼šè®¾å¤‡ä¸Šç‹¬ç«‹çš„æœ‰åºæ‰§è¡Œé˜Ÿåˆ—ã€‚record_eventã€wait_eventã€wait_streamã€synchronizeã€‚(docs.pytorch.org)\nEventï¼šè®¾å¤‡ä¾§æ …æ /æ—¶é—´æˆ³ï¼›recordã€waitã€synchronizeã€elapsed_timeã€‚(docs.pytorch.org)\nå®‰å…¨è·¨æµï¼šå†™ä¾èµ– + tensor.record_stream(consumer)ï¼ˆæˆ–æ‰‹åŠ¨ç¡®ä¿é‡Šæ”¾å‰åŒæ­¥å›åˆ›å»ºæµï¼‰ã€‚(docs.pytorch.org)\né«˜æ•ˆ D2Hï¼špinned + ä¸“ç”¨æ‹·è´æµ + äº‹ä»¶ï¼›æŒ‰éœ€ç­‰å¾…ï¼Œé¿å…å…¨è®¾å¤‡åŒæ­¥ã€‚(docs.pytorch.org)\n\n\nå‚è€ƒèµ„æ–™ï¼ˆå¼ºçƒˆå»ºè®®ç»†è¯»åŸæ–‡ï¼‰\n\nPyTorchï¼štorch.cuda.Stream APIï¼ˆå« wait_event / wait_stream / synchronizeï¼‰ä¸æ–‡æ¡£æ³¨é‡Šã€‚(docs.pytorch.org)\nPyTorchï¼štorch.cuda.Event APIï¼ˆrecord / wait / synchronize / elapsed_timeï¼‰ã€‚(docs.pytorch.org)\nPyTorchï¼štensor.record_streamï¼ˆè·¨æµå†…å­˜ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼‰ã€‚(docs.pytorch.org)\nPyTorch æ•™ç¨‹ï¼špin_memory() ä¸ non_blocking ä½¿ç”¨ä¸æ³¨æ„äº‹é¡¹ã€‚(docs.pytorch.org)\nNVIDIA CUDA æ–‡æ¡£ï¼šé»˜è®¤æµï¼ˆLegacy vs PTDSï¼‰è¯­ä¹‰ä¸æµä¼˜å…ˆçº§è¯´æ˜ã€‚(NVIDIA Docs)\nNVIDIA åŸ¹è®­è®²ä¹‰ï¼šcudaDeviceSynchronize / cudaStreamSynchronize / cudaEvent* çš„åŒæ­¥å¯¹æ¯”ä¸ç¤ºä¾‹ã€‚(developer.download.nvidia.com)\n\n\n","categories":["åˆ†å¸ƒå¼åŸºç¡€"],"tags":["stream"]},{"title":"pytorchä¸­TCPStore Rendezvousæœºåˆ¶","url":"/2025/06/14/distribute/tcpstore_rendezvous/","content":"\n\nğŸ§  èƒŒæ™¯æ¦‚è¿°\n\nç›®æ ‡ï¼šåœ¨ init_process_group ä¸­å®ç°è·¨è¿›ç¨‹æ³¨å†Œã€æ’åºåŠ barrier åŒæ­¥ï¼Œä¸º NCCL/Gloo é€šä¿¡ç»„æ„å»ºåˆ›å»ºä¸€è‡´ä¸Šä¸‹æ–‡ã€‚\næ—¶åºï¼šæ‰€æœ‰ set/get/wait æ“ä½œå‡å‘ç”Ÿåœ¨ NCCL é€šä¿¡åˆå§‹åŒ–ä¹‹å‰ï¼ˆå³ rendezvous é˜¶æ®µï¼‰ã€‚\næœºåˆ¶ï¼šsocket å®¢æˆ·ç«¯â€”æœåŠ¡å™¨æ¨¡å‹ + backend æ§åˆ¶åŒæ­¥é€»è¾‘ã€‚\n\n\n1. æ¶ˆæ¯åè®®æ ¼å¼\nå®¢æˆ·ç«¯å‘ master å‘é€çš„åŒ…æ ¼å¼ä¸ºï¼š\n\\[4â€¯B æ€»é•¿åº¦]\\[1â€¯B æ“ä½œç ]\\[4â€¯B key\\_len]\\[4â€¯B value\\_len]\\[key]\\[value]\n\næ€»é•¿åº¦ï¼šç½‘ç»œå­—èŠ‚åºï¼Œä¸å«è‡ªèº«ï¼›\næ“ä½œç ï¼š1=SET, 2=GET, 3=WAITï¼›\nkey_len, value_lenï¼šåç»­å­—æ®µé•¿åº¦ï¼›\nkey, valueï¼šå®é™…æ•°æ®ï¼›\nMaster è§£æåï¼Œå›å¤ï¼šOK / value å†…å®¹ / READY ç­‰ã€‚\n\n\n2. Rendezvous é˜¶æ®µæµç¨‹ï¼ˆ2 æœºï¼Œ4 å¡ eachï¼Œèšç„¦ rank1 &amp; rank5ï¼‰\nflowchart TB  subgraph A[&quot;Machine A (rank0-3)&quot;]    master[&quot;TCPStoreBackend (master)&quot;]    r1[Worker rank1]    master --- r1  end  subgraph B[&quot;Machine B (rank4-7)&quot;]    r5[Worker rank5]    master --- r5  end  r1 --&gt;|SET key rank1_addr| master  r5 --&gt;|SET key rank5_addr| master  r1 --&gt;|WAIT  rendezvous_done| master  r5 --&gt;|WAIT  rendezvous_done| master  %% Server: waits until all ranks set, then:  master --&gt;|write READY| r1  master --&gt;|write READY| r5  %% å®Œæˆ WAIT è¿”å›ï¼Œè¿›å…¥ NCCL åˆå§‹åŒ–  r1 --&gt;|recv READY â†’ NCCL init| NCCL_1[NCCL Init rank1]  r5 --&gt;|recv READY â†’ NCCL init| NCCL_5[NCCL Init rank5]\nğŸ§© æ­¥éª¤è§£æ\n\nMaster åœ¨ç«¯å£ï¼ˆå¦‚ 29500ï¼‰ä¾¦å¬ï¼Œæ¥æ”¶è¿æ¥ï¼›\nrank1 / rank5 åˆ†åˆ«å‘é€ SETï¼ˆæ³¨å†Œåœ°å€ï¼‰ï¼›\néšåå‘é€ WAIT(\"rendezvous_done\")ï¼ŒSocket å¤„äºé˜»å¡çŠ¶æ€ï¼›\nMaster æ”¶é›†æ‰€æœ‰ 8 ä¸ª rank çš„ SET åï¼Œéå† wait é˜»å¡çš„è¿æ¥ï¼Œé€ä¸€å†™å…¥ READYï¼›\nWorker æ”¶åˆ° READYï¼Œé€€å‡ºé˜»å¡ï¼Œè¿›å…¥ NCCL åˆå§‹åŒ–é˜¶æ®µï¼›\néšååœ¨è¿™ä¸€é˜¶æ®µå†…ï¼šäº¤æ¢ ncclUniqueId (via store), è°ƒç”¨ ncclCommInitRank æ„å»ºé€šä¿¡ç»„ (github.com, pytorch.org)ã€‚\n\n\n3. Backend ç»†èŠ‚å¯¹æ¯”\n\n\n\n\n\n\n\n\nBackend\nI/O æ¨¡å‹\nç‰¹ç‚¹ä¸é€‚åº”æ€§\n\n\n\n\nç»å…¸ TCPStoreBackend\naccept() + per-conn é˜»å¡/POLL\nç®€å•ï¼Œè¿æ¥è¾ƒå¤šæ—¶æ‰©å±•æ€§å·®\n\n\nlibuv å¼‚æ­¥ Backend\nå•çº¿ç¨‹ event-loop, readable/writeable\né»˜è®¤å¯ç”¨ï¼ˆv2.4+ï¼‰ï¼Œé«˜å¹¶å‘æ›´ä¼˜ (docs.pytorch.org)\n\n\n\n\nlibuv backend ä½¿ç”¨ uv_read_start è‡ªåŠ¨åˆ†å—è¯»å–ï¼Œæ ¹æ® header æ§åˆ¶æ‹¼åŒ…ï¼›\næ³¨å†Œ WAIT æ—¶ï¼Œå°† conn ä¿å­˜åœ¨ map ä¸­ï¼Œä¸ç«‹å³å›å†™ï¼›å½“æ¡ä»¶æ»¡è¶³ï¼Œè§¦å‘ uv_write() â†’ uv_write_cb å®ç°å”¤é†’ã€‚\n\n\n4. partial-key WAIT æœºåˆ¶\n\nå®¢æˆ·ç«¯å¯ä»¥æ‰§è¡Œ store.wait([\"kA\", \"kB\"])ï¼›\nMaster å°†æ­¤ç­‰å¾…ç™»è®°è‡³ MultiWaitRegistryï¼›\nå½“ æ‰€æœ‰ç›¸å…³ key å‡è¢« SET åï¼Œæ‰ç»Ÿä¸€å‘è¯¥è¿æ¥å†™ READYï¼Œè§¦å‘å”¤é†’ã€‚\n\n\n5. â€œå¹¿æ’­ READYâ€ çš„å®ç°æœºåˆ¶\n\nä¸æ˜¯é€šè¿‡ NCCL/Gloo broadcast ç®—å­ï¼›\nMaster éå†æŒ‚èµ·çš„ WAIT socketsï¼Œé€ä¸ªå†™ READYï¼›\nä¸º rendezvous è¿‡ç¨‹è‡ªèº«æä¾›åŒæ­¥æœºåˆ¶ï¼Œé€šä¿¡ç»„å°šæœªåˆ›å»ºã€‚\n\n\n6. æ—¶é—´çº¿æ¦‚è§ˆ\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚ SET/WAIT via TCP Store   â”‚  # rendezvous é˜¶æ®µâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â†“â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚ recv READY â†’ wait returnsâ”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â†“â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚ NCCL Init                â”‚  # è°ƒç”¨ ncclUniqueId, CommInitRankâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â†“â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚ Collective Ops (DDP)     â”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nâœ… æ€»ç»“è¦ç‚¹\n\næ ‡æ³¨ rank1 / rank5 çš„æµç¨‹å›¾ï¼Œæ›´ç›´è§‚ï¼›\nSET + WAIT æ“ä½œå…¨éƒ¨å‘ç”Ÿäº rendezvous é˜¶æ®µï¼Œè§å›¾ï¼›\nMaster â€œå¹¿æ’­ READYâ€ æ˜¯ socket å†™æ“ä½œï¼Œä¸æ˜¯é€šä¿¡åº“å¹¿æ’­ï¼›\nNCCL åˆå§‹åŒ–åœ¨ rendezvous å®Œæˆåè¿›è¡Œï¼›\nlibuv backend æä¾›æ›´é«˜æ•ˆ I/O å¤„ç†åŠ message æ‹¼æ¥å¤„ç†èƒ½åŠ› (docs.pytorch.org, pytorch.org, github.com)ã€‚\n\n\n","categories":["åˆ†å¸ƒå¼åŸºç¡€"],"tags":["tcpstore"]},{"title":"ubuntuå¸¸è§shellå‘½ä»¤","url":"/2025/08/17/other/shell/","content":"\n\n1. ç£ç›˜å ç”¨ä¸æ’åºï¼ˆdu/sortï¼‰\nå¸¸ç”¨å†™æ³•\n# æŒ‰â€œå½“å‰ç›®å½•çš„ç›´æ¥å­é¡¹â€æ±‡æ€»ï¼ˆäººç±»å¯è¯»ï¼‰ï¼Œå¹¶æŒ‰å¤§å°å€’åºdu -h --max-depth=1 . | sort -hr# ä»…ç»Ÿè®¡æ¯ä¸ªæ¡ç›®æ€»å¤§å°ï¼ˆä¸æ˜¾ç¤ºå­å±‚çº§ï¼‰ï¼Œå¹¶å¯¹æ¡ç›®æ’åºdu -sh -- * | sort -h\n2. æ–‡æœ¬æœç´¢ï¼ˆgrepï¼‰\nåŸºç¡€\ngrep &quot;keyword&quot; file.txt          # åœ¨å•ä¸ªæ–‡ä»¶ä¸­æŸ¥æ‰¾grep -n &quot;keyword&quot; file.txt       # æ˜¾ç¤ºè¡Œå·grep -i &quot;keyword&quot; file.txt       # å¿½ç•¥å¤§å°å†™\nç›®å½•é€’å½’ä¸ä¸Šä¸‹æ–‡\ngrep -rin --color=auto &quot;keyword&quot; .      # é€’å½’ã€å¿½ç•¥å¤§å°å†™ã€è¡Œå·ã€é«˜äº®grep -nC 3 &quot;keyword&quot; file.txt           # ä¸Šä¸‹å„ 3 è¡Œgrep -nA 2 &quot;keyword&quot; file.txt           # å 2 è¡Œgrep -nB 2 &quot;keyword&quot; file.txt           # å‰ 2 è¡Œ\nç²¾ç¡®åŒ¹é…ä¸æ­£åˆ™\ngrep -rw &quot;\\&lt;token\\&gt;&quot; .                  # æŒ‰â€œæ•´è¯â€åŒ¹é…grep -E &quot;err(or)?|fail(ed)?&quot; app.log    # æ‰©å±•æ­£åˆ™grep -rF &quot;literal*text&quot; .               # çº¯å­—ç¬¦ä¸²ï¼ˆä¸å½“æ­£åˆ™ï¼‰ï¼Œæ›´å¿«\næ’é™¤æ–‡ä»¶/ç›®å½•\ngrep -rin &quot;keyword&quot; . \\  --exclude-dir=&#123;.git,node_modules,dist&#125; \\  --exclude=&quot;*.min.js&quot;\n\n3. æ–‡ä»¶è·¯å¾„æŸ¥æ‰¾ï¼ˆfind/locateï¼‰\nfindï¼šçµæ´»ä½†å®æ—¶æ‰«æï¼ˆæ…¢ï¼‰\n# æŒ‰æ–‡ä»¶åï¼ˆå¤§å°å†™ä¸æ•æ„Ÿï¼‰find /path -type f -iname &quot;*name*&quot;# é™åˆ¶æœç´¢æ·±åº¦find . -maxdepth 2 -type d -name &quot;build&quot;# æŸ¥æ‰¾å¤§æ–‡ä»¶ï¼ˆ&gt; 100MBï¼‰å¹¶æŒ‰å¤§å°é™åºåˆ—å‡ºå‰ 20 ä¸ªfind /var -type f -size +100M -printf &#x27;%s\\t%p\\n&#x27; | sort -nr | head -20# æŸ¥æ‰¾æœ€è¿‘ 1 å¤©å†…ä¿®æ”¹çš„æ–‡ä»¶find . -type f -mtime -1# å¯¹ç»“æœæ‰§è¡Œå‘½ä»¤ï¼ˆå®‰å…¨å¤„ç†ç©ºæ ¼ï¼‰find . -type f -name &quot;*.log&quot; -print0 | xargs -0 gzip\n\nè·³è¿‡ç³»ç»Ÿç›®å½•ä¸”å‹åˆ¶æŠ¥é”™\n\nfind / \\( -path /proc -o -path /sys -o -path /run \\) -prune -o \\  -type f -name &quot;*.conf&quot; -print 2&gt;/dev/null\nlocate/plocateï¼šåŸºäºç´¢å¼•ï¼ˆå¿«ï¼‰\nsudo apt-get install -y plocatesudo updatedb                 # é€šå¸¸è‡ªåŠ¨å®šæ—¶æ›´æ–°locate filename_or_pattern\n\n4. å¸¸è§ç½‘ç»œå·¥å…·å®‰è£…åŒ…\n# pingsudo apt-get install -y iputils-ping# ifconfigï¼ˆè€å·¥å…·ï¼Œä»å¸¸è§ï¼‰sudo apt-get install -y net-tools# ç°ä»£æ›¿ä»£ï¼šipï¼ˆé€šå¸¸å·²è‡ªå¸¦äº iproute2ï¼‰ip addrip linkip route# killallsudo apt-get install -y psmisc\n\n5. è¿›ç¨‹æŸ¥æ€ï¼ˆkill/pkill/killallï¼‰\nps -ef | grep python3 | awk &#x27;&#123;print $2&#125;&#x27; | xargs kill -9\næ›´å®‰å…¨çš„åšæ³•\n# ä¼˜é›…ç»ˆæ­¢ï¼ˆSIGTERMï¼‰ï¼›æ—  PID æ—¶ä¸æ‰§è¡Œ (-r)pgrep -f python3 | xargs -r kill# ç›´æ¥æŒ‰åç§°åŒ¹é…ï¼ˆä¼˜é›…ç»ˆæ­¢ï¼‰ï¼Œå¿…è¦æ—¶å† -9pkill -f python3pkill -9 -f python3# é¿å…åŒ¹é…åˆ° grep è‡ªèº«ps -ef | grep &#x27;[p]ython3&#x27; | awk &#x27;&#123;print $2&#125;&#x27; | xargs -r kill\n\nå»ºè®®å…ˆå°è¯• SIGTERMï¼ˆé»˜è®¤ï¼‰ï¼Œæ— å“åº”å†ç”¨ SIGKILLï¼ˆ-9ï¼‰ã€‚\n\n\n6. é«˜é¢‘å‘½ä»¤æ¸…å•ä¸ç¤ºä¾‹\nç³»ç»Ÿ/èµ„æº\ntop                     # å®æ—¶æ¦‚è§ˆhtop                    # æ›´å‹å¥½ï¼ˆéœ€ï¼šsudo apt-get install -y htopï¼‰free -h                 # å†…å­˜df -h                   # ç£ç›˜åˆ†åŒºå®¹é‡du -sh * | sort -h      # ç›®å½•å ç”¨uname -a                # å†…æ ¸ä¿¡æ¯lsb_release -a          # å‘è¡Œç‰ˆä¿¡æ¯\nè¿›ç¨‹/ç½‘ç»œ\nps aux | lesspstree -p               # è¿›ç¨‹æ ‘ï¼ˆéœ€ï¼šsudo apt-get install -y psmiscï¼‰lsof -i :8080           # ç«¯å£å ç”¨ï¼ˆéœ€ï¼šsudo apt-get install -y lsofï¼‰ss -lntp                # ç›‘å¬ç«¯å£ + è¿›ç¨‹\næ–‡æœ¬/æ—¥å¿—\nless file.logtail -f file.logwc -l file.txtsort file | uniq -c | sort -nrcut -d&#x27;,&#x27; -f1,3 file.csvsed -n &#x27;1,20p&#x27; file.txtawk -F: &#x27;&#123;print $1,$3&#125;&#x27; /etc/passwd\næ–‡ä»¶/å½’æ¡£/ä¼ è¾“\ntar -czf logs.tgz logs/        # å‹ç¼©tar -xzf logs.tgz              # è§£å‹zip -r src.zip src/            # zipï¼ˆéœ€ï¼šsudo apt-get install -y zip unzipï¼‰rsync -av --progress src/ dst/scp file user@host:/path/\næƒé™/é“¾æ¥\nchmod +x run.shchown user:group fileln -s /real/path link_name\næœåŠ¡ä¸æ—¥å¿—ï¼ˆsystemdï¼‰\nsystemctl status nginxsudo systemctl start nginxjournalctl -u nginx --since &quot;1 hour ago&quot;\nå…¶ä»–\nwhich python3command -v nodedate &quot;+%F %T&quot;nohup python3 app.py &gt;out.log 2&gt;&amp;1 &amp;tmux new -s work              # ç»ˆç«¯å¤ç”¨ï¼ˆéœ€ï¼šsudo apt-get install -y tmuxï¼‰\n\n7. å°è´´å£«ä¸å¸¸è§å‘\n\néšè—æ–‡ä»¶ï¼š* ä¸åŒ¹é…éšè—é¡¹ï¼Œå¯ç”¨ .* * ç»„åˆæˆ–å¼€å¯ dotglobã€‚\né˜²æ­¢å‚æ•°è¢«å½“ä½œé€‰é¡¹ï¼šå½“æ–‡ä»¶åä»¥ - å¼€å¤´æ—¶åŠ  --ï¼Œå¦‚ rm -- -weirdfileã€‚\nxargs å®‰å…¨ï¼šäºŒè¿›åˆ¶æ–‡ä»¶/ç©ºæ ¼ç”¨ -0 é…åˆ -print0ï¼›æ— ç»“æœæ—¶ä¸æ‰§è¡Œç”¨ -rã€‚\nä¼˜é›…åœæœåŠ¡ä¼˜å…ˆï¼škill -TERM â†’ ä¸è¡Œå† kill -KILLã€‚\næƒé™ï¼šç³»ç»Ÿç›®å½•æ“ä½œæ…ç”¨ sudoï¼Œå†™å‰å…ˆ ls/du/stat ç¡®è®¤ã€‚\ngrep æ­£åˆ™ vs å­—ç¬¦ä¸²ï¼šçº¯æ–‡æœ¬åŒ¹é…æ›´ç¨³æ›´å¿«ç”¨ -Fã€‚\nfind æ€§èƒ½ï¼šå¤§ç›®å½•ç”¨ -maxdepth é™åˆ¶å±‚çº§æˆ–æ”¹ç”¨ locate/plocateã€‚\n\n\n","categories":["å…¶å®ƒ"],"tags":["shell"]},{"title":"token ç®€ä»‹","url":"/2025/09/07/other/token/","content":"\n\nğŸ§  ä»€ä¹ˆæ˜¯ Tokenï¼Ÿ\nåœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­ï¼ŒToken æ˜¯æ–‡æœ¬çš„åŸºæœ¬å•ä½ã€‚å®ƒå¯ä»¥æ˜¯ä¸€ä¸ªå­—ç¬¦ã€ä¸€ä¸ªè¯ã€ä¸€ä¸ªå­è¯ï¼Œç”šè‡³æ˜¯ä¸€ä¸ªæ ‡ç‚¹ç¬¦å·ã€‚Token çš„å®šä¹‰å–å†³äºæ‰€é‡‡ç”¨çš„æ ‡è®°åŒ–ï¼ˆtokenizationï¼‰æ–¹æ³•ã€‚\n\nğŸ”„ æ–‡æœ¬å¦‚ä½•è½¬æ¢ä¸ºæ•°å­—ï¼Ÿ\nåœ¨è®­ç»ƒè¯­è¨€æ¨¡å‹æ—¶ï¼Œæ–‡æœ¬éœ€è¦è¢«è½¬æ¢ä¸ºæ•°å­—å½¢å¼ã€‚è¿™ä¸€è¿‡ç¨‹é€šå¸¸åŒ…æ‹¬ä»¥ä¸‹æ­¥éª¤ï¼š\n\næ ‡è®°åŒ–ï¼ˆTokenizationï¼‰ï¼šå°†æ–‡æœ¬åˆ†è§£ä¸º tokensã€‚\næ„å»ºè¯æ±‡è¡¨ï¼ˆVocabularyï¼‰ï¼šä¸ºæ¯ä¸ª token åˆ†é…ä¸€ä¸ªå”¯ä¸€çš„æ•°å­— IDã€‚\næ•°å­—åŒ–ï¼ˆNumericalizationï¼‰ï¼šå°†æ–‡æœ¬ä¸­çš„ tokens æ›¿æ¢ä¸ºå¯¹åº”çš„æ•°å­— IDã€‚\n\nä¾‹å¦‚ï¼Œå¥å­ \"hello world\" å¯èƒ½è¢«æ ‡è®°åŒ–ä¸º [\"hello\", \"world\"]ï¼Œç„¶åæ ¹æ®è¯æ±‡è¡¨è½¬æ¢ä¸º [1, 2]ã€‚\n\nğŸ”¤ å¸¸è§çš„æ ‡è®°åŒ–æ–¹æ³•\n1. Word-based Tokenizationï¼ˆåŸºäºè¯çš„æ ‡è®°åŒ–ï¼‰\nå°†æ–‡æœ¬æŒ‰ç©ºæ ¼æˆ–æ ‡ç‚¹ç¬¦å·åˆ†å‰²æˆå•è¯ã€‚è¿™ç§æ–¹æ³•ç®€å•ç›´è§‚ï¼Œä½†å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š\n\nè¯æ±‡è¡¨è¿‡å¤§ï¼šéœ€è¦ä¸ºæ¯ä¸ªå•è¯åˆ†é…ä¸€ä¸ªå”¯ä¸€çš„ IDï¼Œå¯¼è‡´è¯æ±‡è¡¨åºå¤§ã€‚\nå¤„ç†æœªç™»å½•è¯å›°éš¾ï¼šå¯¹äºè®­ç»ƒæ•°æ®ä¸­æœªå‡ºç°çš„å•è¯ï¼Œæ¨¡å‹éš¾ä»¥å¤„ç†ã€‚\n\nç¤ºä¾‹ï¼š\n\nè¾“å…¥æ–‡æœ¬ï¼š\"I love NLP\"\næ ‡è®°åŒ–ç»“æœï¼š[\"I\", \"love\", \"NLP\"]\næ•°å­—åŒ–è¡¨ç¤ºï¼š[1, 2, 3]\n\n2. Character-based Tokenizationï¼ˆåŸºäºå­—ç¬¦çš„æ ‡è®°åŒ–ï¼‰\nå°†æ–‡æœ¬åˆ†è§£ä¸ºå•ä¸ªå­—ç¬¦ã€‚è¿™ç§æ–¹æ³•å¯ä»¥æœ‰æ•ˆå‡å°‘è¯æ±‡è¡¨å¤§å°ï¼Œä½†å¯èƒ½å¯¼è‡´ä»¥ä¸‹é—®é¢˜ï¼š\n\nä¿¡æ¯ä¸¢å¤±ï¼šå­—ç¬¦çº§åˆ«çš„è¡¨ç¤ºå¯èƒ½æ— æ³•æ•æ‰åˆ°è¯æ±‡çš„å®Œæ•´è¯­ä¹‰ã€‚\nåºåˆ—é•¿åº¦å¢åŠ ï¼šåŒä¸€æ–‡æœ¬çš„ token æ•°é‡å¢åŠ ï¼Œå¯èƒ½å½±å“æ¨¡å‹çš„å¤„ç†æ•ˆç‡ã€‚\n\nç¤ºä¾‹ï¼š\n\nè¾“å…¥æ–‡æœ¬ï¼š\"I love NLP\"\næ ‡è®°åŒ–ç»“æœï¼š[\"I\", \" \", \"l\", \"o\", \"v\", \"e\", \" \", \"N\", \"L\", \"P\"]\næ•°å­—åŒ–è¡¨ç¤ºï¼š[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n\nğŸ”¬ Subword-based Tokenizationï¼šBPEï¼ˆå­—èŠ‚å¯¹ç¼–ç ï¼‰\nBPE æ˜¯ä¸€ç§å­è¯çº§åˆ«çš„æ ‡è®°åŒ–æ–¹æ³•ï¼Œæ—¨åœ¨å¹³è¡¡è¯æ±‡è¡¨å¤§å°å’Œè¯­ä¹‰è¡¨è¾¾èƒ½åŠ›ã€‚å®ƒé€šè¿‡è¿­ä»£åœ°åˆå¹¶æœ€é¢‘ç¹çš„å­—ç¬¦å¯¹æ¥æ„å»ºå­è¯å•å…ƒï¼Œå¹¶è¢«å¹¿æ³›åº”ç”¨äº GPTã€BERT ç­‰å¤§è¯­è¨€æ¨¡å‹ã€‚BPE çš„è¿‡ç¨‹å¯ä»¥æ¦‚æ‹¬ä¸ºä»¥ä¸‹äº”ä¸ªé˜¶æ®µï¼š\n1. åˆå§‹åŒ–è¯æ±‡è¡¨\n\næ‹†åˆ†å­—ç¬¦ï¼šé¦–å…ˆå°†è¯­æ–™åº“æ‹†åˆ†ä¸ºæœ€å°å•ä½â€”â€”å•ä¸ªå­—ç¬¦ã€‚ä¾‹å¦‚ï¼Œå¯¹å•è¯ lower æ‹†åˆ†å¾—åˆ° l o w e r&lt;/w&gt;ï¼Œå¹¶åœ¨æ¯ä¸ªè¯å°¾æ·»åŠ ç‰¹æ®Šç»“æŸç¬¦ï¼ˆå¦‚ &lt;/w&gt;ï¼‰ï¼Œä»¥åŒºåˆ†ä¸åŒè¯ã€‚\næ„å»ºåˆå§‹è¯è¡¨ï¼šè®°å½•æ‰€æœ‰å‡ºç°è¿‡çš„å­—ç¬¦ï¼Œä½œä¸ºåˆå§‹ token é›†ã€‚\n\n2. ç»Ÿè®¡ç›¸é‚»å­—ç¬¦å¯¹é¢‘ç‡\néå†æ‰€æœ‰è¯ï¼Œç»Ÿè®¡æ¯ä¸ªç›¸é‚»å­—ç¬¦ï¼ˆæˆ–å·²åˆå¹¶çš„å­è¯ï¼‰å¯¹çš„å‡ºç°æ¬¡æ•°ã€‚BPE é€šè¿‡è¿™ä¸€ç»Ÿè®¡æ¥è¯†åˆ«è¯­è¨€ä¸­æœ€å¸¸è§çš„æ¨¡å¼ï¼Œä»¥å†³å®šæ¥ä¸‹æ¥è¦åˆå¹¶çš„ç¬¦å·å¯¹ã€‚\n3. åˆå¹¶æœ€é¢‘ç¹çš„ç¬¦å·å¯¹\næ‰¾åˆ°å‡ºç°é¢‘ç‡æœ€é«˜çš„å­—ç¬¦å¯¹ï¼Œå¹¶å°†å®ƒä»¬åœ¨æ•´ä¸ªæ•°æ®é›†ä¸­åˆå¹¶æˆæ–°çš„å­è¯ã€‚ä¾‹å¦‚ï¼Œå¦‚æœ (w, e) æ˜¯æœ€é«˜é¢‘ç»„åˆï¼Œåˆ™å°†å…¶åˆå¹¶ä¸º weï¼›æ›´æ–°æ‰€æœ‰ç›¸å…³è¯ï¼Œå¹¶æŠŠæ–°å­è¯åŠ å…¥è¯æ±‡è¡¨ã€‚\n4. é‡å¤æ­¥éª¤ç›´åˆ°è¾¾åˆ°è¯è¡¨å¤§å°\nBPE æ˜¯ä¸€ä¸ªè¿­ä»£è¿‡ç¨‹ã€‚æ¯æ¬¡åˆå¹¶åï¼Œç»Ÿè®¡æ–°çš„ç›¸é‚»ç¬¦å·å¯¹å¹¶ç»§ç»­åˆå¹¶ï¼Œç›´åˆ°è¯æ±‡è¡¨è¾¾åˆ°é¢„è®¾å¤§å°æˆ–ä¸å†æœ‰éœ€è¦åˆå¹¶çš„ç¬¦å·å¯¹ã€‚\n5. æ„å»ºæœ€ç»ˆè¯æ±‡è¡¨å¹¶åº”ç”¨åˆ°æ–‡æœ¬\næœ€ç»ˆè¯æ±‡è¡¨æ—¢åŒ…å«åˆå§‹çš„å­—ç¬¦ï¼ŒåˆåŒ…å«æ‰€æœ‰åˆå¹¶å¾—åˆ°çš„é«˜é¢‘å­è¯ã€‚æ–°è¯å¯ä»¥é€šè¿‡è¿™äº›å­è¯ç»„åˆè¡¨ç¤ºï¼Œå› æ­¤ä»»ä½•æ–°è¯éƒ½èƒ½æ‹†è§£ä¸ºå·²çŸ¥çš„å­è¯åºåˆ—ã€‚\nç¤ºä¾‹ï¼šBPE åˆ†è¯è¿‡ç¨‹æ¼”ç¤º\nä»¥ä»¥ä¸‹è¯æ±‡é›†ä¸ºä¾‹ï¼šhuggingfaceã€huggingã€faceã€hugã€huggerã€learningã€learnerã€learnã€‚å°†æ¯ä¸ªè¯æ‹†åˆ†ä¸ºå­—ç¬¦å¹¶åŠ ä¸Šç»“æŸç¬¦ï¼Œç„¶åæ‰§è¡Œé¢‘æ¬¡ç»Ÿè®¡å’Œåˆå¹¶ã€‚ä»¥ä¸‹æ˜¯å‰å‡ æ¬¡åˆå¹¶ï¼š\n\n(h, u) â†’ hu\n(hu, g) â†’ hug\n(hug, g) â†’ hugg\n(i, n) â†’ in\n(in, g) â†’ ing\n(l, e) â†’ le\n(le, a) â†’ lea\n(lea, r) â†’ lear\n\næ‰§è¡Œ 8 æ¬¡åˆå¹¶åï¼Œè¯è¡¨æ‰©å¤§è‡³ 20 ä¸ª tokenï¼Œå…¶ä¸­åŒ…æ‹¬åŸºæœ¬å­—ç¬¦ï¼ˆh,u,g,i ç­‰ï¼‰å’Œæ–°åˆæˆçš„å­è¯ï¼ˆhug,hugg,ing,lear ç­‰ï¼‰ã€‚è¯ huggingface ç»è¿‡æ ‡è®°åŒ–åä¸º hugg ing f a c e &lt;/w&gt;ï¼Œlearning åˆ™ä¸º lear n ing &lt;/w&gt;ï¼Œå…¶ä½™è¯ä¹Ÿå¯ä»¥ç”¨ç±»ä¼¼æ–¹å¼è¡¨ç¤ºã€‚\nğŸ§ª BPE çš„ä¼˜ç¼ºç‚¹\nä¼˜ç‚¹ï¼š\n\nå¤„ç†æœªç™»å½•è¯ï¼šé€šè¿‡æŠŠè¯æ‹†è§£ä¸ºå­è¯ï¼ŒBPE å¯ä»¥ç”¨å·²æœ‰çš„å­è¯ç»„åˆæ¥è¡¨ç¤ºè®­ç»ƒé›†ä¸­æœªå‡ºç°çš„è¯æ±‡ã€‚\nå‡å°‘è¯æ±‡è¡¨å¤§å°ï¼šç›¸æ¯”åŸºäºè¯çš„æ ‡è®°åŒ–ï¼ŒBPE å¯ä»¥æ˜¾è‘—ç¼©å°è¯è¡¨è§„æ¨¡ï¼Œä½¿æ¨¡å‹æ›´é«˜æ•ˆã€‚\næå‡æ³›åŒ–èƒ½åŠ›ï¼šå­è¯çº§è¡¨ç¤ºå…è®¸æ¨¡å‹å­¦ä¹ æ›´ç»†ç²’åº¦çš„è¯­è¨€ç»“æ„ï¼Œå¯¹ä¸åŒé¢†åŸŸã€ä¸åŒè¯­è¨€å…·æœ‰æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚\n\nç¼ºç‚¹ï¼š\n\nåˆå¹¶è§„åˆ™ä¾èµ–è¯­æ–™ï¼šä¸åŒè¯­æ–™å¾—åˆ°çš„åˆå¹¶è§„åˆ™å·®å¼‚è¾ƒå¤§ï¼Œå¤šè¯­è¨€åœºæ™¯ä¸‹å¯èƒ½éœ€è¦å¤æ‚çš„å¤„ç†ã€‚\nè¯­ä¹‰å®Œæ•´æ€§å¯èƒ½å—æŸï¼šå¦‚æœåˆå¹¶è¿‡åº¦ï¼ŒæŸäº›åˆæˆè¯çš„è¯­ä¹‰ä»å¯èƒ½åˆ†å‰²ï¼Œéœ€æ ¹æ®ä»»åŠ¡é€‰æ‹©åˆé€‚çš„è¯è¡¨å¤§å°ã€‚\n\n\nğŸ“ æ€»ç»“\næ ‡è®°åŒ–æ˜¯è‡ªç„¶è¯­è¨€å¤„ç†çš„æ ¸å¿ƒæ­¥éª¤ï¼Œå®ƒå°†æ–‡æœ¬è½¬æ¢ä¸ºæ¨¡å‹å¯å¤„ç†çš„æ•°å­—å½¢å¼ã€‚åŸºäºè¯å’ŒåŸºäºå­—ç¬¦çš„æ ‡è®°åŒ–æ–¹æ³•ç®€å•æ˜“ç†è§£ï¼Œä½†åˆ†åˆ«å­˜åœ¨è¯æ±‡è¡¨è¿‡å¤§å’Œåºåˆ—è¿‡é•¿çš„é—®é¢˜ã€‚BPE ä½œä¸ºä¸€ç§å­è¯çº§æ ‡è®°åŒ–ç®—æ³•ï¼Œä»¥åˆå§‹åŒ–å­—ç¬¦é›†ä¸ºåŸºç¡€ï¼Œé€šè¿‡è¿­ä»£åˆå¹¶é«˜é¢‘ç¬¦å·å¯¹æ„å»ºæ–°çš„å­è¯å•å…ƒã€‚è¿™ç§æ–¹æ³•å…¼é¡¾äº†è¯è¡¨å¤§å°å’Œè¯­ä¹‰è¡¨è¾¾èƒ½åŠ›ï¼Œæ—¢èƒ½å¤„ç†æœªç™»å½•è¯ï¼Œä¹Ÿèƒ½ä¿ç•™è¶³å¤Ÿçš„è¯­ä¹‰ä¿¡æ¯ã€‚å› æ­¤ï¼Œç°ä»£å¤§è¯­è¨€æ¨¡å‹é€šå¸¸é‡‡ç”¨ BPE æˆ–å…¶å˜ç§ï¼ˆå¦‚ WordPieceã€SentencePieceï¼‰ä½œä¸ºé»˜è®¤çš„æ ‡è®°åŒ–æ–¹æ¡ˆã€‚\n","categories":["å…¶å®ƒ"],"tags":["token"]},{"title":"ubuntuæ­å»ºæŠ€æœ¯åšå®¢æŒ‡å—","url":"/2025/06/14/other/web_init/","content":"\n\n1. å®‰è£… Hexo ç¯å¢ƒ\n2. é€‰æ‹©ä¸é…ç½® Hexo ä¸»é¢˜\n3. æ’°å†™ä¸ç®¡ç†åšå®¢å†…å®¹\n4. SEO ä¼˜åŒ–\n5. åšå®¢éƒ¨ç½²\n6. ç»´æŠ¤ä¸ä¼˜åŒ–\n\næœ¬æŒ‡å—è¯¦ç»†ä»‹ç»äº†å¦‚ä½•åœ¨ Ubuntu æœåŠ¡å™¨ä¸Šæ­å»ºå¹¶éƒ¨ç½²ä¸€ä¸ª Hexo æŠ€æœ¯åšå®¢ï¼ŒåŒ…æ‹¬ä»ç¯å¢ƒå®‰è£…åˆ°åæœŸç»´æŠ¤çš„å®Œæ•´æ­¥éª¤ã€‚\n1. å®‰è£… Hexo ç¯å¢ƒ\næ­å»º Hexo åšå®¢é¦–å…ˆéœ€è¦å®‰è£… Node.jsï¼ˆHexo åŸºäº Node.jsï¼‰ã€npmã€Git ä»¥åŠ Hexo CLI å·¥å…·ã€‚è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤é…ç½®ç¯å¢ƒï¼š\nå®‰è£… Node.js å’Œ npmï¼š\nåœ¨ Ubuntu ä¸Šï¼Œé€šè¿‡åŒ…ç®¡ç†å™¨æˆ– Node å®˜æ–¹ä»“åº“å®‰è£… Node.jsã€‚å»ºè®®å®‰è£… LTS ç‰ˆæœ¬ï¼ˆå¦‚ Node 14+ï¼‰ã€‚æ‰§è¡Œä»¥ä¸‹å‘½ä»¤æ·»åŠ  NodeSource ä»“åº“å¹¶å®‰è£… Node.jsï¼š\ncurl -sL https://deb.nodesource.com/setup_18.x | sudo -E bash -sudo apt-get install -y nodejs\nå®‰è£…å®Œæˆåï¼Œæ£€æŸ¥ç‰ˆæœ¬ä»¥ç¡®ä¿ Node æ­£å¸¸å¯ç”¨ï¼š\nnode -v  # åº”è¿”å›ç±»ä¼¼ v18.20.6 çš„ç‰ˆæœ¬å·npm -v   # éªŒè¯ npm æ˜¯å¦æ­£å¸¸å®‰è£…\nå®‰è£… Gitï¼š\nGit æ˜¯ Hexo éƒ¨ç½²å’Œå¤‡ä»½çš„å¸¸ç”¨å·¥å…·ã€‚Ubuntu é€šå¸¸é¢„è£… Gitï¼Œè‹¥æœªå®‰è£…ï¼Œè¯·æ‰§è¡Œï¼š\nsudo apt-get install -y git\nå®‰è£…åï¼Œé…ç½® Git çš„å…¨å±€ç”¨æˆ·åå’Œé‚®ç®±ï¼š\ngit config --global user.name &quot;Your Name&quot;git config --global user.email &quot;youremail@example.com&quot;\nå®‰è£… Hexo CLIï¼š\né€šè¿‡ npm å…¨å±€å®‰è£… Hexo CLIï¼š\nsudo npm install -g hexo-cli\nå®‰è£…æˆåŠŸåï¼Œé€šè¿‡ hexo -v æ£€æŸ¥ç‰ˆæœ¬ï¼Œç¡®ä¿ Hexo CLI å¯ç”¨ã€‚\nåˆå§‹åŒ– Hexo åšå®¢ï¼š\né€‰æ‹©åšå®¢æ–‡ä»¶å¤¹ï¼ˆä¾‹å¦‚ /var/www/hexo æˆ–å½“å‰ç”¨æˆ·ä¸»ç›®å½•ä¸‹çš„ my-blog æ–‡ä»¶å¤¹ï¼‰ï¼Œå¹¶åœ¨è¯¥ç›®å½•ä¸‹åˆå§‹åŒ– Hexo åšå®¢ï¼š\nsudo mkdir -p /var/www/hexo &amp;&amp; sudo chown $USER:$USER /var/www/hexocd /var/www/hexohexo initnpm install\nåˆå§‹åŒ–å®Œæˆåï¼ŒHexo ä¼šç”Ÿæˆé»˜è®¤çš„åšå®¢ç»“æ„ï¼ŒåŒ…æ‹¬ _config.yml é…ç½®æ–‡ä»¶ã€scaffolds/ æ¨¡æ¿ç›®å½•ã€source/ å†…å®¹ç›®å½•å’Œ themes/ ä¸»é¢˜ç›®å½•ç­‰ã€‚å¯ä»¥é€šè¿‡è¿è¡Œ hexo server é¢„è§ˆæœ¬åœ°åšå®¢ã€‚\nå¼€å¯é˜²ç«å¢™ï¼š\nä¸ºäº†ç¡®ä¿æœåŠ¡å™¨å®‰å…¨ï¼Œå»ºè®®å¼€å¯é˜²ç«å¢™ã€‚Ubuntu è‡ªå¸¦ UFW é˜²ç«å¢™ï¼Œå¯ä»¥å¼€å¯ SSHã€HTTP(S) ä»¥åŠ Hexo é»˜è®¤é¢„è§ˆç«¯å£ 4000ï¼š\nsudo apt-get install ufw  sudo ufw allow &quot;OpenSSH&quot;  sudo ufw allow 4000  sudo ufw allow http  sudo ufw allow https  sudo ufw enable\n2. é€‰æ‹©ä¸é…ç½® Hexo ä¸»é¢˜\nHexo é»˜è®¤ä¸»é¢˜ä¸º Landscapeï¼Œä½†ä¸ºäº†æ‰“é€ ä¸€ä¸ªç®€æ´ç¾è§‚çš„æŠ€æœ¯åšå®¢ï¼Œæˆ‘ä»¬æ¨èä½¿ç”¨ NexT ä¸»é¢˜ï¼Œå®ƒåŠŸèƒ½å¼ºå¤§ä¸”å¤–è§‚ä¼˜é›…ã€‚ä»¥ä¸‹æ˜¯ä¸»é¢˜çš„å®‰è£…å’Œé…ç½®æ­¥éª¤ï¼š\nè·å– NexT ä¸»é¢˜ï¼š\nåœ¨ Hexo åšå®¢æ ¹ç›®å½•ä¸‹æ‰§è¡Œä»¥ä¸‹å‘½ä»¤æ¥å…‹éš† NexT ä¸»é¢˜ï¼š\ncd /var/www/hexogit clone https://github.com/theme-next/hexo-theme-next themes/next\nä¿®æ”¹ä¸»é¢˜é…ç½®ï¼š\nå…‹éš†å®Œæˆåï¼Œæ‰“å¼€ _config.yml é…ç½®æ–‡ä»¶ï¼Œå°† theme é…ç½®ä»é»˜è®¤çš„ landscape æ”¹ä¸º nextï¼š\n# _config.ymltheme: next\nå®‰è£…ä¸»é¢˜ä¾èµ–ï¼š\næ ¹æ®éœ€è¦å®‰è£… NexT ä¸»é¢˜çš„ä¾èµ–ï¼Œå¹¶å¯ç”¨ä½ æ‰€éœ€çš„åŠŸèƒ½ã€‚\nç”Ÿæˆå¸¸ç”¨é¡µé¢ï¼š\nä¸ºäº†å®Œå–„ç½‘ç«™ç»“æ„ï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ç”Ÿæˆæ ‡ç­¾ã€åˆ†ç±»ã€å½’æ¡£ç­‰é¡µé¢ï¼š\nhexo new page &quot;tags&quot;hexo new page &quot;categories&quot;hexo new page &quot;archives&quot;hexo new page &quot;about&quot;\nç¼–è¾‘æ¯ä¸ªé¡µé¢çš„ index.mdï¼Œåœ¨ Front-matter ä¸­æŒ‡å®šé¡µé¢ç±»å‹ï¼š\ntitle: æ ‡ç­¾date: 2025-03-06 15:00:00type: &quot;tags&quot;\nå¯¼èˆªæ èœå•å®šåˆ¶ï¼š\nåœ¨ themes/next/_config.yml ä¸­æ‰¾åˆ° menu è®¾ç½®ï¼Œå¹¶æ·»åŠ æ–°åˆ›å»ºçš„é¡µé¢ï¼š\nmenu:  home: / || home  categories: /categories/ || th  tags: /tags/ || tags  archives: /archives/ || archive  about: /about/ || user\nä¿å­˜ä¿®æ”¹åï¼Œé‡æ–°ç”Ÿæˆç«™ç‚¹ï¼Œæ–°çš„å¯¼èˆªæ èœå•å³ä¼šæ˜¾ç¤ºã€‚\n3. æ’°å†™ä¸ç®¡ç†åšå®¢å†…å®¹\nHexo ä½¿ç”¨ Markdown æ ¼å¼æ¥æ’°å†™æ–‡ç« ï¼Œéå¸¸é€‚åˆæŠ€æœ¯åšå®¢ã€‚ä»¥ä¸‹æ˜¯å¦‚ä½•ç®¡ç†å’Œç¼–å†™æ–‡ç« çš„æ­¥éª¤ï¼š\næ–°å»ºåšæ–‡ï¼š\nä½¿ç”¨ Hexo CLI åˆ›å»ºæ–°çš„æ–‡ç« ï¼š\nhexo new &quot;æ–‡ç« æ ‡é¢˜&quot;\nè¿™å°†åœ¨ source/_posts/ ç›®å½•ä¸‹åˆ›å»ºä¸€ä¸ª Markdown æ–‡ä»¶ï¼Œæ–‡ä»¶çš„å¼€å¤´æ˜¯ Front-matterï¼Œç”¨äºé…ç½®æ–‡ç« çš„å…ƒæ•°æ®ï¼ˆå¦‚æ ‡é¢˜ã€æ—¥æœŸã€åˆ†ç±»å’Œæ ‡ç­¾ç­‰ï¼‰ï¼š\ntitle: æ·±åº¦å­¦ä¹ å…¥é—¨æŒ‡å—  date: 2025-03-06 15:00:00  categories:    - äººå·¥æ™ºèƒ½    - æ·±åº¦å­¦ä¹   tags:    - ç¥ç»ç½‘ç»œ    - å…¥é—¨æ•™ç¨‹ \nä½¿ç”¨ Markdown æ’°å†™å†…å®¹ï¼š\nåœ¨ Front-matter ä¸‹æ–¹ï¼Œç”¨ Markdown è¯­æ³•æ’°å†™æ­£æ–‡ã€‚Hexo é»˜è®¤æ”¯æŒ GFMï¼ˆGitHub Flavored Markdownï¼‰ï¼Œå¯ä»¥æ–¹ä¾¿åœ°ä¹¦å†™æ ¼å¼ï¼Œä¾‹å¦‚ï¼š\n# ä¸€çº§æ ‡é¢˜## äºŒçº§æ ‡é¢˜**ç²—ä½“**ã€*æ–œä½“*å¼ºè°ƒ\næ’å…¥å›¾ç‰‡å’Œèµ„æºï¼š\nå¯ç”¨ post_asset_folder: true åï¼Œæ¯ç¯‡æ–‡ç« ä¼šæœ‰ç‹¬ç«‹çš„èµ„æºç›®å½•ã€‚å¯ä»¥å°†å›¾ç‰‡æ–‡ä»¶æ”¾å…¥è¯¥æ–‡ä»¶å¤¹ï¼Œå¹¶åœ¨æ–‡ç« ä¸­å¼•ç”¨ï¼š\n![](my-post/images/example.png)\nè‰ç¨¿ç®¡ç†ä¸å‘å¸ƒï¼š\nå¯ç”¨è‰ç¨¿åŠŸèƒ½åï¼Œæ–°åˆ›å»ºçš„æ–‡ç« ä¼šå…ˆæ”¾åœ¨ _drafts/ ä¸‹ã€‚å®Œæˆåï¼Œä½¿ç”¨ hexo publish \"æ–‡ç« æ ‡é¢˜\" å°†å…¶å‘å¸ƒã€‚\næ–‡ç« ç»“æ„å’Œåˆ†é¡µï¼š\nHexo æ”¯æŒæ–‡ç« åˆ†ç±»å’Œæ ‡ç­¾è‡ªåŠ¨æ•´ç†ã€‚ä½ ä¹Ÿå¯ä»¥é€šè¿‡ &lt;!-- more --&gt; æ¥æ‰‹åŠ¨æˆªæ–­æ‘˜è¦ï¼Œæé«˜é¦–é¡µåŠ è½½é€Ÿåº¦ã€‚\n4. SEO ä¼˜åŒ–\nä¸ºäº†è®©æ›´å¤šäººçœ‹åˆ°ä½ çš„æŠ€æœ¯åšå®¢ï¼Œè¿›è¡Œ SEOï¼ˆæœç´¢å¼•æ“ä¼˜åŒ–ï¼‰éå¸¸é‡è¦ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›ä¼˜åŒ–æªæ–½ï¼š\nç«™ç‚¹æ ‡é¢˜ä¸å…ƒä¿¡æ¯ï¼š\nåœ¨ _config.yml ä¸­å¡«å†™æœ‰åŠ©äº SEO çš„ç«™ç‚¹åŸºæœ¬ä¿¡æ¯ï¼ŒåŒ…æ‹¬ titleï¼ˆæ ‡é¢˜ï¼‰ã€descriptionï¼ˆæè¿°ï¼‰å’Œ keywordsï¼ˆå…³é”®è¯ï¼‰ã€‚\né“¾æ¥ä¼˜åŒ–ï¼š\nä¿®æ”¹æ°¸ä¹…é“¾æ¥æ ¼å¼ï¼Œç®€åŒ– URL ç»“æ„ï¼š\npermalink: :category/:title/\nç«™ç‚¹åœ°å›¾ï¼š\nç”Ÿæˆç«™ç‚¹åœ°å›¾å¸®åŠ©æœç´¢å¼•æ“æŠ“å–æ‰€æœ‰é¡µé¢ï¼š\nnpm install hexo-generator-sitemap hexo-generator-baidu-sitemap --save\nå¹¶åœ¨ _config.yml ä¸­æ·»åŠ é…ç½®ï¼š\nsitemap:  path: sitemap.xmlbaidusitemap:  path: baidusitemap.xml\næœºå™¨äººåè®®ï¼š\nåœ¨ source/ ç›®å½•ä¸‹åˆ›å»º robots.txt æ–‡ä»¶ï¼Œå¹¶å†™å…¥è§„åˆ™ï¼š\nUser-agent: *Allow: /Disallow: /admin/Sitemap: https://ä½ çš„åŸŸå/sitemap.xml\nå¥½çš„ï¼Œä»¥ä¸‹æ˜¯æˆ‘é‡æ–°ç”Ÿæˆå¹¶ä¿æŒå®Œæ•´çš„ Hexo Deploy è‡ªåŠ¨éƒ¨ç½²éƒ¨åˆ†ï¼Œç¡®ä¿æ²¡æœ‰çœç•¥ä»»ä½•ç»†èŠ‚ï¼š\n\n5. åšå®¢éƒ¨ç½²\nå®Œæˆå†…å®¹åˆ›ä½œå’Œä¼˜åŒ–åï¼Œå°±éœ€è¦å°†åšå®¢éƒ¨ç½²ä¸Šçº¿ã€‚Hexo ç”Ÿæˆçš„æ˜¯çº¯é™æ€ç½‘é¡µï¼Œå¯ä»¥éƒ¨ç½²åœ¨ä»»æ„é™æ€æœåŠ¡å™¨æˆ–æ‰˜ç®¡å¹³å°ä¸Šã€‚è¿™é‡Œä»‹ç»åœ¨ Ubuntu æœåŠ¡å™¨ä¸Šä½¿ç”¨ Nginx éƒ¨ç½²çš„æ–¹æ¡ˆï¼Œå¹¶è®¨è®º Nginx é…ç½®å’Œ Git è‡ªåŠ¨éƒ¨ç½²æ–¹æ³•ã€‚\næœ¬åœ°ç”Ÿæˆé™æ€æ–‡ä»¶ï¼š\nHexo æä¾›å‘½ä»¤å°† Markdown å†…å®¹ç”Ÿæˆé™æ€ç½‘é¡µã€‚ä¸€èˆ¬åœ¨æœ¬åœ°æˆ–æœåŠ¡å™¨ä¸Šè¿è¡Œï¼š\nhexo clean        # æ¸…ç†ä¸Šæ¬¡ç”Ÿæˆçš„æ–‡ä»¶hexo generate (hexo g)   # ç”Ÿæˆæœ€æ–°é™æ€ç½‘é¡µ\nç”Ÿæˆçš„æ–‡ä»¶ä½äºåšå®¢ç›®å½•ä¸‹çš„ public/ æ–‡ä»¶å¤¹ï¼Œå…¶ä¸­åŒ…å«åšå®¢çš„æ‰€æœ‰ HTMLã€CSSã€JSã€å›¾ç‰‡ç­‰é™æ€èµ„æºã€‚è¿™ä¸ª public æ–‡ä»¶å¤¹å³æ˜¯æœ€ç»ˆéƒ¨ç½²çš„ç½‘ç«™å†…å®¹ã€‚\nNginx éƒ¨ç½²é™æ€ç«™ç‚¹ï¼š\nåœ¨æœåŠ¡å™¨ä¸Šå®‰è£… Nginx å¹¶é…ç½®ç«™ç‚¹ï¼Œä»¥æä¾› Web æœåŠ¡ï¼š\nå®‰è£… Nginxï¼š\nsudo apt-get install -y nginx\nå®‰è£…åå¯åŠ¨ Nginx æœåŠ¡ï¼š\nsudo systemctl start nginx  # å¯è®¾ç½®å¼€æœºè‡ªå¯\né…ç½®ç«™ç‚¹ï¼šåœ¨ /etc/nginx/sites-available/ ç›®å½•ä¸‹åˆ›å»ºé…ç½®æ–‡ä»¶ï¼Œå¦‚ hexo.confï¼Œå†…å®¹å¦‚ä¸‹ï¼š\nserver &#123;    listen 80;    server_name example.com;  # å°†æ­¤æ›¿æ¢ä¸ºä½ çš„åŸŸåæˆ–æœåŠ¡å™¨IP    root /var/www/hexo/public;    index index.html index.htm;    location / &#123;        try_files $uri $uri/ =404;    &#125;&#125;\nä¸Šè¿°é…ç½®æŒ‡å®šæœåŠ¡å™¨ç›‘å¬ 80 ç«¯å£ï¼Œserver_name ä¸ºä½ çš„åŸŸåï¼ˆéœ€è¦å°†åŸŸåè§£ææŒ‡å‘è¯¥æœåŠ¡å™¨ï¼‰ã€‚root æŒ‡å‘ Hexo ç”Ÿæˆçš„ public ç›®å½•ï¼Œindex å£°æ˜é»˜è®¤é¦–é¡µæ–‡ä»¶ã€‚\nå¯ç”¨ç«™ç‚¹é…ç½®ï¼šå°†é…ç½®æ–‡ä»¶é“¾æ¥åˆ° sites-enabledï¼š\nln -s /etc/nginx/sites-available/hexo.conf /etc/nginx/sites-enabled/nginx -t  # æµ‹è¯•é…ç½®è¯­æ³•æ­£ç¡®æ€§systemctl reload nginx  # é‡æ–°åŠ è½½ Nginx é…ç½®\næ‰§è¡Œä»¥ä¸Šå‘½ä»¤åï¼Œåšå®¢ç«™ç‚¹å³å¯é€šè¿‡åŸŸåè®¿é—®ã€‚å¦‚æœæš‚æ—¶æ²¡æœ‰åŸŸåï¼Œä½¿ç”¨æœåŠ¡å™¨ IP ä¹Ÿèƒ½è®¿é—®ï¼ˆæ­¤æ—¶å¯å°† server_name æ”¹ä¸º _ é€šé…ç¬¦ï¼‰ã€‚\né…ç½® HTTPSï¼ˆå¯é€‰ï¼‰ï¼š\nå»ºè®®ä¸ºåšå®¢é…ç½® SSL è¯ä¹¦ã€‚å¯ä»¥ä½¿ç”¨ Certbot è·å– Letâ€™s Encrypt å…è´¹è¯ä¹¦ã€‚æ­¥éª¤å¦‚ä¸‹ï¼š\napt-get install -y certbot python3-certbot-nginx  certbot --nginx -d example.com -d www.example.com\næŒ‰æç¤ºå®ŒæˆåŸŸåæ‰€æœ‰æƒéªŒè¯åï¼ŒCertbot ä¼šè‡ªåŠ¨ç”Ÿæˆè¯ä¹¦å¹¶é…ç½® Nginx å°†ç«™ç‚¹å‡çº§ä¸º HTTPSã€‚\nHexo Deploy è‡ªåŠ¨éƒ¨ç½²ï¼š\næ¯æ¬¡æ›´æ–°å†…å®¹åéƒ½è¦é‡æ–°ç”Ÿæˆå¹¶ä¸Šä¼ æ–‡ä»¶ï¼Œä½¿ç”¨ Hexo çš„éƒ¨ç½²åŠŸèƒ½å¯ä»¥ç®€åŒ–æµç¨‹ã€‚Hexo æ”¯æŒå¤šç§éƒ¨ç½²æ–¹å¼ï¼Œå…¶ä¸­ Git éƒ¨ç½²æ˜¯å¸¸ç”¨æ–¹æ¡ˆä¹‹ä¸€ã€‚åŸºæœ¬æ€è·¯æ˜¯åˆ©ç”¨ Git æŠŠç”Ÿæˆçš„é™æ€æ–‡ä»¶æ¨é€åˆ°æœåŠ¡å™¨æˆ–æ‰˜ç®¡æœåŠ¡ã€‚æ¦‚æ‹¬äº†è¿™ç§æ€è·¯ï¼šåœ¨æœåŠ¡å™¨ä¸Šå®‰è£… Nginx æä¾›ç½‘é¡µæœåŠ¡ï¼Œç”¨ Git å®ç°ä»£ç ä¸Šä¼ è‡ªåŠ¨åŒ–ï¼Œè¿™æ ·æœ¬åœ°æ‰§è¡Œä¸€æ¬¡ hexo dï¼ˆdeployï¼‰å°±èƒ½è®©ç½‘ç«™æ›´æ–°ã€‚\næ¨é€åˆ°è¿œç¨‹æ‰˜ç®¡ï¼š\nå°†åšå®¢é™æ€æ–‡ä»¶éƒ¨ç½²åˆ°åƒ GitHub Pagesã€Coding Pages è¿™ç±»å¹³å°ã€‚è¿™éœ€è¦åœ¨ _config.yml ä¸­é…ç½®ï¼š\ndeploy:  type: git  repo: https://github.com/yourname/yourrepo.git  branch: main  # æˆ– gh-pages åˆ†æ”¯ç­‰\nç„¶åè¿è¡Œ hexo generate &amp;&amp; hexo deployï¼ŒHexo ä¼šæŠŠ public æ–‡ä»¶å¤¹å†…å®¹æ¨é€åˆ°æŒ‡å®šä»“åº“çš„åˆ†æ”¯ã€‚å¯¹äº GitHub Pagesï¼Œå¦‚æœ repo æ˜¯ yourname.github.io åˆ™ç›´æ¥ç”¨ä¸»åˆ†æ”¯ï¼›è‹¥æ˜¯é¡¹ç›®ä»“åº“ï¼Œå¯ä»¥ç”¨ gh-pages åˆ†æ”¯æ‰˜ç®¡ã€‚\néƒ¨ç½²åï¼ŒGitHub Pages æœåŠ¡å°†æ‰˜ç®¡ä½ çš„é™æ€åšå®¢ï¼Œä½ å¯ä»¥ä½¿ç”¨è‡ªå®šä¹‰åŸŸåç»‘å®šå®ƒã€‚ä½†æ³¨æ„ï¼šå¦‚æœä½ å¸Œæœ›åšå®¢è¿è¡Œåœ¨è‡ªå·±çš„æœåŠ¡å™¨ä¸Šï¼ˆè€Œéç¬¬ä¸‰æ–¹å¹³å°ï¼‰ï¼Œåˆ™è¿™ç§æ–¹æ¡ˆä¸æ¶‰åŠä½ çš„æœåŠ¡å™¨ Nginxã€‚å¦å¤–ï¼Œå›½å†…è®¿é—® GitHub Pages å¯èƒ½ä¸ç¨³å®šï¼Œéœ€ç»“åˆå®é™…æƒ…å†µè€ƒè™‘ã€‚\næ¨é€åˆ°è‡ªå·±æœåŠ¡å™¨ï¼š\næ­å»ºå±äºè‡ªå·±çš„ Git è‡ªåŠ¨åŒ–éƒ¨ç½²æµç¨‹ï¼Œå®ç°å°†æœ¬åœ°æ›´æ–°ä¸€é”®éƒ¨ç½²åˆ°æœåŠ¡å™¨ã€‚æ­¥éª¤å¦‚ä¸‹ï¼š\n\nåœ¨æœåŠ¡å™¨ä¸Šåˆ›å»ºä¸€ä¸ªè£¸ä»“åº“ï¼ˆbare repositoryï¼‰ï¼Œç”¨äºæ¥æ”¶æ¨é€ã€‚ä¾‹å¦‚åˆ›å»º /home/git/hexo.git è£¸ä»“åº“ã€‚\nç¼–å†™ Git é’©å­ï¼ˆpost-receiveï¼‰ï¼šè£¸ä»“åº“çš„ hooks/post-receive è„šæœ¬ä¼šåœ¨æ”¶åˆ°æ–°æ¨é€æ—¶æ‰§è¡Œã€‚è„šæœ¬å†…å®¹å¯ä»¥æ˜¯å°†æ›´æ–°çš„å†…å®¹æ£€å‡ºåˆ° Nginx ç›®å½•ã€‚ä¾‹å¦‚ï¼š\nGIT_WORK_TREE=/var/www/hexo git checkout -f  # å°†ä»“åº“å†…å®¹å¼ºåˆ¶æ£€å‡ºåˆ° /var/www/hexocd /var/www/hexo &amp;&amp; hexo generate            # ï¼ˆè‹¥æ¨é€çš„æ˜¯æºç è€Œéç”Ÿæˆæ–‡ä»¶ï¼Œåˆ™éœ€è¦åœ¨æœåŠ¡å™¨æ‰§è¡Œç”Ÿæˆï¼‰\nç»™è„šæœ¬å¯æ‰§è¡Œæƒé™ï¼š\nchmod +x post-receive\nè¿™æ ·ï¼Œæ¯å½“æ¨é€åˆ°è¯¥ä»“åº“æ—¶ï¼Œå®ƒå°±ä¼šæŠŠæ›´æ–°éƒ¨ç½²åˆ°åšå®¢ç›®å½•å¹¶ç”Ÿæˆæœ€æ–°é¡µé¢ã€‚\næœ¬åœ° Hexo é…ç½®éƒ¨ç½²ï¼šå°† _config.yml ä¸­çš„ deploy.repo è®¾ç½®ä¸ºä¸Šè¿°è£¸ä»“åº“çš„åœ°å€ï¼ˆé€šè¿‡ SSHï¼‰ã€‚ä¾‹å¦‚ï¼š\ndeploy:  type: git  repo: ssh://[emailÂ protected]/home/git/hexo.git  branch: master\nç„¶åæ‰§è¡Œ hexo clean &amp;&amp; hexo deployã€‚Hexo ä¼šé€šè¿‡ Git æ¨é€åˆ°æœåŠ¡å™¨ä»“åº“ï¼Œè§¦å‘ post-receive é’©å­ï¼Œå®ç°è‡ªåŠ¨éƒ¨ç½²ã€‚å®Œæˆåï¼ŒNginx ä¼šç«‹åˆ»æä¾›æ–°å†…å®¹æœåŠ¡ï¼Œæ— éœ€æ‰‹åŠ¨ç™»å½•æœåŠ¡å™¨æ“ä½œã€‚\n\né€šè¿‡è¿™ç§æ–¹æ¡ˆï¼Œå¯ä»¥åœ¨æœ¬åœ°å†™å¥½æ–‡ç« åä¸€æ¡å‘½ä»¤å®Œæˆéƒ¨ç½²ï¼Œéå¸¸é«˜æ•ˆã€‚è®¸å¤šå¼€æºåšå®¢éƒ¨ç½²è„šæœ¬å’Œå·¥å…·ä¹Ÿæ˜¯åŸºäºç±»ä¼¼åŸç†å®ç°çš„ã€‚åˆæ¬¡è®¾ç½®å¯èƒ½ç¨æ˜¾ç¹çï¼Œä½†ä¸€æ—¦é…ç½®æˆåŠŸï¼Œæ—¥å¸¸æ›´æ–°å°†éå¸¸ä¾¿æ·ã€‚\næç¤ºï¼š ä½¿ç”¨ Git è‡ªåŠ¨éƒ¨ç½²éœ€ç¡®ä¿æœåŠ¡å™¨å¼€æ”¾ Git æ‰€ç”¨çš„ SSH ç«¯å£ï¼ˆé»˜è®¤ä¸º 22ï¼‰ï¼Œå¹¶é…ç½®å¥½å…¬é’¥å…å¯†ç™»å½•ï¼Œä»¥ä¾¿ Hexo åœ¨æœ¬åœ°èƒ½é¡ºåˆ©æ¨é€åˆ°æœåŠ¡å™¨ã€‚å¦‚æœä½ çš„æœåŠ¡å™¨ SSH ç«¯å£ä¸æ˜¯ 22ï¼Œå¯åœ¨éƒ¨ç½²é…ç½®ä¸­åŠ å…¥ç«¯å£å·æˆ–åœ¨ .ssh/config ä¸­é…ç½®åˆ«åã€‚å¯¹äºä¸ç†Ÿæ‚‰ Git é’©å­çš„æ–°æ‰‹ï¼Œä¹Ÿå¯ä»¥è€ƒè™‘ä½¿ç”¨ç®€å•çš„ rsync è„šæœ¬åŒæ­¥æ–‡ä»¶æˆ–å€ŸåŠ© CI å¹³å°å®ç°éƒ¨ç½²ï¼Œä½†åŸç†ç±»ä¼¼ã€‚\n\n6. ç»´æŠ¤ä¸ä¼˜åŒ–\nåšå®¢æ­å»ºå®Œæˆå¹¶ä¸æ„å‘³ç€ä¸€åŠ³æ°¸é€¸ï¼Œå®šæœŸçš„ç»´æŠ¤å’Œä¼˜åŒ–èƒ½ä¿è¯åšå®¢ç¨³å®šã€å®‰å…¨ï¼Œå¹¶æŒç»­æå‡ç”¨æˆ·ä½“éªŒã€‚\n\næ’ä»¶æ‰©å±•ï¼š Hexo æ‹¥æœ‰ä¸°å¯Œçš„æ’ä»¶ç”Ÿæ€ï¼Œå¯æ ¹æ®éœ€è¦å®‰è£…æ’ä»¶ä»¥å¢å¼ºåŠŸèƒ½ã€‚\nå¤‡ä»½ä¸ç‰ˆæœ¬æ§åˆ¶ï¼š ä½¿ç”¨ Git ç®¡ç†åšå®¢æºç ï¼Œå®šæœŸå¤‡ä»½ã€‚\næ›´æ–°ä¸å‡çº§ï¼š å…³æ³¨ Hexo çš„ç‰ˆæœ¬æ›´æ–°ã€æ’ä»¶æ›´æ–°ç­‰ã€‚\n\n","categories":["å…¶å®ƒ"]},{"title":"lumos:Efficient Performance Modeling and Estimation for Large-scale LLM Training","url":"/2025/08/17/paper/lumos/","content":"\n\n\nä¸€å¥è¯æ€»ç»“ï¼šLumos æ˜¯ä¸€ä¸ªåŸºäºè¿è¡Œæ—¶ trace çš„å»ºæ¨¡/æ¨¡æ‹Ÿå·¥å…·ï¼Œä» PyTorch Kineto ç­‰é‡‡é›†åˆ°çš„äº‹ä»¶ä¸­è‡ªåŠ¨æ¢å¤ç²¾ç»†çš„æ‰§è¡Œå›¾ï¼ˆå«ç®—-é€šé‡å ä¸è·¨æµä¾èµ–ï¼‰ï¼Œå¹¶æ”¯æŒåœ¨ä¸é‡æ–°è·‘æ¨¡å‹çš„æƒ…å†µä¸‹ï¼Œå¯¹ DP/PP/æ¨¡å‹ç»“æ„ åš â€œwhat-ifâ€ ä¿®æ”¹ä¸å¿«é€Ÿä¼°ç®—ï¼›åœ¨ 512Ã—H100 é›†ç¾¤ä¸Šå›æ”¾å¹³å‡è¯¯å·®çº¦ 3.3%ã€‚(arXiv)\n\n\n1. æ ¸å¿ƒè´¡çŒ®ä¸å®šä½\n\nç²¾ç»†æ‰§è¡Œå›¾ï¼šä»…ç”¨æ¡†æ¶å†…ç½®çš„ profilerï¼ˆå¦‚ PyTorch Kinetoï¼‰å³å¯ä» CPU/GPU äº‹ä»¶æ¢å¤å››ç±»å…³é”®ä¾èµ–ï¼ˆCPUâ†’GPUã€GPUâ†’CPUã€åŒæµé¡ºåºã€è·¨æµäº‹ä»¶ï¼‰ï¼Œç²¾å‡†è¡¨è¾¾ç®—-é€šé‡å ä¸åŒæ­¥å…³ç³»ã€‚(arXiv)\nå›¾ç¼–è¾‘ &amp; å¿«é€Ÿå¤–æ¨ï¼šåœ¨ä¸æ”¹åŠ¨æ¨¡å‹/ç³»ç»Ÿçš„å‰æä¸‹ï¼Œä»åŸå§‹ trace-graph å‡ºå‘ï¼Œå¯¹ æ•°æ®å¹¶è¡Œï¼ˆDPï¼‰ã€æµæ°´å¹¶è¡Œï¼ˆPPï¼‰ ä¸æ¨¡å‹å±‚æ•°/éšè—ç»´åº¦åšå›¾çº§æ”¹å†™ï¼Œå†ç”¨æ¨¡æ‹Ÿå™¨é‡æ”¾ä¸€æ•´ä¸ªè¿­ä»£ä¼°ç®—æ€§èƒ½ã€‚(arXiv)\né«˜ç²¾åº¦å›æ”¾ï¼šåœ¨ç”Ÿäº§é›†ç¾¤ æœ€å¤š 512Ã—H100ã€å¤šç§ GPT-3 å˜ä½“ã€ä¸åŒå¹¶è¡Œç­–ç•¥ä¸‹ï¼Œè¿­ä»£æ—¶é—´å›æ”¾å¹³å‡è¯¯å·® 3.3%ï¼Œå¹¶èƒ½å†ç°å®æµ‹çš„æ‰§è¡Œç»†åˆ†å æ¯”ã€‚(arXiv)\n\n\n2. Lumos å¦‚ä½•ä» trace æ„å»ºæ‰§è¡Œå›¾\n\näº‹ä»¶æ¥æºï¼šç›´æ¥ä½¿ç”¨ PyTorch/TensorFlow çš„å†…ç½® profilerï¼ˆå¦‚ Kinetoï¼‰ï¼Œæ— éœ€å¯¹æ¨¡å‹æˆ–æ¡†æ¶åšä¾µå…¥å¼æ”¹é€ ã€‚(arXiv)\nä¾èµ–å»ºæ¨¡ï¼ˆå››ç±»ï¼‰ï¼š\n\nCPUâ†’GPUï¼ˆlaunchï¼‰ï¼šç”¨ correlation ID ç»‘å®š CPU ç«¯çš„ cudaLaunchKernel/cudaMemsetAsync ä¸å¯¹åº”çš„ GPU kernelã€‚\nGPUâ†’CPUï¼ˆåŒæ­¥ï¼‰ï¼šcudaDeviceSync/cudaStreamSync ç­‰éœ€è¦ç­‰åˆ°ç›¸å…³ GPU kernel å®Œæˆã€‚\nåŒæµé¡ºåºï¼šåŒä¸€ CUDA stream å†…æ ¸ä¸¥æ ¼é¡ºåºã€‚\nè·¨æµäº‹ä»¶ï¼šcudaEventRecord ä¸ cudaStreamWaitEvent å½¢æˆâ€œè®°å½•â†’ç­‰å¾…â€çš„è·¨æµä¾èµ–ï¼Œè¡¨è¾¾ä¸åŒæµé—´çš„æœ‰åºæ€§ã€‚(arXiv)\n\n\n\n3. å›¾ç¼–è¾‘ï¼šæ”¯æŒå“ªäº› â€œwhat-ifâ€ æ”¹åŠ¨\n\næ•°æ®å¹¶è¡Œï¼ˆDPï¼‰ï¼šåªéœ€è°ƒæ•´é€šä¿¡ä»»åŠ¡ï¼ˆå¦‚æ¢¯åº¦è§„çº¦ç±»ï¼‰çš„æ‰§è¡Œæ—¶é—´ï¼›æœ¬åœ°è®¡ç®—ä¸å˜ã€‚(arXiv)\næµæ°´å¹¶è¡Œï¼ˆPPï¼‰ï¼š\n\nå…ˆæŒ‰æ‰€é€‰è°ƒåº¦ï¼ˆå¦‚ 1F1Bï¼‰æ›´æ–°å„å¾®æ‰¹çš„å‰åå‘é¡ºåºï¼›\nå°†åŸå›¾ä¸­ä»»åŠ¡æŒ‰å±‚èšç±»åé‡åˆ†é…åˆ°æ–° stageï¼›\nåœ¨ stage è¾¹ç•Œæ’å…¥/é‡è¿æ¿€æ´»ä¸æ¢¯åº¦çš„ send/recvï¼›\nä¿ç•™åŸ trace ä¸­çš„ä¾èµ–æ¨¡å¼ä»¥ä¿è¯å¯é‡æ”¾æ­£ç¡®æ€§ã€‚(arXiv)\n\næ¨¡å‹ç»“æ„ï¼š\n\néšè—ç»´åº¦å˜æ›´ï¼šé‡å†™ç›¸å…³ç®—å­/å†…æ ¸çš„è¾“å…¥å¼ é‡ç»´åº¦å¹¶é‡ä¼°æ—¶é•¿ï¼›\nå±‚æ•°å˜æ›´ï¼šå¤åˆ¶/åˆ å‡å±‚å—å¹¶é‡è¿ä¾èµ–ä¸é€šä¿¡ã€‚(arXiv)\n\næš‚ä¸æ”¯æŒï¼šä¿®æ”¹ Tensor Parallelismï¼ˆTPï¼‰ï¼ˆé€šå¸¸å—é™äºå•æœºä¸”é€šä¿¡é‡ï¼Œç•™ä½œæœªæ¥å·¥ä½œï¼‰ã€‚(arXiv)\n\n\n4. æ¨¡æ‹Ÿå™¨ï¼šäº‹ä»¶é©±åŠ¨æµç¨‹ï¼ˆè®ºæ–‡ç®—æ³• 1 çš„è¦ç‚¹ï¼‰\n\nç»´æŠ¤ä¸¤ä¸ªé›†åˆï¼š\n\nå›ºå®šä¾èµ–ï¼ˆåˆå§‹åŒ–é˜¶æ®µä¸€æ¬¡æ€§ç¡®å®šï¼Œå¦‚åŒçº¿ç¨‹/åŒæµé¡ºåºã€CPUâ†’GPU çš„ launch è¾¹ï¼‰ï¼›\nè¿è¡ŒæœŸä¾èµ–ï¼ˆä¾‹å¦‚ cudaStreamSync éœ€è¦ç­‰å¾…**è¯¥æµä¸Šâ€œæœ€åä¸€ä¸ª kernelâ€**å®Œæˆï¼Œè¿™ä¸ªâ€œæœ€åâ€è¦åœ¨è°ƒåº¦æ—¶æ‰èƒ½ç¡®å®šï¼‰ã€‚\n\nä¸»å¾ªç¯ï¼šä»å°±ç»ªé›†åˆå–ä»»åŠ¡ â†’ åˆ†é…åˆ°å…¶â€œå¤„ç†å™¨â€ï¼ˆCPU çº¿ç¨‹/CUDA streamï¼‰ä¸Šè¿è¡Œ â†’ æ›´æ–°å¤„ç†å™¨å¯ç”¨æ—¶é—´ä¸åç»§ä»»åŠ¡çš„æœ€æ—©å¯å¯åŠ¨æ—¶é—´ï¼›è‹¥ä»æœ‰è¿è¡ŒæœŸä¾èµ–æœªæ»¡è¶³åˆ™å»¶åã€‚(arXiv)\n\n\n5. è¯„æµ‹è®¾ç½®ä¸å…³é”®æ•°å­—\n\nè§„æ¨¡ä¸ç¯å¢ƒï¼šæœ€å¤š 512Ã—H100ï¼ˆ32 å°ä¸»æœºï¼‰ï¼ŒRoCE æ•°æ®ä¸­å¿ƒç½‘ç»œï¼ˆæ¯ä¸»æœº 8Ã—400Gbpsï¼‰ï¼ŒCUDA 12.4ï¼ŒPyTorch 2.5ï¼ŒTransformer Engine 0.12.0ï¼ŒLightning 1.9.4ã€‚(arXiv)\nå¯¹æ¯”åŸºçº¿ï¼šä¸ dPROï¼ˆtrace-driven å›æ”¾ç³»ç»Ÿï¼‰ç›¸æ¯”ï¼ŒLumos åœ¨å¤æ‚å¹¶è¡Œé…ç½®ä¸‹èƒ½æ›´å¥½æ•æ‰è·¨æµä¾èµ–ä¸ç®—-é€šé‡å ï¼Œæ˜¾è‘—é™ä½å›æ”¾è¯¯å·®ã€‚(arXiv)\nç»“æœï¼šå›æ”¾å¹³å‡è¯¯å·® ~3.3%ï¼›å¹¶å±•ç¤ºåœ¨ DP/PP/ç»“æ„å¤–æ¨æ—¶çš„ä¼°ç®—å‡†ç¡®æ€§ä¸æ‰§è¡Œç»†åˆ†ï¼ˆæš´éœ²è®¡ç®—/æš´éœ²é€šä¿¡/é‡å /å…¶ä»–ï¼‰ã€‚(arXiv)\n\n\n6. å·¥ç¨‹å®ç°ä¸ä½¿ç”¨é—¨æ§›\n\nå®ç°è§„æ¨¡ï¼šçº¦ 5,200 è¡Œ Pythonã€‚(arXiv)\næ¥å…¥æˆæœ¬ï¼šåœ¨è®­ç»ƒä»£ç é‡Œæ’å…¥ ~10 è¡Œ profiler hook é‡‡é›† Kineto traceï¼Œéšåèµ°è‡ªåŠ¨åŒ–æµç¨‹ï¼šå»ºå›¾ â†’ å›¾ç¼–è¾‘ â†’ æ¨¡æ‹Ÿä¼°ç®—ã€‚(arXiv)\n\n\n7. é€‚ç”¨/ä¸é€‚ç”¨åœºæ™¯\n\né€‚ç”¨ï¼š\n\néœ€è¦åœ¨çœŸå®æœºç¾¤å¤–å¿«é€Ÿæ¯”è¾ƒå¹¶è¡Œ/ç»“æ„é…ç½®ï¼ˆDP/PP/å±‚æ•°/éšè—ç»´ï¼‰å¹¶ä¼°ç®—æ”¶ç›Šï¼›\néœ€è¦é«˜ä¿çœŸå›æ”¾æ¥å®šä½ç®—-é€šé‡å ä¸è·¨æµåŒæ­¥å¤„çš„æ€§èƒ½ç“¶é¢ˆã€‚\n\nå½“å‰ä¸é€‚ç”¨/æ³¨æ„ï¼š\n\nä¿®æ”¹ TP çš„å¤–æ¨ï¼ˆè®ºæ–‡æš‚æœªæ”¯æŒï¼‰ï¼›\nè¿½æ±‚ FLOPsã€å†…å­˜ã€å¸¦å®½ã€èƒ½è€—ç­‰ç³»ç»Ÿçº§æŒ‡æ ‡ï¼ˆè®ºæ–‡ç§°ä¸ºåç»­è®¡åˆ’ï¼‰ï¼›\nä¼°ç®—å‡è®¾æ–°é…ç½®å¯æ­£å¸¸è¿è¡Œï¼ˆä¸è€ƒè™‘ OOM ç­‰å¤±æ•ˆæƒ…å½¢ï¼‰ã€‚(arXiv)\n\n\n\n8. ä¸æ—¢æœ‰å·¥ä½œçš„å…³ç³»ï¼ˆç¤ºä¾‹ï¼šdPROï¼‰\n\ndPRO åŒæ ·æ˜¯ trace-driven çš„æ€§èƒ½è¯Šæ–­/å›æ”¾ç³»ç»Ÿï¼Œä½†åœ¨å¤æ‚ LLM å¹¶è¡Œä¸‹ï¼Œè·¨æµä¾èµ–ä¸é‡å çš„ç²¾ç»†å»ºæ¨¡æ›´å›°éš¾ï¼Œå®¹æ˜“å¯¼è‡´è¿‡åº¦ä¹è§‚çš„å¹¶è¡Œé¢„æµ‹ï¼›Lumos åœ¨è¿™äº›æ–¹é¢åšäº†ç³»ç»Ÿå¢å¼ºå¹¶æ˜¾è‘—é™ä½è¯¯å·®ã€‚(arXiv)\n\n\n9. è®ºæ–‡ä¸ä¼šè®®ä¿¡æ¯ï¼ˆå¯å¼•ç”¨ï¼‰\n\nè®ºæ–‡ï¼ˆarXivï¼‰ï¼šâ€œLumos: Efficient Performance Modeling and Estimation for Large-scale LLM Trainingâ€ï¼ˆ2025-04-12 é¦–æ¬¡æäº¤ï¼‰ã€‚(arXiv)\nPDFï¼ˆä½œè€…ä¸»é¡µé•œåƒ/MLSys è®ºæ–‡ï¼‰ï¼šå¯ä¸‹è½½å…¨æ–‡ã€‚(mingyu-liang.github.io)\nMLSys 2025 æ¥æ”¶ä¸æ—¥ç¨‹é¡µé¢ï¼ˆå«æŠ¥å‘Š/å½•æ’­å…¥å£ï¼‰ã€‚(mlsys.org)\n\n\n10. ä»£ç ä¸å¼€æºçŠ¶æ€ï¼ˆæˆªè‡³ 2025-08-15ï¼‰\n\næœªè§å®˜æ–¹ä»£ç åº“é“¾æ¥ï¼ˆarXiv/MLSys é¡µé¢ä¸ä½œè€… PDF ä¸­å‡æœªæä¾›ï¼‰ï¼Œç¤¾åŒºé‡Œå­˜åœ¨åŒåä½†æ— å…³çš„ â€œLumosâ€ é¡¹ç›®ï¼ˆå¦‚ Agent/è§†é¢‘ç”Ÿæˆ/è§†è§‰ç­‰ï¼‰ï¼Œæ³¨æ„åŒºåˆ†ã€‚(arXiv, mlsys.org, GitHub)\n\n\n11. å¿«é€Ÿä¸Šæ‰‹ï¼ˆç¤ºæ„ï¼‰\n\né‡‡é›† Kineto trace â†’ æ„å»ºæ‰§è¡Œå›¾ â†’ åœ¨å›¾ä¸Šç¼–è¾‘ï¼ˆDP/PP/ç»“æ„ï¼‰â†’ æ¨¡æ‹Ÿå›æ”¾/ä¼°ç®—ã€‚ è®ºæ–‡æ­£æ–‡ç»™å‡ºäº†å…¸å‹çš„ PyTorch profiler ç”¨æ³•ç¤ºæ„ä¸å…¨æµç¨‹ç¤ºæ„å›¾ã€‚(arXiv)\n\n\n12. ä½ å¯èƒ½å…³å¿ƒçš„ç»†èŠ‚ï¼ˆç²¾ç‚¼ç‰ˆï¼‰\n\nä¸ºä»€ä¹ˆæ›´å‡†ï¼Ÿ\n\nç”¨ correlation ID ä¸²èµ· CPU launch ä¸ GPU kernelï¼›\næ˜¾å¼æ¢å¤ è·¨æµäº‹ä»¶ï¼ˆRecord/Waitï¼‰ä¸åŒæ­¥ï¼ˆStream/Device Syncï¼‰ï¼›\nåœ¨æ¨¡æ‹Ÿå™¨ä¸­å°†ä¾èµ–åˆ†ä¸ºå›ºå®šä¸è¿è¡ŒæœŸï¼Œç¡®ä¿åƒ â€œç­‰å¾…è¯¥æµæœ€åä¸€ä¸ª kernelâ€ è¿™ç±»è¯­ä¹‰è¢«æ­£ç¡®è¡¨è¾¾ã€‚(arXiv)\n\næ”¹ DP/PP æ€ä¹ˆç®—ï¼Ÿ\n\nDPï¼šåªé‡èµ‹é€šä¿¡ä»»åŠ¡æ—¶é•¿ï¼›\nPPï¼šæ›´æ–°è°ƒåº¦ï¼ˆå¦‚ 1F1Bï¼‰â†’ ä»»åŠ¡æŒ‰å±‚åˆ†ç»„å¹¶é‡åˆ† stage â†’ åœ¨è¾¹ç•Œæ’å…¥ send/recv â†’ ä¿æŒä¾èµ–é—­åˆã€‚(arXiv)\n\n\n\nå‚è€ƒæ–‡çŒ® / é“¾æ¥\n\nLumos è®ºæ–‡ï¼ˆarXiv é¡µé¢ä¸ PDFï¼‰ï¼š(arXiv)\nLumosï¼ˆMLSys 2025 ä¼šè®®é¡µé¢/æ—¥ç¨‹/å½•æ’­ï¼‰ï¼š(mlsys.org)\ndPROï¼ˆtrace-driven å›æ”¾åŸºçº¿è®ºæ–‡ï¼‰ï¼š(arXiv)\n\n\n\næ³¨ï¼šæœ¬æ–‡æ¡£åªæ‘˜å–å¯¹å·¥ç¨‹è½åœ°æœ€å…³é”®çš„äº‹å®ä¸æ–¹æ³•ï¼Œæ›´å¤šå›¾ä¾‹ï¼ˆå¦‚ PPÃ—TP å¾®æ‰¹è°ƒåº¦ç¤ºä¾‹ï¼‰ä¸å®Œæ•´ç®—æ³•ç»†èŠ‚è¯·å‚é˜…åŸè®ºæ–‡æ­£æ–‡ä¸é™„å›¾ã€‚(arXiv)\n\n\n","categories":["è®ºæ–‡é˜…è¯»"],"tags":["paper"]},{"title":"Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism","url":"/2025/11/22/paper/megatron_lm/","content":"\n\nåŸæ–‡ï¼šMegatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism Â· arXiv\n\nä¸€ã€è®ºæ–‡é€Ÿè§ˆ\nMegatron-LMè®ºæ–‡æå‡ºäº†ä¸€ç§åœ¨ç°æœ‰æ·±åº¦å­¦ä¹ æ¡†æ¶ä¸‹è®­ç»ƒè¶…å¤§è§„æ¨¡Transformerè¯­è¨€æ¨¡å‹çš„å®ç”¨æ–¹æ³•ã€‚ä½œè€…é€šè¿‡å±‚å†…æ¨¡å‹å¹¶è¡Œï¼ˆIntra-layer Model Parallelismï¼‰å°†å•ä¸ªTransformerå±‚çš„è®¡ç®—æ‹†åˆ†åˆ°å¤šä¸ªGPUä¸Šæ‰§è¡Œï¼Œä»¥çªç ´å•GPUå†…å­˜é™åˆ¶ã€‚è¿™ä¸€æ–¹æ³•ä»…éœ€åœ¨æ ‡å‡†PyTorchå®ç°ä¸­æ’å…¥å°‘é‡é€šä¿¡æ“ä½œï¼Œæ— éœ€å®šåˆ¶ç¼–è¯‘å™¨æˆ–åº•å±‚åº“ä¿®æ”¹ï¼Œä¾¿å®ç°äº†å¯¹æ•°åäº¿å‚æ•°æ¨¡å‹çš„é«˜æ•ˆè®­ç»ƒã€‚è®ºæ–‡ä»¥GPT-2å’ŒBERTä¸¤ç±»æ¨¡å‹ä¸ºä¾‹ï¼ŒæˆåŠŸåœ¨512å¼ GPUä¸Šè®­ç»ƒäº†çº¦83äº¿å‚æ•°çš„GPT-2æ¨¡å‹å’Œ39äº¿å‚æ•°çš„BERTæ¨¡å‹ï¼Œè¾¾åˆ°äº†å½“æ—¶æœ€å…ˆè¿›çš„æ€§èƒ½å’Œæ•ˆæœã€‚\nåœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œå·¥ç¨‹å®è·µæ˜¯æ ¸å¿ƒï¼šé€šè¿‡å·§å¦™åˆ©ç”¨å¼ é‡å¹¶è¡ŒæŠ€æœ¯ï¼ŒMegatron-LMå……åˆ†å‘æŒ¥äº†GPUé›†ç¾¤ç®—åŠ›ã€‚åœ¨ä¸ç‰ºç‰²è®¡ç®—ç²¾åº¦å’Œæ¨¡å‹æ”¶æ•›çš„å‰æä¸‹ï¼Œä½œè€…å®ç°äº†æ¥è¿‘çº¿æ€§çš„åŠ é€Ÿæ¯”å’Œé«˜è¾¾15.1 PetaFLOPsçš„æŒç»­è®¡ç®—ååã€‚æ›´é‡è¦çš„æ˜¯ï¼Œè®ºæ–‡å±•ç¤ºäº†æ¨¡å‹è§„æ¨¡ä¸æ€§èƒ½çš„è‰¯æ€§å…³ç³»ï¼šéšç€å‚æ•°å¢å¤šï¼Œè¯­è¨€æ¨¡å‹çš„å›°æƒ‘åº¦ï¼ˆperplexityï¼‰æ˜¾è‘—ä¸‹é™ï¼Œä¸‹æ¸¸ä»»åŠ¡å‡†ç¡®ç‡ç¨³æ­¥æå‡ã€‚æ­¤å¤–ï¼Œä½œè€…è¿˜å‘ç°å¯¹äºBERTè¿™ç±»åŒå‘Transformeræ¨¡å‹ï¼Œéœ€è¦å¯¹Layer Normalizationå±‚çš„æ’å…¥ä½ç½®è¿›è¡Œè°ƒæ•´ï¼Œä»¥ç¡®ä¿å¤§æ¨¡å‹è®­ç»ƒè¿‡ç¨‹çš„ç¨³å®šå’Œç²¾åº¦æå‡ã€‚\näºŒã€è®ºæ–‡ç»“æ„\nè®ºæ–‡é¦–å…ˆä»‹ç»äº†ç ”ç©¶èƒŒæ™¯å’ŒæŒ‘æˆ˜ï¼ŒåŒ…æ‹¬å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒçš„è¶‹åŠ¿ä»¥åŠè®­ç»ƒæ­¤ç±»æ¨¡å‹é¢ä¸´çš„å†…å­˜ç“¶é¢ˆï¼ˆç¬¬2èŠ‚ï¼‰ã€‚æ¥ä¸‹æ¥ï¼Œåœ¨æ–¹æ³•éƒ¨åˆ†ï¼ˆç¬¬3èŠ‚ï¼‰ï¼Œä½œè€…è¯¦ç»†æè¿°äº†Transformeræ¶æ„ä¸­çš„æ¨¡å‹å¹¶è¡Œå®ç°æ–¹æ¡ˆï¼Œè§£é‡Šå¦‚ä½•åœ¨ä¸æ”¹å˜æ¨¡å‹åŸºæœ¬ç»“æ„çš„æƒ…å†µä¸‹ï¼Œå°†æ¯ä¸€å±‚çš„è®¡ç®—åˆ†æ‘Šåˆ°å¤šä¸ªè®¾å¤‡ï¼Œå¹¶å®šä¹‰äº†ç›¸åº”çš„é€šä¿¡åŸè¯­ï¼ˆå¦‚All-Reduceï¼‰çš„ä½¿ç”¨ç­–ç•¥ã€‚ç„¶åï¼Œè®ºæ–‡è¿›å…¥å®éªŒè®¾ç½®å’Œç»“æœåˆ†æï¼ˆç¬¬4~5èŠ‚ï¼‰ï¼šä½œè€…ç»™å‡ºäº†æ¨¡å‹ä¸è®­ç»ƒé…ç½®ã€è¯„ä¼°æŒ‡æ ‡ï¼Œå¹¶é€šè¿‡ä¸€ç³»åˆ—å®éªŒå±•ç¤ºäº†æ‰€ææ–¹æ³•çš„æ‰©å±•æ€§å’Œæœ‰æ•ˆæ€§ã€‚å…¶ä¸­ï¼Œç¬¬5èŠ‚åˆ†åˆ«æŠ¥å‘Šäº†é’ˆå¯¹GPT-2ï¼ˆå•å‘è¯­è¨€æ¨¡å‹ï¼‰å’ŒBERTï¼ˆåŒå‘è¯­è¨€æ¨¡å‹ï¼‰çš„é¢„è®­ç»ƒç»“æœï¼Œä»¥åŠåœ¨WikiText103ã€LAMBADAã€RACEç­‰åŸºå‡†ä¸Šçš„æ€§èƒ½å¯¹æ¯”ã€‚æœ€åï¼Œç¬¬6èŠ‚æ€»ç»“äº†ä¸»è¦ç»“è®ºå¹¶è®¨è®ºäº†æœªæ¥å·¥ä½œã€‚\n\næ ¸å¿ƒæ€æƒ³ï¼šé€šè¿‡åœ¨Transformerå±‚å†…å¼•å…¥ç®€æ´é«˜æ•ˆçš„æ¨¡å‹å¹¶è¡Œå’Œé€šä¿¡æœºåˆ¶ï¼ŒMegatron-LMå®ç°äº†è¶…å¤§æ¨¡å‹çš„åˆ†å¸ƒå¼è®­ç»ƒï¼Œåœ¨ç°æœ‰è½¯ç¡¬ä»¶æ ˆä¸Šè¾¾æˆäº†å‰æ‰€æœªæœ‰çš„æ¨¡å‹è§„æ¨¡ä¸æ€§èƒ½æå‡ã€‚\n\nä¸‰ã€æ–¹æ³•ä¸ç³»ç»Ÿè®¾è®¡\næœ¬æ–‡æ–¹æ³•çš„æ ¸å¿ƒæ˜¯åœ¨ä¸æ”¹å˜æ¨¡å‹æ•´ä½“ç»“æ„çš„å‰æä¸‹ï¼Œå°†å•ä¸ªTransformerå±‚çš„è®¡ç®—åˆ’åˆ†åˆ°å¤šä¸ªGPUä¸Šå¹¶è¡Œæ‰§è¡Œã€‚å›´ç»•è¿™ä¸€ç›®æ ‡ï¼Œä½œè€…è§£å†³äº†è‹¥å¹²å­é—®é¢˜ï¼š\n* å¦‚ä½•å¯¹Transformerçš„å…³é”®ç»„æˆï¼ˆè‡ªæ³¨æ„åŠ›å’Œå‰é¦ˆç½‘ç»œï¼‰è¿›è¡Œåˆ’åˆ†ï¼Œä»¥æœ€å°åŒ–è·¨GPUé€šä¿¡ï¼Ÿ * å¦‚ä½•åœ¨PyTorchä¸­ç”¨å°‘é‡åŸç”Ÿæ“ä½œå®ç°ä¸Šè¿°å¹¶è¡Œè®¡ç®—ï¼Œå¹¶ç¡®ä¿è‡ªåŠ¨æ±‚å¯¼æ­£ç¡®å·¥ä½œï¼Ÿ * å¦‚ä½•ä¸æ•°æ®å¹¶è¡Œã€æµæ°´å¹¶è¡Œç­‰å…¶ä»–å¹¶è¡ŒèŒƒå¼å…¼å®¹ï¼Œå……åˆ†åˆ©ç”¨å¤§å‹é›†ç¾¤çš„è®¡ç®—èƒ½åŠ›ï¼Ÿ * å¦‚ä½•åœ¨ä¿æŒæ¨¡å‹ç²¾åº¦å’Œç¨³å®šæ€§çš„åŒæ—¶ï¼Œå®ç°è®¡ç®—ä¸é€šä¿¡çš„é«˜æ•ˆé‡å ï¼Ÿ\n3.1 æ ¸å¿ƒæ¨¡å—ä¸€è§ˆ\n\nå¼ é‡å¹¶è¡ŒTransformerå±‚ï¼šå°†Transformerå±‚å†…éƒ¨çš„å¤§çŸ©é˜µä¹˜æ³•æ‹†åˆ†åˆ°å¤šGPUæ‰§è¡Œã€‚ä¾‹å¦‚ï¼Œå°†è‡ªæ³¨æ„åŠ›å’Œå‰é¦ˆå±‚ä¸­çš„æƒé‡çŸ©é˜µæŒ‰åˆ—æˆ–è¡Œåˆ†å—ï¼Œæ¯ä¸ªGPUè´Ÿè´£ä¸€éƒ¨åˆ†è®¡ç®—ã€‚æ­¤æ¨¡å—çš„ä½œç”¨æ˜¯åœ¨ä¿è¯è®¡ç®—æ­£ç¡®æ€§çš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½å•GPUæ˜¾å­˜å ç”¨ï¼Œå­é—®é¢˜æ¶‰åŠå¦‚ä½•åˆ’åˆ†æƒé‡åŠé‡ç»„è¾“å‡ºã€‚\né€šä¿¡æ“ä½œæ¨¡å—ï¼šæä¾›å¿…è¦çš„GPUé—´é€šä¿¡åŸè¯­ï¼Œå¦‚All-Reduceï¼ˆå…¨å½’çº¦æ±‚å’Œï¼‰å’ŒAll-Gatherï¼ˆå…¨æ±‡é›†ï¼‰ã€‚è¿™äº›é€šä¿¡åœ¨å‰å‘æˆ–åå‘è¿‡ç¨‹ä¸­æ’å…¥ï¼Œç”¨äºæ±‡æ€»è·¨GPUçš„éƒ¨åˆ†ç»“æœæˆ–æ¢¯åº¦ã€‚æ¨¡å—ä½œç”¨æ˜¯åœ¨å¹¶è¡Œè®¡ç®—çš„å„å­éƒ¨åˆ†ä¹‹é—´ä¼ é€’ä¿¡æ¯ï¼Œå¯¹åº”çš„å­é—®é¢˜æ˜¯å¦‚ä½•å°†é€šä¿¡å¼€é”€é™åˆ°æœ€ä½å¹¶é¿å…é˜»å¡è®­ç»ƒæµç¨‹ã€‚\nå¹¶è¡Œè°ƒåº¦æ§åˆ¶ï¼šè´Ÿè´£åè°ƒå¤šGPUçš„æ‰§è¡Œé¡ºåºå’ŒåŒæ­¥ï¼ŒåŒ…æ‹¬åˆ’åˆ†æ•°æ®å¹¶è¡Œç»„ä¸æ¨¡å‹å¹¶è¡Œç»„ã€åœ¨ä¸åŒå¹¶è¡Œç»´åº¦é—´åˆ†é…è®¡ç®—ä»»åŠ¡ç­‰ã€‚å…¶ä½œç”¨æ˜¯ä¿éšœå„GPUæŒ‰è®¡åˆ’ååŒå·¥ä½œï¼Œå­é—®é¢˜åŒ…æ‹¬å¦‚ä½•è®¾è®¡åŒæ­¥ç‚¹ä»¥åŠé¿å…æ­»é”ã€‚\næ··åˆç²¾åº¦ä¸å†…å­˜ä¼˜åŒ–ï¼šåœ¨ä¿è¯è®­ç»ƒç¨³å®šçš„æƒ…å†µä¸‹ä½¿ç”¨åŠç²¾åº¦æµ®ç‚¹ï¼ˆFP16/BF16ï¼‰å’Œæ¢¯åº¦æ£€æŸ¥ç‚¹ç­‰æŠ€æœ¯æ¥è¿›ä¸€æ­¥é™ä½æ˜¾å­˜å ç”¨ã€æé«˜è¿ç®—æ•ˆç‡ã€‚è¯¥æ¨¡å—è¾…åŠ©å¤§è§„æ¨¡å¹¶è¡Œè®­ç»ƒé¡ºåˆ©è¿›è¡Œï¼Œæ¶‰åŠçš„å­é—®é¢˜æ˜¯å¦‚ä½•åœ¨å‡å°å†…å­˜çš„åŒæ—¶ä¸å¼•å…¥æ•°å€¼ä¸ç¨³å®šã€‚\n\n3.2 æ•°æ®æµä¸æ§åˆ¶æµ\næ•´ä¸ªæ¨¡å‹å¹¶è¡Œè®­ç»ƒæµç¨‹å¯ä»¥åˆ†ä¸ºä»¥ä¸‹ä¸»è¦æ­¥éª¤ï¼š 1. æ•°æ®åˆ†å‘ï¼šè®­ç»ƒå¼€å§‹æ—¶ï¼Œæ•°æ®åŠ è½½å™¨å°†æ¯ä¸ªmini-batchåˆ’åˆ†ç»™å„ä¸ªæ•°æ®å¹¶è¡Œç»„ï¼›åœ¨åŒä¸€æ•°æ®å¹¶è¡Œç»„å†…ï¼Œå±äºæ¨¡å‹å¹¶è¡Œç»„çš„å¤šä¸ªGPUæ¥æ”¶ç›¸åŒçš„è¾“å…¥å­æ‰¹ã€‚è¿™ä¿è¯äº†å¹¶è¡ŒGPUåœ¨å¤„ç†åŒä¸€ç»„æ ·æœ¬æ—¶æ‰€éœ€çš„ä¸€è‡´è¾“å…¥ã€‚ 2. å‰å‘ä¼ æ’­ï¼ˆæ¨¡å‹å¹¶è¡Œéƒ¨åˆ†ï¼‰ï¼šå¯¹äºTransformerçš„æ¯ä¸€å±‚ï¼Œæ‰§è¡Œä»¥ä¸‹å­æ­¥éª¤ï¼š * æ¯ä¸ªGPUæŒæœ‰è¯¥å±‚æƒé‡çš„ä¸€éƒ¨åˆ†ï¼ˆä¾‹å¦‚ï¼Œå°†æƒé‡çŸ©é˜µæ²¿åˆ—åˆ’åˆ†ä¸º\\(P\\)å—ï¼Œåˆ†é…ç»™\\(P\\)ä¸ªGPUï¼‰ã€‚å„GPUåŸºäºå®Œæ•´çš„è¾“å…¥æ¿€æ´»\\(X\\)ï¼Œå„è‡ªè®¡ç®—éƒ¨åˆ†çº¿æ€§å˜æ¢ï¼š\\(Y_i = X \\times A_i\\)ï¼ˆå…¶ä¸­\\(A_i\\)è¡¨ç¤ºGPU \\(i\\)ä¸Šçš„æƒé‡å­çŸ©é˜µï¼‰ã€‚å¯¹\\(Y_i\\)åº”ç”¨éçº¿æ€§æ¿€æ´»ï¼ˆå¦‚GeLUï¼‰å¾—åˆ°éƒ¨åˆ†è¾“å‡ºã€‚ * å°†ä¸Šè¿°éƒ¨åˆ†è¾“å‡º\\(Y_i\\)åœ¨GPUé—´è¿›è¡Œé€šä¿¡ç»„åˆã€‚å…·ä½“è€Œè¨€ï¼Œå¯¹å‰é¦ˆå±‚ç¬¬äºŒéƒ¨åˆ†çš„è®¡ç®—ï¼Œå„GPUè®¡ç®—è‡ªå·±çš„éƒ¨åˆ†è¾“å‡º\\(Z_i = Y_i \\times B_i\\)ï¼ˆè¿™é‡Œ\\(B_i\\)æ˜¯è¯¥GPUæŒæœ‰çš„ç¬¬äºŒä¸ªæƒé‡å­çŸ©é˜µï¼‰ã€‚éšåæ‰§è¡Œä¸€æ¬¡All-Reduceé€šä¿¡ï¼šå„GPUå°†\\(Z_i\\)ç›¸åŠ å¹¶åŒæ­¥å¾—åˆ°å®Œæ•´è¾“å‡º\\(Z = \\sum_{i=1}^{P} Z_i\\)ï¼Œå†è¿›å…¥åç»­å±‚ã€‚å¯¹äºè‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œé‡‡ç”¨ç±»ä¼¼ç­–ç•¥ï¼šå„GPUåˆ†åˆ«è®¡ç®—ä¸€éƒ¨åˆ†æ³¨æ„åŠ›å¤´çš„è¾“å‡ºï¼Œæœ€åé€šè¿‡é€šä¿¡æ•´åˆå¾—åˆ°å®Œæ•´çš„å¤šå¤´æ³¨æ„åŠ›ç»“æœã€‚ * ï¼ˆå¯é€‰ï¼‰æ‰§è¡Œå…¶ä»–å¿…è¦æ“ä½œï¼ˆå¦‚Dropoutã€æ®‹å·®è¿æ¥å’ŒLayerNormï¼‰ï¼Œè¿™äº›æ“ä½œå¤§å¤šä¸éœ€è¦è·¨GPUé€šä¿¡æˆ–è€…é€šä¿¡å¼€é”€å¾ˆå°ã€‚è‡³æ­¤å®Œæˆå½“å‰å±‚çš„å‰å‘è®¡ç®—ï¼Œå†å°†ç»“æœä¼ é€’ç»™ä¸‹ä¸€å±‚é‡å¤ä¸Šè¿°è¿‡ç¨‹ã€‚ 3. æŸå¤±è®¡ç®—ï¼šæ¨¡å‹æœ€åä¸€å±‚è¾“å‡ºç»è¿‡å¿…è¦çš„æ‹¼æ¥æˆ–èšåˆåï¼Œç”¨äºè®¡ç®—è¯­è¨€æ¨¡å‹çš„è®­ç»ƒç›®æ ‡ï¼ˆä¾‹å¦‚ï¼ŒGPT-2çš„è‡ªå›å½’ä¸‹ä¸€ä¸ªè¯é¢„æµ‹çš„äº¤å‰ç†µæŸå¤±æˆ–BERTçš„æ©ç è¯­è¨€æ¨¡å‹æŸå¤±ï¼‰ã€‚æŸå¤±æ ‡é‡åœ¨æ•°æ®å¹¶è¡Œç»´åº¦ä¸Šè¿›ä¸€æ­¥åšä¸€æ¬¡All-Reduceï¼Œä»¥ç¡®ä¿å„GPUä½¿ç”¨å…¨å±€ä¸€è‡´çš„æŸå¤±å€¼è¿›è¡Œæ¢¯åº¦è®¡ç®—ã€‚ 4. åå‘ä¼ æ’­ï¼šæŒ‰ç…§å±‚é¡ºåºåå‘ä¼ æ’­æ¢¯åº¦ã€‚åœ¨æ¯ä¸ªå¹¶è¡Œå±‚åä¼ æ—¶æ‰§è¡Œä¸å‰å‘å¯¹å¶çš„é€šä¿¡ï¼š * å¯¹äºå‰å‘ä¸­é€šè¿‡All-Reduceèšåˆçš„è¾“å‡ºï¼Œåœ¨åå‘ä¸­å„GPUä¼šæ”¶åˆ°ç›¸åŒçš„æ¢¯åº¦\\(\\partial Z\\)ï¼Œå› æ­¤ä¸éœ€è¦å†é€šä¿¡ï¼ˆç›¸å½“äºå‰å‘é€šä¿¡çš„â€œä¼´éšâ€æ“ä½œåœ¨åå‘æ˜¯æ’ç­‰ä¼ é€’ï¼‰ã€‚ * å¯¹äºå‰å‘ä¸­æœªé€šä¿¡è€Œå¤åˆ¶å­˜åœ¨çš„è¾“å…¥ï¼ˆä¾‹å¦‚æ¯ä¸ªGPUéƒ½ç”¨åˆ°äº†å®Œæ•´çš„\\(X\\)ï¼‰ï¼Œåå‘æ¢¯åº¦éœ€è¦æ±‡æ€»ï¼šå„GPUæ ¹æ®æœ¬åœ°è®¡ç®—å¾—åˆ°\\(\\partial X_i\\)åï¼Œæ‰§è¡Œä¸€æ¬¡All-Reduceå°†æ¢¯åº¦æ±‚å’Œ\\(\\partial X = \\sum_{i=1}^{P} \\partial X_i\\)ï¼Œå†ä¼ å›ä¸Šä¸€å±‚ã€‚è¿™å¯¹åº”äºå‰å‘å¤åˆ¶æ“ä½œçš„åå‘é€šä¿¡ã€‚ * å„GPUè®¡ç®—è‡ªå·±æŒæœ‰æƒé‡çš„æ¢¯åº¦\\(\\partial A_i, \\partial B_i\\)ï¼Œè¿™äº›æ¢¯åº¦ä¼šåœ¨æ¨¡å‹å¹¶è¡Œç»„å†…ä¿æŒåˆ†å¸ƒçŠ¶æ€ï¼ˆæ¯ä¸ªGPUåªæ›´æ–°è‡ªå·±é‚£éƒ¨åˆ†æƒé‡ï¼‰ã€‚åœ¨æ•°æ®å¹¶è¡Œç»„èŒƒå›´ï¼Œåˆ™éœ€å¯¹æ¢¯åº¦åšAll-Reduceä»¥èšåˆæ¥è‡ªä¸åŒæ•°æ®åˆ†ç‰‡çš„æ›´æ–°ã€‚ 5. å‚æ•°æ›´æ–°ï¼šåœ¨ä¼˜åŒ–å™¨é˜¶æ®µï¼Œå„GPUä½¿ç”¨èšåˆåçš„å…¨å±€æ¢¯åº¦æ›´æ–°å¯¹åº”çš„æƒé‡å­çŸ©é˜µå‚æ•°ã€‚ç”±äºä½¿ç”¨äº†å¦‚Adamä¹‹ç±»çš„ä¼˜åŒ–å™¨ï¼Œæ¯ä¸ªGPUä¹Ÿç»´æŠ¤å¹¶æ›´æ–°ä¸å…¶å‚æ•°å¯¹åº”çš„ä¼˜åŒ–å™¨çŠ¶æ€ï¼ˆå¦‚ä¸€é˜¶ã€äºŒé˜¶åŠ¨é‡ï¼‰ï¼Œä¿è¯å„è‡ªå‚æ•°çš„æ›´æ–°åŒæ­¥ä¸€è‡´ã€‚ 6. è¿­ä»£ä¸åŒæ­¥ï¼šä¸€ä¸ªè®­ç»ƒiterationå®Œæˆåï¼Œè¿›å…¥ä¸‹ä¸€æ‰¹æ•°æ®é‡å¤ä¸Šè¿°è¿‡ç¨‹ã€‚è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå„GPUé€šè¿‡åŒæ­¥é€šè®¯ä¿è¯åœ¨å…³é”®ç‚¹ï¼ˆå¦‚All-Reduceï¼‰ä¸Šä¸€è‡´ï¼Œé¿å…å‡ºç°è®¡ç®—ç«æ€ã€‚åŒæ—¶åˆ©ç”¨æµæ°´çº¿å¹¶è¡Œï¼ˆå¦‚æœ‰ï¼‰å¯ä»¥åœ¨ç­‰å¾…é€šä¿¡æ—¶å¼€å§‹ä¸‹ä¸€å±‚çš„è®¡ç®—ï¼Œä»¥æé«˜è®¡ç®—é€šä¿¡é‡å åº¦ã€‚\né€šè¿‡ä¸Šè¿°æ•°æ®æµä¸æ§åˆ¶æµè®¾è®¡ï¼ŒMegatron-LMå®ç°äº†åœ¨å¤šGPUé—´é«˜å¹¶è¡Œåº¦ä¸”åè°ƒä¸€è‡´çš„è®­ç»ƒè¿‡ç¨‹ã€‚åœ¨å…¸å‹å®ç°ä¸­ï¼Œæ¯å¼ GPUè¿›ç¨‹ä¸¥æ ¼æŒ‰ç…§æ—¢å®šé¡ºåºæ‰§è¡Œï¼Œæ—¢å‘æŒ¥GPUå¹¶è¡Œç®—åŠ›åˆå°†é€šä¿¡å¼€é”€é™è‡³å¿…è¦çš„æœ€å°ã€‚\n3.3 å…³é”®å‡è®¾ä¸é€‚ç”¨èŒƒå›´\nè®­ç»ƒæ¡†æ¶åœ¨è®¾è®¡æ—¶åšå‡ºäº†ä¸€äº›é»˜è®¤å‡è®¾ï¼Œè¿™äº›å‡è®¾ç•Œå®šäº†æ–¹æ³•é€‚ç”¨çš„èŒƒå›´ï¼Œä¹ŸæŒ‡æ˜åœ¨ä½•ç§æƒ…å†µä¸‹æ•ˆæœå¯èƒ½ä¸ä½³ï¼š * é«˜å¸¦å®½ä½å»¶è¿Ÿçš„é€šä¿¡ç½‘ç»œï¼šå‡è®¾GPUä¹‹é—´æ‹¥æœ‰é«˜é€Ÿäº’è”ï¼ˆå¦‚NVLinkæˆ–InfiniBandï¼‰ï¼Œä»¥æ”¯æ’‘é¢‘ç¹çš„All-Reduceæ“ä½œã€‚å¦‚æœé€šä¿¡ç½‘ç»œè¾ƒæ…¢æˆ–è€…èŠ‚ç‚¹é—´å»¶è¿Ÿè¿‡é«˜ï¼Œæ¨¡å‹å¹¶è¡Œçš„åŒæ­¥å¼€é”€å°†æ˜¾è‘—å¢é•¿ï¼Œæ•´ä½“åŠ é€Ÿæ¯”ä¼šé™ä½ç”šè‡³å¤±å»ä¼˜åŠ¿ã€‚ * æ¨¡å‹ç»“æ„æ˜“äºåˆ†å—ï¼šæ–¹æ³•å‡è®¾Transformerå±‚ç­‰ç»“æ„å¯ä»¥æŒ‰ç»´åº¦è§„åˆ™åˆ’åˆ†ï¼ˆä¾‹å¦‚å°†çŸ©é˜µå‡åŒ€åˆ‡åˆ†ï¼‰ã€‚å¦‚æœæ¨¡å‹ä¸­å­˜åœ¨éš¾ä»¥åˆ‡åˆ†çš„ç®—å­æˆ–å¼ºè€¦åˆçš„è·¨é€šé“è¿ç®—ï¼ˆå¦‚æŸäº›è‡ªå®šä¹‰å±‚æˆ–åŠ¨æ€è®¡ç®—å›¾ï¼‰ï¼Œæ¨¡å‹å¹¶è¡Œéš¾ä»¥ç›´æ¥åº”ç”¨ï¼Œéœ€ä¿®æ”¹æ¨¡å‹ç»“æ„æˆ–æ”¾å¼ƒå¹¶è¡Œï¼Œå¦åˆ™ä¼šå¯¼è‡´ä¸æ­£ç¡®æˆ–æ•ˆç‡ä½ä¸‹ã€‚ * è¶³å¤Ÿå¤§çš„batchå’Œè®¡ç®—è´Ÿè½½ï¼šä¸ºæ‘Šè–„é€šä¿¡æˆæœ¬ï¼Œé»˜è®¤è®­ç»ƒä½¿ç”¨è¾ƒå¤§çš„mini-batchå’Œé•¿åºåˆ—ã€‚è‹¥åœºæ™¯ä¸­batchå°ºå¯¸å—é™æˆ–æ¨¡å‹è§„æ¨¡ä¸å¤Ÿå¤§ï¼Œé€šä¿¡å¼€é”€ç›¸å¯¹è®¡ç®—å¯èƒ½å æ¯”è¿‡é«˜ï¼Œä½¿å¹¶è¡Œæ”¶æ•ˆç”šå¾®ã€‚è¿™ç§æƒ…å†µä¸‹ï¼Œç®€å•çš„æ•°æ®å¹¶è¡Œå¯èƒ½æ›´é«˜æ•ˆã€‚ * GPUèµ„æºè§„æ¨¡åŒ¹é…æ¨¡å‹å¤§å°ï¼šå‡å®šæœ‰å……è¶³çš„GPUæ¥åˆ†æ‹…æ¨¡å‹ï¼ˆä¾‹å¦‚83äº¿å‚æ•°æ¨¡å‹éœ€è¦8è·¯æ¨¡å‹å¹¶è¡Œä»¥ä¸Šï¼‰ã€‚å¦‚æœGPUæ•°é‡ä¸è¶³ä»¥åˆ‡åˆ†æ¨¡å‹è‡³å„è‡ªå†…å­˜å®¹é‡å¯å®¹çº³ï¼Œä»ç„¶ä¼šå‡ºç°å†…å­˜ä¸è¶³çš„é—®é¢˜ã€‚æ­¤å¤–ï¼Œæ–¹æ³•æš‚æœªè€ƒè™‘å¼‚æ„å†…å­˜ï¼ˆå¦‚CPUå†…å­˜ã€NVMeï¼‰çš„è°ƒåº¦åˆ©ç”¨ã€‚ * ä¸€è‡´çš„è®¡ç®—ç¯å¢ƒï¼šè¦æ±‚å‚ä¸è®­ç»ƒçš„æ‰€æœ‰GPUç®—åŠ›å‡è¡¡ã€ç¯å¢ƒä¸€è‡´ã€‚è‹¥éƒ¨åˆ†è®¾å¤‡æ€§èƒ½ä¸ä¸€æˆ–å‡ºç°ä¸­æ–­ï¼ŒåŒæ­¥è®­ç»ƒä¼šæ‹–æ…¢è‡³æœ€æ…¢èŠ‚ç‚¹ã€‚è¿™æ„å‘³ç€åœ¨ä¸å…·å¤‡æ•…éšœå®¹é”™æœºåˆ¶æ—¶ï¼Œé›†ç¾¤ä¸­ä»»ä¸€èŠ‚ç‚¹çš„å¤±è´¥éƒ½ä¼šä¸­æ–­æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ã€‚\nä¸Šè¿°å‡è®¾ç¡®ä¿äº†Megatron-LMæ–¹æ³•åœ¨å¤§å‹GPUé›†ç¾¤ã€æ ‡å‡†Transformeræ¨¡å‹åœºæ™¯ä¸‹è¡¨ç°è‰¯å¥½ã€‚å½“è¿™äº›æ¡ä»¶ä¸æ»¡è¶³æ—¶ï¼Œéœ€å¯¹è®­ç»ƒé…ç½®è¿›è¡Œè°ƒæ•´ï¼ˆä¾‹å¦‚å‡å°‘å¹¶è¡Œåº¦ã€é‡‡ç”¨æ¿€æ´»é‡è®¡ç®—æˆ–ZeROä¼˜åŒ–ç­‰ï¼‰æ¥å¼¥è¡¥æˆ–é€‚é…ï¼Œå¦åˆ™è®­ç»ƒæ•ˆç‡å’Œæ•ˆæœå¯èƒ½å—å½±å“ã€‚\n3.4 æ•°å­¦å…¬å¼ä¸ç®—æ³•è§£è¯»\nç”±äºæœ¬æ–‡åé‡ç³»ç»Ÿå®ç°ï¼Œè®ºæ–‡ä¸­å¹¶æœªå¤§é‡ä½¿ç”¨å¤æ‚å…¬å¼æ¨å¯¼ï¼Œä½†å…¶ä¸­å…³é”®è¿‡ç¨‹å¯ç”¨ç®€æ˜çš„æ•°å­¦è¡¨ç¤ºæè¿°å…¶æ­£ç¡®æ€§å’Œé«˜æ•ˆæ€§ã€‚ä¾‹å¦‚ï¼Œå¯¹äºTransformerå‰é¦ˆå±‚ï¼ˆä¸¤ä¸ªçº¿æ€§å±‚çš„ç»„åˆï¼‰åœ¨ä¸¤è·¯æ¨¡å‹å¹¶è¡Œ(\\(P=2\\))ä¸‹çš„åˆ’åˆ†ï¼Œå¯ä»¥è¡¨ç¤ºå¦‚ä¸‹ï¼š\n\nåˆ’åˆ†è®¡ç®—ï¼šè®¾è¾“å…¥å¼ é‡ä¸º\\(X \\in \\mathbb{R}^{B\\times H}\\)ï¼ˆæ‰¹å¤§å°\\(B\\)ï¼Œéšå±‚ç»´åº¦\\(H\\)ï¼‰ï¼Œç¬¬ä¸€å±‚æƒé‡\\(A \\in \\mathbb{R}^{H\\times I}\\)ï¼Œç¬¬äºŒå±‚æƒé‡\\(B \\in \\mathbb{R}^{I\\times H}\\)ï¼Œå…¶ä¸­\\(I\\)ä¸ºå‰é¦ˆå±‚éšç»´åº¦ã€‚å°†\\(A\\)æŒ‰åˆ—å‡åˆ†ä¸ºä¸¤éƒ¨åˆ†\\([A_1,\\ A_2]\\)ï¼Œå°†\\(B\\)æŒ‰è¡Œå‡åˆ†ä¸ºä¸¤éƒ¨åˆ†\\(\\begin{pmatrix}B_1;\\\\ B_2\\end{pmatrix}\\)ï¼ˆè¿™æ ·\\(A_1, A_2 \\in \\mathbb{R}^{H\\times (I/2)}\\)ï¼Œ \\(B_1, B_2 \\in \\mathbb{R}^{(I/2)\\times H}\\)ï¼‰ã€‚\nå±€éƒ¨å‰å‘ï¼šGPUâ‚å’ŒGPUâ‚‚åˆ†åˆ«è®¡ç®—ï¼š\\(Y_1 = \\mathrm{GeLU}(X A_1)\\)ï¼Œ\\(Y_2 = \\mathrm{GeLU}(X A_2)\\)ã€‚ç”±äºå¯¹éçº¿æ€§\\(\\mathrm{GeLU}(Â·)\\)çš„åˆ’åˆ†è¾“å‡ºäº’ä¸ä¾èµ–ï¼Œè¿™ä¸€æ­¥ä¸éœ€è¦é€šä¿¡ã€‚\nå±€éƒ¨åˆå¹¶ï¼šæ¥ç€ï¼Œå„GPUç»§ç»­è®¡ç®—ç¬¬äºŒå±‚å±€éƒ¨è¾“å‡ºï¼š\\(Z_1 = Y_1 B_1\\), \\(Z_2 = Y_2 B_2\\)ã€‚æ­¤æ—¶æ¯ä¸ª\\(Z_i\\)éƒ½æ˜¯æœ€ç»ˆè¾“å‡º\\(Z\\)çš„ä¸€éƒ¨åˆ†è´¡çŒ®ã€‚å®Œæ•´è¾“å‡ºå¯è¡¨ç¤ºä¸º\\(Z = Z_1 + Z_2 = X (A_1 B_1 + A_2 B_2)\\)ã€‚ä¸ºäº†å¾—åˆ°\\(Z\\)ï¼Œç³»ç»Ÿæ‰§è¡Œä¸€æ¬¡All-Reduceå°†\\(Z_1, Z_2\\)åœ¨ä¸¤GPUé—´æ±‚å’ŒåŒæ­¥ï¼Œä½¿æ¯ä¸ªGPUéƒ½è·å¾—å®Œæ•´çš„\\(Z\\)ç”¨äºåç»­è®¡ç®—ã€‚\næ¢¯åº¦å›ä¼ ï¼šåœ¨åå‘ä¼ æ’­ä¸­ï¼Œè®¾æœ€ç»ˆè¾“å‡ºçš„æ¢¯åº¦ä¸º\\(\\partial Z\\)ï¼ˆå„GPUåœ¨All-Reduceåæ‹¥æœ‰ç›¸åŒçš„\\(\\partial Z\\)ï¼‰ã€‚åˆ™æ¯ä¸ªGPUå¯ä»¥å±€éƒ¨è®¡ç®—è‡ªå·±çš„æ¢¯åº¦åˆ†é‡ï¼š\\(\\partial Y_1 = \\partial Z B_1^T\\), \\(\\partial Y_2 = \\partial Z B_2^T\\)ï¼Œä»¥åŠ\\(\\partial X_1 = \\partial Y_1 A_1^T\\), \\(\\partial X_2 = \\partial Y_2 A_2^T\\)ï¼Œè¿˜æœ‰å±€éƒ¨æƒé‡æ¢¯åº¦\\(\\partial B_1 = Y_1^T \\partial Z\\), \\(\\partial B_2 = Y_2^T \\partial Z\\)ï¼Œ\\(\\partial A_1 = X^T (\\partial Y_1)\\), \\(\\partial A_2 = X^T (\\partial Y_2)\\)ã€‚\n\nå¯¹äº\\(\\partial Z\\)ï¼Œå‰å‘å·²é€šè¿‡All-Reduceå¾—åˆ°å®Œæ•´\\(Z\\)ï¼Œåå‘ä¸éœ€é€šä¿¡ï¼Œå„GPUç›´æ¥ä½¿ç”¨\\(\\partial Z\\)è®¡ç®—å³å¯ï¼ˆå³æ¢¯åº¦åœ¨è¿™ä¸€å±‚çš„å‰å‘é€šä¿¡å¯¹åº”åå‘æ’ç­‰ï¼‰ã€‚\nå¯¹äº\\(\\partial X\\)ï¼Œç”±äºå‰å‘æ—¶\\(X\\)çš„è®¡ç®—è¢«å„GPUå¤ç”¨ï¼Œåå‘éœ€å°†å„GPUç®—å¾—çš„\\(\\partial X_i\\)æ±‚å’Œã€‚é€šè¿‡ä¸€æ¬¡All-Reduceï¼Œå¾—åˆ°\\(\\partial X = \\partial X_1 + \\partial X_2\\)å¹¶å°†ç»“æœå¹¿æ’­è‡³ä¸¤GPUï¼ˆè¿™å¯¹åº”å‰å‘å¤åˆ¶çš„åå‘é€šä¿¡æ­¥éª¤ï¼‰ã€‚\næƒé‡æ¢¯åº¦\\(\\partial A_i, \\partial B_i\\)å¤©ç„¶æ˜¯åˆ†å¸ƒå¼çš„ï¼Œå„GPUå„è‡ªè´Ÿè´£è‡ªå·±åˆ†å—çš„æ›´æ–°ï¼›ä¸åŒæ•°æ®å¹¶è¡Œå®ä¾‹çš„æƒé‡æ¢¯åº¦ç¨åè¿˜éœ€è·¨èŠ‚ç‚¹æ±‚å’Œå¹³å‡ï¼Œä½†åœ¨æ¨¡å‹å¹¶è¡Œç»„å†…éƒ¨ä¸éœ€è¦é¢å¤–åŒæ­¥ã€‚\n\n\nä¸Šè¿°è¿‡ç¨‹ä½“ç°äº†ä½œè€…å¼•å…¥çš„ä¸¤ä¸ªå…³é”®é€šä¿¡ç®—å­\\(f\\)å’Œ\\(g\\)çš„ä½œç”¨:contentReferenceoaicite:2ï¼š * è¿ç®—\\(g\\)åœ¨å‰å‘æ˜¯All-Reduceï¼ˆå¦‚å°†\\(Z_i\\)æ±‚å’Œå¾—åˆ°\\(Z\\)ï¼‰ï¼Œåœ¨åå‘åˆ™æ˜¯æ’ç­‰ä¼ é€’æ¢¯åº¦ï¼› * è¿ç®—\\(f\\)åœ¨å‰å‘æ˜¯æ’ç­‰ï¼ˆå¦‚å°†\\(X\\)å¤åˆ¶ä½¿ç”¨ï¼‰ï¼Œåœ¨åå‘åˆ™æ˜¯All-Reduceï¼ˆæ±‡æ€»\\(\\partial X\\)ï¼‰ã€‚\né€šè¿‡è¿™å¯¹å…±è½­ç®—å­\\(f/g\\)ï¼Œä½œè€…ä»…ç”¨å¯¥å¯¥æ•°è¡Œä»£ç å®ç°äº†æ¨¡å‹å¹¶è¡Œæ‰€éœ€çš„åŒæ­¥ã€‚æ•´ä½“è€Œè¨€ï¼Œè™½ç„¶è®ºæ–‡å…¬å¼ä¸å¤šï¼Œä½†ç®—æ³•æœ¬èº«åŸºäºä»¥ä¸Šç®€å•æ­£ç¡®çš„çº¿æ€§ä»£æ•°å…³ç³»ï¼Œç¡®ä¿å¹¶è¡Œè®¡ç®—å®Œå…¨ç­‰ä»·äºåŸå§‹å…¨æ¨¡å‹è®¡ç®—ã€‚æ­¤å¤–ï¼Œè®­ç»ƒæ—¶è¿˜æ­é…äº†æ ‡å‡†çš„äº¤å‰ç†µæŸå¤±\\(\\mathcal{L}(\\theta) = -\\frac{1}{N}\\sum_{i=1}^{N}\\log P_\\theta(w_i \\mid \\text{context}_i)\\)æ¥å½¢å¼åŒ–è¯­è¨€æ¨¡å‹ç›®æ ‡ï¼Œå…¶ä¸­\\(P_\\theta\\)æ˜¯æ¨¡å‹å¯¹è¯\\(w_i\\)çš„é¢„æµ‹æ¦‚ç‡ã€‚æ¨¡å‹é€šè¿‡æœ€å°åŒ–æ­¤æŸå¤±è®­ç»ƒï¼ŒåŒæ—¶ä»¥å›°æƒ‘åº¦ï¼ˆPerplexityï¼‰\\(\\mathrm{PPL} = \\exp(\\mathcal{L})\\)è¡¡é‡æ¨¡å‹å¯¹è¯­è¨€çš„æ‹Ÿåˆç¨‹åº¦ã€‚\nä¸å¸¸è§è®­ç»ƒæ ˆçš„å¯¹åº”å…³ç³»ï¼šä¸Šè¿°Megatron-LMçš„å®ç°ä¸å…¸å‹æ·±åº¦å­¦ä¹ è®­ç»ƒæ ˆå„ç»„ä»¶ä¸€ä¸€å¯¹åº”ï¼š * æ•°æ®åŠ è½½ï¼šåˆ©ç”¨å¸¸è§„çš„æ•°æ®è¯»å–ç®¡é“ï¼Œç»“åˆDistributedSamplerç­‰æœºåˆ¶ï¼Œåœ¨æ•°æ®å¹¶è¡Œç»´åº¦ä¸Šåˆ’åˆ†æ•°æ®é›†ã€‚å¯¹äºæ¨¡å‹å¹¶è¡Œç»„å†…çš„GPUï¼Œç¡®ä¿å®ƒä»¬æ”¶åˆ°ç›¸åŒçš„æ ·æœ¬æ‰¹ï¼ˆä¾‹å¦‚é€šè¿‡å›ºå®šéšæœºç§å­æˆ–å¹¿æ’­æ•°æ®ï¼‰æ¥å…±åŒè®¡ç®—ä¸€ä¸ªå­æ‰¹æ¬¡ã€‚è¿™ä¸æ ‡å‡†DataLoaderæµç¨‹å…¼å®¹ï¼Œåªæ˜¯éœ€è¦è€ƒè™‘ç»„å†…æ•°æ®ä¸€è‡´æ€§ã€‚ * å¹¶è¡Œè°ƒåº¦ï¼šé€šè¿‡PyTorchåˆ†å¸ƒå¼é€šä¿¡ç»„ç­‰æ‰‹æ®µï¼Œå°†GPUåˆ’åˆ†ä¸ºå¤šå±‚æ¬¡å¹¶è¡Œç»„ï¼ˆå¦‚æ¯8å—GPUä¸ºä¸€ç»„è¿›è¡Œå¼ é‡æ¨¡å‹å¹¶è¡ŒTPï¼Œå¤šç»„ä¹‹é—´å†åšæ•°æ®å¹¶è¡ŒDPï¼‰ã€‚æ¡†æ¶åˆ©ç”¨PyTorch DDPï¼ˆDistributed Data Parallelï¼‰å’Œè‡ªå®šä¹‰çš„å¹¶è¡Œåº“åè°ƒå„ç»´åº¦ä¸Šçš„åŒæ­¥ã€‚Megatron-LMçš„æ–¹æ³•ä¹Ÿå¯ä¸æµæ°´å¹¶è¡Œ(PP)ç»“åˆä½¿ç”¨ï¼Œå°†æ¨¡å‹å±‚æ‹†åˆ†åˆ°ä¸åŒè®¾å¤‡ä»¥è·å¾—è¿›ä¸€æ­¥æ‰©å±•ã€‚æ­¤å¤–ï¼Œæ–°è¿‘å‡ºç°çš„ä¸Šä¸‹æ–‡å¹¶è¡Œ(CP)ï¼ˆåœ¨åºåˆ—é•¿åº¦ç»´åº¦è¿›è¡Œå¹¶è¡Œï¼‰ä¹Ÿå±äºå¯é€‰æ–¹æ¡ˆï¼Œå°½ç®¡åŸè®ºæ–‡æœªæ¶‰åŠï¼Œä½†æ¦‚å¿µä¸Šå¯ä¸TP/PPäº’è¡¥ï¼Œç”¨äºå¤„ç†è¶…é•¿åºåˆ—ã€‚æ€»ä½“æ¥è¯´ï¼Œå¹¶è¡Œè°ƒåº¦ç”±é«˜å±‚è„šæœ¬æˆ–Launcherè´Ÿè´£ï¼Œæ— éœ€äººå·¥å¹²é¢„æ¯æ­¥é€šä¿¡ï¼Œè®­ç»ƒè¿‡ç¨‹äº•ç„¶æœ‰åºåœ°åœ¨å„è®¾å¤‡ä¸Šå¹¶è¡Œå±•å¼€ã€‚ * å†…æ ¸ç®—å­ï¼šæ¨¡å‹çš„å¤§éƒ¨åˆ†è®¡ç®—ä»é€šè¿‡æ ‡å‡†æ·±åº¦å­¦ä¹ ç®—å­ï¼ˆçŸ©é˜µä¹˜ã€LayerNormã€æ¿€æ´»å‡½æ•°ç­‰ï¼‰å®ç°ã€‚Megatron-LMå……åˆ†åˆ©ç”¨äº†NVIDIA GPUä¸Šçš„cuBLASå’ŒNCCLåº“ï¼Œä¿è¯çŸ©é˜µä¹˜æ³•ã€All-Reduceç­‰å…³é”®è·¯å¾„é«˜åº¦ä¼˜åŒ–ã€‚æ•´ä¸ªå®ç°æœªå¼•å…¥æ–°çš„åº•å±‚å†…æ ¸ï¼Œä»…åœ¨Pythonå±‚å°†å·²æœ‰ç®—å­ç»„åˆä»¥å®ç°æ¨¡å‹å¹¶è¡Œã€‚ç„¶è€Œï¼Œå·¥ç¨‹ä¸Šå›¢é˜Ÿä¹Ÿæ•´åˆäº†ä¸€äº›Kernelä¼˜åŒ–ï¼ˆå¦‚èåˆQKVçº¿æ€§å˜æ¢ã€èåˆDropout+Biasç­‰ï¼‰æ¥å‡å°‘æ¡†æ¶å¼€é”€ï¼Œæé«˜å•æ­¥æ‰§è¡Œæ•ˆç‡ã€‚è¿™å¯¹åº”è®­ç»ƒæ ˆä¸­å¯¹ç®—å­çš„é«˜æ•ˆå®ç°éƒ¨åˆ†ï¼Œä¸å¸¸è§æ¡†æ¶ï¼ˆPyTorchã€DeepSpeedç­‰ï¼‰çš„ä¼˜åŒ–æ€è·¯ä¸€è‡´ã€‚ * é€šä¿¡åç«¯ï¼šä½¿ç”¨NCCLç­‰é«˜æ€§èƒ½é€šä¿¡åº“å®ç°All-Reduceã€All-Gatherç­‰æ“ä½œï¼Œç¡®ä¿åœ¨å¤šGPUå¤šèŠ‚ç‚¹ç¯å¢ƒä¸‹é€šä¿¡é«˜æ•ˆå¯é ã€‚NCCLè´Ÿè´£åº•å±‚ä¼ è¾“ï¼Œåˆ©ç”¨ç¯å½¢ç®—æ³•ç­‰åœ¨GPUé—´ä¼ è¾“å¼ é‡ï¼Œå¹¶è‡ªåŠ¨ä½¿ç”¨NVLinkæˆ–InfiniBandç­‰äº’è”åŠ é€Ÿã€‚Megatron-LMçš„é€šä¿¡éœ€æ±‚ä¸å…¸å‹Collectiveé€šä¿¡åœºæ™¯åŒ¹é…ï¼Œå¦‚åŒæ­¥SGDä¸­çš„æ¢¯åº¦All-Reduceï¼Œåªæ˜¯è¿™é‡Œåœ¨æ¨¡å‹å†…éƒ¨æ›´é¢‘ç¹ã€‚ç”±äºé‡‡ç”¨æˆç†Ÿåç«¯ï¼Œå¼€å‘è€…ä¸éœ€å…³å¿ƒé€šä¿¡ç»†èŠ‚ï¼Œä½†éœ€è¦æ­£ç¡®è®¾ç½®ç¯å¢ƒï¼ˆå¦‚MPIå¯åŠ¨ã€GPUæ‹“æ‰‘ï¼‰ä»¥å‘æŒ¥å¸¦å®½æ½œåŠ›ã€‚ * è®­ç»ƒè¿‡ç¨‹é›†æˆï¼šä¸Šè¿°å„æ¨¡å—èå…¥è®­ç»ƒä¸»å¾ªç¯ï¼Œä¸å¸¸è§è®­ç»ƒæ ˆä¸­çš„DataLoaderã€Optimizerã€Schedulerå…±åŒæ„æˆå®Œæ•´æµç¨‹ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒMegatron-LMä¸ä¸»æµè®­ç»ƒæ¡†æ¶ï¼ˆä¾‹å¦‚NVIDIAçš„Megatron-LMä»£ç åº“ã€Microsoft DeepSpeedç­‰ï¼‰è‰¯å¥½ç»“åˆï¼Œè¿™äº›æ¡†æ¶æä¾›äº†é…ç½®æ¥å£æ¥æ‰“å¼€å¼ é‡å¹¶è¡Œã€æµæ°´å¹¶è¡Œç­‰ç‰¹æ€§ï¼Œä½¿å¾—å®é™…è½åœ°æ—¶åªéœ€åœ¨é…ç½®æ–‡ä»¶ä¸­æŒ‡å®šå¹¶è¡Œç¨‹åº¦å³å¯ï¼Œå¤§å¤§é™ä½äº†å·¥ç¨‹å®æ–½éš¾åº¦ã€‚\né€šè¿‡ä¸Šè¿°å¯¹åº”å…³ç³»å¯ä»¥çœ‹å‡ºï¼ŒMegatron-LMçš„æ–¹æ³•è¢«è®¾è®¡ä¸ºå¯ç§»æ¤ã€å¯ç»„åˆçš„ï¼Œå¼€å‘è€…æ— éœ€é‡æ„æ•´ä¸ªè®­ç»ƒæ ˆï¼Œåªéœ€åœ¨å¸¸è§„çš„è®­ç»ƒæµç¨‹ä¸­å¼€å¯ç›¸åº”å¹¶è¡Œç­–ç•¥ï¼Œä¾¿èƒ½åœ¨ç°æœ‰ç¡¬ä»¶ä¸Šè®­ç»ƒè¶…å¤§è§„æ¨¡æ¨¡å‹ã€‚\nå››ã€å»ºæ¨¡æ–¹å¼ä¸è¯„ä¼°æŒ‡æ ‡\n4.1 é—®é¢˜æ˜¯å¦‚ä½•å½¢å¼åŒ–çš„ï¼Ÿ\nä½œè€…å°†è¶…å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹è®­ç»ƒé—®é¢˜å½¢å¼åŒ–ä¸ºç»å…¸çš„æ— ç›‘ç£è¯­è¨€å»ºæ¨¡ä»»åŠ¡ã€‚å¯¹äºGPT-2è¿™ç±»è‡ªå›å½’è¯­è¨€æ¨¡å‹ï¼Œç›®æ ‡æ˜¯åœ¨ç»™å®šå‰æ–‡çš„æ¡ä»¶ä¸‹æœ€å¤§åŒ–ä¸‹ä¸€ä¸ªå•è¯å‡ºç°çš„æ¦‚ç‡ï¼›å¯¹äºBERTè¿™ç±»åŒå‘æ¨¡å‹ï¼Œåˆ™é€šè¿‡æ©ç è¯­è¨€æ¨¡å‹é¢„æµ‹è¢«é®è”½çš„å•è¯ã€‚åŒæ—¶ï¼ŒBERTçš„é¢„è®­ç»ƒè¿˜åŒ…å«ä¸‹ä¸€å¥é¢„æµ‹ç­‰ä»»åŠ¡ã€‚ä½†æ€»ä½“è€Œè¨€ï¼Œè®­ç»ƒå¯å½’ç»“ä¸ºåœ¨å¤§è§„æ¨¡è¯­æ–™ä¸Šæœ€å°åŒ–é¢„æµ‹è¯¯å·®çš„é—®é¢˜ã€‚\nå½¢å¼åŒ–æ¥è¯´ï¼Œç»™å®šè®­ç»ƒè¯­æ–™åºåˆ—\\(\\{w_1, w_2, ..., w_N\\}\\)ï¼Œæ¨¡å‹éœ€å­¦ä¹ å‚æ•°\\(\\theta\\)ä»¥æœ€å¤§åŒ–åºåˆ—æ¦‚ç‡\\(P_\\theta(w_1, ..., w_N)\\)ã€‚è¿™é€šå¸¸è½¬åŒ–ä¸ºæœ€å°åŒ–äº¤å‰ç†µæŸå¤±ï¼š \\[L(\\theta) = -\\frac{1}{N}\\sum_{t=1}^{N} \\log P_\\theta(w_t \\mid w_{&lt;t})\\] å¯¹äºGPT-2ï¼Œ\\(P_\\theta(w_t \\mid w_{&lt;t})\\)æ˜¯åŸºäºå…ˆå‰æ‰€æœ‰è¯é¢„æµ‹ä¸‹ä¸€è¯çš„æ¦‚ç‡ï¼›å¯¹äºBERTï¼Œè®­ç»ƒæ—¶å¯¹éšæœºé®è”½çš„è¯\\(w_k\\)é¢„æµ‹å…¶åŸè¯ã€‚è¯¥æŸå¤±è¡¡é‡æ¨¡å‹å¯¹è®­ç»ƒåˆ†å¸ƒçš„æ‹Ÿåˆç¨‹åº¦ï¼Œè¶Šå°è¡¨ç¤ºæ¨¡å‹å¯¹ä¸Šä¸‹æ–‡çš„é¢„æµ‹è¶Šå‡†ç¡®ã€‚ä¸ºä¾¿äºè§£é‡Šè®­ç»ƒéš¾åº¦ï¼Œè®ºæ–‡è¿˜ä½¿ç”¨å›°æƒ‘åº¦ï¼ˆPerplexity, PPLï¼‰æŒ‡æ ‡ï¼Œå°†å¹³å‡æŸå¤±æŒ‡æ•°åŒ–ï¼š\\(\\mathrm{PPL} = \\exp(L)\\)ï¼Œå®ƒè¡¨ç¤ºæ¨¡å‹åœ¨ä¸ç¡®å®šåº¦ä¸Šçš„ç­‰æ•ˆè¯æ±‡è¡¨è§„æ¨¡ï¼Œå›°æƒ‘åº¦è¶Šä½æ„å‘³ç€è¯­è¨€æ¨¡å‹è¶Šå¥½ã€‚\nåœ¨æ¨¡å‹å¹¶è¡Œçš„èƒŒæ™¯ä¸‹ï¼Œä½œè€…æ²¡æœ‰å¯¹ç›®æ ‡å‡½æ•°è¿›è¡Œä¿®æ”¹ï¼Œæ¨¡å‹å¹¶è¡Œä»…æ”¹å˜äº†è®¡ç®—åˆ†å¸ƒæ–¹å¼ï¼Œä¸å½±å“ä¸Šè¿°å½¢å¼åŒ–å®šä¹‰ã€‚å› æ­¤ï¼Œé—®é¢˜ä»ç„¶æ˜¯é€šè¿‡æ¢¯åº¦ä¸‹é™æ±‚è§£\\(\\min_\\theta L(\\theta)\\)ã€‚ä¸åŒçš„æ˜¯ï¼Œä»–ä»¬æ„å»ºäº†ä¸€ä¸ªå¯æ‰©å±•çš„è®¡ç®—ç»“æ„ä½¿è¿™ä¸ªä¼˜åŒ–è¿‡ç¨‹åœ¨æ•°ç™¾GPUä¸Šå¹¶è¡Œå®Œæˆã€‚æ¢è¨€ä¹‹ï¼Œå½¢å¼åŒ–çš„ç›®æ ‡ä¿æŒä¸å˜ï¼Œå˜åŒ–çš„æ˜¯å®ç°è¿™ä¸€ç›®æ ‡çš„è®¡ç®—ç­–ç•¥ã€‚\n4.2 æ ¸å¿ƒè¯„ä¼°æŒ‡æ ‡\nä¸ºè¯„ä¼°æ–¹æ³•æ•ˆæœï¼Œè®ºæ–‡é‡‡ç”¨äº†å¤šæ–¹é¢çš„æŒ‡æ ‡ï¼ŒåŒ…æ‹¬æ¨¡å‹æ€§èƒ½å’Œç³»ç»Ÿæ•ˆç‡ï¼š * å›°æƒ‘åº¦ (Perplexity)ï¼šè¯­è¨€æ¨¡å‹å¸¸ç”¨æŒ‡æ ‡ï¼Œå®šä¹‰ä¸ºæµ‹è¯•é›†ä¸Š\\(2^{\\text{äº¤å‰ç†µ}}\\)ã€‚å›°æƒ‘åº¦åæ˜ æ¨¡å‹é¢„æµ‹ä¸‹ä¸€ä¸ªè¯çš„ä¸ç¡®å®šæ€§ï¼Œå€¼è¶Šä½è¡¨ç¤ºæ¨¡å‹é¢„æµ‹è¶Šå‡†ç¡®ã€‚ä½œè€…æŠ¥å‘Šäº†WikiText-103æ•°æ®é›†çš„å›°æƒ‘åº¦ï¼Œç”¨äºè¡¡é‡ä¸åŒå‚æ•°è§„æ¨¡GPT-2æ¨¡å‹çš„è¯­è¨€å»ºæ¨¡èƒ½åŠ›ã€‚ * å‡†ç¡®ç‡ (Accuracy)ï¼šé’ˆå¯¹ä¸‹æ¸¸ä»»åŠ¡çš„è¯„ä»·æŒ‡æ ‡ã€‚ä¾‹å¦‚LAMBADAæ•°æ®é›†çš„å®Œå½¢å¡«ç©ºä»»åŠ¡é‡‡ç”¨å®Œå¥é¢„æµ‹å‡†ç¡®ç‡ï¼ŒRACEé˜…è¯»ç†è§£ä»»åŠ¡é‡‡ç”¨é€‰æ‹©é¢˜å‡†ç¡®ç‡ã€‚è¿™äº›æŒ‡æ ‡è¡¡é‡æ¨¡å‹åœ¨ç‰¹å®šNLPä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼Œæ•°å€¼è¶Šé«˜è¶Šå¥½ã€‚è®ºæ–‡ä¸­ç‰¹åˆ«å…³æ³¨LAMBADAçš„å•è¯é¢„æµ‹å‡†ç¡®ç‡å’ŒRACEè€ƒè¯•é¢˜çš„å‡†ç¡®ç‡æå‡ã€‚ * ä¸‹æ¸¸ä»»åŠ¡ç»¼åˆæŒ‡æ ‡ï¼šå¯¹äºBERTæ¨¡å‹ï¼Œä½œè€…è¯„ä¼°äº†åœ¨GLUEåŸºå‡†ä¸Šçš„å¤šé¡¹ä»»åŠ¡ï¼ˆMNLIã€QQPç­‰ï¼‰çš„å‡†ç¡®ç‡å’Œåœ¨SQuADé—®ç­”ä¸Šçš„F1/Exact Matchç­‰ã€‚è¿™äº›æŒ‡æ ‡ç»¼åˆä½“ç°å¤§æ¨¡å‹åœ¨è¿ç§»å­¦ä¹ åœºæ™¯çš„æ•ˆæœã€‚è®ºæ–‡å°†ä¸åŒè§„æ¨¡BERTæ¨¡å‹åœ¨è¿™äº›ä»»åŠ¡ä¸Šçš„åˆ†æ•°è¿›è¡Œå¯¹æ¯”ï¼Œè¯æ˜æ¨¡å‹è§„æ¨¡æå‡å¸¦æ¥çš„æ€§èƒ½å¢é•¿ã€‚ * è®¡ç®—ååé‡ï¼šä»¥æ¯ç§’å¤„ç†çš„æµ®ç‚¹è¿ç®—æ•°æ¥è¡¡é‡è®­ç»ƒæ•ˆç‡ã€‚ä½œè€…æŠ¥å‘Šäº†åœ¨512 GPUä¸Šè¾¾åˆ°çš„15.1 PetaFLOPsæŒç»­æ€§èƒ½ï¼Œä»¥åŠå•GPUçš„39 TeraFLOPsä¸ºåŸºå‡†:contentReferenceoaicite:3ã€‚è¿™ä¸€æŒ‡æ ‡å±•ç¤ºå¹¶è¡Œä¼˜åŒ–çš„ç¡¬ä»¶æ•ˆç‡ï¼Œæ¥è¿‘ç†è®ºå³°å€¼çš„æ¯”ä¾‹è¶Šé«˜è¡¨ç¤ºå¹¶è¡Œæ–¹æ³•è¶Šé«˜æ•ˆã€‚è®ºæ–‡ä¸­æåˆ°è¾¾åˆ°å•å¡å³°å€¼30%ï¼ˆé‡‡ç”¨FP16è®­ç»ƒï¼‰ï¼Œå¤šå¡æ‰©å±•æ•ˆç‡çº¦76%ã€‚ * æ‰©å±•æ•ˆç‡ (Scaling Efficiency)ï¼šå®šä¹‰ä¸ºå®é™…åŠ é€Ÿæ¯”ä¸ç†æƒ³çº¿æ€§åŠ é€Ÿæ¯”çš„æ¯”å€¼ã€‚ä¾‹å¦‚512å¡è¾¾åˆ°76%æ„å‘³ç€å®é™…é€Ÿåº¦çº¦ä¸ºçº¿æ€§512å€åŠ é€Ÿçš„0.76å€ã€‚ä½œè€…é€šè¿‡å¼±æ‰©å±•ï¼ˆå¢åŠ GPUåŒæ—¶å¢å¤§æ¨¡å‹å‚æ•°ï¼‰å’Œå¼ºæ‰©å±•ï¼ˆå›ºå®šæ¨¡å‹è§„æ¨¡å¢åŠ GPUï¼‰å®éªŒè¯„ä¼°äº†è¯¥å€¼ã€‚é«˜æ‰©å±•æ•ˆç‡è¡¨æ˜å¹¶è¡Œç®—æ³•åœ¨å¢åŠ è®¡ç®—èµ„æºæ—¶èƒ½æœ‰æ•ˆåˆ©ç”¨è€Œéæµªè´¹ç®—åŠ›ã€‚ * è®­ç»ƒç¨³å®šæ€§ï¼šè¿™ä¸æ˜¯æ˜ç¡®çš„æ•°å€¼æŒ‡æ ‡ï¼Œä½†é€šè¿‡lossæ›²çº¿å’Œå¹³ç¨³è®­ç»ƒè¿‡ç¨‹æ¥è¡¡é‡ã€‚ç‰¹åˆ«æ˜¯BERTæ¨¡å‹åœ¨ä¸åŒLayerNormæ”¾ç½®æ–¹å¼ä¸‹çš„å¤§æ¨¡å‹è®­ç»ƒæ˜¯å¦å‘æ•£ï¼Œè¢«ä½œä¸ºæ¯”è¾ƒå†…å®¹ã€‚è®ºæ–‡é€šè¿‡æ›²çº¿å›¾å±•ç¤ºäº†åŸå§‹æ¶æ„ä¸‹å¤§æ¨¡å‹è®­ç»ƒçš„ä¸ç¨³å®šï¼Œä»¥åŠè°ƒæ•´æ¶æ„åçš„ç¨³å®šä¸‹é™ï¼Œä»è€Œä¾§é¢åæ˜ äº†è®­ç»ƒç¨³å®šæ€§æ”¹è¿›ã€‚\nç»¼ä¸Šï¼Œè¿™äº›æŒ‡æ ‡æ¶µç›–æ¨¡å‹æ•ˆæœï¼ˆå›°æƒ‘åº¦ã€å‡†ç¡®ç‡ï¼‰å’Œç³»ç»Ÿæ•ˆç‡ï¼ˆFLOPsã€æ‰©å±•æ¯”ï¼‰ä¸¤ä¸ªæ–¹é¢ã€‚é€šè¿‡åŒæ—¶å…³æ³¨NLPä»»åŠ¡è¡¨ç°å’Œèµ„æºåˆ©ç”¨ç‡ï¼Œä½œè€…å…¨é¢è¯„ä¼°äº†Megatron-LMçš„ä¼˜è¶Šæ€§ã€‚\näº”ã€ä¸»è¦å®éªŒå‘ç°\n\næ¨¡å‹å¹¶è¡Œæœ‰æ•ˆæå‡äº†å¯è®­ç»ƒæ¨¡å‹è§„æ¨¡ä¸æ€§èƒ½ï¼šä½œè€…æˆåŠŸè®­ç»ƒäº†å‚æ•°é‡é«˜è¾¾8.3äº¿ï¼ˆGPT-2ï¼‰å’Œ3.9äº¿ï¼ˆBERTï¼‰çš„è¶…å¤§æ¨¡å‹:contentReferenceoaicite:4:contentReferenceoaicite:5ï¼ˆæ³¨ï¼šåŸæ–‡å•ä½ä¸º billionï¼Œå³10äº¿ï¼Œè¿™é‡Œç®€åŒ–æè¿°ï¼‰ï¼Œæ˜¾è‘—è¶…å‡ºå½“æ—¶å¹¿æ³›ä½¿ç”¨çš„æ¨¡å‹è§„æ¨¡ï¼ˆä¾‹å¦‚BERT-Largeçš„3.36äº¿ï¼‰ã€‚éšç€è§„æ¨¡æ‰©å¤§ï¼Œæ¨¡å‹åœ¨è¯­è¨€å»ºæ¨¡å’Œä¸‹æ¸¸ä»»åŠ¡ä¸Šçš„è¡¨ç°å•è°ƒæå‡:contentReferenceoaicite:6:contentReferenceoaicite:7ã€‚è¿™éªŒè¯äº†â€œå¤§æ¨¡å‹å¸¦æ¥æ›´å¥½æ•ˆæœâ€çš„è¶‹åŠ¿ï¼Œå¹¶è¯æ˜äº†åªè¦é…å¥—çš„å¹¶è¡Œè®­ç»ƒå¾—å½“ï¼Œæå‡å‚æ•°è§„æ¨¡ä¾ç„¶èƒ½å¸¦æ¥æ”¶ç›Šã€‚\næé«˜çš„ç¡¬ä»¶ååä¸å¯æ‰©å±•æ€§ï¼šåœ¨512 GPUçš„GPUé›†ç¾¤ä¸Šï¼ŒMegatron-LMå®ç°äº†15.1 PFLOPsçš„æŒç»­è®­ç»ƒååï¼Œè¾¾åˆ°å•å¡æ€§èƒ½çš„76%æ‰©å±•æ•ˆç‡:contentReferenceoaicite:8ã€‚è€ƒè™‘åˆ°é€šä¿¡å’ŒåŒæ­¥å¼€é”€ï¼Œè¿™ä¸€æ•ˆç‡éå¸¸æ¥è¿‘çº¿æ€§æ‰©å±•çš„ç†æƒ³å€¼ï¼Œè¯´æ˜ä½œè€…çš„æ–¹æ³•å……åˆ†åˆ©ç”¨äº†é›†ç¾¤è®¡ç®—èƒ½åŠ›ã€‚å¼±æ‰©å±•å®éªŒæ˜¾ç¤ºï¼Œæ¨¡å‹å‚æ•°ä¸GPUæ•°é‡åŒæ¯”å¢é•¿æ—¶ï¼ŒåååŸºæœ¬éšGPUçº¿æ€§å¢åŠ ï¼›å¼ºæ‰©å±•å®éªŒä¹Ÿå±•ç¤ºäº†è‰¯å¥½çš„åŠ é€Ÿæ¯”ã€‚è¿™æ„å‘³ç€é€šè¿‡æœ¬æ–¹æ³•ï¼Œå¢åŠ ç®—åŠ›å‡ ä¹å¯ä»¥ç›´æ¥ç”¨äºè®­ç»ƒæ›´å¤§æ¨¡å‹æˆ–åŠ é€Ÿè®­ç»ƒè¿‡ç¨‹ï¼Œå¹¶è¡Œæ”¶ç›Šæ¥è¿‘ç†æƒ³ã€‚\nSOTAæ°´å¹³çš„ä»»åŠ¡æ•ˆæœï¼šè®­ç»ƒå¾—åˆ°çš„8.3B GPT-2æ¨¡å‹åœ¨WikiText103æ•°æ®é›†ä¸Šè¾¾åˆ°10.8çš„å›°æƒ‘åº¦ï¼ˆæ­¤å‰æœ€ä½³ä¸º15.8ï¼‰:contentReferenceoaicite:9ï¼Œåœ¨LAMBADAå®Œå½¢å¡«ç©ºæµ‹è¯•ä¸­å‡†ç¡®ç‡66.5%ï¼ˆæ­¤å‰æœ€ä½³63.2%ï¼‰:contentReferenceoaicite:10ã€‚åŒæ ·ï¼Œ3.9Bçš„Megatron-BERTåœ¨RACEé˜…è¯»ç†è§£ä»»åŠ¡ä¸Šè¾¾åˆ°90.9%å‡†ç¡®ç‡ï¼ˆè¶…è¿‡æ­¤å‰SOTAçš„89.4%ï¼‰:contentReferenceoaicite:11ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œé€šè¿‡å¢åŠ æ¨¡å‹å®¹é‡å’Œä½¿ç”¨æ›´é•¿æ—¶é—´é¢„è®­ç»ƒï¼Œè¯­è¨€æ¨¡å‹å¯ä»¥å¤§å¹…æå‡å¯¹æ–‡æœ¬çš„ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ï¼Œåˆ·æ–°å¤šä¸ªåŸºå‡†ä»»åŠ¡çš„è®°å½•ã€‚\næ¶æ„å¾®è°ƒå¯¹å¤§æ¨¡å‹è‡³å…³é‡è¦ï¼šå®éªŒä¸­ä¸€ä¸ªçªå‡ºçš„å‘ç°æ˜¯ï¼ŒLayerNormçš„ä½ç½®ä¼šå½±å“BERTå¤§å‹æ¨¡å‹çš„è®­ç»ƒå¯è¡Œæ€§:contentReferenceoaicite:12:contentReferenceoaicite:13ã€‚åŸå§‹BERTæ¶æ„åœ¨æ®‹å·®è¿æ¥ä¹‹åä½¿ç”¨LayerNormï¼ˆPost-LNï¼‰ï¼Œä½œè€…å‘ç°å½“å‚æ•°æ‰©å±•åˆ°æ•°äº¿è§„æ¨¡æ—¶è®­ç»ƒå‡ºç°ä¸ç¨³å®šç”šè‡³æ€§èƒ½é€€åŒ–ã€‚é€šè¿‡æ”¹ç”¨Pre-LNæ¶æ„ï¼ˆåœ¨æ¯ä¸ªå­å±‚è®¡ç®—å‰åº”ç”¨LayerNormï¼‰ï¼Œæ¨¡å‹è®­ç»ƒå˜å¾—ç¨³å®šï¼Œå¹¶éšç€è§„æ¨¡å¢åŠ å‡†ç¡®ç‡æŒç»­æå‡:contentReferenceoaicite:14:contentReferenceoaicite:15ã€‚è¿™ä¸€ç°è±¡å¼ºè°ƒäº†åœ¨æ”¾å¤§æ¨¡å‹å°ºå¯¸æ—¶ï¼Œè®­ç»ƒç¨³å®šæ€§å¯èƒ½æˆä¸ºç“¶é¢ˆï¼Œéœ€è¦é€šè¿‡æ¶æ„è°ƒæ•´ï¼ˆæˆ–ä¼˜åŒ–å™¨è¶…å‚è°ƒæ•´ï¼‰æ¥è§£å†³ã€‚\nå·¥ç¨‹å®ç°å¼€æ”¾ä¸”å¯å¤ç”¨ï¼šä½œè€…å°†å®Œæ•´çš„è®­ç»ƒä»£ç å’Œæµæ°´çº¿å®ç°å¼€æºåœ¨NVIDIA/Megatron-LMä»“åº“:contentReferenceoaicite:16ã€‚è¿™æ„å‘³ç€ç ”ç©¶ç¤¾åŒºå’Œå·¥ä¸šç•Œå¯ä»¥ç›´æ¥ä½¿ç”¨è¿™ä¸€æˆæœæ¥è®­ç»ƒè‡ªå·±çš„å¤§æ¨¡å‹ã€‚è¿™åœ¨å½“æ—¶å…·æœ‰é‡è¦æ„ä¹‰ï¼šä¸ä»…è¯æ˜äº†æ–¹æ³•çš„å¯è¡Œæ€§ï¼Œä¹Ÿé™ä½äº†æŠ€æœ¯ä¼ æ’­é—¨æ§›ã€‚è®¸å¤šåç»­å·¥ä½œï¼ˆä¾‹å¦‚å¾®è½¯çš„Turing-NLG 170äº¿å‚æ•°æ¨¡å‹ï¼‰éƒ½å»ºç«‹åœ¨Megatron-LMçš„æ–¹æ³•ä¹‹ä¸Š:contentReferenceoaicite:17:contentReferenceoaicite:18ï¼Œä½“ç°äº†è¯¥å·¥ä½œçš„å½±å“åŠ›å’Œå®ç”¨ä»·å€¼ã€‚\n\n5.1 å…³é”®å›¾è¡¨è§£è¯»\nå®éªŒéƒ¨åˆ†åŒ…å«å¤šå¹…å›¾è¡¨ï¼Œå½¢è±¡åœ°æ”¯æŒäº†ä¸Šè¿°å‘ç°ï¼š * æ‰©å±•æ•ˆç‡æ›²çº¿ï¼šè®ºæ–‡çš„Figure 1å±•ç¤ºäº†ä¸åŒå¹¶è¡Œé…ç½®ä¸‹çš„è®¡ç®—æ•ˆç‡å¯¹æ¯”ã€‚å…¶ä¸­æ¨¡å‹å¹¶è¡Œï¼ˆå¼ é‡å¹¶è¡Œï¼‰éšGPUæ•°é‡å¢é•¿çš„åååŸºæœ¬æ¥è¿‘ç†æƒ³ç›´çº¿ï¼Œè€Œä»…æ•°æ®å¹¶è¡Œåœ¨é«˜GPUæ•°æ—¶æ•ˆç‡å¼€å§‹ä¸‹é™ã€‚å›¾ä¸­æ ‡æ³¨çš„76%æ‰©å±•æ•ˆç‡è¯æ˜äº†8è·¯æ¨¡å‹å¹¶è¡Œåœ¨512å¡ä¸Šä»ä¿æŒé«˜æ•ˆ:contentReferenceoaicite:19ã€‚è¿™ä¸€å›¾è¡¨ç›´è§‚è¯æ˜äº†Megatron-LMæ–¹æ¡ˆçš„é«˜å¯æ‰©å±•æ€§ï¼Œæ”¯æŒç¬¬ä¸€æ¡ä¸»è¦å‘ç°ã€‚ * éªŒè¯å›°æƒ‘åº¦éšè¿­ä»£æ”¶æ•›å›¾ï¼šFigure 6ç»˜åˆ¶äº†ä¸åŒè§„æ¨¡GPT-2æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„å›°æƒ‘åº¦éšè®­ç»ƒè¿›ç¨‹ï¼ˆè¿­ä»£æ•°ï¼‰çš„ä¸‹é™è¶‹åŠ¿:contentReferenceoaicite:20:contentReferenceoaicite:21ã€‚ä»å›¾ä¸­å¯ä»¥çœ‹åˆ°ï¼Œè¾ƒå¤§çš„æ¨¡å‹ä¸ä»…æœ€ç»ˆå›°æƒ‘åº¦æ›´ä½ï¼ˆä¾‹å¦‚8.3Bæ¨¡å‹æœ€ç»ˆéªŒè¯PPLçº¦9.27ï¼Œå°æ¨¡å‹æ˜æ˜¾æ›´é«˜ï¼‰ï¼Œè€Œä¸”æ”¶æ•›æ›´å¿«ï¼ˆåœ¨ç›¸åŒè¿­ä»£å†…å¤§æ¨¡å‹è¾¾åˆ°æ›´ä½PPLï¼‰ã€‚è¿™è¯´æ˜å¢åŠ æ¨¡å‹å®¹é‡å¸¦æ¥çš„æ”¶ç›Šæ˜¯åŒé‡çš„ï¼šæ€§èƒ½æå‡å’Œæ”¶æ•›åŠ é€Ÿï¼Œæ”¯æŒäº†â€œå¤§æ¨¡å‹æ›´æœ‰æ•ˆâ€çš„è®ºæ–­ã€‚ * BERTæ¶æ„å¯¹æ¯”è®­ç»ƒæ›²çº¿ï¼šFigure 7æ¯”è¾ƒäº†åŸå§‹BERTæ¶æ„å’Œè°ƒæ•´LayerNormåæ¶æ„åœ¨è®­ç»ƒå¤§æ¨¡å‹æ—¶çš„lossæ›²çº¿:contentReferenceoaicite:22:contentReferenceoaicite:23ã€‚æ›²çº¿(a)ï¼ˆåŸå§‹ï¼‰å‡ºç°éœ‡è¡ç”šè‡³æ— æ³•é™ä½ï¼Œè€Œæ›²çº¿(b)ï¼ˆè°ƒæ•´åï¼‰å¹³æ»‘æ”¶æ•›åˆ°æ›´ä½lossã€‚è¿™å¼ å›¾å½¢è±¡åœ°æ”¯æ’‘äº†ç¬¬å››æ¡å‘ç°ï¼šæ­£ç¡®çš„LayerNormä½ç½®æ¶ˆé™¤äº†è®­ç»ƒä¸ç¨³å®šï¼Œä½¿å¾—3.9Bå‚æ•°BERTæˆåŠŸæ”¶æ•›å¹¶å–å¾—æ›´é«˜ç²¾åº¦ã€‚å®ƒæé†’æˆ‘ä»¬åœ¨å¤§æ¨¡å‹è®­ç»ƒä¸­ï¼Œå°çš„æ¶æ„æ”¹åŠ¨ä¼šå¸¦æ¥å·¨å¤§å½±å“ã€‚ * ä¸‹æ¸¸ä»»åŠ¡ç»“æœè¡¨æ ¼ï¼šè®ºæ–‡çš„Table 3å’ŒTable 5æ±‡æ€»äº†æ¨¡å‹åœ¨WikiText103ã€LAMBADAç­‰æ— ç›‘ç£ä»»åŠ¡ä»¥åŠRACEã€MNLIç­‰ä¸‹æ¸¸ä»»åŠ¡çš„å…·ä½“æ•°å€¼:contentReferenceoaicite:24:contentReferenceoaicite:25ã€‚ä¾‹å¦‚Table 3æ¸…æ™°åˆ—å‡ºäº†355Mã€2.5Bã€8.3Bå„æ¨¡å‹çš„WikiTextå›°æƒ‘åº¦å’ŒLAMBADAå‡†ç¡®ç‡ï¼Œä»¥åŠè¿‡å»SOTAå¯¹æ¯”:contentReferenceoaicite:26:contentReferenceoaicite:27ã€‚è¿™äº›è¡¨æ ¼æ•°æ®ä¸€ç›®äº†ç„¶åœ°è¯æ˜äº†æ¨¡å‹è§„æ¨¡æå‡å¸¦æ¥çš„æ€§èƒ½å¢ç›Šå’ŒSOTAè¶…è¶Šï¼Œä¸ºç¬¬äºŒå’Œç¬¬ä¸‰æ¡å‘ç°æä¾›äº†å®šé‡ä¾æ®ã€‚\né€šè¿‡ä»¥ä¸Šå…³é”®å›¾è¡¨ï¼Œè¯»è€…å¯ä»¥ç›´è§‚ç†è§£Megatron-LMæ–¹æ³•çš„æ•ˆæœï¼šè®¡ç®—æ•ˆç‡é«˜ã€æ¨¡å‹è¡¨ç°ä¼˜å¼‚ä¸”æ¶æ„è°ƒæ•´å‘æŒ¥å…³é”®ä½œç”¨ã€‚æ¯ä¸ªå›¾è¡¨å’Œè¡¨æ ¼éƒ½å¯¹åº”åœ°æ”¯æ’‘äº†å‰æ–‡çš„å®éªŒç»“è®ºã€‚\nç»“æœè§£è¯»ä¸è¾¹ç•Œï¼šæ€»ä½“è€Œè¨€ï¼ŒMegatron-LMçš„å®éªŒç»“æœå±•ç°äº†ä»¤äººä¿¡æœçš„æ€§èƒ½æå‡å’Œæ‰©å±•èƒ½åŠ›ï¼Œè¯æ˜åªè¦è®­ç»ƒèµ„æºå……è¶³ï¼Œå¤§è§„æ¨¡æ¨¡å‹çš„æ½œåŠ›å¯ä»¥è¢«å……åˆ†æŒ–æ˜ã€‚è¿™ä¸€ç»“è®ºå¯¹NLPé¢†åŸŸå½±å“æ·±è¿œâ€”â€”å®ƒä¸ºæ­¤åå‡ºç°çš„æ›´å¤§æ¨¡å‹ï¼ˆå¦‚GPT-3ç­‰ï¼‰å¥ å®šäº†æ–¹æ³•åŸºç¡€ï¼Œè¡¨æ˜é‡‡ç”¨æ¨¡å‹å¹¶è¡Œç­‰æŠ€æœ¯èƒ½å¤Ÿæœ‰æ•ˆåœ°è®­ç»ƒç™¾äº¿çº§å‚æ•°æ¨¡å‹ã€‚ç„¶è€Œï¼Œä¹Ÿéœ€è¦ç†æ€§çœ‹å¾…è¿™äº›ç»“æœçš„é€‚ç”¨èŒƒå›´å’Œå±€é™ï¼š * é¦–å…ˆï¼Œæˆæœ¬ä¸èƒ½è€—è¾¹ç•Œï¼šè¾¾åˆ°è®ºæ–‡ä¸­çš„SOTAç»“æœä¾èµ–æ•°ç™¾GPUæ—¥ä»¥ç»§å¤œçš„è®¡ç®—ï¼ˆè®ºæ–‡æåŠ8.3Bæ¨¡å‹å•è½®epochè®­ç»ƒéœ€çº¦ä¸¤å¤©:contentReferenceoaicite:28:contentReferenceoaicite:29ï¼‰ã€‚è¿™ç§è§„æ¨¡çš„è®¡ç®—ä»£ä»·ä½¿å¾—å¤§æ¨¡å‹è®­ç»ƒä¸»è¦å±€é™äºé¡¶å°–å®éªŒå®¤å’Œå…¬å¸ã€‚æ¢è¨€ä¹‹ï¼Œæ–¹æ³•è™½ç„¶è¯æ˜å¯è¡Œï¼Œä½†åœ¨èµ„æºå—é™ç¯å¢ƒä¸‹éš¾ä»¥å¤ç°ï¼Œæˆæœ¬å’Œèƒ½è€—æ˜¯ç°å®è¾¹ç•Œä¹‹ä¸€ã€‚ * æ¨¡å‹è§„æ¨¡çš„æ”¶ç›Šé€’å‡ï¼šå°½ç®¡è®ºæ–‡ä¸­æ€§èƒ½éšè§„æ¨¡å¢é•¿è€Œæå‡ï¼Œä½†å¹¶æœªç³»ç»Ÿæ¢è®¨å¢é•¿åˆ°æ›´é«˜å‚æ•°é‡æ—¶æ˜¯å¦å­˜åœ¨æ‹ç‚¹æˆ–ç“¶é¢ˆã€‚åç»­ç ”ç©¶æå‡ºäº†Scaling Lawï¼ˆæ‰©å±•è§„å¾‹ï¼‰ï¼ŒæŒ‡å‡ºæ€§èƒ½æå‡å¯¹æ•°é€’å‡ã€‚Megatron-LMçš„ç»“æœä¸»è¦è¦†ç›–åˆ°8Bé‡çº§ï¼Œå¯¹äºç™¾äº¿ç”šæˆ–åƒäº¿å‚æ•°æ˜¯å¦çº¿æ€§é€‚ç”¨ï¼Œä»å­˜åœ¨ä¸ç¡®å®šæ€§ï¼ˆå¾…æ ¸å®ï¼‰ã€‚ * é€šç”¨æ€§ä¸å…¶å®ƒå› ç´ ï¼šè®ºæ–‡é›†ä¸­åœ¨Transformerè¯­è¨€æ¨¡å‹ï¼Œå¯¹å…¶å®ƒæ¶æ„ï¼ˆCNNã€RNNï¼‰æˆ–å…¶å®ƒä»»åŠ¡çš„å¯æ¨å¹¿æ€§æœªåšå®éªŒã€‚ä¾‹å¦‚è§†è§‰æ¨¡å‹çš„å¤§è§„æ¨¡è®­ç»ƒæ˜¯å¦ä¹Ÿèƒ½ç›´æ¥å¥—ç”¨ç±»ä¼¼æ–¹æ³•å°šå¾…éªŒè¯ã€‚æ­¤å¤–ï¼Œè®ºæ–‡å…³æ³¨è§„æ¨¡å’Œå¹¶è¡Œï¼Œæœ¬èº«å¹¶æœªè¯¦ç»†è®¨è®ºä¼˜åŒ–ç®—æ³•ã€æ­£åˆ™åŒ–ç­‰å¯¹æœ€ç»ˆæ€§èƒ½çš„å½±å“ï¼Œè¿™äº›åœ¨æ›´å¤§è§„æ¨¡è®­ç»ƒæ—¶å¯èƒ½å˜å¾—æ˜¾è‘—ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œç»“æœçš„ä¼˜ç§€éƒ¨åˆ†å½’å› äºæ›´å¤§æ¨¡å‹å®¹é‡ï¼Œä½†ä¼˜åŒ–ç»†èŠ‚æˆ–è®­ç»ƒæ•°æ®ç­‰å› ç´ å¯¹ç»“æœçš„è´¡çŒ®æ²¡æœ‰åˆ†åˆ«é‡åŒ–ã€‚ * è¯„æµ‹ç»´åº¦æœ‰é™ï¼šä½œè€…ä¸»è¦ä»¥æ ‡å‡†åŸºå‡†ä»»åŠ¡è¡¡é‡æ¨¡å‹ï¼Œä¾§é‡äºå‡†ç¡®ç‡å’Œå›°æƒ‘åº¦ç­‰æŒ‡æ ‡ã€‚è€Œå¯¹äºå¤§æ¨¡å‹æ½œåœ¨çš„å…¶å®ƒè¯„æµ‹ç»´åº¦ï¼ˆå¦‚æ³›åŒ–èƒ½åŠ›ã€åè§å’Œå…¬å¹³æ€§ã€é²æ£’æ€§ç­‰ï¼‰ï¼Œè®ºæ–‡æ²¡æœ‰æ¶‰çŒã€‚è¿™äº›æ„æˆäº†ç»“æœè§£è¯»çš„è¾¹ç•Œï¼šæ€§èƒ½å“è¶Šä¸ç­‰äºå®Œç¾ï¼Œå¤§æ¨¡å‹åœ¨å®ç”¨ä¸­è¿˜éœ€è¦è€ƒè™‘æ›´å¤šå…¨é¢çš„æŒ‡æ ‡ã€‚\næ€»ä¹‹ï¼ŒMegatron-LMçš„å®éªŒæˆæœåœ¨å¤§æ¨¡å‹è®­ç»ƒé¢†åŸŸæ ‘ç«‹äº†æ ‡æ†ï¼Œä½†åŒæ—¶ä¹Ÿæç¤ºæˆ‘ä»¬æ³¨æ„èƒŒåçš„ä»£ä»·å’Œæœªè§£å†³çš„é—®é¢˜ã€‚åœ¨ç»§ç»­è¿½æ±‚æ›´å¤§æ›´å¼ºæ¨¡å‹çš„é“è·¯ä¸Šï¼Œè¿™äº›è¾¹ç•Œæ¡ä»¶å°†æ˜¯éœ€è¦å…‹æœçš„æŒ‘æˆ˜ã€‚\nå…­ã€ä¼˜ç‚¹ä¸å±€é™\nStrengths â€“ äº®ç‚¹ï¼š * å¤§å¹…æå‡å¯è®­ç»ƒæ¨¡å‹è§„æ¨¡ï¼šMegatron-LMæ–¹æ¡ˆæ˜¾è‘—çªç ´å•æœºæ˜¾å­˜é™åˆ¶ï¼Œä½¿å¾—å½“æ—¶æ¨¡å‹å‚æ•°è§„æ¨¡ä»æ•°äº¿æå‡åˆ°æ•°åäº¿çº§åˆ«æˆä¸ºå¯èƒ½ã€‚è¿™ç§èƒ½åŠ›ç›´æ¥æ¨åŠ¨äº†æ›´é«˜æ€§èƒ½çš„è¯­è¨€æ¨¡å‹å‡ºç°ï¼Œä¸ºä¹‹åçš„è¶…å¤§è§„æ¨¡æ¨¡å‹ï¼ˆå¦‚GPT-3ç­‰ï¼‰é“ºå¹³é“è·¯ã€‚ * å·¥ç¨‹å®ç°ç®€å•é«˜æ•ˆï¼šæ–¹æ³•ä¸ä¾èµ–ç‰¹æ®Šç¼–è¯‘å™¨æˆ–æ¡†æ¶æ”¹åŠ¨ï¼Œä»…é€šè¿‡æ’å…¥All-Reduceç­‰é€šä¿¡æ“ä½œå®ç°ã€‚å€ŸåŠ©PyTorchå·²æœ‰æœºåˆ¶ï¼Œå°±èƒ½è¾¾åˆ°æ¥è¿‘ç†æƒ³çš„æ‰©å±•æ•ˆç‡ã€‚è¿™æ„å‘³ç€ç°æœ‰ä»£ç åº“æ˜“äºé›†æˆï¼Œé™ä½äº†å¹¶è¡Œè®­ç»ƒçš„å®ç°å¤æ‚åº¦ï¼Œå…·æœ‰å¾ˆé«˜çš„å·¥ç¨‹å®ç”¨ä»·å€¼ã€‚ * SOTAæ€§èƒ½è¯æ˜æœ‰æ•ˆæ€§ï¼šè®ºæ–‡ä¸ä»…åœ¨ç†è®ºä¸Šæå‡ºæ–¹æ³•ï¼Œè¿˜é€šè¿‡å®é™…è®­ç»ƒéªŒè¯äº†å¤§æ¨¡å‹å¸¦æ¥çš„æ€§èƒ½æå‡ï¼ŒåŒ…æ‹¬åˆ·æ–°å¤šé¡¹NLPä»»åŠ¡çš„SOTAã€‚è¿™ä¸ºâ€œå¤§æ¨¡å‹æ›´å¥½â€æä¾›äº†ç›´æ¥è¯æ®ï¼Œå¢å¼ºäº†å­¦ç•Œä¸šç•Œå¯¹æŠ•å…¥èµ„æºè®­ç»ƒæ›´å¤§æ¨¡å‹çš„ä¿¡å¿ƒã€‚ * çµæ´»å…¼å®¹å…¶ä»–å¹¶è¡Œç­–ç•¥ï¼šä½œè€…å¼ºè°ƒå…¶å¼ é‡æ¨¡å‹å¹¶è¡Œä¸æ•°æ®å¹¶è¡Œå’Œæµæ°´çº¿å¹¶è¡Œæ˜¯æ­£äº¤ä¸”å¯ç»“åˆçš„ã€‚è¿™ä¸€ç‰¹æ€§è®©æ–¹æ³•å¯åº”ç”¨äºå„ç§é›†ç¾¤è§„æ¨¡å’Œå†…å­˜éœ€æ±‚ä¸‹ï¼Œé€šè¿‡å¤šé‡å¹¶è¡Œçš„ç»„åˆè¿›ä¸€æ­¥æ‰©å±•ã€‚ä¾‹å¦‚8è·¯æ¨¡å‹å¹¶è¡Œé…åˆ64è·¯æ•°æ®å¹¶è¡Œçš„æ··åˆæ–¹æ¡ˆåœ¨è®ºæ–‡ä¸­è·å¾—æˆåŠŸã€‚ * æ¶æ„æ´å¯Ÿä¸æ”¹è¿›ï¼šå·¥ä½œä¸­å‘ç°çš„LayerNormè°ƒæ•´å¯¹BERTæ€§èƒ½çš„å½±å“ï¼Œæ˜¯ä¸€ä¸ªå®è´µçš„ç»éªŒæ•™è®­ã€‚è¿™å±•ç¤ºäº†ä½œè€…å¯¹æ¨¡å‹è®­ç»ƒåŠ¨æ€çš„æ·±å…¥æ´å¯Ÿï¼Œå¹¶æä¾›äº†æ”¹è¿›å¤§æ¨¡å‹ç¨³å®šæ€§çš„ä¸€ä¸ªé€šç”¨æŠ€å·§ï¼ˆåæ¥è¢«å¹¿æ³›é‡‡ç”¨ä¸ºPre-LN Transformeræ¶æ„ï¼‰ã€‚ * å¼€æºä¸å½±å“ï¼šä½œè€…å¼€æºäº†Megatron-LMè®­ç»ƒä»£ç å’Œé…ç½®ï¼Œä¸ºç¤¾åŒºæä¾›äº†ç›´æ¥ä½¿ç”¨å¤§è§„æ¨¡è®­ç»ƒæ–¹æ¡ˆçš„æœºä¼šã€‚è¿™æå¤§åœ°åŠ é€Ÿäº†ç›¸å…³ç ”ç©¶çš„å‘å±•ã€‚éšåè®¸å¤šå¤§å‹æ¨¡å‹è®­ç»ƒï¼ˆMicrosoft Turing-NLG, EleutherAI GPTç­‰ï¼‰éƒ½å€Ÿé‰´æˆ–ç›´æ¥ä½¿ç”¨äº†Megatron-LMçš„å®ç°ï¼Œå……åˆ†ä½“ç°äº†æœ¬å·¥ä½œçš„å½±å“åŠ›ã€‚\nLimitations â€“ å±€é™ï¼š * èµ„æºè¦æ±‚æé«˜ï¼šè¯¥æ–¹æ³•éœ€è¦å¤§é‡GPUååŒè®­ç»ƒæ‰èƒ½å‘æŒ¥ä¼˜åŠ¿ã€‚è®ºæ–‡å®éªŒç”¨åˆ°512å—V100 GPUï¼Œè¿™ç§è§„æ¨¡çš„èµ„æºæä¸ºæ˜‚è´µä¸”æ™®é€šå›¢é˜Ÿéš¾ä»¥è·å¾—ã€‚å³ä½¿æ–¹æ³•æœ¬èº«é«˜æ•ˆï¼Œä½†ç®—åŠ›å’Œå†…å­˜é—¨æ§›ä¾ç„¶é™åˆ¶äº†å®ƒçš„æ™®åŠé¢ï¼Œè¿™å±äºæ— æ³•å¿½è§†çš„ç°å®å±€é™ã€‚ * é€šä¿¡ç“¶é¢ˆä»å­˜åœ¨ï¼šå°½ç®¡å·²å°†é€šä¿¡å‹ç¼©åˆ°æ¯å±‚ä»…2æ¬¡All-Reduceï¼Œä½†å¯¹äºæ›´å¤§è§„æ¨¡å¹¶è¡Œï¼ˆå¦‚æˆåƒä¸Šä¸‡GPUï¼‰ï¼Œé€šä¿¡å¼€é”€å¯èƒ½å¢é•¿å¹¶æˆä¸ºç“¶é¢ˆã€‚ç½‘ç»œæ‹“æ‰‘ä¸ä½³æˆ–å¸¦å®½ä¸è¶³æ—¶æ•ˆç‡ä¼šæ€¥å‰§ä¸‹é™ã€‚å› æ­¤è¯¥æ–¹æ³•åœ¨è¶…å¤§è§„æ¨¡é›†ç¾¤ä¸‹çš„æ•ˆç‡å¯ä¼¸ç¼©æ€§éœ€è¦è¿›ä¸€æ­¥éªŒè¯ï¼Œé€šä¿¡å»¶å±•æ€§æ˜¯æ½œåœ¨çš„çŸ­æ¿ã€‚ * ä¾èµ–ç‰¹å®šæ¨¡å‹ç»“æ„ï¼šæ–¹æ¡ˆåˆ©ç”¨Transformerå±‚çš„å‡åŒ€ç»“æ„å’Œç‹¬ç«‹æ€§å®ç°å¹¶è¡Œï¼Œå¯¹Transformerä»¥å¤–çš„æ¨¡å‹ï¼ˆå¦‚RNNã€CNNï¼‰å¹¶ä¸ä¸€å®šç›´æ¥é€‚ç”¨ã€‚è‹¥æ¨¡å‹å±‚ä¹‹é—´å­˜åœ¨ä¾èµ–é¡ºåºæˆ–å…¨å±€æ“ä½œï¼Œåˆ™æ— æ³•å¥—ç”¨ç®€å•çš„å¼ é‡å¹¶è¡Œåˆ’åˆ†ã€‚æ­¤å¤–ï¼Œå¯¹äºæŸäº›éœ€è¦è·¨å±‚é€šä¿¡çš„ç½‘ç»œï¼Œæ–¹æ³•éœ€è°ƒæ•´æˆ–æ— æ³•ä½¿ç”¨ã€‚ * å†…å­˜ç“¶é¢ˆè½¬ç§»ï¼šæ¨¡å‹å¹¶è¡Œé™ä½äº†æ¯ä¸ªGPUçš„æ¨¡å‹å‚æ•°å†…å­˜ï¼Œä½†å¹¶æœªè§£å†³ä¼˜åŒ–å™¨çŠ¶æ€å’Œæ¿€æ´»çš„å†…å­˜æ¶ˆè€—ã€‚ä»¥Adamä¼˜åŒ–ä¸ºä¾‹ï¼Œä»éœ€è¦ä¸ºæ¯ä¸ªå‚æ•°ç»´æŠ¤é¢å¤–2å€çš„çŠ¶æ€ã€‚è¿™äº›åœ¨å¤§æ¨¡å‹ä¸‹å æ®å¤§é‡å†…å­˜ã€‚è™½ç„¶å¯ä»¥å€ŸåŠ©æ¢¯åº¦æ£€æŸ¥ç‚¹ç­‰ç¼“è§£æ¿€æ´»å†…å­˜ï¼Œä½†ä¼˜åŒ–å™¨çŠ¶æ€å’Œæ¢¯åº¦çš„å†…å­˜é—®é¢˜åœ¨è®ºæ–‡ä¸­æœªè§£å†³ï¼Œåç»­ZeROç­‰æŠ€æœ¯æ­£æ˜¯ä¸ºæ­¤æå‡ºã€‚ * è®­ç»ƒç¨³å®šæ€§å…¶ä»–é—®é¢˜ï¼šé™¤äº†LayerNormä½ç½®è°ƒæ•´ï¼Œè¶…å¤§æ¨¡å‹è®­ç»ƒå¯èƒ½é¢ä¸´å…¶ä»–æ•°å€¼ç¨³å®šæŒ‘æˆ˜ï¼Œå¦‚æ¢¯åº¦çˆ†ç‚¸/æ¶ˆå¤±ã€å­¦ä¹ ç‡è§„åˆ’ç­‰ã€‚è®ºæ–‡ä»…æ¢è®¨äº†LayerNormä¸€ç§å› ç´ ã€‚å¯¹äºä¸åŒæ¨¡å‹å’Œæ›´é•¿è®­ç»ƒè¿‡ç¨‹ï¼Œè¿˜å¯èƒ½å‡ºç°æœªé¢„è§çš„ä¸ç¨³å®šï¼Œéœ€è¦é¢å¤–è°ƒä¼˜ã€‚æ–¹æ³•æœ¬èº«æ²¡æœ‰æä¾›å…³äºè¿™äº›æ–¹é¢çš„ä¿è¯ã€‚ * è¯„ä¼°èŒƒå›´æœ‰é™ï¼šä½œè€…ä¸»è¦å…³æ³¨æ¨¡å‹ç²¾åº¦å’Œé€Ÿåº¦ï¼Œå¯¹æ¨¡å‹äº§ç”Ÿçš„å…¶ä»–å½±å“å¦‚æ³›åŒ–ã€é²æ£’æ€§ã€åè§ç­‰æœªåšè®¨è®ºã€‚å¤§æ¨¡å‹å¾€å¾€å¸¦æ¥å‚æ•°å¤šã€è¡¨è¾¾èƒ½åŠ›å¼ºçš„åŒæ—¶ï¼Œä¹Ÿå¯èƒ½è®°å¿†è®­ç»ƒæ•°æ®æˆ–æ”¾å¤§åè§ã€‚Megatron-LMè®­ç»ƒå‡ºçš„æ¨¡å‹åœ¨è¿™äº›æ–¹é¢çš„è¡Œä¸ºæ²¡æœ‰åœ¨è®ºæ–‡ä¸­æ¢è®¨ï¼Œè¿™å±äºæ–¹æ³•åœ¨å®é™…åº”ç”¨ä¸­çš„å±€é™å’Œé£é™©ã€‚\nä¸ƒã€ä¸šå†…ç›¸å…³å·¥ä½œå¯¹æ¯”\nå¤§è§„æ¨¡æ¨¡å‹è®­ç»ƒæ˜¯è¿‘å¹´AIç ”ç©¶çš„çƒ­ç‚¹ï¼ŒMegatron-LMä¸å…¶ä»–ä¸€äº›å¹¶è¡ŒåŒ–æˆ–æ¨¡å‹å‹ç¼©æ€è·¯æœ‰æ‰€åŒºåˆ«å’Œå…³è”ã€‚ä¸‹é¢é€‰å–å‡ é¡¹åŒæœŸæˆ–ç›¸å…³å·¥ä½œè¿›è¡Œå¯¹æ¯”ï¼š\n\nGPipe (2018) â€“ æµæ°´çº¿å¹¶è¡Œï¼šGoogleæå‡ºçš„GPipe:contentReferenceoaicite:30å°†æ¨¡å‹ä¸åŒå±‚åˆ‡åˆ†åˆ°ä¸²è¡Œçš„è®¾å¤‡ä¸Šï¼Œé‡‡ç”¨å¾®æ‰¹æ¬¡æµæ°´çº¿æ–¹å¼æ¥å¹¶è¡Œè®­ç»ƒã€‚å…¶é—®é¢˜å®šä¹‰åŒä¸ºçªç ´å•å¡å†…å­˜é™åˆ¶ï¼Œä½†æ–¹æ³•è·¯çº¿ä¸åŒï¼šGPipeä¸»æ‰“è·¨å±‚å¹¶è¡Œï¼Œå°†æ¨¡å‹åˆ†æ®µè€ŒMegatron-LMä¸»æ‰“å±‚å†…å¹¶è¡Œï¼Œåœ¨æ¯å±‚å†…éƒ¨åˆ‡åˆ†çŸ©é˜µã€‚GPipeéœ€è¦å°†æ¨¡å‹é‡æ„ä¸ºpipelineå¹¶ç®¡ç†â€œbubbleâ€å»¶è¿Ÿï¼Œè€ŒMegatron-LMåªéœ€åœ¨å±‚å†…æ’å…¥é€šä¿¡ã€‚ä¸¤è€…å¯ç»„åˆï¼ˆæ­£å¦‚Megatronä½œè€…æ‰€è¨€æ¨¡å‹å¹¶è¡Œä¸æµæ°´çº¿å¹¶è¡Œæ­£äº¤ï¼‰ï¼ŒGPipeä¾§é‡å‡å°‘å³°å€¼å†…å­˜ï¼ŒMegatronè¿½æ±‚å……åˆ†åˆ©ç”¨ç®—åŠ›ã€‚ä¸»è§‚è¯„ä»·æ¥çœ‹ï¼ŒGPipeå®ç°å¤æ‚åº¦è¾ƒé«˜ï¼Œéœ€è¦ç‰¹æ®Šæ¡†æ¶æ”¯æŒï¼ˆå¦‚TensorFlow XLAï¼‰ï¼Œè®­ç»ƒæ—¶éœ€è¦å‡è¡¡å„åˆ†æ®µè®¡ç®—è´Ÿè½½ï¼Œå¦åˆ™ä¼šæœ‰æµæ°´ç­‰å¾…ã€‚è€ŒMegatron-LMå®ç°æ›´ç®€æ´ç›´æ¥ï¼Œåœ¨PyTorché‡Œå‡ ä¹å³æ’å³ç”¨ã€‚ä½†GPipeå¯¹é€šä¿¡çš„éœ€æ±‚è¾ƒä½ï¼ˆæ¯é˜¶æ®µä»…éœ€ä¼ é€’æ¿€æ´»ç»™ä¸‹æ¸¸ï¼‰ï¼Œåœ¨è¶…é•¿åºåˆ—æˆ–ææ·±ç½‘ç»œæ—¶å¯èƒ½æ›´é«˜æ•ˆã€‚æ€»ä½“è€Œè¨€ï¼ŒäºŒè€…å„æ“…æ‰€é•¿ï¼Œå¯ç»“åˆç”¨äºæ›´å¤§æ¨¡å‹ï¼šä¸šç•Œå®è·µå¸¸å°†Megatronçš„å¼ é‡å¹¶è¡Œä¸GPipeçš„åˆ†å±‚å¹¶è¡Œä¸€åŒä½¿ç”¨ï¼Œå®ç°2Då¹¶è¡Œæ‰©å±•ã€‚\nMesh-TensorFlow (2018) â€“ å¼ é‡åˆ’åˆ†æ¡†æ¶ï¼šShazeerç­‰æå‡ºçš„Mesh-TensorFlowæä¾›äº†ä¸€ç§åœ¨ä»»æ„åˆ†å¸ƒå¼è®¾å¤‡ç½‘æ ¼ï¼ˆmeshï¼‰ä¸Šåˆ’åˆ†å¼ é‡çš„æ–¹æ³•ã€‚å®ƒçš„é—®é¢˜å®šä¹‰ä¹Ÿæ˜¯åœ¨ä¸åŒè®¾å¤‡é—´åˆ’åˆ†æ¨¡å‹å¼ é‡ï¼Œæ–¹æ³•ä¸Šé€šè¿‡åœ¨TensorFlowä¸­å£°æ˜å¼ é‡çš„åˆ†å¸ƒç»´åº¦ï¼Œç”±XLAç¼–è¯‘å™¨è‡ªåŠ¨ç”Ÿæˆå¹¶è¡Œæ‰§è¡Œè®¡åˆ’ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒMegatron-LMæ˜¯æ‰‹å·¥åœ¨PyTorchä¸­æ’å…¥é€šä¿¡å®ç°å¹¶è¡Œï¼ŒMesh-TFåˆ™é«˜åº¦ä¾èµ–ç¼–è¯‘å™¨ä¼˜åŒ–ã€‚Mesh-TFçš„å¯ç»„åˆæ€§å¼ºï¼Œå¯ä»¥æ”¯æŒå¤šç§å¹¶è¡Œæ¨¡å¼æ··åˆï¼Œä½†éœ€è¦ä½¿ç”¨å…¶DSLé‡æ–°å®šä¹‰æ¨¡å‹ï¼Œå®šåˆ¶æˆæœ¬é«˜ã€‚Megatron-LMæ³¨é‡æ˜“ç”¨ï¼Œåœ¨PyTorchåŸç”Ÿæ¨¡å‹ä¸Šç¨åŠ ä¿®æ”¹å³å¯ã€‚ä¸»è§‚è¯„ä»·ï¼ŒMesh-TFä½œä¸ºé€šç”¨æ¡†æ¶çµæ´»å¼ºå¤§ï¼Œæ”¯æŒä¾‹å¦‚TPUä¸Šçš„å¹¶è¡Œå¹¶æ›¾ç”¨äºè°·æ­Œçš„T5ç­‰æ¨¡å‹è®­ç»ƒï¼›ä½†è°ƒè¯•å’Œå®ç°éš¾åº¦è¾ƒå¤§ï¼Œæ¨¡å‹å¼€å‘è€…éœ€è¦ç†è§£å¹¶è¡Œå¸ƒå±€æ¦‚å¿µã€‚è€ŒMegatron-LMèƒœåœ¨å®ç”¨æ•ˆç‡ï¼Œé’ˆå¯¹Transformerè¿™ç§è§„åˆ™æ¨¡å‹ç»™å‡ºäº†ç°æˆä¼˜åŒ–æ–¹æ¡ˆã€‚Mesh-TFä¾é XLAï¼ŒæŸç§ç¨‹åº¦ä¸Šé¢„ç¤ºäº†æœªæ¥æ·±åº¦å­¦ä¹ ç¼–è¯‘å™¨çš„æ–¹å‘ï¼›Megatron-LMåˆ™åœ¨å½“æ—¶ç¡¬ä»¶è½¯ä»¶æ¡ä»¶ä¸‹åŠæ—¶æä¾›äº†å¯è½åœ°çš„æ–¹æ¡ˆã€‚\nDeepSpeed ZeRO (2020) â€“ ä¼˜åŒ–å™¨çŠ¶æ€å¹¶è¡Œï¼šå¾®è½¯æå‡ºçš„ZeROä¼˜åŒ–å™¨å±äºæ•°æ®å¹¶è¡Œå†…å­˜ä¼˜åŒ–èŒƒç•´ã€‚å®ƒä¸Megatron-LMé—®é¢˜å®šä¹‰çš„å…±åŒç‚¹åœ¨äºéƒ½è§£å†³GPUæ˜¾å­˜ä¸è¶³é™åˆ¶å¤§æ¨¡å‹è®­ç»ƒï¼Œä½†è·¯çº¿æˆªç„¶ä¸åŒï¼šZeROé€šè¿‡åˆ’åˆ†ä¼˜åŒ–å™¨çŠ¶æ€å’Œæ¢¯åº¦æ¥é™ä½æ¯å¼ å¡çš„å†…å­˜å ç”¨ï¼Œä¸æ”¹å˜æ¨¡å‹æœ¬èº«çš„å¹¶è¡Œè®¡ç®—é¡ºåºã€‚ç®€è¨€ä¹‹ï¼ŒZeROä»æ˜¯æ•°æ®å¹¶è¡Œè®­ç»ƒï¼Œåªæ˜¯åœ¨æ¯æ­¥åå°†å„å¡çš„æ¢¯åº¦å’Œä¼˜åŒ–å™¨ç´¯ç§¯ä¿¡æ¯åˆ†æ‘Šå­˜å‚¨ã€‚è¿™æ ·æ¯å¼ å¡åªéœ€ç»´æŠ¤å…¨å±€1/æµ·é‡çš„æ•°æ®å‰¯æœ¬ï¼Œä»è€Œæ”¯æŒæ›´å¤§æ¨¡å‹ã€‚ZeROä¸Megatronå…·å¤‡å¾ˆå¼ºçš„å¯ç»„åˆæ€§ï¼šäº‹å®ä¸Šè®¸å¤šè®­ç»ƒæ ˆåŒæ—¶é‡‡ç”¨Megatronçš„æ¨¡å‹å¹¶è¡Œå’ŒZeROçš„ä¼˜åŒ–å™¨ç¢ç‰‡åŒ–ï¼Œä½¿å¾—æ¨¡å‹å‚æ•°ã€æ¢¯åº¦ã€ä¼˜åŒ–å™¨éƒ½å¾—åˆ°å……åˆ†å¹¶è¡Œã€‚ä¸»è§‚ä¸Šçœ‹ï¼ŒZeROå¯¹ç°æœ‰è®­ç»ƒä»£ç æ”¹åŠ¨è¾ƒå°‘ï¼ˆåˆ©ç”¨DeepSpeedåº“å°è£…å®ç°ï¼‰ï¼Œä½†å®ƒéœ€è¦é¢‘ç¹é€šä¿¡åŒæ­¥ç¢ç‰‡åŒ–çš„æ¢¯åº¦ï¼Œé€šä¿¡é‡éšå‚æ•°å¢é•¿çº¿æ€§ä¸Šå‡ï¼Œå¯¹ç½‘ç»œä¾èµ–å¤§ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒMegatronåœ¨é™ä½é€šä¿¡é¢‘æ¬¡æ–¹é¢åšäº†ä¼˜åŒ–ï¼ˆæ¯å±‚2æ¬¡All-Reduceå›ºå®šï¼‰ã€‚ä¸¤è€…çš„æ€æƒ³å¯ä»¥ç»“åˆï¼šMegatronè§£å†³è®¡ç®—å’Œå‰å‘å†…å­˜ï¼ŒZeROè§£å†³æ¢¯åº¦å’Œä¼˜åŒ–å™¨å†…å­˜ï¼Œå…±åŒçªç ´å¤šæ–¹é¢ç“¶é¢ˆã€‚æœªæ¥ä¸Šç™¾äº¿å‚æ•°æ¨¡å‹è®­ç»ƒä¸­ï¼Œæ··åˆå¼ é‡å¹¶è¡Œ+ZeROå·²æˆä¸ºäº‹å®æ ‡å‡†é…ç½®ã€‚\nALBERT (2019) â€“ å‚æ•°å…±äº«å‹ç¼©ï¼šLanç­‰æå‡ºçš„ALBERTé’ˆå¯¹BERTæ¨¡å‹è§„æ¨¡ç“¶é¢ˆï¼Œé‡‡ç”¨è·¨å±‚å‚æ•°å…±äº«å’Œå‘é‡åˆ†è§£åµŒå…¥ç­‰æ–¹æ³•å‡å°‘å‚æ•°æ€»é‡ï¼Œä»¥æå‡æ¨¡å‹è®­ç»ƒå¯è¡Œæ€§ã€‚å®ƒè§£å†³çš„æ˜¯ç±»ä¼¼é—®é¢˜ï¼ˆBERTè¶…è¿‡BERT-Largeåæ•ˆæœä¸‹é™å’Œèµ„æºä¸è¶³ï¼‰ï¼Œä½†æ–¹æ³•ä¸æ˜¯å¹¶è¡Œè®­ç»ƒï¼Œè€Œæ˜¯æ”¹å˜æ¨¡å‹ç»“æ„ä½¿å‚æ•°æ›´å°‘ã€æ›´é«˜æ•ˆã€‚ä¾‹å¦‚å°†æ¯å±‚Transformeræƒé‡å…±äº«ï¼Œä»è€Œå¤§å¹…å‡å°‘å‚æ•°é‡ã€‚Megatron-LMå’ŒALBERTå¯ä»¥è¯´å–å¾„ç›¸åï¼šä¸€ä¸ªæ˜¯é€šè¿‡å¢åŠ ç¡¬ä»¶èµ„æºå¹¶è¡Œä»¥å®¹çº³æ›´å¤šå‚æ•°ï¼Œä¸€ä¸ªæ˜¯é€šè¿‡ä¼˜åŒ–ç½‘ç»œè®¾è®¡åœ¨åŒæ ·èµ„æºä¸‹å‡å°‘å‚æ•°ã€‚è¿™ä¸¤ç§å¯ä¸€å®šç¨‹åº¦ç»„åˆï¼ˆæ¯”å¦‚ä½¿ç”¨æ¨¡å‹å¹¶è¡Œè®­ç»ƒALBERTä¹Ÿå¯è¿›ä¸€æ­¥æé«˜æ•ˆç‡ï¼‰ï¼Œä½†å› ä¸ºALBERTå‡å°‘å‚æ•°ä¹Ÿæ„å‘³ç€å®¹é‡ä¸‹é™ï¼Œåæ¥çš„å®è·µè¯æ˜ä¸å…±äº«å‚æ•°çš„å¤§æ¨¡å‹å¾€å¾€æ•ˆæœæ›´å¥½ã€‚å› æ­¤Megatronçš„æ–¹æ³•æ›´åå‘â€œç”¨ç¡¬ä»¶ brute force å®ç°æ•ˆæœæå‡â€ï¼Œè€ŒALBERTå±äºâ€œå·§å¦™è®¾è®¡æ¨¡å‹å‹ç¼©â€ã€‚ä¸»è§‚è¯„ä»·ï¼ŒALBERTå¯¹å­¦æœ¯ç ”ç©¶æœ‰æ„ä¹‰ï¼Œå¯å‘äº†å‚æ•°é«˜æ•ˆåˆ©ç”¨çš„æ€è·¯ï¼Œä½†åœ¨çœŸæ­£è¿½æ±‚SOTAæ—¶è¿˜æ˜¯æ›´å¤§çš„éå…±äº«æ¨¡å‹èƒœå‡ºã€‚Megatron-LMä»£è¡¨çš„è·¯çº¿è·¯å¾„åœ¨åæ¥å±…ä¸Šï¼Œè¯æ˜äº†åªè¦èƒ½è®­ç»ƒï¼Œå¤§æ¨¡å‹çš„æ•ˆæœç»ˆå°†ä¼˜äºå°æ¨¡å‹+å‚æ•°å…±äº«ã€‚\n\n7.1 ä¸ªäººè§‚ç‚¹\nç»¼è§‚è¿™äº›å·¥ä½œï¼ŒMegatron-LMä»¥å…¶å®ç”¨æ€§å’Œé«˜æ•ˆæ€§èƒ½è„±é¢–è€Œå‡ºã€‚ä½œä¸ºè¯»è€…ï¼Œæˆ‘è®¤ä¸ºå…¶æˆåŠŸåœ¨äºæ´æ‚‰å¹¶å¹³è¡¡äº†è®¡ç®—ä¸é€šä¿¡ï¼šä¸åƒæ—©æœŸæ¡†æ¶é‚£æ ·å¼ºä¾èµ–æ–°ç¼–è¯‘æŠ€æœ¯ï¼Œè€Œæ˜¯é¡ºåº”å½“ä¸‹PyTorchç”Ÿæ€ï¼Œç”¨æœ€å°æ”¹åŠ¨æ¢å–å·¨å¤§æ”¶ç›Šã€‚è¿™ç§â€œä»¥å·¥ç¨‹æ¢æ€§èƒ½â€çš„åšæ³•éå¸¸ç°å®ï¼Œä½“ç°äº†å·¥ä¸šç•ŒèƒŒæ™¯ç ”ç©¶äººå‘˜çš„æ€è·¯ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒGPipeå’ŒMesh-TFæ›´å…·å‰ç»æ€§ä½†å®ç°é—¨æ§›é«˜ã€æ³›ç”¨æ€§æœ‰é™ã€‚Megatron-LMçš„æ–¹æ¡ˆåˆ™å¿«äººä¸€æ­¥æ»¡è¶³äº†è®­ç»ƒGTçº§æ¨¡å‹çš„ç‡ƒçœ‰ä¹‹æ€¥ï¼Œè¿™ä¹Ÿæ˜¯åæ¥è®¸å¤šå¤§å‹æ¨¡å‹ç›´æ¥é‡‡ç”¨å®ƒçš„åŸå› ã€‚\nå¦‚æœä»æ”¹è¿›ç©ºé—´æ¥çœ‹ï¼Œæˆ‘ä¸ªäººè§‰å¾—Megatron-LMè¿˜æœ‰ä»¥ä¸‹å¯ä»¥è¿›ä¸€æ­¥å®Œå–„ä¹‹å¤„ï¼š * è‡ªåŠ¨åŒ–ç¨‹åº¦ï¼šç›®å‰å¹¶è¡Œåˆ’åˆ†éœ€è¦äººå…ˆéªŒæŒ‡å®šï¼ˆå¦‚æ¨¡å‹å¹¶è¡Œåº¦ã€åˆ†ç»„å¤§å°ï¼‰ã€‚æœªæ¥æˆ‘ä¼šè€ƒè™‘è®¾è®¡è‡ªåŠ¨å¹¶è¡Œè§„åˆ’ç®—æ³•ï¼Œæ ¹æ®é›†ç¾¤æ‹“æ‰‘å’Œæ¨¡å‹ç»“æ„è‡ªåŠ¨å†³å®šåˆ‡åˆ†ç­–ç•¥ï¼Œå‡å°‘äººå·¥è¯•é”™ã€‚ä¾‹å¦‚å¯ä»¥å€Ÿé‰´å¯å‘å¼æœç´¢æˆ–ä½¿ç”¨profilingæ•°æ®æ¥åˆ†é…æœ€ä¼˜å¹¶è¡Œç»´åº¦ç»„åˆã€‚ * å†…å­˜ä¼˜åŒ–é›†æˆï¼šæ­£å¦‚ZeROæ‰€è§£å†³çš„ï¼Œæ¨¡å‹å¹¶è¡Œå°šæœªå¤„ç†ä¼˜åŒ–å™¨å’Œæ¢¯åº¦çš„å†…å­˜ã€‚æˆ‘ä¼šåœ¨MegatronåŸºç¡€ä¸Šé›†æˆZeROæˆ–ç±»ä¼¼æŠ€æœ¯ï¼Œç”šè‡³åœ¨æ¨¡å‹å¹¶è¡Œä¸­å¼•å…¥æ¢¯åº¦ç‰‡æ®µAll-Gatherï¼Œä½¿å¾—æ— è®ºæ­£å‘è¿˜æ˜¯åå‘ï¼Œå„éƒ¨åˆ†å†…å­˜éƒ½èƒ½è¢«ä¸åŒGPUåˆ†æ‹…ã€‚è¿™æ ·èƒ½å¤Ÿè¿›ä¸€æ­¥æå‡å•æœºèƒ½æ”¯æŒçš„å‚æ•°ä¸Šé™ï¼Œä¹Ÿå‡å°‘æ¯å¼ å¡çš„å†…å­˜å‹åŠ›ï¼Œé™ä½OOMé£é™©ã€‚ * é€šä¿¡ä¸è®¡ç®—é‡å ï¼šè™½ç„¶è®ºæ–‡å·²æœ‰éƒ¨åˆ†é‡å ï¼ˆä¾‹å¦‚ä¸‹ä¸€å±‚è®¡ç®—å¯åœ¨ç­‰å¾…All-Reduceæ—¶æå‰ï¼‰ï¼Œä½†æˆ‘è®¤ä¸ºä»æœ‰ç©ºé—´é€šè¿‡å¼‚æ­¥é€šä¿¡ã€å‹ç¼©é€šä¿¡ç­‰æ–¹å¼å‰Šå‡åŒæ­¥å¼€é”€ã€‚æ¯”å¦‚å¯¹æ¢¯åº¦All-Reduceä½¿ç”¨ä½ç²¾åº¦å‹ç¼©ã€åˆ†æ®µé€šä¿¡ï¼Œä»è€Œåœ¨ä¸æŸå¤±å¤šå°‘ç²¾åº¦ä¸‹è¿›ä¸€æ­¥æé«˜æ‰©å±•æ•ˆç‡ã€‚å¦‚æœç½‘ç»œå¸¦å®½æˆä¸ºç“¶é¢ˆï¼Œä¹Ÿå¯è€ƒè™‘æ‹“æ‰‘æ„ŸçŸ¥çš„é€šä¿¡è®¡åˆ’ï¼Œè®©é€šä¿¡åˆ©ç”¨åˆ†å¸ƒå¼ç¼“å­˜æˆ–NVSwitchæ›´é«˜æ•ˆã€‚ * è®­ç»ƒç¨³å®šæ€§ç ”ç©¶ï¼šLayerNormçš„ä½ç½®åªæ˜¯ä¸€ä¸ªå› ç´ ï¼Œæˆ‘å€¾å‘äºç³»ç»Ÿæ€§åœ°ç ”ç©¶è¶…å¤§æ¨¡å‹è®­ç»ƒä¸­çš„ä¸ç¨³å®šæ¥æºï¼Œå¦‚ä¼˜åŒ–å™¨è¶…å‚æ•°ã€åˆå§‹åŒ–æ–¹æ¡ˆã€æ¢¯åº¦è£å‰ªé˜ˆå€¼ç­‰ï¼Œå¹¶é’ˆå¯¹æ€§æå‡ºæ”¹è¿›ã€‚Megatron-LMä¸­å¯ä»¥åŠ å…¥è‡ªé€‚åº”ä¼˜åŒ–è°ƒæ•´æ¨¡å—ï¼Œç›‘æ§æ¢¯åº¦èŒƒæ•°å’Œlossæ›²çº¿ï¼Œä¸€æ—¦æ£€æµ‹åˆ°ä¸ç¨³å®šå¾å…†è‡ªåŠ¨è°ƒæ•´å­¦ä¹ ç‡æˆ–grad clippingï¼Œä»¥æå‡å¤§è§„æ¨¡è®­ç»ƒçš„é²æ£’æ€§ã€‚ * è·¨ç¡¬ä»¶æ”¯æŒï¼šç›®å‰Megatron-LMä¸»è¦é’ˆå¯¹NVIDIA GPUã€‚æˆ‘ä¼šè€ƒè™‘å¦‚ä½•è®©ç±»ä¼¼æ€æƒ³æ‹“å±•åˆ°TPUã€ä»¥åŠæ–°çš„AIåŠ é€Ÿå™¨ä¸Šï¼ŒåŒ…æ‹¬åº”å¯¹ä¸åŒç¡¬ä»¶çš„é€šä¿¡æœºåˆ¶å’Œå†…å­˜æ¶æ„ã€‚è®©å¹¶è¡Œæ–¹æ¡ˆå…·æœ‰ç¡¬ä»¶æ— å…³æ€§ï¼Œå°†ä½¿å…¶å¯¹æ›´å¹¿æ³›çš„è®­ç»ƒç¯å¢ƒé€‚ç”¨ï¼Œä¹Ÿæœ‰åˆ©äºå­¦æœ¯ç•Œç”¨TPU podç­‰èµ„æºå¤ç°ã€‚\næ€»çš„æ¥è¯´ï¼ŒMegatron-LMçš„æ€è·¯éå¸¸å€¼å¾—å€Ÿé‰´ã€‚æˆ‘åœ¨é˜…è¯»å’Œæ€è€ƒè¿‡ç¨‹ä¸­æ„Ÿå—åˆ°ï¼Œåœ¨AIæ¨¡å‹è§„æ¨¡æ¼”è¿›ä¸­ï¼Œç³»ç»Ÿä¼˜åŒ–å’Œæ¨¡å‹è®¾è®¡å¿…é¡»ååŒæ¨è¿›ã€‚æœ‰æ—¶ç¡¬ä»¶èµ„æºçš„æŠ•å…¥å’Œå·§å¦™çš„å¹¶è¡Œè®¡ç®—è®¾è®¡æœ¬èº«å°±æ˜¯æ¨åŠ¨ç®—æ³•èƒ½åŠ›çš„å…³é”®å› ç´ ã€‚ä½œä¸ºç ”ç©¶è€…ï¼Œæˆ‘ä¹Ÿä¼šè€ƒè™‘åœ¨è‡ªå·±å®éªŒä¸­åˆ©ç”¨ç±»ä¼¼æ¨¡å‹å¹¶è¡ŒæŠ€å·§æ¥å°è¯•è®­ç»ƒæ›´å¤§çš„æ¨¡å‹ï¼Œå¹¶ç•™æ„å¯èƒ½å‡ºç°çš„æ•°å€¼å’Œå·¥ç¨‹é—®é¢˜ï¼ŒåŠæ—¶åº”ç”¨è®ºæ–‡ä¸­çš„ç»éªŒæ¥è§£å†³ã€‚\nå…«ã€åœ¨å®é™…è®­ç»ƒæ ˆä¸­å¦‚ä½•è½åœ°ï¼Ÿ\nå°†Megatron-LMçš„æ–¹æ³•åº”ç”¨åˆ°å®é™…è®­ç»ƒæ ˆï¼Œéœ€è¦ç»¼åˆè€ƒè™‘æ•°æ®å¤„ç†ã€å¹¶è¡Œè°ƒåº¦ã€åº•å±‚ç®—å­å’Œç³»ç»Ÿå·¥ç¨‹ç­‰å¤šæ–¹é¢ã€‚ä»¥ä¸‹æŒ‰ç…§å…³é”®ç¯èŠ‚åˆ†ç±»è¯´æ˜å…¶è½åœ°æ–¹å¼ã€æ‰€éœ€çš„å·¥ç¨‹å·¥ä½œé‡ä»¥åŠæ½œåœ¨é£é™©ç‚¹ï¼š\n\næ•°æ®è½½å…¥ä¸æ ·æœ¬æ‰“åŒ…ï¼šå®é™…è®­ç»ƒæ—¶ï¼Œæ•°æ®ç®¡çº¿éœ€è¦ç¡®ä¿åœ¨å¤šæœºå¤šå¡ç¯å¢ƒä¸‹é«˜æ•ˆä¾›ç»™æ ·æœ¬ã€‚ä¸€æ–¹é¢ï¼Œéœ€è¦ä½¿ç”¨åˆ†å¸ƒå¼æ•°æ®åŠ è½½ï¼ˆä¾‹å¦‚PyTorchçš„DistributedSamplerï¼‰è®©æ¯ä¸ªæ•°æ®å¹¶è¡Œç»„è¯»å–ä¸åŒåˆ†ç‰‡çš„æ•°æ®ï¼Œä»è€Œæ•´ä½“æ¶µç›–å¤§æ•°æ®é›†ï¼›å¦ä¸€æ–¹é¢ï¼Œåœ¨æ¨¡å‹å¹¶è¡Œç»„å†…éƒ¨ï¼ŒåŒç»„GPUåº”æ¥æ”¶å®Œå…¨ç›¸åŒçš„è¾“å…¥æ‰¹æ¬¡ã€‚è¿™é€šå¸¸é€šè¿‡åœ¨ä¸€ä¸ªç»„çš„ä¸»è¿›ç¨‹ä¸ŠåŠ è½½æ•°æ®ï¼Œç„¶åå°†è¯¥batchå¹¿æ’­åˆ°ç»„å†…å…¶ä»–è¿›ç¨‹å®ç°ã€‚å·¥ç¨‹ä¸Šéœ€è¦ä»”ç»†å¤„ç†éšæœºæ•°ç§å­ã€æ•°æ®shuffleä¸€è‡´æ€§ç­‰ï¼Œä»¥å…ä¸åŒGPUçœ‹åˆ°ä¸åŒé¡ºåºçš„æ•°æ®å¯¼è‡´æ¢¯åº¦ä¸å¯¹é½ã€‚æ­¤å¤–ï¼Œå¯¹äºè‡ªå›å½’è¯­è¨€æ¨¡å‹ï¼Œå¸¸ç”¨æ•°æ®æ‰“åŒ…ï¼ˆPackingï¼‰æŠ€å·§å°†å¤šæ®µæ–‡æœ¬æ‹¼æ¥æˆé•¿åºåˆ—ä»¥å……åˆ†åˆ©ç”¨ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œæé«˜æ•ˆç‡ã€‚è¿™éœ€è¦DataLoaderæ”¯æŒæŒ‰epoché¢„å¤„ç†æˆ–åŠ¨æ€æ‰“åŒ…ã€‚é£é™©åœ¨äºï¼šæ•°æ®I/Oå¯èƒ½æˆä¸ºç“¶é¢ˆï¼Œå¦‚æœä¸èƒ½æä¾›ç¨³å®šçš„é«˜ååè¯»å–ï¼ˆä¾‹å¦‚NVMe SSDæˆ–é«˜é€Ÿç½‘ç»œæ–‡ä»¶ç³»ç»Ÿï¼‰ï¼ŒGPUä¼šå› ç­‰å¾…æ•°æ®è€Œç©ºè½¬ã€‚è§£å†³æ–¹æ³•åŒ…æ‹¬é¢„å…ˆå¤„ç†æ•°æ®ä¸ºå†…å­˜æ˜ å°„æ ¼å¼ã€å¯ç”¨å¤šçº¿ç¨‹/å¤šè¿›ç¨‹è¯»å–ç”šè‡³é‡‡ç”¨Streamingæ–¹å¼æŒ‰éœ€æ‹‰å–æ•°æ®ã€‚æ€»ä½“æ¥è¯´ï¼Œè¿™ä¸€é˜¶æ®µéœ€è¦å·¥ç¨‹å›¢é˜Ÿç¡®ä¿æ•°æ®æµæ°´çº¿è¶³å¤Ÿå¼ºå£®ï¼Œå¯æŒç»­åœ°å–‚é¥±æ•°ç™¾GPUã€‚\nå¹¶è¡Œè°ƒåº¦ (DP/TP/PP/CP)ï¼šåœ¨å¤šå¹¶è¡ŒèŒƒå¼ç»“åˆä¸‹ï¼Œè°ƒåº¦å’Œåè°ƒå˜å¾—å¤æ‚ã€‚å®é™…è½åœ°æ—¶ï¼Œé€šå¸¸ä½¿ç”¨å¼€æºè®­ç»ƒæ¡†æ¶ï¼ˆå¦‚NVIDIA Megatron-LMåº“ã€DeepSpeedã€Horovodç­‰ï¼‰æ¥éšè—ç»†èŠ‚ã€‚ç”¨æˆ·é€šè¿‡é…ç½®å¹¶è¡Œåº¦å‚æ•°ï¼ˆå¦‚å¼ é‡å¹¶è¡Œå¤§å°ã€æµæ°´å¹¶è¡Œé˜¶æ®µæ•°ã€æ•°æ®å¹¶è¡Œè¿›ç¨‹æ•°ã€ä¸Šä¸‹æ–‡å¹¶è¡Œå¤§å°ï¼‰å³å¯å¯åŠ¨è®­ç»ƒã€‚èƒŒåæ¡†æ¶ä¼šåˆ’åˆ†MPIé€šä¿¡ç»„æˆ–è¿›ç¨‹ç»„ï¼šä¾‹å¦‚512 GPUå¯ä»¥æŒ‰8GPUä¸€ç»„æ„æˆ64ç»„è¿›è¡Œå¼ é‡å¹¶è¡Œï¼Œå†å°†è¿™64ç»„åˆ†åˆ«ç»„åˆæˆè‹¥å¹²æµæ°´çº¿é˜¶æ®µï¼Œç­‰ç­‰ã€‚è¿™æ ·æ¯ä¸ªGPUæœ‰å¤šä¸ªèº«ä»½ï¼ˆæ‰€åœ¨çš„DPç»„ã€TPç»„ã€PPç»„ç­‰ï¼‰ï¼Œæ¡†æ¶è´Ÿè´£åœ¨æ°å½“çš„é˜¶æ®µè°ƒç”¨NCCLé€šä¿¡ã€‚å·¥ç¨‹ä¸Šéœ€è¦éªŒè¯è¿™äº›ç»„çš„åˆ’åˆ†æ˜¯å¦æ­£ç¡®åŒ¹é…ç¡¬ä»¶æ‹“æ‰‘ï¼Œä¾‹å¦‚å°½é‡è®©åŒä¸€æ¨¡å‹å¹¶è¡Œç»„çš„GPUåœ¨åŒä¸€æœåŠ¡å™¨æˆ–åŒä¸€InfiniBandäº¤æ¢æœºä¸‹ï¼Œä»¥é™ä½è·¨èŠ‚ç‚¹é€šä¿¡å»¶è¿Ÿã€‚å¹¶è¡Œè°ƒåº¦éƒ¨åˆ†è¿˜æœ‰ä¸€ä¸ªéš¾ç‚¹æ˜¯é”™è¯¯å¤„ç†ï¼šåœ¨è¶…å¤§è§„æ¨¡è¿è¡Œä¸­ï¼Œä»»ä¸€èŠ‚ç‚¹æ•…éšœéƒ½å¯èƒ½å¯¼è‡´æ•´ä½“å´©æºƒï¼Œéœ€è¦æœ‰æ£€æŸ¥ç‚¹æ¢å¤ï¼ˆè§åï¼‰ä»¥åŠå¼¹æ€§è®­ç»ƒçš„è€ƒè™‘ã€‚å¦‚æœä½¿ç”¨è¯¸å¦‚PyTorch DDPï¼Œè‡ªèº«æœ‰åŸºæœ¬çš„å®¹é”™ä½†è¿˜ä¸å®Œå–„ï¼Œå·¥ç¨‹ä¸Šå¯èƒ½éœ€è¦è„šæœ¬ç›‘æ§è®­ç»ƒè¿›ç¨‹ã€å‡ºç°å®•æœºè‡ªåŠ¨é‡å¯å¹¶åŠ è½½æœ€è¿‘checkpointï¼Œä»¥å‡å°‘é•¿æ—¶é—´è®­ç»ƒä¸­æ–­çš„æŸå¤±ã€‚å¹¶è¡Œè°ƒåº¦çš„æ­£ç¡®æ€§ä¸æ•ˆç‡ç›´æ¥å†³å®šäº†è®­ç»ƒèƒ½å¦é¡ºåˆ©è¿è¡Œå’Œè¾¾åˆ°è®ºæ–‡ä¸­çš„æ‰©å±•æ•ˆç‡æŒ‡æ ‡ï¼Œè¿™æ˜¯è½åœ°ä¸­çš„å…³é”®ç¯èŠ‚ä¹‹ä¸€ã€‚\nç®—å­å®ç°ä¸Kernelä¼˜åŒ–ï¼šMegatron-LMä¾èµ–çš„ä¸€äº›å…³é”®ç®—å­å¦‚GEMMã€LayerNormåœ¨æ·±åº¦å­¦ä¹ æ¡†æ¶ä¸­å·²æœ‰é«˜æ•ˆå®ç°ã€‚ä½†ä¸ºäº†è¿›ä¸€æ­¥æå‡æ€§èƒ½ï¼Œå·¥ç¨‹å®è·µä¸­å¾€å¾€ä¼šå¼•å…¥è‡ªå®šä¹‰Kernelæˆ–èåˆå†…æ ¸ã€‚ä¾‹å¦‚ï¼Œé‡‡ç”¨CUDAå†…æ ¸å®ç°QKVæŠ•å½±çš„èåˆï¼Œå°†åŸæœ¬ä¸‰ä¸ªçŸ©é˜µä¹˜åˆå¹¶ä¸ºä¸€ä¸ªä»¥å‡å°‘å†…å­˜è¯»å†™ï¼›åˆå¦‚å°†BiasåŠ å’ŒDropoutèåˆè¿›GEMMè¾“å‡ºï¼Œä»¥å‡å°‘ä¸­é—´ç»“æœå­˜å–ã€‚è¿™äº›ä¼˜åŒ–åœ¨NVIDIAçš„APExåº“ã€FlashAttentionç­‰é¡¹ç›®ä¸­å·²æœ‰ç¤ºä¾‹ã€‚å°†å…¶åº”ç”¨åœ¨è®­ç»ƒæ ˆä¸­éœ€è¦ç†Ÿæ‚‰CUDAç¼–ç¨‹å¹¶æ·±åˆ»ç†è§£æ¨¡å‹è®¡ç®—æµç¨‹ã€‚åœ¨æ²¡æœ‰è¿™äº›ä¼˜åŒ–æ—¶ï¼ŒMegatron-LMä¹Ÿèƒ½è¿è¡Œï¼Œä½†å…¶FLOPsåˆ©ç”¨ç‡å¯èƒ½è¾¾ä¸åˆ°æœ€ä¼˜ã€‚é€‰æ‹©æ ¸å¿ƒç®—å­åšå®šåˆ¶ä¼˜åŒ–å¾€å¾€å¸¦æ¥5-20%çš„æ€§èƒ½æå‡ã€‚ç›¸åº”çš„é£é™©æ˜¯å¼•å…¥è‡ªå®šä¹‰ç®—å­å¯èƒ½å¼•å‘æ•°å€¼è¯¯å·®ç§¯ç´¯æˆ–è°ƒè¯•å›°éš¾ï¼Œéœ€è¦ç¡®ä¿å…¶ä¸æ ‡å‡†å®ç°ç»“æœä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œä¸åŒGPUæ¶æ„ï¼ˆå¦‚A100, H100ï¼‰å¯èƒ½éœ€è¦é‡æ–°è°ƒä¼˜å†…æ ¸å‚æ•°æ‰èƒ½å‘æŒ¥æœ€ä½³æ€§èƒ½ã€‚å› æ­¤å·¥ç¨‹å›¢é˜Ÿéœ€è¦è¯„ä¼°æ”¶ç›Šå’Œç»´æŠ¤æˆæœ¬ï¼Œåœ¨è¿½æ±‚æè‡´æ€§èƒ½æ—¶æŠ•å…¥Kernelä¼˜åŒ–èµ„æºã€‚åœ¨ç®—å­æ–¹é¢å¦ä¸€ä¸ªè€ƒè™‘æ˜¯æ··åˆç²¾åº¦ï¼šæ¡†æ¶åº”ä½¿ç”¨FP16/BF16è¿›è¡ŒçŸ©é˜µè¿ç®—ï¼ŒåŒæ—¶ä¿è¯LayerNormã€æ®‹å·®ç´¯åŠ åœ¨FP32ç´¯ç§¯é¿å…ç²¾åº¦æŸå¤±ã€‚è¿™äº›ç»†èŠ‚é€šå¸¸ç”±æ¡†æ¶çš„AMP (Automatic Mixed Precision)æ¨¡å—å¤„ç†ï¼Œä½†åœ¨å¤§è§„æ¨¡å¹¶è¡Œæƒ…å†µä¸‹ï¼Œéœ€è¦ç¡®ä¿æ‰€æœ‰rankä¸€è‡´è¿›è¡Œloss scalingç­‰æ“ä½œï¼Œé¿å…ä¸ªåˆ«GPUä¸Šæº¢æˆ–ä¸‹æº¢å¯¼è‡´æ¢¯åº¦å¼‚å¸¸ã€‚\né€šä¿¡æ¨¡å¼ä¸Collectiveæ“ä½œï¼šå¤§è§„æ¨¡è®­ç»ƒä¸­é€šä¿¡å¾€å¾€æˆä¸ºæ€§èƒ½ç“¶é¢ˆï¼Œå› æ­¤åœ¨å·¥ç¨‹ä¸Šéœ€è¦ç²¾å¿ƒè®¾è®¡å’Œé…ç½®é€šä¿¡backendã€‚NCCLæ˜¯äº‹å®æ ‡å‡†ï¼Œå®ƒä¼šä¾æ®æ‹“æ‰‘è‡ªåŠ¨é€‰æ‹©All-Reduceç®—æ³•ï¼ˆç¯å½¢ã€æ ‘å½¢ã€æ··åˆæ‹“æ‰‘ç­‰ï¼‰ã€‚å¯¹äº512å¡è¿™ç§è§„æ¨¡ï¼Œå¤šæœºå¤šå±‚äº¤æ¢æœºæ‹“æ‰‘ä¸‹ï¼ŒNCCLå¯èƒ½ä½¿ç”¨åˆ†çº§All-Reduceï¼ˆå…ˆæœºæ¶å†…ã€å†æœºæ¶é—´ï¼‰ã€‚å·¥ç¨‹å®è·µä¸­ï¼Œåº”ç»‘å®šCPUäº²å’Œã€åˆ’åˆ†é€šä¿¡è½¨é“ï¼šä¾‹å¦‚åœ¨NVSwitch/InfiniBandåŒæ—¶å­˜åœ¨æ—¶ï¼Œè®©äº¤å‰èŠ‚ç‚¹é€šä¿¡ç”¨PCIe+InfiniBandï¼Œæœºå†…ç”¨NVLinkï¼Œé¿å…èµ„æºäº‰ç”¨ã€‚å¦å¤–å¯ä»¥ä½¿ç”¨åˆ†ç»„All-Reduceï¼ˆHierarchical Reductionï¼‰ä¼˜åŒ–å»¶è¿Ÿã€‚é…ç½®æ–¹é¢ï¼Œéœ€è¦ç¡®ä¿MPIæˆ–torch.distributedåˆå§‹åŒ–é€šä¿¡æ—¶ï¼Œç¯å¢ƒå˜é‡å¦‚NCCL_TREE_THRESHOLDç­‰è°ƒä¼˜å¾—å½“ã€‚å¾ˆå¤šè®­ç»ƒæ¡†æ¶ï¼ˆMegatron-LM, DeepSpeedï¼‰ä¼šç»™å‡ºæ¨èNCCLå‚æ•°å’Œlaunchè„šæœ¬ã€‚é€šä¿¡é‡å ä¹Ÿæ˜¯å·¥ç¨‹å…³æ³¨ç‚¹ï¼Œå³åœ¨GPUæ‰§è¡Œè®¡ç®—çš„åŒæ—¶ï¼Œé€šä¿¡åœ¨åå°æµå¼è¿›è¡Œã€‚PyTorchçš„å¼‚æ­¥é€šä¿¡ä»¥åŠCUDAæµçš„æ­£ç¡®ä½¿ç”¨å¯ä»¥å®ç°è®¡ç®—-é€šä¿¡å¹¶è¡Œã€‚é£é™©æ–¹é¢ï¼Œé€šä¿¡æœ€æ€•é‡åˆ°æ­»é”æˆ–hangï¼šä»»ä½•ä¸€æ¬¡All-Reduceç­‰å¾…ä¸åˆ°å¯¹ç«¯éƒ½ä¼šå…¨ä½“å¡ä½ã€‚è¿™é€šå¸¸ç”±å¹¶è¡Œä»£ç é€»è¾‘é”™è¯¯æˆ–ç½‘ç»œä¸ç¨³å®šå¼•èµ·ã€‚å·¥ç¨‹ä¸Šéœ€è¦å…·å¤‡é€šä¿¡debugèƒ½åŠ›ï¼Œä¾‹å¦‚ä½¿ç”¨NCCL_DEBUG=INFOè·Ÿè¸ªæ¯æ¬¡é€šä¿¡è°ƒåº¦ï¼Œæˆ–è€…ä½¿ç”¨å·¥å…·æ£€æŸ¥ç½‘ç»œå¥åº·åº¦ã€‚é›†ç¾¤ç¯å¢ƒçš„å¤æ‚æ€§ä¹Ÿæ„å‘³ç€å¯èƒ½å‡ºç°å¸¦å®½è·‘ä¸æ»¡çš„æƒ…å†µï¼Œå¦‚PCIeæ‹“æ‰‘æ¬¡ä¼˜å¯¼è‡´NCCLæ•ˆç‡ä½ï¼Œè¿™éœ€è¦åœ¨éƒ¨ç½²å‰é€šè¿‡é€šä¿¡benchmarksæµ‹è¯•åŠ ä»¥è°ƒæ•´ã€‚æ€»ä¹‹ï¼Œåœ¨è½åœ°é˜¶æ®µï¼Œå¯¹é€šä¿¡éƒ¨åˆ†è¦æŠ•å…¥ä¸“é—¨å·¥ç¨‹ç²¾åŠ›ä¼˜åŒ–ï¼Œæ¯æé«˜ç™¾åˆ†ä¹‹ä¸€çš„é“¾è·¯åˆ©ç”¨ç‡ï¼Œå¯¹åº”æ•´ä½“ååæå‡å¯èƒ½å°±æ˜¯æ•°å°æ—¶è®­ç»ƒæ—¶é—´çš„èŠ‚çœã€‚\né…ç½®æœç´¢ä¸è‡ªåŠ¨è°ƒå‚ï¼šè¶…å¤§è§„æ¨¡è®­ç»ƒæ¶‰åŠä¼—å¤šå¯è°ƒå‚æ•°ï¼ŒåŒ…æ‹¬å¹¶è¡Œå‚æ•°ï¼ˆDP/TP/PPåˆ’åˆ†æ–¹æ¡ˆã€micro-batchå¤§å°ç­‰ï¼‰ã€ä¼˜åŒ–å™¨å‚æ•°ï¼ˆå­¦ä¹ ç‡ã€betaã€weight decayï¼‰ã€è°ƒåº¦ç­–ç•¥ï¼ˆå­¦ä¹ ç‡warmupã€æ¢¯åº¦è£å‰ªé˜ˆå€¼ï¼‰ç­‰ã€‚è¿™äº›å‚æ•°åœ¨å¤§æ¨¡å‹æƒ…å¢ƒä¸‹å½¼æ­¤å½±å“å¤æ‚ã€‚ä¾‹å¦‚ï¼Œæ€»æ‰¹æ¬¡å¤§å°=å¾®æ‰¹å¤§å°Ã—æ•°æ®å¹¶è¡Œåº¦ï¼Œè¿‡å¤§å¯èƒ½å¯¼è‡´æ³›åŒ–å˜å·®ï¼Œè¿‡å°åˆæ— æ³•å……åˆ†åˆ©ç”¨ç®—åŠ›ã€‚è½åœ°æ—¶ï¼Œå¾€å¾€éœ€è¦è¿›è¡Œä¸€äº›è¶…å‚æœç´¢æˆ–å€Ÿé‰´ç»éªŒå€¼ã€‚è®¸å¤šå›¢é˜Ÿä¼šåŸºäºè®ºæ–‡æä¾›çš„è®¾ç½®ä½œä¸ºèµ·ç‚¹ï¼ˆå¦‚Megatron-LMä½œè€…ç»™å‡ºçš„3.9B BERTåœ¨512GPUä¸Šçš„å­¦ä¹ ç‡å’Œæ‰¹é‡é…ç½®ï¼‰ï¼Œç„¶ååœ¨æœ¬ä»»åŠ¡ä¸Šå¾®è°ƒã€‚è‡ªåŠ¨è°ƒå‚æ–¹é¢ï¼Œå¯ä»¥è€ƒè™‘ä½¿ç”¨å·¥å…·ï¼ˆå¦‚Optunaæˆ–è‡ªå®šä¹‰è„šæœ¬ï¼‰å¯¹å…³é”®å‚æ•°åšç½‘æ ¼æˆ–è´å¶æ–¯ä¼˜åŒ–ï¼Œä½†ç”±äºæ¯æ¬¡è¯•éªŒæˆæœ¬æé«˜ï¼ˆè®­ç»ƒä¸€ä¸ªæ¨¡å‹éœ€æ•°å¤©ï¼‰ï¼Œè°ƒå‚åŸºæœ¬ä¸Šä¾èµ–ç»éªŒå’Œå±€éƒ¨è¯•æ¢ã€‚ä¸ºäº†å‡å°‘åå¤å°è¯•ï¼Œå®è·µä¸­å¸¸æ¸è¿›æ‰©å±•ï¼šå…ˆç”¨è¾ƒå°‘GPUæˆ–å°æ¨¡å‹è¯•è¿è¡ŒéªŒè¯ï¼Œå†æŒ‰æ¯”ä¾‹æ”¾å¤§é…ç½®ã€‚è¿™éœ€è¦æ³¨æ„ä¸€äº›éçº¿æ€§å˜åŒ–ï¼šæ¯”å¦‚æ›´å¤šGPUæ—¶é€‚å½“æé«˜å­¦ä¹ ç‡ï¼Œä½†ä¸èƒ½çº¿æ€§æé«˜ï¼Œå¦åˆ™æŸå¤±å¯èƒ½éœ‡è¡ã€‚é£é™©æ˜¯ï¼Œå¦‚æœé…ç½®ä¸å½“ï¼Œå¤§è§„æ¨¡è®­ç»ƒå¯èƒ½ä¸­é€”å‘æ•£ï¼Œå¯¼è‡´è®¡ç®—èµ„æºæµªè´¹ã€‚å› æ­¤åœ¨å‘èµ·å¤§Jobä¹‹å‰ï¼Œå·¥ç¨‹å›¢é˜Ÿä¼šå……åˆ†éªŒè¯é…ç½®çš„ç¨³å®šæ€§ï¼Œç›‘æ§åˆæœŸlossæ›²çº¿ï¼Œå¿…è¦æ—¶ä¸­æ­¢è°ƒæ•´ã€‚å¼•å…¥è‡ªåŠ¨åŒ–è°ƒå‚å¯ä»¥åœ¨ä¸€å®šç¨‹åº¦ä¸Šç¼“è§£äººå·¥è´Ÿæ‹…ï¼Œä½†ä»éœ€äººå·¥æ™ºæ…§ä»‹å…¥å…³é”®å†³ç­–ã€‚å¯¹å®é™…è®­ç»ƒæ ˆè€Œè¨€ï¼Œå»ºç«‹ä¸€å¥—é…ç½®åŸºçº¿å’Œç›‘æ§æŠ¥è­¦ç³»ç»Ÿå°¤ä¸ºé‡è¦ï¼Œä¸€æ—¦æ£€æµ‹åˆ°è®­ç»ƒæŒ‡æ ‡å¼‚å¸¸ï¼ˆå¦‚lossçˆ†ç‚¸ï¼‰ï¼Œèƒ½åŠæ—¶ä»‹å…¥è°ƒæ•´ï¼Œé¿å…é•¿æ—¶é—´è®¡ç®—æµªè´¹åœ¨é”™è¯¯çš„å‚æ•°ä¸Šã€‚\nCheckpoint ä¸å®¹é”™æ¢å¤ï¼šå¤§æ¨¡å‹è®­ç»ƒé€šå¸¸æŒç»­æ•°å‘¨ï¼ŒæœŸé—´å¯èƒ½å› ä¸ºä½œä¸šè°ƒåº¦ã€ç¡¬ä»¶æ•…éšœç­‰åŸå› ä¸­æ–­ã€‚å› æ­¤å®ç°å¯é çš„æ–­ç‚¹ç»­è®­(checkpointing)æœºåˆ¶æ˜¯è½åœ°å¿…å¤‡ã€‚Megatron-LMçš„è®­ç»ƒæ ˆä¼šå®šæœŸä¿å­˜æ¨¡å‹checkpointï¼ŒåŒ…æ‹¬æ¨¡å‹å„åˆ†ç‰‡æƒé‡ã€ä¼˜åŒ–å™¨çŠ¶æ€ã€éšæœºæ•°ç§å­ç­‰ã€‚å·¥ç¨‹ä¸Šè¦ç¡®ä¿æ¯ä¸ªæ¨¡å‹å¹¶è¡ŒGPUå°†è‡ªå·±çš„æƒé‡å¿«ç…§ä¿å­˜åˆ°å­˜å‚¨ï¼ˆé€šå¸¸æ¯ä¸ªrankä¸€ä¸ªæ–‡ä»¶ï¼‰ï¼Œæ–‡ä»¶å‘½åå’Œç›®å½•ç»“æ„è¦æ¸…æ™°ï¼ˆä¾‹å¦‚åŒ…å«è¿­ä»£å·å’Œrank idï¼‰ã€‚ç”±äºå•ä¸ªæ¨¡å‹æƒé‡å°±å¯èƒ½æ•°åGBï¼Œ512 GPUå†™checkpointéœ€è¦å¹¶è¡ŒIOï¼Œè¿™å¯¹æ–‡ä»¶ç³»ç»Ÿæ˜¯å·¨å¤§å‹åŠ›ã€‚ç»éªŒä¸Šéœ€è¦é…ç½®é«˜æ€§èƒ½å¹¶è¡Œå­˜å‚¨ï¼ˆå¦‚Lustreã€BeeGFSï¼‰æˆ–è€…åˆ†æ•£æ¯èŠ‚ç‚¹æœ¬åœ°å­˜å‚¨ç„¶åå†æ±‡æ€»ã€‚Checkpointé¢‘ç‡éœ€è¦æƒè¡¡ï¼šè¿‡äºé¢‘ç¹ä¼šä¸¥é‡æ‹–æ…¢è®­ç»ƒï¼ˆæ¯æ¬¡å¯èƒ½è€—æ—¶æ•°åˆ†é’Ÿï¼‰ï¼Œå¤ªå°‘åˆ™ä¸€æ—¦ä¸­æ–­æŸå¤±è¿›åº¦è¿‡å¤šã€‚å¸¸è§ç­–ç•¥æ˜¯åœ¨è®­ç»ƒæ—©æœŸé¢‘ç¹checkpointï¼ˆæ¨¡å‹ä¸ç¨³å®šå®¹æ˜“å‘æ•£æ—¶å¯ä»¥å›é€€ï¼‰ï¼ŒåæœŸæ”¶æ•›å¥½äº†é€‚å½“æ‹‰é•¿é—´éš”ã€‚æ¢å¤æ—¶ï¼Œè®­ç»ƒæ¡†æ¶åº”èƒ½æ–¹ä¾¿åœ°åŠ è½½å…ˆå‰ä¿å­˜çš„åˆ‡ç‰‡æ¨¡å‹ã€‚Megatron-LMæä¾›äº†åˆ†å¸ƒå¼åŠ è½½åŠŸèƒ½ï¼Œå³æ¯ä¸ªGPUåªè¯»å–å±äºè‡ªå·±çš„å‚æ•°æ–‡ä»¶ä»¥é‡å»ºä¼˜åŒ–å™¨å’Œæ¨¡å‹çŠ¶æ€ã€‚å·¥ç¨‹è½åœ°éœ€è¦æµ‹è¯•è¿™ä¸€è¿‡ç¨‹ï¼Œç¡®ä¿è·¨ç‰ˆæœ¬å…¼å®¹ã€æ–­ç‚¹æ–‡ä»¶å¯é æ€§ã€‚å¦ä¸€ä¸ªå®¹é”™ç‚¹æ˜¯ç¬æ—¶é€šä¿¡é”™è¯¯æˆ–å•æœºæ‰çº¿ï¼Œå¦‚ä½•è‡ªåŠ¨æ¢å¤ã€‚é€šå¸¸é…åˆä¸Šå±‚ä½œä¸šè°ƒåº¦å™¨å®ç°ï¼šæ¯”å¦‚æ£€æµ‹åˆ°æŸGPUå¤±è”ï¼Œåˆ™é‡å¯æ•´ä¸ªMPIä½œä¸šä»ä¸Šä¸€ä¸ªcheckpointç»§ç»­ã€‚ç†æƒ³æƒ…å†µä¸‹ï¼Œå¯è¡Œçš„æ”¹è¿›æ˜¯å®ç°å±€éƒ¨æ•…éšœéš”ç¦»ï¼Œä¾‹å¦‚æŸèŠ‚ç‚¹æ‰çº¿èƒ½å¦ç”¨å†—ä½™èŠ‚ç‚¹æ¥æ›¿å¹¶åŠ è½½å¯¹åº”checkpointç»§ç»­è®­ç»ƒï¼Œè€Œä¸å¿…æ•´ä¸ªjobé‡å¯ã€‚ä½†å½“å‰è®­ç»ƒæ ˆæ”¯æŒæœ‰é™ï¼Œå¤§å¤šé‡‡ç”¨å…¨ä½œä¸šé‡å¯ç­–ç•¥ï¼Œè¿™ä¼šé€ æˆæ•°åˆ†é’Ÿåˆ°æ•°å°æ—¶çš„æŸè€—ï¼ˆé‡å¯åŠ é‡æ–°åˆ†é…èµ„æºæ—¶é—´ï¼‰ã€‚å› æ­¤ï¼Œæé«˜å®¹é”™æ€§çš„å…³é”®åœ¨äºåŠ å¿«checkpointå’Œæ¢å¤é€Ÿåº¦ï¼Œä»¥åŠæé«˜é›†ç¾¤ç¨³å®šæ€§ã€‚å·¥ç¨‹ä¸Šä¼šåœ¨è®­ç»ƒå‰åšå‹åŠ›æµ‹è¯•ç¡®ä¿ç¡¬ä»¶å¯é ï¼Œå¹¶åœ¨è®­ç»ƒä¸­å®æ—¶ç›‘æ§èµ„æºçŠ¶å†µï¼Œå°½é‡æå‰é¢„é˜²æ•…éšœã€‚æ€»è€Œè¨€ä¹‹ï¼Œåœ¨å®é™…è½åœ°æ—¶ï¼Œéœ€è¦å°†checkpointæœºåˆ¶èå…¥è®­ç»ƒLoopï¼Œä½œä¸ºå’Œå‰å‘åå‘åŒç­‰é‡è¦çš„ä¸€éƒ¨åˆ†æ¥å¯¹å¾…ï¼Œæ‰èƒ½ä¿è¯é•¿æ—¶é—´çš„å¤§è§„æ¨¡è®­ç»ƒé¡ºåˆ©å®Œæˆã€‚\n\nä»¥ä¸Šå„æ–¹é¢æ„æˆäº†ä¸€ä¸ªå¤§å‹æ¨¡å‹è®­ç»ƒæ ˆè½åœ°Megatron-LMæ–¹æ³•æ‰€éœ€çš„å·¥ç¨‹å·¥ä½œã€‚å¯ä»¥çœ‹åˆ°ï¼Œè½åœ°å¹¶éæ˜“äº‹ï¼šæ—¢è¦å†™ä»£ç å±‚é¢çš„å®ç°ï¼Œåˆè¦è€ƒè™‘åˆ†å¸ƒå¼ç³»ç»Ÿè°ƒä¼˜ï¼Œè¿˜è¦å‡†å¤‡æ•…éšœé¢„æ¡ˆã€‚è¿™ä¹Ÿè§£é‡Šäº†ä¸ºä½•æœ‰äº†è®ºæ–‡æ–¹æ³•åï¼Œä¸šå†…ä»èŠ±è´¹å¤§é‡ç²¾åŠ›æ‰“é€ å®Œå–„çš„è®­ç»ƒæ¡†æ¶ï¼ˆå¦‚Megatron-LMåº“ã€DeepSpeedã€Horovodç­‰ï¼‰æ¥æ”¯æ’‘è¿™äº›éœ€æ±‚ã€‚å¯¹äºä¸€ä¸ªå…¸å‹çš„è®­ç»ƒå›¢é˜Ÿæ¥è¯´ï¼Œå……åˆ†åˆ©ç”¨å·²æœ‰å¼€æºå·¥å…·å¹¶æ ¹æ®è‡ªå·±é›†ç¾¤ç‰¹ç‚¹åšé’ˆå¯¹æ€§ä¼˜åŒ–ï¼Œæ˜¯å®è·µä¸­è¡Œä¹‹æœ‰æ•ˆçš„ç­–ç•¥ã€‚\nä¹ã€å€¼å¾—è¿›ä¸€æ­¥æ¢ç´¢çš„ç ”ç©¶æ–¹å‘\né¢å‘æœªæ¥çš„å¤§æ¨¡å‹è®­ç»ƒï¼ŒMegatron-LMæ‰“å¼€äº†ä¸€ä¸ªèµ·ç‚¹ï¼Œä½†ä»æœ‰è®¸å¤šæ–¹å‘å€¼å¾—æ·±å…¥ï¼Œä»¥æå‡æ€§èƒ½ã€é™ä½æˆæœ¬å¹¶æ‰©å±•é€‚ç”¨æ€§ï¼š\n\nè‡ªåŠ¨å¹¶è¡Œåˆ’åˆ†ä¸ç¼–è¯‘ä¼˜åŒ–ï¼šå‘å±•æ™ºèƒ½çš„å¹¶è¡Œåˆ’åˆ†ç®—æ³•ï¼Œå°†æ‰‹å·¥æŒ‡å®šå¹¶è¡Œåº¦è½¬å˜ä¸ºç¼–è¯‘å™¨è‡ªåŠ¨æ¢ç´¢ã€‚è¿™æ–¹é¢å¯ä»¥å€Ÿé‰´DeepMindçš„GSPMDã€OpenAIçš„FTXç¼–è¯‘ç­‰ï¼Œè®©ç³»ç»Ÿæ ¹æ®æ¨¡å‹è®¡ç®—å›¾è‡ªåŠ¨å†³å®šåœ¨å“ªäº›ç»´åº¦åˆ‡åˆ†ã€ä½•æ—¶æ’å…¥All-Reduceï¼Œç”šè‡³å¼•å…¥å¼ é‡åˆ‡ç‰‡è¯­è¨€ä½¿å¼€å‘è€…å£°æ˜å¹¶è¡Œç­–ç•¥ã€‚è‡ªåŠ¨åŒ–å¹¶è¡Œèƒ½æå‡æ˜“ç”¨æ€§ï¼Œå‡å°‘äººä¸ºè°ƒå‚ï¼Œå¹¶å¯èƒ½æ‰¾åˆ°éç›´è§‰çš„æ€§èƒ½æœ€ä¼˜åˆ’åˆ†æ–¹æ¡ˆï¼Œæé«˜ç¡¬ä»¶åˆ©ç”¨ç‡ã€‚\næ›´å¤§è§„æ¨¡ä¸æ··åˆå¹¶è¡Œç­–ç•¥ï¼šæŒç»­æ¢ç´¢ç™¾äº¿åˆ°åƒäº¿å‚æ•°æ¨¡å‹çš„é«˜æ•ˆè®­ç»ƒæ–¹æ¡ˆã€‚ç›®å‰æ™®éé‡‡ç”¨çš„æ•°æ®+å¼ é‡+æµæ°´çº¿ä¸‰é‡å¹¶è¡Œå¯ä»¥è¿›ä¸€æ­¥æ‰©å±•ï¼Œæ¯”å¦‚å¼•å…¥MoEä¸“å®¶å¹¶è¡Œï¼ˆå°†æ¨¡å‹ä¸åŒéƒ¨åˆ†è·¯ç”±åˆ°ä¸åŒä¸“å®¶æ¨¡å—ï¼‰æˆ–Sequence Parallelï¼ˆåºåˆ—å¹¶è¡Œï¼‰ï¼ˆåœ¨åºåˆ—é•¿åº¦ç»´åº¦æ‹†åˆ†è®¡ç®—ï¼‰ç­‰æ–°å¹¶è¡Œç»´åº¦ã€‚è¿™äº›æ··åˆç­–ç•¥æœ‰æœ›çªç ´å•ä¸€å¹¶è¡ŒèŒƒå¼çš„ç“¶é¢ˆï¼Œä½¿å¾—è®­ç»ƒæ›²çº¿åœ¨å¢åŠ è®¡ç®—èµ„æºåä¿æŒæ¥è¿‘çº¿æ€§ã€‚ç‰¹åˆ«æ˜¯å¯¹äºè¶…è¿‡GPUæ˜¾å­˜å¤šä¸ªæ•°é‡çº§çš„å¤§æ¨¡å‹ï¼Œç»“åˆåˆ†å¸ƒå¼å­˜å‚¨ã€CPUå†…å­˜æ¢å…¥æ¢å‡ºç­‰æŠ€æœ¯ï¼Œä¹Ÿæ˜¯é‡è¦æ–¹å‘ã€‚ç›®æ ‡æ˜¯åœ¨ä¸ç‰ºç‰²è®­ç»ƒé€Ÿåº¦çš„æƒ…å†µä¸‹ï¼Œå®ç°å‚æ•°è§„æ¨¡å†æå‡ä¸€ä¸ªæ•°é‡çº§ï¼ŒåŒæ—¶å°½é‡å‡å°‘é€šä¿¡å¼€é”€çš„è¶…çº¿æ€§å¢é•¿ã€‚\né€šä¿¡ä¼˜åŒ–ä¸ç½‘ç»œæ¶æ„å…±è®¾ï¼šéšç€å¹¶è¡Œè§„æ¨¡æ‰©å¤§ï¼Œé€šä¿¡æˆæœ¬å¯èƒ½è·ƒå‡ä¸ºä¸»è¦çŸ›ç›¾ã€‚å› æ­¤ï¼Œä¸€ä¸ªæ–¹å‘æ˜¯åœ¨è½¯ç¡¬ä»¶ä¸¤ç«¯ä¼˜åŒ–é€šä¿¡æ•ˆç‡ã€‚åœ¨è½¯ä»¶ä¸Šï¼Œå¯ä»¥ç ”ç©¶æ–°çš„é€šä¿¡ç®—æ³•ï¼ˆä¾‹å¦‚åˆ†ç»„All-Reduceã€æ··åˆæ‹“æ‰‘è°ƒåº¦ï¼‰ä»¥åŠé€šä¿¡å‹ç¼©æŠ€æœ¯ï¼ˆå¦‚8-bitæˆ–æ¢¯åº¦æˆªæ–­å‹ç¼©ï¼‰æ¥é™ä½å¸¦å®½éœ€æ±‚ã€‚åœ¨ç¡¬ä»¶ä¸Šï¼Œæ¨åŠ¨æ›´é«˜é€Ÿä½å»¶è¿Ÿçš„äº’è”ï¼ˆå¦‚NVLinkæ›´æ–°ã€æ›´å¼ºå¤§çš„äº¤æ¢æœºæ¶æ„ï¼‰å’Œç½‘ç»œæ‹“æ‰‘æ„ŸçŸ¥çš„è°ƒåº¦ï¼Œå‡å°‘è¿œè·ç¦»é€šä¿¡å æ¯”ã€‚è¿™éœ€è¦æœºå™¨å­¦ä¹ å’Œç³»ç»Ÿæ¶æ„ç¤¾åŒºååŒåˆ›æ–°ã€‚ä¾‹å¦‚ï¼ŒNVIDIAè¿‘æœŸæå‡ºçš„NVLink Switchå’Œåˆ†å¸ƒå¼Shard TraderæŠ€æœ¯ï¼Œå°±æ˜¯æœç€é™ä½å¤§è§„æ¨¡é€šä¿¡å¼€é”€è¿ˆè¿›ã€‚é€šä¿¡ä¼˜åŒ–ç›´æ¥å…³ç³»åˆ°æ€§èƒ½å’Œæˆæœ¬æ¯”ï¼šæå‡5-10%é€šä¿¡æ•ˆç‡ï¼Œåœ¨æ•°æœˆçš„è®­ç»ƒä½œä¸šä¸­å°†èŠ‚çœå¯è§‚çš„æ—¶é—´ä¸ç»è´¹ã€‚\nè®­ç»ƒé²æ£’æ€§ä¸å®¹é”™ï¼šå½“è®­ç»ƒè·¨è¶Šæˆç™¾ä¸ŠåƒGPUã€å†æ—¶æ•°å‘¨ï¼Œå¦‚ä½•ä¿è¯è®­ç»ƒè¿‡ç¨‹ä¸å› é”™è¯¯ä¸­æ–­ä¸”æ¨¡å‹æ”¶æ•›ç¨³å¥æ˜¯é‡å¤§è¯¾é¢˜ã€‚ä¸€æ–¹é¢ï¼Œå¯ä»¥æ¢ç´¢åˆ†å¸ƒå¼è®­ç»ƒçš„å®¹é”™ç®—æ³•ï¼Œä¾‹å¦‚å±€éƒ¨checkpointã€å†—ä½™è®¡ç®—ã€æŒ‰éœ€é‡æ–°åŒæ­¥ç­‰ï¼Œä½¿å¾—å¶å‘çš„èŠ‚ç‚¹æ•…éšœä¸ä¼šå¯¼è‡´æ•´ä¸ªè®­ç»ƒåœæ‘†ã€‚è°·æ­Œçš„Checkpointingå¾®è°ƒå’Œè®ºæ–‡å·²ç»æœ‰åˆæ­¥æ¢è®¨ï¼Œä½†ä»æœ‰æ”¹è¿›ç©ºé—´ã€‚å¦ä¸€æ–¹é¢ï¼Œè¶…é•¿æ—¶é—´è®­ç»ƒä¸‹æ¨¡å‹å¯èƒ½å‡ºç°æ„å¤–çš„ä¸ç¨³å®šï¼ˆå¦‚çªç„¶lossçˆ†ç‚¸ï¼‰ã€‚å¼€å‘åœ¨çº¿ç›‘æ§å’Œè‡ªé€‚åº”è°ƒæ•´ç³»ç»Ÿï¼ŒåŸºäºæ£€æµ‹åˆ°çš„å‘æ•£å¾å…†è‡ªåŠ¨é‡‡å–æªæ–½ï¼ˆé™ä½å­¦ä¹ ç‡ã€é‡ç½®æ¢¯åº¦ç­‰ï¼‰æå‡é²æ£’æ€§ã€‚å¢å¼ºå®¹é”™å’Œé²æ£’æ€§æ„å‘³ç€æ›´é«˜çš„è®­ç»ƒæˆåŠŸç‡å’Œèµ„æºåˆ©ç”¨ç‡ï¼Œå¯¹äºå·¥ä¸šç•Œçš„å¤§æ¨¡å‹è®­ç»ƒä»»åŠ¡æœ‰å·¨å¤§çš„å®é™…ä»·å€¼ã€‚\nèƒ½æ•ˆå’Œæˆæœ¬ä¼˜åŒ–ï¼šå¤§æ¨¡å‹è®­ç»ƒæˆæœ¬é«˜æ˜‚ï¼Œå› æ­¤æœªæ¥ä¸€ä¸ªé‡è¦æ–¹å‘æ˜¯æå‡èƒ½æ•ˆå’Œé™ä½æˆæœ¬ã€‚è¿™åŒ…æ‹¬ç®—æ³•å±‚é¢çš„æ”¹è¿›ï¼Œå¦‚åˆ©ç”¨ä½ç²¾åº¦è®¡ç®—ï¼ˆFP8ã€INT8æ··åˆè®­ç»ƒï¼‰ã€ç¨€ç–æ¿€æ´»æˆ–ç½‘ç»œå‰ªæåœ¨è®­ç»ƒä¸­åŠ¨æ€é™ä½è®¡ç®—é‡ï¼Œä»¥åŠä¼˜åŒ–å™¨å±‚é¢çš„é©æ–°ï¼ˆå¦‚æ›´å¿«é€Ÿæ”¶æ•›çš„æ–°ä¼˜åŒ–ç®—æ³•å‡å°‘è¿­ä»£æ¬¡æ•°ï¼‰ã€‚ä¹ŸåŒ…å«å·¥ç¨‹å±‚é¢ï¼Œå¦‚æ›´å¥½åœ°åˆ©ç”¨äº‘é—²ç½®ç®—åŠ›ã€æŒ‰éœ€å¼¹æ€§æ‰©å±•/æ”¶ç¼©GPUæ•°ä»¥ä¼˜åŒ–èµ„æºã€‚åœ¨èƒ½è€—æ–¹é¢ï¼Œå¯ä»¥ç ”ç©¶å°†éƒ¨åˆ†è®¡ç®—ç§»åˆ°æ›´èƒ½æ•ˆæ¯”é«˜çš„ç¡¬ä»¶ï¼ˆå¦‚TPUï¼‰æˆ–åœ¨å†·å´ã€ä¾›ç”µä¸Šåšç³»ç»Ÿä¼˜åŒ–ã€‚ç»ˆæç›®æ ‡æ˜¯åœ¨ä¿è¯æ¨¡å‹æ€§èƒ½çš„åŒæ—¶ï¼Œè®©æ¯æå‡1ç‚¹å‡†ç¡®ç‡æ‰€èŠ±çš„ç¾å…ƒå’Œç¢³æ’æ”¾å°½å¯èƒ½å‡å°‘ã€‚è¿™ä¸ä»…å¯¹ä¼ä¸šæˆæœ¬é‡è¦ï¼Œä¹Ÿæ˜¯AIå¯æŒç»­å‘å±•çš„è¦æ±‚ã€‚\n\nä»¥ä¸Šç ”ç©¶æ–¹å‘å„æœ‰ä¾§é‡ï¼šæœ‰çš„ç€çœ¼äºæ€§èƒ½æé™ï¼Œæœ‰çš„æŒ‡å‘è®­ç»ƒç¨³å®šå’Œæ˜“ç”¨ï¼Œä¹Ÿæœ‰çš„å…³æ³¨ç°å®æˆæœ¬ä¸å¯æŒç»­æ€§ã€‚å¯ä»¥é¢„è§ï¼Œå¯¹è¿™äº›æ–¹å‘çš„æ¢ç´¢å°†ç›¸äº’ä¿ƒè¿›ï¼Œæ„æˆæœªæ¥å‡ å¹´è¶…å¤§è§„æ¨¡æ¨¡å‹è®­ç»ƒæŠ€æœ¯çš„ä¸»æ—‹å¾‹ã€‚\nåã€çŸ¥è¯†å›¾è°±æ€ç»´é“¾\nåœ¨æœ¬è®ºæ–‡ä¸ç›¸å…³èƒŒæ™¯ä¸­ï¼Œå¯ä»¥æ„å»ºå¦‚ä¸‹çš„çŸ¥è¯†è„‰ç»œé“¾æ¡ï¼Œå°†é—®é¢˜ã€æ–¹æ³•ä¸æ•ˆæœä¸²è”èµ·æ¥ï¼š * æ¨¡å‹è§„æ¨¡å—é™ (å†…å­˜ç“¶é¢ˆ) â†’ å¼•å…¥å¹¶è¡ŒåŒ–ç­–ç•¥æ‰“ç ´é™åˆ¶ â†’ æ¨¡å‹å¹¶è¡Œ (å¼ é‡å¹¶è¡Œ) å°†å•å±‚è®¡ç®—åˆ†ç‰‡è‡³å¤šè®¾å¤‡ â†’ å•è®¾å¤‡å†…å­˜å‹åŠ›é™ä½ï¼Œè®­ç»ƒè¶…å¤§æ¨¡å‹æˆä¸ºå¯èƒ½ * Transformer ç»“æ„è§„åˆ™ â†’ è®¡ç®—å¯æ‹†è§£ä¸ºç‹¬ç«‹éƒ¨åˆ† + å°‘é‡åŒæ­¥ (All-Reduce) â†’ å±€éƒ¨è®¡ç®— + å…¨å±€é€šä¿¡ å¹¶è¡ŒèŒƒå¼æˆç«‹ â†’ å¹¶è¡Œè®¡ç®—ä¸é€šä¿¡åè°ƒå®ç°é«˜æ•ˆæ‰©å±• * è®¡ç®—èµ„æºå¢åŠ  â†’ å¯è®­ç»ƒæ¨¡å‹å‚æ•°å¢å¤š â†’ æ¨¡å‹æ€§èƒ½æå‡ (å›°æƒ‘åº¦é™ä½ã€ä¸‹æ¸¸ç²¾åº¦æé«˜) â†’ å¤§æ¨¡å‹å±•ç°å‡ºæ›´ä¼˜NLPä»»åŠ¡è¡¨ç°ï¼Œè¯å®â€œè§„æ¨¡æœ‰å¥‡æ•ˆâ€ * BERTå¤§æ¨¡å‹ä¸ç¨³å®š â†’ åˆ†æç“¶é¢ˆ (LayerNormä½ç½®) â†’ æ¶æ„æ”¹è¿› (Pre-LN) æ¶ˆé™¤æ¢¯åº¦é˜»å¡ â†’ æˆåŠŸè®­ç»ƒæ›´å¤§BERTï¼Œæå‡ä¸‹æ¸¸ä»»åŠ¡å‡†ç¡®ç‡ * ç³»ç»Ÿå®ç°ä¸ç®—æ³•ç»“åˆ â†’ å¼€æºæ¡†æ¶ (Megatron-LMä»£ç ) å¤ç°æ–¹æ¡ˆ â†’ ç¤¾åŒºè·Ÿè¿› (å„å¤§æ¨¡å‹é‡‡ç”¨ç±»ä¼¼å¹¶è¡Œ) â†’ è¶…å¤§æ¨¡å‹è®­ç»ƒæˆä¸ºæ–°å¸¸æ€ï¼Œæ¨åŠ¨NLP SOTAä¸æ–­åˆ·æ–°\nä¸Šè¿°æ€ç»´é“¾è¡¨æ˜ï¼Œä»é—®é¢˜å‡ºå‘ï¼ˆå†…å­˜ä¸è§„æ¨¡ç“¶é¢ˆï¼‰ï¼Œé€šè¿‡æ¨¡å‹å¹¶è¡Œçš„åˆ›æ–°æ‰‹æ®µï¼Œç»“åˆå¯¹Transformerç»“æ„çš„ç†è§£ä¸æ¶æ„è°ƒæ•´ï¼Œæœ€ç»ˆå®ç°äº†å¤§æ¨¡å‹çš„è®­ç»ƒä¸åº”ç”¨çªç ´ã€‚è¿™æ¡è·¯å¾„æ—¢æ¶‰åŠè®¡ç®—æœºä½“ç³»ç»“æ„å’Œå¹¶è¡Œè®¡ç®—çŸ¥è¯†ï¼Œä¹Ÿè´¯ç©¿ç€å¯¹æ·±åº¦å­¦ä¹ æ¨¡å‹è¡Œä¸ºçš„è§‚å¯Ÿå’Œæ”¹è¿›ï¼Œä½“ç°äº†è·¨é¢†åŸŸçš„èåˆåˆ›æ–°ã€‚\n10.1 ä¸ªäººæ”¶è·ä¸åæ€\né˜…è¯»å¹¶æ¶ˆåŒ–Megatron-LMè¿™ç¯‡è®ºæ–‡ï¼Œæˆ‘æ”¶è·è‰¯å¤šã€‚é¦–å…ˆï¼Œå®ƒè®©æˆ‘æ·±åˆ»ä½“ä¼šåˆ°å·¥ç¨‹å®è·µå¯¹AIå‰æ²¿çš„é‡è¦æ€§ï¼šè®¸å¤šçœ‹ä¼¼æ— æ³•çªç ´çš„ç“¶é¢ˆï¼ˆå¦‚æ˜¾å­˜é™åˆ¶ï¼‰å¾€å¾€å¯ä»¥é€šè¿‡å·§å¦™çš„ç³»ç»Ÿè®¾è®¡åŠ ä»¥è§£å†³ï¼Œä»è€ŒæŠŠå­¦æœ¯ä¸Šâ€œæ›´å¤§æ¨¡å‹=æ›´å¥½æ•ˆæœâ€çš„æƒ³æ³•çœŸæ­£è½åœ°æˆä¸ºç°å®ã€‚ä½œè€…åœ¨ä¸å¼•å…¥å…¨æ–°æ¡†æ¶çš„æƒ…å†µä¸‹ï¼Œç”¨å°‘é‡é€šä¿¡æ“ä½œæ”¹å˜äº†æ¸¸æˆè§„åˆ™ï¼Œå¯å‘æˆ‘åœ¨è‡ªå·±ç ”ç©¶ä¸­ä¹Ÿåº”å–„äºåˆ©ç”¨ç°æœ‰å·¥å…·ï¼Œé€šè¿‡å·§æ€æ•´åˆæ¥å®ç°åˆ›æ–°ã€‚\nå…¶æ¬¡ï¼Œæˆ‘åæ€åˆ°ï¼Œå¤§è§„æ¨¡åˆ†å¸ƒå¼è®­ç»ƒéœ€è¦å…¼é¡¾å…¨å±€ä¸å±€éƒ¨ã€‚ä¸€æ–¹é¢è¦ç«™åœ¨æ•´ä½“ç³»ç»Ÿè§’åº¦è€ƒè™‘é€šä¿¡å’Œè®¡ç®—åˆ†å·¥ï¼Œå¦ä¸€æ–¹é¢åˆè¦å¤„ç†åº•å±‚ç»†èŠ‚ï¼ˆå¦‚æ•°å€¼ç¨³å®šæ€§ã€é€šä¿¡æ­»é”ç­‰ï¼‰ã€‚è®ºæ–‡ä¸­é’ˆå¯¹BERT LayerNormçš„å°è°ƒæ•´ï¼Œå°±æ˜¯ä»æ¨¡å‹å†…éƒ¨ç»†èŠ‚å‡ºå‘è§£å†³å¤§é—®é¢˜çš„å…¸å‹ï¼Œè®©æˆ‘æ„è¯†åˆ°å®è§‚æ€§èƒ½æå‡å¾€å¾€ä¾èµ–å¾®è§‚æœºåˆ¶ä¿éšœã€‚è¿™ä¿ƒä½¿æˆ‘åœ¨ä»Šåç ”ç©¶ä¸­ï¼Œä¸ä»…å…³æ³¨ç®—æ³•å±‚åˆ›æ–°ï¼Œä¹Ÿå¤šè€ƒè™‘å®ç°å±‚æŒ‘æˆ˜ï¼Œæå‰è®¾è®¡åº”å¯¹æ–¹æ¡ˆã€‚\næœ€åï¼Œè¿™é¡¹å·¥ä½œä¹Ÿæ¿€å‘äº†æˆ‘å¯¹ååŒä¼˜åŒ–çš„å…´è¶£ã€‚AIæ¨¡å‹ã€è½¯ä»¶æ¡†æ¶ã€ç¡¬ä»¶èµ„æºä¸‰è€…ç›¸è¾…ç›¸æˆï¼Œå…±åŒå†³å®šäº†æœ€ç»ˆæ•ˆæœã€‚Megatron-LMçš„æˆåŠŸå½’åŠŸäºå¯¹Transformerç»“æ„çš„æ´å¯Ÿï¼ˆç®—æ³•ï¼‰å’Œå¯¹PyTorch/NCCLçš„æ·±å…¥æŠŠæ¡ï¼ˆè½¯ä»¶ï¼‰ï¼Œä»¥åŠå……åˆ†åˆ©ç”¨äº†512 GPUé›†ç¾¤ï¼ˆç¡¬ä»¶ï¼‰ã€‚è¿™è®©æˆ‘è®¤è¯†åˆ°ï¼Œåœ¨è¿½æ±‚æè‡´AIæ€§èƒ½æ—¶ï¼Œä»»ä½•å•ä¸€å±‚é¢çš„æ”¹è¿›éƒ½å¯èƒ½ä¸è¶³ï¼Œå”¯æœ‰è”åˆä¼˜åŒ–æ‰èƒ½å–å¾—é£è·ƒã€‚æˆ‘ä¼šå°†è¿™ç§æ€ç»´è¿ç”¨åˆ°è‡ªå·±çš„è¯¾é¢˜ä¸­ï¼Œä¾‹å¦‚è€ƒè™‘æ–°çš„æ¨¡å‹è®¾è®¡æ—¶åŒæ­¥è€ƒè™‘è®­ç»ƒå¹¶è¡Œç­–ç•¥ï¼Œä»ä¸€å¼€å§‹å°±ä¸ºå¤§è§„æ¨¡å®ç°åšå¥½å‡†å¤‡ã€‚\n\næ€»ä½“è€Œè¨€ï¼ŒMegatron-LMè®ºæ–‡åœ¨å·¥ç¨‹å®è·µä¸­æˆåŠŸæ‰©å±•äº†Transformeræ¨¡å‹çš„è§„æ¨¡ä¸Šé™ï¼Œä»¥ç®€æ´æœ‰æ•ˆçš„æ¨¡å‹å¹¶è¡Œç­–ç•¥è®©æ•°åäº¿å‚æ•°çº§çš„è®­ç»ƒæˆä¸ºç°å®ï¼Œä¸ä»…å–å¾—äº†å‡ºè‰²çš„æ€§èƒ½æå‡ï¼Œä¹Ÿä¸ºåæ¥è¶…å¤§æ¨¡å‹çš„è®­ç»ƒæ–¹æ³•å¥ å®šäº†åŸºç¡€ã€‚ç„¶è€Œï¼Œå®ƒä¹Ÿæé†’æˆ‘ä»¬å¤§æ¨¡å‹æ—¶ä»£ä¼´ç”Ÿçš„ç³»ç»Ÿå¤æ‚åº¦å’Œèµ„æºä»£ä»·ï¼Œéœ€è¦æŒç»­çš„æŠ€æœ¯åˆ›æ–°æ¥å¹³è¡¡è§£å†³ã€‚\n\n","categories":["è®ºæ–‡é˜…è¯»"],"tags":["paper"]}]